Run: 4
/cm/local/apps/slurm/var/spool/job1046146/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1496/1496.pkl
working on 
../data/c/1496/class_full_MCAR_0.5_1
2.887383460998535
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-12 09:00:00,881] A new study created in memory with name: no-name-5232bf8a-7a99-4d49-9864-78ab5337f1a0
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-12 09:00:01,519] Trial 8 finished with value: 0.20294749736417922 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 8 with value: 0.20294749736417922.
running
[I 2024-11-12 09:00:05,659] Trial 11 finished with value: 0.20294749736417922 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4735, 'weights': 'uniform'}. Best is trial 8 with value: 0.20294749736417922.
running
[I 2024-11-12 09:00:06,999] Trial 7 finished with value: 0.2029437664564223 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2848, 'weights': 'uniform'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:07,444] Trial 18 finished with value: 0.38030868856018396 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:09,913] Trial 10 finished with value: 0.2030571570270522 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:13,305] Trial 19 finished with value: 0.20295040468402906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5435, 'weights': 'distance'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:13,600] Trial 21 finished with value: 0.38030868856018396 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:14,199] Trial 0 finished with value: 0.20300102653340302 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:14,448] Trial 23 finished with value: 0.38030868856018396 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:14,694] Trial 24 finished with value: 0.20294749736417922 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:15,839] Trial 20 finished with value: 0.20295040468402906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5327, 'weights': 'distance'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:16,163] Trial 13 finished with value: 0.20329801144527146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 13, 'imputation_order': 'ascending'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:16,663] Trial 9 finished with value: 0.20332356381569383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:18,878] Trial 6 finished with value: 0.35047938692989716 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9059069534993288, 'alpha': 72, 'iterations': 1, 'learning_rate': 0.07762969419351207, 'p_miss': 0.25376549740977666}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:22,822] Trial 25 finished with value: 0.3525000303002551 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.5547496056253621, 'alpha': 88, 'iterations': 12, 'learning_rate': 0.014242993030543036, 'p_miss': 0.2659128804839518}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:26,575] Trial 26 finished with value: 0.36399706054473874 and parameters: {'model_name': 'GAIN', 'batch_size': 124, 'hint_rate': 0.6349485009266442, 'alpha': 89, 'iterations': 19, 'learning_rate': 0.0005803358980672553, 'p_miss': 0.1003485366024091}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:29,633] Trial 15 finished with value: 0.35401424834941614 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6761357525606086, 'alpha': 15, 'iterations': 35, 'learning_rate': 0.03479095726773629, 'p_miss': 0.2296211685783524}. Best is trial 7 with value: 0.2029437664564223.
running
[I 2024-11-12 09:00:33,882] Trial 27 finished with value: 0.1267667410744325 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 29, 'learning_rate': 0.003715061082158436, 'p_miss': 0.12225534924534129}. Best is trial 27 with value: 0.1267667410744325.
running
[I 2024-11-12 09:00:36,293] Trial 28 finished with value: 0.20908772793680197 and parameters: {'model_name': 'VAE', 'batch_size': 195, 'iterations': 7, 'learning_rate': 0.011399452393828996, 'p_miss': 0.286588251647937}. Best is trial 27 with value: 0.1267667410744325.
running
[I 2024-11-12 09:01:09,012] Trial 1 finished with value: 0.28215300900406903 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 27 with value: 0.1267667410744325.
running
[I 2024-11-12 09:01:29,549] Trial 4 finished with value: 0.22031591234819187 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 11, 'imputation_order': 'random'}. Best is trial 27 with value: 0.1267667410744325.
running
[I 2024-11-12 09:15:18,137] Trial 5 finished with value: 0.10746347041937847 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 387, 'learning_rate': 0.00014890131240882437, 'p_miss': 0.09504953201349577}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 09:19:25,252] Trial 22 finished with value: 0.21358767705377843 and parameters: {'model_name': 'VAE', 'batch_size': 237, 'iterations': 379, 'learning_rate': 0.0017851072978099577, 'p_miss': 0.06257519929938445}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 09:50:04,426] Trial 17 finished with value: 0.21198410684963603 and parameters: {'model_name': 'VAE', 'batch_size': 547, 'iterations': 842, 'learning_rate': 0.06571639440435309, 'p_miss': 0.20057920216366049}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 10:12:11,198] Trial 36 finished with value: 0.21583601027734814 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1521, 'learning_rate': 0.0010945345749339298, 'p_miss': 0.027747194034134892}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 10:16:16,756] Trial 16 finished with value: 0.21401348297879558 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 1330, 'learning_rate': 0.021588188519004306, 'p_miss': 0.021187328123434407}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 10:16:25,230] Trial 41 finished with value: 0.20320877864225723 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1019, 'weights': 'uniform'}. Best is trial 5 with value: 0.10746347041937847.
running
[I 2024-11-12 10:18:38,615] Trial 40 finished with value: 0.09776868023900247 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 120, 'learning_rate': 0.00010441124138362285, 'p_miss': 0.1366111249130557}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:23:38,998] Trial 42 finished with value: 0.09992399195451412 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 123, 'learning_rate': 0.00010071944670161082, 'p_miss': 0.12459426455721472}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:29:23,433] Trial 43 finished with value: 0.10052602988073447 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 148, 'learning_rate': 0.00012983961229421314, 'p_miss': 0.13813376560274912}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:34:50,899] Trial 44 finished with value: 0.09970287318127048 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 193, 'learning_rate': 0.00010406202015531201, 'p_miss': 0.1566580796178832}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:39:09,018] Trial 45 finished with value: 0.0984311836466025 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 133, 'learning_rate': 0.00010235007276654745, 'p_miss': 0.16602787793016627}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:41:21,234] Trial 37 finished with value: 0.21739917325822064 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1691, 'learning_rate': 0.00011822374803926288, 'p_miss': 0.011222033925680011}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:43:16,359] Trial 2 finished with value: 0.3695557372145425 and parameters: {'model_name': 'GAIN', 'batch_size': 114, 'hint_rate': 0.8619933641980745, 'alpha': 15, 'iterations': 3951, 'learning_rate': 0.054327186888454025, 'p_miss': 0.1960530909069725}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:45:29,084] Trial 46 finished with value: 0.09965234427754102 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 148, 'learning_rate': 0.00010289871387936288, 'p_miss': 0.16380083706481055}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:46:42,691] Trial 47 finished with value: 0.10154898889755345 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 120, 'learning_rate': 0.00026671213614960033, 'p_miss': 0.17834913253198534}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:47:20,731] Trial 48 finished with value: 0.10154866323133453 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 127, 'learning_rate': 0.0003781673072219522, 'p_miss': 0.1789074343963092}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:48:59,803] Trial 49 finished with value: 0.10038275815298463 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 99, 'learning_rate': 0.00029830803992759016, 'p_miss': 0.16788661177633418}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 10:52:09,174] Trial 50 finished with value: 0.1065205782297252 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 92, 'learning_rate': 0.00032530522565149376, 'p_miss': 0.17679154026634367}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:02:21,319] Trial 53 finished with value: 0.1137529070653414 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 249, 'learning_rate': 0.00020963044220159298, 'p_miss': 0.14748492047614772}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:04:23,120] Trial 51 finished with value: 0.17142085593360865 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 335, 'learning_rate': 0.00031728585430345084, 'p_miss': 0.1651824158917468}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:04:52,104] Trial 55 finished with value: 0.09806667294172064 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 47, 'learning_rate': 0.000614530308514826, 'p_miss': 0.1477003359972475}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:07:19,755] Trial 56 finished with value: 0.10241918398022057 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 46, 'learning_rate': 0.0001026029780115492, 'p_miss': 0.11706320525275643}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:07:59,986] Trial 57 finished with value: 0.10122242989613568 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 50, 'learning_rate': 0.00010334538209609887, 'p_miss': 0.14045521434024116}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:08:22,235] Trial 59 finished with value: 0.10221909265810836 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.0008089207217628886, 'p_miss': 0.21003396991785128}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:09:20,721] Trial 52 finished with value: 0.1841520888679941 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 336, 'learning_rate': 0.00026766827112587494, 'p_miss': 0.15731116953443242}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:10:06,284] Trial 54 finished with value: 0.10499607064191212 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 322, 'learning_rate': 0.00018703172777621255, 'p_miss': 0.1473199971388626}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:10:19,301] Trial 58 finished with value: 0.10553424965818867 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 54, 'learning_rate': 0.0006560944357002201, 'p_miss': 0.1487248715230492}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 11:23:50,395] Trial 34 finished with value: 0.21647272737478818 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2993, 'learning_rate': 0.0009174953707604395, 'p_miss': 0.012146046915981784}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:03:59,071] Trial 61 finished with value: 0.20441652613803055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:04:19,292] Trial 60 finished with value: 0.2041184973080466 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:06:09,216] Trial 62 finished with value: 0.20446968135485322 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:06:38,703] Trial 63 finished with value: 0.20404444876173783 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 19, 'imputation_order': 'roman'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:12:27,262] Trial 3 finished with value: 0.37891961986082784 and parameters: {'model_name': 'GAIN', 'batch_size': 129, 'hint_rate': 0.5441920966208289, 'alpha': 7, 'iterations': 9341, 'learning_rate': 0.0033515330031108166, 'p_miss': 0.0367985440735478}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:13:50,710] Trial 14 finished with value: 0.21532673288624168 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 5113, 'learning_rate': 0.00012021670180593806, 'p_miss': 0.2983860837325713}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:15:23,704] Trial 66 finished with value: 0.10206094099249532 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 197, 'learning_rate': 0.00016988324274110116, 'p_miss': 0.12199978887542173}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:17:05,447] Trial 68 finished with value: 0.0998597341809224 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 180, 'learning_rate': 0.00015777396155489934, 'p_miss': 0.12598784839284938}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:19:28,973] Trial 64 finished with value: 0.20304118195970333 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:19:37,081] Trial 67 finished with value: 0.10126946908585552 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 194, 'learning_rate': 0.00017600942751258184, 'p_miss': 0.12288262726438864}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:19:44,013] Trial 74 finished with value: 0.20370608360172165 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 137, 'weights': 'distance'}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:23:14,925] Trial 75 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.07805620162320825, 'alpha': 46, 'iterations': 658, 'learning_rate': 0.00017087321811535517, 'p_miss': 0.09309874776537821}. Best is trial 40 with value: 0.09776868023900247.
running
[I 2024-11-12 13:23:26,417] Trial 69 finished with value: 0.09733545653439585 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 178, 'learning_rate': 0.00015845089207093657, 'p_miss': 0.11908764055693197}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:25:23,617] Trial 70 finished with value: 0.10210726636931519 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 183, 'learning_rate': 0.00017710644042236121, 'p_miss': 0.11991945514904154}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:26:59,608] Trial 77 finished with value: 0.09858463988610466 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 70, 'learning_rate': 0.00046075257062401823, 'p_miss': 0.10093978742297548}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:28:43,352] Trial 76 finished with value: 0.09902574662786272 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 83, 'learning_rate': 0.00011472864403208877, 'p_miss': 0.09646137904583357}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:28:44,341] Trial 80 finished with value: 0.31856926281625525 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:29:41,087] Trial 78 finished with value: 0.10204501731218625 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 78, 'learning_rate': 0.000498581141933435, 'p_miss': 0.10109834369472898}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:30:54,905] Trial 79 finished with value: 0.09765716824241252 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 67, 'learning_rate': 0.0004513424556481039, 'p_miss': 0.08648755367725754}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:31:31,284] Trial 82 finished with value: 0.10060309223997192 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 28, 'learning_rate': 0.00020830151729158601, 'p_miss': 0.07342128194526286}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:31:51,196] Trial 84 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.16758250385255058, 'alpha': 44, 'iterations': 58, 'learning_rate': 0.00166169121360502, 'p_miss': 0.06506797093205911}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:32:18,688] Trial 83 finished with value: 0.10284973297097418 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 22, 'learning_rate': 0.00044138813513928943, 'p_miss': 0.09052672802744255}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:32:48,584] Trial 85 finished with value: 0.17775506267195984 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 15, 'learning_rate': 0.005823556251529955, 'p_miss': 0.08105318163257805}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:32:59,075] Trial 81 finished with value: 0.09992606762628463 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 73, 'learning_rate': 0.0004676582163738597, 'p_miss': 0.07270731081330166}. Best is trial 69 with value: 0.09733545653439585.
running
[I 2024-11-12 13:35:14,560] Trial 88 finished with value: 0.09700256520126034 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 38, 'learning_rate': 0.00012777506829394377, 'p_miss': 0.10348143782734578}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:35:20,781] Trial 29 finished with value: 0.21334518847939296 and parameters: {'model_name': 'VAE', 'batch_size': 270, 'iterations': 4645, 'learning_rate': 0.00015376835880374196, 'p_miss': 0.02190440476419725}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:36:44,713] Trial 87 finished with value: 0.155555891934469 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 70, 'learning_rate': 0.00138274159916275, 'p_miss': 0.19147168776209827}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:36:59,361] Trial 91 finished with value: 0.20296021695629665 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2909, 'weights': 'distance'}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:37:00,312] Trial 92 finished with value: 0.31856926281625525 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:37:12,454] Trial 89 finished with value: 0.09965503011060503 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 35, 'learning_rate': 0.00023595299170000659, 'p_miss': 0.0477845664491869}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:37:22,333] Trial 90 finished with value: 0.09992815173522604 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 37, 'learning_rate': 0.0002323501271832135, 'p_miss': 0.10156795822251939}. Best is trial 88 with value: 0.09700256520126034.
running
[I 2024-11-12 13:37:53,870] Trial 86 finished with value: 0.09652954554880841 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 70, 'learning_rate': 0.00022876634452563744, 'p_miss': 0.07812607297362237}. Best is trial 86 with value: 0.09652954554880841.
running
[I 2024-11-12 13:38:55,991] Trial 93 finished with value: 0.10125241819276005 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 38, 'learning_rate': 0.00023720765331871138, 'p_miss': 0.10800668578195224}. Best is trial 86 with value: 0.09652954554880841.
running
[I 2024-11-12 13:39:39,590] Trial 94 finished with value: 0.09956626049456042 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 38, 'learning_rate': 0.0001318100352255577, 'p_miss': 0.10724231534522197}. Best is trial 86 with value: 0.09652954554880841.
running
[I 2024-11-12 13:42:13,476] Trial 95 finished with value: 0.09999160569253318 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 96, 'learning_rate': 0.00013371795990903244, 'p_miss': 0.10936710371064261}. Best is trial 86 with value: 0.09652954554880841.
running
[I 2024-11-12 13:44:27,290] Trial 96 finished with value: 0.09996624143566203 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 89, 'learning_rate': 0.00013685281757178729, 'p_miss': 0.11010072197246899}. Best is trial 86 with value: 0.09652954554880841.
running
[I 2024-11-12 13:44:53,006] Trial 97 finished with value: 0.09564929385177687 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 82, 'learning_rate': 0.00013576687518545793, 'p_miss': 0.08462490719658414}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:46:09,150] Trial 100 finished with value: 0.09659356332129944 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 23, 'learning_rate': 0.0005849441456406974, 'p_miss': 0.08578357223446703}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:46:29,472] Trial 71 finished with value: 0.13631631915439696 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 599, 'learning_rate': 0.00018008713506050157, 'p_miss': 0.09665781171570129}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:46:38,674] Trial 99 finished with value: 0.1126479921910859 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 63, 'learning_rate': 0.0006385583354632466, 'p_miss': 0.08612921449265983}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:46:43,621] Trial 103 finished with value: 0.3730559406732422 and parameters: {'model_name': 'GAIN', 'batch_size': 56, 'hint_rate': 0.2899415741375917, 'alpha': 63, 'iterations': 5, 'learning_rate': 0.0006955722868243549, 'p_miss': 0.055374098418586676}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:46:58,412] Trial 102 finished with value: 0.09599123354676554 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 10, 'learning_rate': 0.0006057748758064829, 'p_miss': 0.051379620610888896}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:47:01,542] Trial 104 finished with value: 0.3712989901096742 and parameters: {'model_name': 'GAIN', 'batch_size': 56, 'hint_rate': 0.2639971331671235, 'alpha': 65, 'iterations': 10, 'learning_rate': 0.00036223303922917644, 'p_miss': 0.05582263053729489}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:47:28,829] Trial 105 finished with value: 0.09604926421586821 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 10, 'learning_rate': 0.001097127856886628, 'p_miss': 0.13625169933836556}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:47:49,762] Trial 108 finished with value: 0.1020264153920621 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 3, 'learning_rate': 0.000978874157649005, 'p_miss': 0.037921958901719885}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:48:08,481] Trial 106 finished with value: 0.1002440658194564 and parameters: {'model_name': 'VAE', 'batch_size': 92, 'iterations': 19, 'learning_rate': 0.0003742288357662052, 'p_miss': 0.13561774303752183}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:48:32,937] Trial 98 finished with value: 0.09726351750284634 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 103, 'learning_rate': 0.00013630931177141095, 'p_miss': 0.051206521225551506}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:48:44,368] Trial 107 finished with value: 0.10068397192796878 and parameters: {'model_name': 'VAE', 'batch_size': 98, 'iterations': 22, 'learning_rate': 0.001182695827924645, 'p_miss': 0.13240414954109522}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:48:55,994] Trial 110 finished with value: 0.09695781746296518 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 10, 'learning_rate': 0.0012480643060705607, 'p_miss': 0.0759604144806762}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:48:59,537] Trial 109 finished with value: 0.09911890797785661 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 17, 'learning_rate': 0.001292191573180177, 'p_miss': 0.0774340443113278}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:49:05,528] Trial 113 finished with value: 0.2030294215682741 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1668, 'weights': 'uniform'}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:49:07,076] Trial 115 finished with value: 0.38030868856018396 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:49:09,218] Trial 114 finished with value: 0.20304608041172342 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1631, 'weights': 'uniform'}. Best is trial 97 with value: 0.09564929385177687.
running
[I 2024-11-12 13:49:10,274] Trial 111 finished with value: 0.09502135196052156 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 9, 'learning_rate': 0.0013091990583973315, 'p_miss': 0.07822188560533344}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:49:37,424] Trial 112 finished with value: 0.21530899347854734 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 9, 'learning_rate': 0.04766986590863559, 'p_miss': 0.0790754591259013}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:49:37,896] Trial 117 finished with value: 0.09928330985944434 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 8, 'learning_rate': 0.0008266291372285017, 'p_miss': 0.06818577849377218}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:49:43,630] Trial 118 finished with value: 0.097603976929897 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 8, 'learning_rate': 0.0007974048330477727, 'p_miss': 0.06610302450386839}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:49:48,537] Trial 116 finished with value: 0.0974931949966517 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 10, 'learning_rate': 0.002019733672550043, 'p_miss': 0.06669731150258647}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:49:52,070] Trial 120 finished with value: 0.09862316037117558 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 3, 'learning_rate': 0.0017732592061319033, 'p_miss': 0.038916906486370785}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:01,095] Trial 121 finished with value: 0.09673430480516551 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 4, 'learning_rate': 0.002977375477629035, 'p_miss': 0.03740774495525857}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:05,047] Trial 122 finished with value: 0.09580329258850658 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 3, 'learning_rate': 0.0026975126213554064, 'p_miss': 0.04525166229017931}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:24,134] Trial 125 finished with value: 0.09660794571671896 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 4, 'learning_rate': 0.0032551984454850125, 'p_miss': 0.049090428434610166}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:28,798] Trial 124 finished with value: 0.09535196357176995 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 5, 'learning_rate': 0.002539609571946865, 'p_miss': 0.02450234124469948}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:37,446] Trial 119 finished with value: 0.11090414662223173 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 12, 'learning_rate': 0.0031859362879718923, 'p_miss': 0.06245036851273412}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:54,704] Trial 123 finished with value: 0.09911368856582206 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 13, 'learning_rate': 0.0014860217667438513, 'p_miss': 0.05924166750841048}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:50:59,718] Trial 126 finished with value: 0.10333647365464364 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 4, 'learning_rate': 0.004039023602351433, 'p_miss': 0.02415992011916299}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:03,162] Trial 127 finished with value: 0.09610673563350762 and parameters: {'model_name': 'VAE', 'batch_size': 140, 'iterations': 4, 'learning_rate': 0.0029788848774735463, 'p_miss': 0.024841137010962258}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:10,929] Trial 128 finished with value: 0.10392084733583581 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 4, 'learning_rate': 0.00497709323025237, 'p_miss': 0.02558482213136582}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:25,371] Trial 130 finished with value: 0.09618583061860855 and parameters: {'model_name': 'VAE', 'batch_size': 290, 'iterations': 2, 'learning_rate': 0.0023582503514536736, 'p_miss': 0.030302413882322313}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:26,748] Trial 131 finished with value: 0.09651066028352949 and parameters: {'model_name': 'VAE', 'batch_size': 258, 'iterations': 2, 'learning_rate': 0.0023876926627550777, 'p_miss': 0.03002627869747271}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:33,399] Trial 132 finished with value: 0.0998681975891432 and parameters: {'model_name': 'VAE', 'batch_size': 239, 'iterations': 2, 'learning_rate': 0.002368302058304322, 'p_miss': 0.032488335659968844}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:35,758] Trial 129 finished with value: 0.09646967837323331 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 4, 'learning_rate': 0.00231185910800921, 'p_miss': 0.0193322660869667}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:43,034] Trial 133 finished with value: 0.09792393694686014 and parameters: {'model_name': 'VAE', 'batch_size': 411, 'iterations': 1, 'learning_rate': 0.0024617588057879464, 'p_miss': 0.014594339094051233}. Best is trial 111 with value: 0.09502135196052156.
running
[I 2024-11-12 13:51:50,705] Trial 134 finished with value: 0.09476590779686003 and parameters: {'model_name': 'VAE', 'batch_size': 307, 'iterations': 1, 'learning_rate': 0.0025224278409787648, 'p_miss': 0.016594323371684833}. Best is trial 134 with value: 0.09476590779686003.
running
[I 2024-11-12 13:51:52,560] Trial 135 finished with value: 0.09460289420728525 and parameters: {'model_name': 'VAE', 'batch_size': 334, 'iterations': 1, 'learning_rate': 0.0027614494995746863, 'p_miss': 0.01596834287583541}. Best is trial 135 with value: 0.09460289420728525.
running
[I 2024-11-12 13:51:56,848] Trial 136 finished with value: 0.09583756563726263 and parameters: {'model_name': 'VAE', 'batch_size': 380, 'iterations': 1, 'learning_rate': 0.0023859846544611834, 'p_miss': 0.015860291980126243}. Best is trial 135 with value: 0.09460289420728525.
running
[I 2024-11-12 13:52:13,744] Trial 137 finished with value: 0.09329136509213477 and parameters: {'model_name': 'VAE', 'batch_size': 853, 'iterations': 2, 'learning_rate': 0.0025995623189815245, 'p_miss': 0.04580137947376245}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:20,201] Trial 138 finished with value: 0.09582460640529053 and parameters: {'model_name': 'VAE', 'batch_size': 375, 'iterations': 2, 'learning_rate': 0.002496707074988764, 'p_miss': 0.044587485007424835}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:21,445] Trial 142 finished with value: 0.31856926281625525 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:22,155] Trial 139 finished with value: 0.09744335699069065 and parameters: {'model_name': 'VAE', 'batch_size': 340, 'iterations': 2, 'learning_rate': 0.0023592319221904753, 'p_miss': 0.018494499244529044}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:38,077] Trial 144 finished with value: 0.0964017324174349 and parameters: {'model_name': 'VAE', 'batch_size': 978, 'iterations': 1, 'learning_rate': 0.0042644268780466345, 'p_miss': 0.014558648578776872}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:49,065] Trial 143 finished with value: 0.09599246106411813 and parameters: {'model_name': 'VAE', 'batch_size': 839, 'iterations': 2, 'learning_rate': 0.0038037720280314903, 'p_miss': 0.04372844107205842}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:52:57,534] Trial 140 finished with value: 0.2175841035266997 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:20,329] Trial 141 finished with value: 0.2198965289846647 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:26,838] Trial 147 finished with value: 0.1279951308036334 and parameters: {'model_name': 'VAE', 'batch_size': 729, 'iterations': 3, 'learning_rate': 0.007799785107916198, 'p_miss': 0.045684573861394615}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:39,322] Trial 149 finished with value: 0.09398910428218996 and parameters: {'model_name': 'VAE', 'batch_size': 434, 'iterations': 1, 'learning_rate': 0.0027268715406542866, 'p_miss': 0.043718549281330836}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:50,640] Trial 150 finished with value: 0.09673746755858723 and parameters: {'model_name': 'VAE', 'batch_size': 533, 'iterations': 1, 'learning_rate': 0.0029307679095010165, 'p_miss': 0.042560252567030395}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:52,433] Trial 148 finished with value: 0.15177867572052844 and parameters: {'model_name': 'VAE', 'batch_size': 514, 'iterations': 3, 'learning_rate': 0.0068722941625614115, 'p_miss': 0.040801413631697966}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:53:55,409] Trial 146 finished with value: 0.2198965289846647 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:09,470] Trial 153 finished with value: 0.09598633665863932 and parameters: {'model_name': 'VAE', 'batch_size': 204, 'iterations': 6, 'learning_rate': 0.0019606703782534935, 'p_miss': 0.03341505579692609}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:24,641] Trial 73 finished with value: 0.1366497215280717 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 679, 'learning_rate': 0.00018383307371244186, 'p_miss': 0.09352346427048416}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:34,044] Trial 154 finished with value: 0.09703275855519855 and parameters: {'model_name': 'VAE', 'batch_size': 213, 'iterations': 6, 'learning_rate': 0.0019281566439520673, 'p_miss': 0.013246759616261636}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:39,243] Trial 151 finished with value: 0.13540420373925346 and parameters: {'model_name': 'VAE', 'batch_size': 517, 'iterations': 6, 'learning_rate': 0.003699670086192256, 'p_miss': 0.011621098387452648}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:43,819] Trial 152 finished with value: 0.1005575507407361 and parameters: {'model_name': 'VAE', 'batch_size': 656, 'iterations': 6, 'learning_rate': 0.0019551551205372816, 'p_miss': 0.032647111204284845}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:45,566] Trial 156 finished with value: 0.0951806160231523 and parameters: {'model_name': 'VAE', 'batch_size': 668, 'iterations': 1, 'learning_rate': 0.0036365265643888817, 'p_miss': 0.033893652148974135}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:47,346] Trial 72 finished with value: 0.14352459335864465 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 743, 'learning_rate': 0.00019188874729661915, 'p_miss': 0.09483875165779442}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:54:50,129] Trial 145 finished with value: 0.2029259736952286 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:00,066] Trial 159 finished with value: 0.09980104643097563 and parameters: {'model_name': 'VAE', 'batch_size': 744, 'iterations': 1, 'learning_rate': 0.002740014374166868, 'p_miss': 0.03391031675560094}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:01,236] Trial 157 finished with value: 0.0982788977318809 and parameters: {'model_name': 'VAE', 'batch_size': 806, 'iterations': 2, 'learning_rate': 0.0016006885260606669, 'p_miss': 0.03195628293803776}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:01,712] Trial 158 finished with value: 0.09406996677445263 and parameters: {'model_name': 'VAE', 'batch_size': 390, 'iterations': 1, 'learning_rate': 0.0028288117905080705, 'p_miss': 0.02278289500745406}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:08,629] Trial 160 finished with value: 0.09709932956303308 and parameters: {'model_name': 'VAE', 'batch_size': 860, 'iterations': 2, 'learning_rate': 0.0015742029206335239, 'p_miss': 0.05235719167149046}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:10,864] Trial 164 finished with value: 0.37657718159508125 and parameters: {'model_name': 'GAIN', 'batch_size': 408, 'hint_rate': 0.4124375936868047, 'alpha': 25, 'iterations': 1, 'learning_rate': 0.004419369426404494, 'p_miss': 0.019974969045161276}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:20,153] Trial 155 finished with value: 0.11005111954328499 and parameters: {'model_name': 'VAE', 'batch_size': 734, 'iterations': 6, 'learning_rate': 0.003587887925515906, 'p_miss': 0.01029780315204382}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:21,507] Trial 161 finished with value: 0.09487972612153228 and parameters: {'model_name': 'VAE', 'batch_size': 888, 'iterations': 2, 'learning_rate': 0.004430121786957219, 'p_miss': 0.04490690319296932}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:25,413] Trial 163 finished with value: 0.09543316131841759 and parameters: {'model_name': 'VAE', 'batch_size': 372, 'iterations': 1, 'learning_rate': 0.005202790858967566, 'p_miss': 0.05235511528493428}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:26,079] Trial 162 finished with value: 0.09806061828072457 and parameters: {'model_name': 'VAE', 'batch_size': 396, 'iterations': 2, 'learning_rate': 0.001560693461497172, 'p_miss': 0.0444748330424694}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:27,881] Trial 165 finished with value: 0.09406150874814845 and parameters: {'model_name': 'VAE', 'batch_size': 440, 'iterations': 1, 'learning_rate': 0.0036431617875342186, 'p_miss': 0.020670754283665764}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:44,776] Trial 170 finished with value: 0.09536687691374299 and parameters: {'model_name': 'VAE', 'batch_size': 614, 'iterations': 1, 'learning_rate': 0.005931090996676145, 'p_miss': 0.025625063312235838}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:48,594] Trial 171 finished with value: 0.09719722813458388 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 1, 'learning_rate': 0.004600579621044516, 'p_miss': 0.02605390177642994}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:49,041] Trial 166 finished with value: 0.10114299579486397 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 5, 'learning_rate': 0.0035067609691632495, 'p_miss': 0.0428782378573089}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:55:50,125] Trial 169 finished with value: 0.09504095628225 and parameters: {'model_name': 'VAE', 'batch_size': 398, 'iterations': 1, 'learning_rate': 0.0050960020010828505, 'p_miss': 0.025689653891740855}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:05,636] Trial 168 finished with value: 0.09773944414579382 and parameters: {'model_name': 'VAE', 'batch_size': 384, 'iterations': 3, 'learning_rate': 0.002598845453717102, 'p_miss': 0.04373612814687849}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:06,365] Trial 172 finished with value: 0.09598771879640092 and parameters: {'model_name': 'VAE', 'batch_size': 636, 'iterations': 1, 'learning_rate': 0.005269023145570926, 'p_miss': 0.025321098049798846}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:08,153] Trial 173 finished with value: 0.09509718112647965 and parameters: {'model_name': 'VAE', 'batch_size': 603, 'iterations': 1, 'learning_rate': 0.0051787491775327444, 'p_miss': 0.020471443422287294}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:08,795] Trial 174 finished with value: 0.09617858340382153 and parameters: {'model_name': 'VAE', 'batch_size': 626, 'iterations': 1, 'learning_rate': 0.005567076596026683, 'p_miss': 0.022298991753318155}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:10,861] Trial 175 finished with value: 0.09799174007958901 and parameters: {'model_name': 'VAE', 'batch_size': 599, 'iterations': 1, 'learning_rate': 0.005649509410188665, 'p_miss': 0.0222859142858145}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:19,553] Trial 167 finished with value: 0.09472124202169803 and parameters: {'model_name': 'VAE', 'batch_size': 593, 'iterations': 5, 'learning_rate': 0.0020714721476901396, 'p_miss': 0.025081932508091195}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:25,351] Trial 176 finished with value: 0.0960984434233435 and parameters: {'model_name': 'VAE', 'batch_size': 477, 'iterations': 1, 'learning_rate': 0.005602855773600612, 'p_miss': 0.020182090879598647}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:27,206] Trial 177 finished with value: 0.09940195943874483 and parameters: {'model_name': 'VAE', 'batch_size': 479, 'iterations': 1, 'learning_rate': 0.009373624402727926, 'p_miss': 0.01948780913221868}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:31,246] Trial 179 finished with value: 0.09682103979389536 and parameters: {'model_name': 'VAE', 'batch_size': 459, 'iterations': 1, 'learning_rate': 0.006861853076080846, 'p_miss': 0.037137969894257564}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:31,876] Trial 180 finished with value: 0.09776544419880873 and parameters: {'model_name': 'VAE', 'batch_size': 495, 'iterations': 1, 'learning_rate': 0.008782124630300795, 'p_miss': 0.036532979812453105}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:34,251] Trial 181 finished with value: 0.2029391940730544 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3983, 'weights': 'distance'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:40,270] Trial 182 finished with value: 0.20294070312426227 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4217, 'weights': 'distance'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:41,023] Trial 183 finished with value: 0.202931730578163 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4332, 'weights': 'distance'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:46,485] Trial 184 finished with value: 0.20294309796732857 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4152, 'weights': 'distance'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:56:48,070] Trial 185 finished with value: 0.20294647336554789 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4132, 'weights': 'distance'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:09,663] Trial 186 finished with value: 0.23666685924257677 and parameters: {'model_name': 'VAE', 'batch_size': 991, 'iterations': 3, 'learning_rate': 0.022875569942640842, 'p_miss': 0.02893096865802297}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:10,433] Trial 191 finished with value: 0.20294749736417922 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:18,397] Trial 187 finished with value: 0.0959301585696629 and parameters: {'model_name': 'VAE', 'batch_size': 979, 'iterations': 3, 'learning_rate': 0.004671990778516825, 'p_miss': 0.02805615223126566}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:26,432] Trial 189 finished with value: 0.1676932769104503 and parameters: {'model_name': 'VAE', 'batch_size': 997, 'iterations': 3, 'learning_rate': 0.014269047921961304, 'p_miss': 0.028922072811854858}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:37,045] Trial 190 finished with value: 0.22728908645466545 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 3, 'learning_rate': 0.02085672912377065, 'p_miss': 0.056929096966028506}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:38,574] Trial 192 finished with value: 0.0965825541860453 and parameters: {'model_name': 'VAE', 'batch_size': 318, 'iterations': 2, 'learning_rate': 0.0031692880159450874, 'p_miss': 0.23948863517136112}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:43,483] Trial 38 finished with value: 0.2194203562906 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 5529, 'learning_rate': 0.00010566501045455207, 'p_miss': 0.14108160842447454}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:49,797] Trial 194 finished with value: 0.09665414793589067 and parameters: {'model_name': 'VAE', 'batch_size': 330, 'iterations': 2, 'learning_rate': 0.003076333784842478, 'p_miss': 0.056581236952615646}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:57:54,578] Trial 193 finished with value: 0.11550692603356494 and parameters: {'model_name': 'VAE', 'batch_size': 320, 'iterations': 2, 'learning_rate': 0.006649663038516913, 'p_miss': 0.05611525786884606}. Best is trial 137 with value: 0.09329136509213477.
running
[I 2024-11-12 13:58:13,449] Trial 195 finished with value: 0.09564851801938831 and parameters: {'model_name': 'VAE', 'batch_size': 597, 'iterations': 2, 'learning_rate': 0.0033015053357159313, 'p_miss': 0.03799256245352378}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 13:58:16,057] Trial 199 finished with value: 0.09747484784684135 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 5, 'learning_rate': 0.002147573844386457, 'p_miss': 0.01799423965310418}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 13:58:16,788] Trial 197 finished with value: 0.09554488386292942 and parameters: {'model_name': 'VAE', 'batch_size': 588, 'iterations': 2, 'learning_rate': 0.002765327724465137, 'p_miss': 0.014833990359251571}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 13:58:30,168] Trial 196 finished with value: 0.09883122212477835 and parameters: {'model_name': 'VAE', 'batch_size': 418, 'iterations': 5, 'learning_rate': 0.0021713622024300177, 'p_miss': 0.015257747450685666}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 13:59:21,027] Trial 33 finished with value: 0.2189023332630121 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6147, 'learning_rate': 0.0009581375896252509, 'p_miss': 0.039283186718997526}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 14:04:09,659] Trial 101 finished with value: 0.21479892853455534 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 499, 'learning_rate': 0.00039153507805997486, 'p_miss': 0.08745511497300815}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 14:16:35,119] Trial 65 finished with value: 0.20652517081918492 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 14:42:37,793] Trial 30 finished with value: 0.21235991675044225 and parameters: {'model_name': 'VAE', 'batch_size': 428, 'iterations': 6166, 'learning_rate': 0.0001166551699889285, 'p_miss': 0.013024444128013957}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 14:57:45,274] Trial 35 finished with value: 0.21815094693954623 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 7608, 'learning_rate': 0.0008948433223435766, 'p_miss': 0.03652447538103795}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 15:04:17,889] Trial 39 finished with value: 0.2187782733791364 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6882, 'learning_rate': 0.00023296387221553722, 'p_miss': 0.12301361011820988}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 15:14:51,241] Trial 12 finished with value: 0.2323021431507791 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9918, 'learning_rate': 0.003752743999110198, 'p_miss': 0.12236279213691104}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 16:17:55,424] Trial 31 finished with value: 0.21175799510851195 and parameters: {'model_name': 'VAE', 'batch_size': 887, 'iterations': 9328, 'learning_rate': 0.0001653302584501731, 'p_miss': 0.014684619316584324}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 16:20:38,796] Trial 32 finished with value: 0.21192261153028963 and parameters: {'model_name': 'VAE', 'batch_size': 944, 'iterations': 8926, 'learning_rate': 0.00011227879853563232, 'p_miss': 0.03156628732237465}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 16:26:57,713] Trial 188 finished with value: 0.21175067785747945 and parameters: {'model_name': 'VAE', 'batch_size': 957, 'iterations': 6103, 'learning_rate': 0.0032362857215840436, 'p_miss': 0.029480840317632137}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 16:27:05,595] Trial 178 finished with value: 0.21208883775183657 and parameters: {'model_name': 'VAE', 'batch_size': 566, 'iterations': 7098, 'learning_rate': 0.007130841049128169, 'p_miss': 0.02119195162681503}. Best is trial 137 with value: 0.09329136509213477.
[I 2024-11-12 16:29:33,379] Trial 198 finished with value: 0.21180490229596166 and parameters: {'model_name': 'VAE', 'batch_size': 602, 'iterations': 8371, 'learning_rate': 0.0021268369926468796, 'p_miss': 0.019581178653372174}. Best is trial 137 with value: 0.09329136509213477.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.09329136509213477
{'model_name': 'VAE', 'batch_size': 853, 'iterations': 2, 'learning_rate': 0.0025995623189815245, 'p_miss': 0.04580137947376245}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ee0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5110069434991746
Generation:   4%|▍         | 1/25 [02:02<49:06, 122.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fb430> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.5129810150755215
Generation:   8%|▊         | 2/25 [02:30<25:32, 66.61s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474736950> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.5138237598403361
Generation:  12%|█▏        | 3/25 [02:57<17:56, 48.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a43130> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.5156881687315533
Generation:  16%|█▌        | 4/25 [03:33<15:19, 43.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658ff6d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.5156881687315533
Generation:  20%|██        | 5/25 [06:06<27:41, 83.10s/it]Generation:  6
Best f1_score score: 0.5156881687315533
Generation:  24%|██▍       | 6/25 [06:50<22:07, 69.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2bac0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.5156881687315533
Generation:  28%|██▊       | 7/25 [07:27<17:40, 58.92s/it]Generation:  8
Best f1_score score: 0.5201814920635084
Generation:  32%|███▏      | 8/25 [08:00<14:23, 50.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0a5f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a63910> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5201814920635084
Generation:  36%|███▌      | 9/25 [08:44<13:00, 48.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b8a770> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474717d00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474739360> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5201814920635084
Generation:  40%|████      | 10/25 [09:16<10:50, 43.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746faec0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5201814920635084
Generation:  44%|████▍     | 11/25 [09:56<09:53, 42.41s/it]Generation:  12
Best f1_score score: 0.5201814920635084
Generation:  48%|████▊     | 12/25 [10:21<08:01, 37.02s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659e1bd0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  13
Best f1_score score: 0.5201814920635084
Generation:  52%|█████▏    | 13/25 [11:04<07:47, 38.94s/it]Generation:  14
Best f1_score score: 0.5201814920635084
Generation:  56%|█████▌    | 14/25 [12:11<08:40, 47.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ac9000> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546783cb50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5201814920635084
Generation:  60%|██████    | 15/25 [15:23<15:10, 91.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546797eb90> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5201814920635084
Generation:  64%|██████▍   | 16/25 [17:27<15:07, 100.81s/it]Generation:  17
Best f1_score score: 0.5201814920635084
Generation:  68%|██████▊   | 17/25 [18:17<11:24, 85.52s/it] Generation:  18
Best f1_score score: 0.5201814920635084
Generation:  72%|███████▏  | 18/25 [18:47<08:02, 68.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679b3df0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  19
Best f1_score score: 0.5201814920635084
Generation:  76%|███████▌  | 19/25 [20:02<07:04, 70.68s/it]Generation:  20
Best f1_score score: 0.5201814920635084
Generation:  80%|████████  | 20/25 [21:10<05:50, 70.06s/it]Generation:  21
Best f1_score score: 0.5201814920635084
Generation:  84%|████████▍ | 21/25 [22:39<05:03, 75.82s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655909d0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  22
Best f1_score score: 0.5201814920635084
Generation:  88%|████████▊ | 22/25 [23:19<03:14, 64.90s/it]Generation:  23
Best f1_score score: 0.5201814920635084
Generation:  92%|█████████▏| 23/25 [24:37<02:17, 68.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464fb7d30> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652666b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5201814920635084
Generation:  96%|█████████▌| 24/25 [25:48<01:09, 69.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465337460> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f089d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.5201814920635084
Generation: 100%|██████████| 25/25 [26:47<00:00, 66.33s/it]Generation: 100%|██████████| 25/25 [26:51<00:00, 64.44s/it]
2024-11-12 16:57:17,458 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36073' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8', 'ndarray-c53919dca1b058e2c461a9c28dab15f1'} (stimulus_id='handle-worker-cleanup-1731459437.4584038')
2024-11-12 16:57:21,449 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,450 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,450 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,450 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,453 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,453 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,453 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,453 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,472 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 16:57:21,472 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.1410654499538,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.2834452595994, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=3,
                               max_leaves=None, min_child_weight=14,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100, n_jobs=1,
                               nthread=1, num_parallel_tree=None, ...))])
score start
train score: {'auroc': 0.8284190330997576, 'accuracy': 0.7390202702702703, 'balanced_accuracy': 0.7388876351923389, 'logloss': 0.5779155672694705, 'f1': 0.7389075606191965}
original test score: {'auroc': 0.5306464603297227, 'accuracy': 0.5378378378378378, 'balanced_accuracy': 0.5358788496414033, 'logloss': 0.6957344839515589, 'f1': 0.5160540853731994}
imputed test score: {'auroc': 0.506215859344609, 'accuracy': 0.504054054054054, 'balanced_accuracy': 0.5040991615392905, 'logloss': 0.719008871896205, 'f1': 0.504054054054054}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014550>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd47f0> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

corrupted size vs. prev_size
2024-11-12 17:01:31,281 - distributed.nanny - WARNING - Restarting worker
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
corrupted size vs. prev_size
2024-11-12 17:05:30,600 - distributed.scheduler - ERROR - Task eval_objective_list-f5b8b4f3d503ad0e47d868634f22d115 marked as failed because 2 workers died while trying to run it
2024-11-12 17:05:30,609 - distributed.nanny - WARNING - Restarting worker
Exception in future
Attempted to run task 'eval_objective_list-f5b8b4f3d503ad0e47d868634f22d115' on 2 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:46903. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd5870> 

Generation:  1
Best f1_score score: 0.8904518443949712
Generation:   4%|▍         | 1/25 [10:02<4:01:04, 602.69s/it]Generation:  2
Best f1_score score: 0.8942966874939324
Generation:   8%|▊         | 2/25 [12:44<2:11:43, 343.64s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d21660> 

Generation:  3
Best f1_score score: 0.8942966874939324
Generation:  12%|█▏        | 3/25 [22:49<2:49:43, 462.86s/it]Generation:  4
Best f1_score score: 0.8996710000135737
Generation:  16%|█▌        | 4/25 [23:56<1:47:19, 306.66s/it]Generation:  5
Best f1_score score: 0.8996710000135737
Generation:  20%|██        | 5/25 [25:19<1:15:16, 225.81s/it]Generation:  6
Best f1_score score: 0.8996710000135737
Generation:  24%|██▍       | 6/25 [31:05<1:24:24, 266.54s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553a0678f70> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.8996710000135737
Generation:  28%|██▊       | 7/25 [32:16<1:00:47, 202.64s/it]Generation:  8
Best f1_score score: 0.8996710000135737
Generation:  32%|███▏      | 8/25 [34:14<49:50, 175.94s/it]  Generation:  9
Best f1_score score: 0.8996710000135737
Generation:  36%|███▌      | 9/25 [38:34<53:52, 202.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456a592a0> 

Generation:  10
Best f1_score score: 0.8996710000135737
Generation:  40%|████      | 10/25 [48:41<1:21:45, 327.02s/it]Generation:  11
Best f1_score score: 0.8996710000135737
Generation:  44%|████▍     | 11/25 [56:15<1:25:22, 365.88s/it]Generation:  12
Best f1_score score: 0.8996710000135737
Generation:  48%|████▊     | 12/25 [56:48<57:22, 264.80s/it]  Generation:  13
Best f1_score score: 0.8996710000135737
Generation:  52%|█████▏    | 13/25 [59:58<48:25, 242.11s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d3e920> 

Generation:  14
Best f1_score score: 0.8996710000135737
Generation:  56%|█████▌    | 14/25 [1:10:03<1:04:29, 351.74s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545558b3a0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fef7b50> 

Generation:  15
Best f1_score score: 0.8996710000135737
Generation:  60%|██████    | 15/25 [1:20:10<1:11:25, 428.60s/it]Generation:  16
Best f1_score score: 0.9008331124309873
Generation:  64%|██████▍   | 16/25 [1:20:47<46:37, 310.86s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd6290> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc0eda0> 

Generation:  17
Best f1_score score: 0.9008331124309873
Generation:  68%|██████▊   | 17/25 [1:30:54<53:18, 399.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f9fbee0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15534ead5f00> 

Generation:  18
Best f1_score score: 0.9008331124309873
Generation:  72%|███████▏  | 18/25 [1:40:58<53:47, 461.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15540ee84640> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  19
Best f1_score score: 0.9008331124309873
Generation:  76%|███████▌  | 19/25 [1:42:19<34:42, 347.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545201fbe0> 

Generation:  20
Best f1_score score: 0.9008331124309873
Generation:  80%|████████  | 20/25 [1:52:25<35:22, 424.59s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fda0b20> 

Exception in thread Thread-25 (funcwrap):
Traceback (most recent call last):
  File "/home/ketrong/miniconda3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/ketrong/miniconda3/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
func_timeout.dafunc.FunctionTimedOut8255346275056043765: Function objective_function (args=[<tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fda0b20>]) (kwargs={'budget': None, 'X':             0   ...        19
0          NaN  ...       NaN
1     0.205142  ...  0.711827
2          NaN  ...       NaN
3          NaN  ...       NaN
4     0.578289  ...       NaN
...        ...  ...       ...
5915  0.863264  ...  0.618440
5916  0.534744  ...  0.474807
5917  0.316322  ...       NaN
5918  0.536906  ...       NaN
5919       NaN  ...       NaN

[5920 rows x 20 columns], 'y': array([1, 0, 1, ..., 0, 0, 1])}) timed out after 600.000000 seconds.

Generation:  21
Best f1_score score: 0.9008331124309873
Generation:  84%|████████▍ | 21/25 [2:02:35<32:01, 480.31s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4bb0> 

Generation:  22
Best f1_score score: 0.9008331124309873
Generation:  88%|████████▊ | 22/25 [2:12:41<25:53, 517.95s/it]Generation:  23
Best f1_score score: 0.9008331124309873
Generation:  92%|█████████▏| 23/25 [2:15:56<14:02, 421.22s/it]Generation:  24
Best f1_score score: 0.9008331124309873
Generation:  96%|█████████▌| 24/25 [2:19:05<05:51, 351.61s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bbb4d30> 

Generation:  25
Best f1_score score: 0.9014641473928748
Generation: 100%|██████████| 25/25 [2:29:11<00:00, 427.73s/it]Generation: 100%|██████████| 25/25 [2:29:11<00:00, 358.05s/it]
2024-11-12 19:26:40,950 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38483' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8', 'DataFrame-a67d9ff754a903140e604fac030d65f0'} (stimulus_id='handle-worker-cleanup-1731468400.9507453')
2024-11-12 19:26:44,937 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,937 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,937 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,938 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,938 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,938 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,940 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,940 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,940 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,940 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,942 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,942 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,942 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,945 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,945 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-11-12 19:26:44,945 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=Ridge(), imputation_order='roman',
                                  n_nearest_features=13)),
                ('gaussiannb', GaussianNB())])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9539151801801647, 'accuracy': 0.8996621621621622, 'balanced_accuracy': 0.8992917166195303, 'logloss': 0.41781559253678, 'f1': 0.8994435952140312}
test score: {'auroc': 0.9590321266877423, 'accuracy': 0.9033783783783784, 'balanced_accuracy': 0.9029798137525089, 'logloss': 0.37585005866291404, 'f1': 0.9031296128891991}
original test score: {'auroc': 0.996986582071807, 'accuracy': 0.8675675675675676, 'balanced_accuracy': 0.8687829992092061, 'logloss': 0.4563717311012285, 'f1': 0.8656238245327315}
score end
1496
lvl
0.5
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
10.447934783233537
hours
DONE
