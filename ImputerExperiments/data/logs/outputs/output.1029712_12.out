Run: 12
/cm/local/apps/slurm/var/spool/job1029712/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/803/803.pkl
working on 
../data/c/803/class_full_MNAR_0.5_1
1.0456502437591553
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-28 21:21:53,164] A new study created in memory with name: no-name-1eacf839-a1df-4267-977c-7934b7fae7e4
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-28 21:21:53,384] Trial 4 finished with value: 0.20795068452955578 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 4 with value: 0.20795068452955578.
running
[I 2024-10-28 21:21:53,540] Trial 3 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.20795068452955578.
[I 2024-10-28 21:21:53,655] Trial 12 finished with value: 0.3114908178545752 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.20795068452955578.
running
[I 2024-10-28 21:21:53,765] Trial 13 finished with value: 0.3114908178545752 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.20795068452955578.
running
running
[I 2024-10-28 21:21:53,883] Trial 6 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.20795068452955578.
running
[I 2024-10-28 21:21:54,062] Trial 14 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.20795068452955578.
[I 2024-10-28 21:21:54,225] Trial 17 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.20795068452955578.
running
[I 2024-10-28 21:21:54,326] Trial 19 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.20795068452955578.
running
running
[I 2024-10-28 21:21:55,378] Trial 0 finished with value: 0.2071786231045047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2165, 'weights': 'uniform'}. Best is trial 0 with value: 0.2071786231045047.
running
[I 2024-10-28 21:21:56,016] Trial 21 finished with value: 0.20505687013173288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.20505687013173288.
running
[I 2024-10-28 21:21:57,520] Trial 25 finished with value: 0.20505687013173288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.20505687013173288.
running
[I 2024-10-28 21:21:58,972] Trial 26 finished with value: 0.20505687013173288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.20505687013173288.
running
[I 2024-10-28 21:22:00,533] Trial 2 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.04464668105366138, 'alpha': 26, 'iterations': 27, 'learning_rate': 0.0013506308144042244, 'p_miss': 0.1809521789976585}. Best is trial 21 with value: 0.20505687013173288.
running
[I 2024-10-28 21:22:01,914] Trial 27 finished with value: 0.20505687013173288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.20505687013173288.
running
[I 2024-10-28 21:22:03,518] Trial 10 finished with value: 0.12588159774573598 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 5, 'learning_rate': 0.000459416723326883, 'p_miss': 0.22756776841002774}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:03,853] Trial 28 finished with value: 0.20505687013173288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:04,925] Trial 8 finished with value: 0.2860683930747653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:05,463] Trial 16 finished with value: 0.2738624624187779 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:06,318] Trial 30 finished with value: 0.12939127618584928 and parameters: {'model_name': 'VAE', 'batch_size': 374, 'iterations': 1, 'learning_rate': 0.00014362957102349963, 'p_miss': 0.28916486715862455}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:06,603] Trial 7 finished with value: 0.2849736562546388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 10 with value: 0.12588159774573598.
running
[I 2024-10-28 21:22:06,935] Trial 22 finished with value: 0.21478453105655446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 10 with value: 0.12588159774573598.
[I 2024-10-28 21:22:07,068] Trial 31 finished with value: 0.12244115825214345 and parameters: {'model_name': 'VAE', 'batch_size': 310, 'iterations': 1, 'learning_rate': 0.00014245685197339521, 'p_miss': 0.29223512231279414}. Best is trial 31 with value: 0.12244115825214345.
running
running
[I 2024-10-28 21:22:09,112] Trial 24 finished with value: 0.20972596229169627 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 31 with value: 0.12244115825214345.
running
[I 2024-10-28 21:22:09,975] Trial 32 finished with value: 0.1199347084796076 and parameters: {'model_name': 'VAE', 'batch_size': 315, 'iterations': 1, 'learning_rate': 0.0001003116825200521, 'p_miss': 0.2805342746800748}. Best is trial 32 with value: 0.1199347084796076.
running
[I 2024-10-28 21:22:11,515] Trial 33 finished with value: 0.12060808282206983 and parameters: {'model_name': 'VAE', 'batch_size': 614, 'iterations': 1, 'learning_rate': 0.00011008918340674342, 'p_miss': 0.29795716209028367}. Best is trial 32 with value: 0.1199347084796076.
running
[I 2024-10-28 21:22:11,703] Trial 36 finished with value: 0.12163702804796266 and parameters: {'model_name': 'VAE', 'batch_size': 593, 'iterations': 1, 'learning_rate': 0.00011244579422516209, 'p_miss': 0.29096523299324784}. Best is trial 32 with value: 0.1199347084796076.
running
[I 2024-10-28 21:22:12,019] Trial 34 finished with value: 0.11931458949850238 and parameters: {'model_name': 'VAE', 'batch_size': 562, 'iterations': 1, 'learning_rate': 0.00010190379408396612, 'p_miss': 0.2928854578620308}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:12,674] Trial 37 finished with value: 0.12325713020310161 and parameters: {'model_name': 'VAE', 'batch_size': 524, 'iterations': 1, 'learning_rate': 0.00011696610578959231, 'p_miss': 0.29504309357339664}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:13,770] Trial 35 finished with value: 0.12620451194155494 and parameters: {'model_name': 'VAE', 'batch_size': 660, 'iterations': 1, 'learning_rate': 0.00012810282357290616, 'p_miss': 0.2930903162785673}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:14,812] Trial 38 finished with value: 0.12366029229628887 and parameters: {'model_name': 'VAE', 'batch_size': 444, 'iterations': 1, 'learning_rate': 0.00012341103446020815, 'p_miss': 0.29409333219396006}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:15,822] Trial 39 finished with value: 0.12644418710459376 and parameters: {'model_name': 'VAE', 'batch_size': 330, 'iterations': 1, 'learning_rate': 0.00011618719247072708, 'p_miss': 0.28846404020007677}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:17,709] Trial 44 finished with value: 0.2607864384055194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5545, 'weights': 'distance'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:17,928] Trial 15 finished with value: 0.3600373099068206 and parameters: {'model_name': 'GAIN', 'batch_size': 615, 'hint_rate': 0.40689870769088, 'alpha': 37, 'iterations': 24, 'learning_rate': 0.00028333479236653626, 'p_miss': 0.1564691555394547}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:18,693] Trial 40 finished with value: 0.12075886775745295 and parameters: {'model_name': 'VAE', 'batch_size': 929, 'iterations': 1, 'learning_rate': 0.00011069012397492942, 'p_miss': 0.2969903225892354}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:22:20,046] Trial 45 finished with value: 0.2607864384055194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5350, 'weights': 'distance'}. Best is trial 34 with value: 0.11931458949850238.
[I 2024-10-28 21:22:20,169] Trial 46 finished with value: 0.2607864384055194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4817, 'weights': 'distance'}. Best is trial 34 with value: 0.11931458949850238.
running
running
[I 2024-10-28 21:24:21,505] Trial 18 finished with value: 0.36430261812911807 and parameters: {'model_name': 'GAIN', 'batch_size': 41, 'hint_rate': 0.5537384851385424, 'alpha': 16, 'iterations': 122, 'learning_rate': 0.00024873395790362015, 'p_miss': 0.1429958738566764}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:31:56,863] Trial 1 finished with value: 0.19718312317776646 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 192, 'learning_rate': 0.0023333088715549177, 'p_miss': 0.19631027803827197}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:33:37,436] Trial 23 finished with value: 0.21795500318839633 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:34:17,864] Trial 54 finished with value: 0.22542894205472633 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 8, 'learning_rate': 0.02103147685551283, 'p_miss': 0.24222651892208114}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:36:20,415] Trial 11 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.6097964924153045, 'alpha': 0, 'iterations': 3044, 'learning_rate': 0.00030482972940191994, 'p_miss': 0.030832184831560562}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:36:40,589] Trial 56 finished with value: 0.1295609423418494 and parameters: {'model_name': 'VAE', 'batch_size': 945, 'iterations': 4, 'learning_rate': 0.0005615838707786015, 'p_miss': 0.2507468556249623}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:37:01,253] Trial 57 finished with value: 0.12897382285274364 and parameters: {'model_name': 'VAE', 'batch_size': 141, 'iterations': 3, 'learning_rate': 0.012066858654852181, 'p_miss': 0.25508462952059885}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:37:12,788] Trial 58 finished with value: 0.12057527175506459 and parameters: {'model_name': 'VAE', 'batch_size': 908, 'iterations': 3, 'learning_rate': 0.00010709901758492722, 'p_miss': 0.26302072006114036}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:37:30,847] Trial 59 finished with value: 0.2402074823294739 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 3, 'learning_rate': 0.06628883407827679, 'p_miss': 0.26412259278688704}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:37:46,708] Trial 60 finished with value: 0.12280792535613205 and parameters: {'model_name': 'VAE', 'batch_size': 964, 'iterations': 3, 'learning_rate': 0.00025855210735044673, 'p_miss': 0.2636166479478372}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:38:33,759] Trial 61 finished with value: 0.12616928899723243 and parameters: {'model_name': 'VAE', 'batch_size': 227, 'iterations': 11, 'learning_rate': 0.0006771609990322479, 'p_miss': 0.22492617390318112}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:38:44,936] Trial 62 finished with value: 0.12497804002122521 and parameters: {'model_name': 'VAE', 'batch_size': 983, 'iterations': 2, 'learning_rate': 0.00023654107618796444, 'p_miss': 0.268674203425239}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:38:52,650] Trial 63 finished with value: 0.12218443817519091 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 2, 'learning_rate': 0.00021084929804169206, 'p_miss': 0.06758686490047652}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:46:28,103] Trial 49 finished with value: 0.21746912426065368 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 505, 'learning_rate': 0.01770735911969991, 'p_miss': 0.07339188078910622}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:46:33,495] Trial 65 finished with value: 0.3445468925191796 and parameters: {'model_name': 'GAIN', 'batch_size': 976, 'hint_rate': 0.9771129667545895, 'alpha': 99, 'iterations': 2, 'learning_rate': 0.00010047586755778131, 'p_miss': 0.2694496420670861}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:46:40,643] Trial 66 finished with value: 0.128893725687862 and parameters: {'model_name': 'VAE', 'batch_size': 492, 'iterations': 1, 'learning_rate': 0.00016867774316756806, 'p_miss': 0.2751522021953058}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:46:48,685] Trial 67 finished with value: 0.12121974740483651 and parameters: {'model_name': 'VAE', 'batch_size': 261, 'iterations': 2, 'learning_rate': 0.00010348444222776633, 'p_miss': 0.2972785757479402}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:47:23,420] Trial 68 finished with value: 0.11992360484575684 and parameters: {'model_name': 'VAE', 'batch_size': 254, 'iterations': 9, 'learning_rate': 0.0001978298420030743, 'p_miss': 0.2982880961494673}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:47:50,416] Trial 69 finished with value: 0.12783897163707347 and parameters: {'model_name': 'VAE', 'batch_size': 235, 'iterations': 8, 'learning_rate': 0.0001868415995062345, 'p_miss': 0.2334666729650281}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:49:01,186] Trial 70 finished with value: 0.12614888107608924 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 20, 'learning_rate': 0.005027039958198695, 'p_miss': 0.2767955428467605}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:49:21,902] Trial 71 finished with value: 0.12138328555925801 and parameters: {'model_name': 'VAE', 'batch_size': 580, 'iterations': 5, 'learning_rate': 0.0001771110023627085, 'p_miss': 0.20301384810386336}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:49:26,853] Trial 72 finished with value: 0.33640301896058433 and parameters: {'model_name': 'GAIN', 'batch_size': 373, 'hint_rate': 0.030658570770055904, 'alpha': 76, 'iterations': 2, 'learning_rate': 0.001117504766636719, 'p_miss': 0.27130826757558774}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:49:34,497] Trial 73 finished with value: 0.1236919249359318 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 2, 'learning_rate': 0.00038843347383191277, 'p_miss': 0.29991971880371265}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:50:33,930] Trial 74 finished with value: 0.13004824478054963 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 13, 'learning_rate': 0.0003934845773657456, 'p_miss': 0.21551259129657893}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:50:34,246] Trial 75 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:51:16,076] Trial 51 finished with value: 0.2163012177289761 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 613, 'learning_rate': 0.043221847511447205, 'p_miss': 0.22841395650263246}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:52:56,014] Trial 9 finished with value: 0.21925446337676893 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 528, 'learning_rate': 0.018193030029609043, 'p_miss': 0.08470046935744788}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:53:17,636] Trial 78 finished with value: 0.13177587390544687 and parameters: {'model_name': 'VAE', 'batch_size': 243, 'iterations': 5, 'learning_rate': 0.00010167396847406795, 'p_miss': 0.2768167873103962}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:53:27,908] Trial 79 finished with value: 0.13096324220368152 and parameters: {'model_name': 'VAE', 'batch_size': 688, 'iterations': 2, 'learning_rate': 0.0001771065329010492, 'p_miss': 0.2532693971572787}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:53:35,966] Trial 80 finished with value: 0.12935876507688948 and parameters: {'model_name': 'VAE', 'batch_size': 201, 'iterations': 2, 'learning_rate': 0.00010033439348066071, 'p_miss': 0.2807567952055806}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:23,540] Trial 76 finished with value: 0.1245977752566155 and parameters: {'model_name': 'VAE', 'batch_size': 223, 'iterations': 57, 'learning_rate': 0.00010328734574874321, 'p_miss': 0.27882591339313434}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:25,434] Trial 82 finished with value: 0.2199062437464753 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 52, 'weights': 'uniform'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:33,804] Trial 77 finished with value: 0.12232441343878164 and parameters: {'model_name': 'VAE', 'batch_size': 189, 'iterations': 53, 'learning_rate': 0.0001009924330866921, 'p_miss': 0.29991432289124415}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:55,804] Trial 84 finished with value: 0.12153929944130268 and parameters: {'model_name': 'VAE', 'batch_size': 357, 'iterations': 4, 'learning_rate': 0.0029590696963550356, 'p_miss': 0.11402436204390506}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:58,324] Trial 83 finished with value: 0.12170111628952847 and parameters: {'model_name': 'VAE', 'batch_size': 344, 'iterations': 7, 'learning_rate': 0.00031863549117190827, 'p_miss': 0.15318722908500518}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:54:59,785] Trial 85 finished with value: 0.35152235217253514 and parameters: {'model_name': 'GAIN', 'batch_size': 704, 'hint_rate': 0.9729630564942655, 'alpha': 61, 'iterations': 1, 'learning_rate': 0.0003090751509537962, 'p_miss': 0.17835815360344137}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:55:04,080] Trial 86 finished with value: 0.12497193364590191 and parameters: {'model_name': 'VAE', 'batch_size': 670, 'iterations': 1, 'learning_rate': 0.00018664487110054502, 'p_miss': 0.19247656386408202}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:55:17,120] Trial 88 finished with value: 0.1211912109809091 and parameters: {'model_name': 'VAE', 'batch_size': 512, 'iterations': 3, 'learning_rate': 0.00016344584926908585, 'p_miss': 0.28585890296846816}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:55:19,222] Trial 87 finished with value: 0.12539315379481467 and parameters: {'model_name': 'VAE', 'batch_size': 531, 'iterations': 5, 'learning_rate': 0.00016250734233784538, 'p_miss': 0.18771248703860705}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:55:19,536] Trial 90 finished with value: 0.20795068452955578 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:55:34,511] Trial 91 finished with value: 0.12375823289647281 and parameters: {'model_name': 'VAE', 'batch_size': 439, 'iterations': 3, 'learning_rate': 0.00014344062257081407, 'p_miss': 0.28312939514325863}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 21:56:59,472] Trial 81 finished with value: 0.12324908446676741 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 48, 'learning_rate': 0.00017140215049613522, 'p_miss': 0.16745765583905883}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:05:34,222] Trial 20 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.6749545660814905, 'alpha': 33, 'iterations': 9029, 'learning_rate': 0.014549994090139726, 'p_miss': 0.1843763158300558}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:05:39,958] Trial 94 finished with value: 0.13830788924197288 and parameters: {'model_name': 'VAE', 'batch_size': 741, 'iterations': 1, 'learning_rate': 0.0001383660002838092, 'p_miss': 0.2854815493124189}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:05:43,032] Trial 95 finished with value: 0.2075404827643453 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2819, 'weights': 'uniform'}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:06:09,792] Trial 96 finished with value: 0.12384120943876872 and parameters: {'model_name': 'VAE', 'batch_size': 477, 'iterations': 5, 'learning_rate': 0.00022859023015440888, 'p_miss': 0.28933993598568164}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:06:28,162] Trial 97 finished with value: 0.12396872549313938 and parameters: {'model_name': 'VAE', 'batch_size': 596, 'iterations': 3, 'learning_rate': 0.00014211239599445374, 'p_miss': 0.29954536090777706}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:07:11,930] Trial 98 finished with value: 0.13622071491868076 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 14, 'learning_rate': 0.0001312082896791855, 'p_miss': 0.25752062692676136}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:07:25,246] Trial 99 finished with value: 0.1284006574354704 and parameters: {'model_name': 'VAE', 'batch_size': 754, 'iterations': 2, 'learning_rate': 0.00021175060670530768, 'p_miss': 0.2869844534118495}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:20:07,119] Trial 64 finished with value: 0.13719416789440905 and parameters: {'model_name': 'VAE', 'batch_size': 287, 'iterations': 535, 'learning_rate': 0.00010254313111647962, 'p_miss': 0.2708657446259012}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:20:11,581] Trial 100 finished with value: 0.1228183664371717 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 247, 'learning_rate': 0.00014009308855351873, 'p_miss': 0.21505989505582468}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:20:48,837] Trial 102 finished with value: 0.12293738515840573 and parameters: {'model_name': 'VAE', 'batch_size': 448, 'iterations': 7, 'learning_rate': 0.0002943542164346949, 'p_miss': 0.2392918205877075}. Best is trial 34 with value: 0.11931458949850238.
running
[I 2024-10-28 22:20:49,942] Trial 101 finished with value: 0.11896707259581887 and parameters: {'model_name': 'VAE', 'batch_size': 465, 'iterations': 7, 'learning_rate': 0.00014179392997488066, 'p_miss': 0.24224433773036555}. Best is trial 101 with value: 0.11896707259581887.
running
[I 2024-10-28 22:22:36,230] Trial 104 finished with value: 0.11888996413366242 and parameters: {'model_name': 'VAE', 'batch_size': 159, 'iterations': 30, 'learning_rate': 0.00015116329978371543, 'p_miss': 0.26098632533231136}. Best is trial 104 with value: 0.11888996413366242.
running
[I 2024-10-28 22:22:36,557] Trial 105 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 104 with value: 0.11888996413366242.
running
[I 2024-10-28 22:24:10,489] Trial 106 finished with value: 0.12144637338384386 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 26, 'learning_rate': 0.00013040213901897106, 'p_miss': 0.2497241850290515}. Best is trial 104 with value: 0.11888996413366242.
running
[I 2024-10-28 22:24:26,425] Trial 107 finished with value: 0.11794041975343794 and parameters: {'model_name': 'VAE', 'batch_size': 288, 'iterations': 3, 'learning_rate': 0.0001295577022046402, 'p_miss': 0.2629920250472374}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:25:22,920] Trial 108 finished with value: 0.12166562472617962 and parameters: {'model_name': 'VAE', 'batch_size': 407, 'iterations': 10, 'learning_rate': 0.0002319031710509576, 'p_miss': 0.2440968193054803}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:26:33,432] Trial 42 finished with value: 0.21626233383843957 and parameters: {'model_name': 'VAE', 'batch_size': 719, 'iterations': 1085, 'learning_rate': 0.04580544103422388, 'p_miss': 0.038710076422844714}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:26:40,075] Trial 109 finished with value: 0.12321808183820886 and parameters: {'model_name': 'VAE', 'batch_size': 838, 'iterations': 17, 'learning_rate': 0.00014894118210539956, 'p_miss': 0.2612251541075996}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:27:21,033] Trial 47 finished with value: 0.3753020899711463 and parameters: {'model_name': 'GAIN', 'batch_size': 76, 'hint_rate': 0.9325102171221731, 'alpha': 95, 'iterations': 2632, 'learning_rate': 0.01913177622279961, 'p_miss': 0.08033313687872601}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:28:03,605] Trial 110 finished with value: 0.11847763496954364 and parameters: {'model_name': 'VAE', 'batch_size': 825, 'iterations': 17, 'learning_rate': 0.0001326169183091035, 'p_miss': 0.2617151708970967}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:34:37,854] Trial 111 finished with value: 0.12361166895556094 and parameters: {'model_name': 'VAE', 'batch_size': 293, 'iterations': 118, 'learning_rate': 0.00013112175264158233, 'p_miss': 0.2626744935645796}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:36:09,899] Trial 112 finished with value: 0.12252996787401345 and parameters: {'model_name': 'VAE', 'batch_size': 292, 'iterations': 116, 'learning_rate': 0.00012660179472968837, 'p_miss': 0.2656135217862416}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:37:56,686] Trial 113 finished with value: 0.20389889399973077 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:39:49,883] Trial 116 finished with value: 0.12779581642521914 and parameters: {'model_name': 'VAE', 'batch_size': 564, 'iterations': 26, 'learning_rate': 0.0002056105146226407, 'p_miss': 0.28699388197511794}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:41:43,649] Trial 117 finished with value: 0.13844159205664408 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 31, 'learning_rate': 0.00016504853830165054, 'p_miss': 0.2801033223889719}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:44:45,181] Trial 114 finished with value: 0.2037963388698596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:44:55,904] Trial 43 finished with value: 0.2182817762679587 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 1612, 'learning_rate': 0.013284866769042204, 'p_miss': 0.029604849422181723}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:45:32,531] Trial 118 finished with value: 0.12839139492091478 and parameters: {'model_name': 'VAE', 'batch_size': 1000, 'iterations': 37, 'learning_rate': 0.00012297527292729903, 'p_miss': 0.2906051184675336}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:45:43,710] Trial 119 finished with value: 0.11897583093216361 and parameters: {'model_name': 'VAE', 'batch_size': 889, 'iterations': 9, 'learning_rate': 0.00025396498791016207, 'p_miss': 0.2921463876647475}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:45:51,756] Trial 115 finished with value: 0.2040506094447836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:45:58,204] Trial 120 finished with value: 0.12257075697573687 and parameters: {'model_name': 'VAE', 'batch_size': 868, 'iterations': 11, 'learning_rate': 0.00012145400817389656, 'p_miss': 0.2926698126255162}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:46:14,478] Trial 121 finished with value: 0.12166396223331918 and parameters: {'model_name': 'VAE', 'batch_size': 416, 'iterations': 10, 'learning_rate': 0.0002637945409608981, 'p_miss': 0.27485931722277346}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:46:17,101] Trial 125 finished with value: 0.26164289278840824 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 163, 'weights': 'distance'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:46:37,640] Trial 122 finished with value: 0.11814460150979333 and parameters: {'model_name': 'VAE', 'batch_size': 789, 'iterations': 10, 'learning_rate': 0.00027596241160526456, 'p_miss': 0.27265881076540804}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:46:42,418] Trial 123 finished with value: 0.12749510770043443 and parameters: {'model_name': 'VAE', 'batch_size': 841, 'iterations': 9, 'learning_rate': 0.00012309348492565164, 'p_miss': 0.2709367950555622}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:47:13,475] Trial 124 finished with value: 0.11991638418238079 and parameters: {'model_name': 'VAE', 'batch_size': 397, 'iterations': 20, 'learning_rate': 0.00021342606969414988, 'p_miss': 0.2719163187377358}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:47:48,496] Trial 126 finished with value: 0.12716459822078477 and parameters: {'model_name': 'VAE', 'batch_size': 509, 'iterations': 18, 'learning_rate': 0.0001605884810051459, 'p_miss': 0.2701747481309052}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:48:07,438] Trial 127 finished with value: 0.12402323338855296 and parameters: {'model_name': 'VAE', 'batch_size': 781, 'iterations': 17, 'learning_rate': 0.000206056324272321, 'p_miss': 0.26791262761330215}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:48:11,790] Trial 128 finished with value: 0.1315324929406319 and parameters: {'model_name': 'VAE', 'batch_size': 661, 'iterations': 18, 'learning_rate': 0.00019606777947020671, 'p_miss': 0.24796983083443158}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:48:45,792] Trial 132 finished with value: 0.12263699078339181 and parameters: {'model_name': 'VAE', 'batch_size': 365, 'iterations': 7, 'learning_rate': 0.0005188017136172124, 'p_miss': 0.25378794532647836}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:48:53,501] Trial 130 finished with value: 0.12036915247515172 and parameters: {'model_name': 'VAE', 'batch_size': 611, 'iterations': 14, 'learning_rate': 0.0003658619307652596, 'p_miss': 0.2534238603131745}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:49:05,077] Trial 131 finished with value: 0.12073153748369012 and parameters: {'model_name': 'VAE', 'batch_size': 621, 'iterations': 13, 'learning_rate': 0.0003692881564971975, 'p_miss': 0.24668520809757963}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:49:11,183] Trial 133 finished with value: 0.350908860315672 and parameters: {'model_name': 'GAIN', 'batch_size': 580, 'hint_rate': 0.36858437094715824, 'alpha': 67, 'iterations': 14, 'learning_rate': 0.0069638137325201835, 'p_miss': 0.238821644435313}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:49:16,243] Trial 129 finished with value: 0.1229922790524566 and parameters: {'model_name': 'VAE', 'batch_size': 602, 'iterations': 21, 'learning_rate': 0.0005039507690410111, 'p_miss': 0.2547621094969706}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:49:18,362] Trial 134 finished with value: 0.3478819191064678 and parameters: {'model_name': 'GAIN', 'batch_size': 575, 'hint_rate': 0.26879440311819536, 'alpha': 62, 'iterations': 12, 'learning_rate': 0.0003501287341886966, 'p_miss': 0.23832188917826846}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:49:48,830] Trial 137 finished with value: 0.12418202935489986 and parameters: {'model_name': 'VAE', 'batch_size': 404, 'iterations': 6, 'learning_rate': 0.00027790376303507395, 'p_miss': 0.2788471746411705}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:50:04,168] Trial 139 finished with value: 0.12885198877569803 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.001008335917135652, 'p_miss': 0.2623662783771682}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:50:06,968] Trial 135 finished with value: 0.34812273634757324 and parameters: {'model_name': 'GAIN', 'batch_size': 265, 'hint_rate': 0.3051395460043518, 'alpha': 59, 'iterations': 35, 'learning_rate': 0.0002598695249901958, 'p_miss': 0.2342012959514139}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:50:39,788] Trial 141 finished with value: 0.12180726152332796 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 8, 'learning_rate': 0.0001155193605568162, 'p_miss': 0.29365644467830837}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:50:45,805] Trial 136 finished with value: 0.12728257791622516 and parameters: {'model_name': 'VAE', 'batch_size': 420, 'iterations': 22, 'learning_rate': 0.0012531526355824356, 'p_miss': 0.2591884362991056}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:50:46,153] Trial 143 finished with value: 0.38354712883604974 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:51:05,986] Trial 144 finished with value: 0.11862095745750818 and parameters: {'model_name': 'VAE', 'batch_size': 825, 'iterations': 4, 'learning_rate': 0.00018988580163889596, 'p_miss': 0.11986047567964077}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:51:38,656] Trial 145 finished with value: 0.13186524619417045 and parameters: {'model_name': 'VAE', 'batch_size': 803, 'iterations': 6, 'learning_rate': 0.00023172786995948071, 'p_miss': 0.2734701718739185}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:52:29,511] Trial 138 finished with value: 0.12534523413787718 and parameters: {'model_name': 'VAE', 'batch_size': 400, 'iterations': 38, 'learning_rate': 0.0002631649719914223, 'p_miss': 0.27883341636265074}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:52:33,009] Trial 142 finished with value: 0.12233548562674135 and parameters: {'model_name': 'VAE', 'batch_size': 451, 'iterations': 23, 'learning_rate': 0.0001874799391156971, 'p_miss': 0.2583563689894572}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:52:33,158] Trial 140 finished with value: 0.11819093113904286 and parameters: {'model_name': 'VAE', 'batch_size': 273, 'iterations': 43, 'learning_rate': 0.00024890880545297574, 'p_miss': 0.2752463697850765}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:52:50,204] Trial 146 finished with value: 0.12100722052271991 and parameters: {'model_name': 'VAE', 'batch_size': 735, 'iterations': 15, 'learning_rate': 0.000182766469547141, 'p_miss': 0.14109175394101037}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:52:58,536] Trial 148 finished with value: 0.12222578702071378 and parameters: {'model_name': 'VAE', 'batch_size': 739, 'iterations': 4, 'learning_rate': 0.00015283621409159683, 'p_miss': 0.1043855987967848}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:53:31,984] Trial 55 finished with value: 0.21767031184317132 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 1712, 'learning_rate': 0.0006631576706027162, 'p_miss': 0.014687369983950205}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:53:39,215] Trial 151 finished with value: 0.12072848877899929 and parameters: {'model_name': 'VAE', 'batch_size': 206, 'iterations': 9, 'learning_rate': 0.00041341334949879287, 'p_miss': 0.1073985310978143}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:54:11,053] Trial 152 finished with value: 0.1231323522052348 and parameters: {'model_name': 'VAE', 'batch_size': 333, 'iterations': 9, 'learning_rate': 0.0004583669533563196, 'p_miss': 0.134871876529579}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:57:00,389] Trial 154 finished with value: 0.13148063460368625 and parameters: {'model_name': 'VAE', 'batch_size': 243, 'iterations': 42, 'learning_rate': 0.00021986493203984123, 'p_miss': 0.28263027230699084}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:57:03,144] Trial 155 finished with value: 0.2063562513216357 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1403, 'weights': 'uniform'}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:57:42,116] Trial 147 finished with value: 0.12294884025326121 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 83, 'learning_rate': 0.00018235631308654416, 'p_miss': 0.12120627614899275}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:58:43,097] Trial 150 finished with value: 0.12115394203697445 and parameters: {'model_name': 'VAE', 'batch_size': 199, 'iterations': 75, 'learning_rate': 0.0003254316853653508, 'p_miss': 0.11548943507838955}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:58:45,624] Trial 149 finished with value: 0.119216705345163 and parameters: {'model_name': 'VAE', 'batch_size': 199, 'iterations': 80, 'learning_rate': 0.00015519479108567054, 'p_miss': 0.0547544430672061}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:59:10,081] Trial 158 finished with value: 0.12610995863537985 and parameters: {'model_name': 'VAE', 'batch_size': 505, 'iterations': 6, 'learning_rate': 0.0001152795939055966, 'p_miss': 0.29479073392357286}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:59:51,999] Trial 153 finished with value: 0.1281455263624309 and parameters: {'model_name': 'VAE', 'batch_size': 330, 'iterations': 79, 'learning_rate': 0.0003273490060368844, 'p_miss': 0.12275320767135872}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 22:59:55,526] Trial 156 finished with value: 0.1229614816786436 and parameters: {'model_name': 'VAE', 'batch_size': 993, 'iterations': 27, 'learning_rate': 0.00011417189196651156, 'p_miss': 0.2950007654075062}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 23:01:01,418] Trial 160 finished with value: 0.1295473597180971 and parameters: {'model_name': 'VAE', 'batch_size': 276, 'iterations': 28, 'learning_rate': 0.0016831884369514865, 'p_miss': 0.09690562641304402}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 23:01:57,421] Trial 161 finished with value: 0.13457460798171575 and parameters: {'model_name': 'VAE', 'batch_size': 183, 'iterations': 30, 'learning_rate': 0.0018991782908766653, 'p_miss': 0.08887035843023511}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 23:02:52,858] Trial 164 finished with value: 0.13099907377579936 and parameters: {'model_name': 'VAE', 'batch_size': 157, 'iterations': 11, 'learning_rate': 0.0001539651998242092, 'p_miss': 0.012233621015033572}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 23:02:59,296] Trial 162 finished with value: 0.12270242004723801 and parameters: {'model_name': 'VAE', 'batch_size': 278, 'iterations': 57, 'learning_rate': 0.0001475087736608997, 'p_miss': 0.04927387409555255}. Best is trial 107 with value: 0.11794041975343794.
running
[I 2024-10-28 23:03:58,482] Trial 163 finished with value: 0.1176709084892003 and parameters: {'model_name': 'VAE', 'batch_size': 162, 'iterations': 46, 'learning_rate': 0.00015809079625443175, 'p_miss': 0.0365077476761852}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:04:41,160] Trial 159 finished with value: 0.11944756296329466 and parameters: {'model_name': 'VAE', 'batch_size': 163, 'iterations': 89, 'learning_rate': 0.00011318316899454239, 'p_miss': 0.2670927171168624}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:04:48,521] Trial 157 finished with value: 0.12255728744153707 and parameters: {'model_name': 'VAE', 'batch_size': 859, 'iterations': 68, 'learning_rate': 0.00011371283830369995, 'p_miss': 0.2895630426693382}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:06:01,046] Trial 165 finished with value: 0.12057863981470214 and parameters: {'model_name': 'VAE', 'batch_size': 874, 'iterations': 44, 'learning_rate': 0.0002441512385899941, 'p_miss': 0.05220818468073026}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:06:36,709] Trial 166 finished with value: 0.12250508071329272 and parameters: {'model_name': 'VAE', 'batch_size': 678, 'iterations': 48, 'learning_rate': 0.00011017238850643095, 'p_miss': 0.26492800119127874}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:07:11,664] Trial 168 finished with value: 0.1197466499054198 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 47, 'learning_rate': 0.00023163774863290445, 'p_miss': 0.038169800342704965}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:08:13,453] Trial 169 finished with value: 0.1188373583585675 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 65, 'learning_rate': 0.0002370661862692153, 'p_miss': 0.03664982570869085}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:08:14,092] Trial 173 finished with value: 0.3114908178545752 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:08:54,584] Trial 167 finished with value: 0.12054970892942667 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 94, 'learning_rate': 0.00021500988804510867, 'p_miss': 0.046325131847427675}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:11:14,837] Trial 170 finished with value: 0.12495904586295095 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 91, 'learning_rate': 0.00020597619373435781, 'p_miss': 0.03066394860651734}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:11:36,053] Trial 53 finished with value: 0.2175832319919521 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 2038, 'learning_rate': 0.02364506651069277, 'p_miss': 0.241206575083993}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:15:07,459] Trial 177 finished with value: 0.11921660707655246 and parameters: {'model_name': 'VAE', 'batch_size': 128, 'iterations': 63, 'learning_rate': 0.00016786755054531348, 'p_miss': 0.022745257553358194}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:15:44,033] Trial 174 finished with value: 0.12518192691257277 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 150, 'learning_rate': 0.00021023711649733953, 'p_miss': 0.02382049782182114}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:15:54,122] Trial 171 finished with value: 0.12238029545557465 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 180, 'learning_rate': 0.00013811028341899573, 'p_miss': 0.02068488346133606}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:18:53,455] Trial 175 finished with value: 0.12614083442321034 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 173, 'learning_rate': 0.00028619865318354527, 'p_miss': 0.026225519241791933}. Best is trial 163 with value: 0.1176709084892003.
running
[I 2024-10-28 23:18:59,908] Trial 179 finished with value: 0.11748005440784767 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 59, 'learning_rate': 0.000169355560418881, 'p_miss': 0.03702512969509307}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:19:19,773] Trial 180 finished with value: 0.12004523905466531 and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 64, 'learning_rate': 0.0001657311770222448, 'p_miss': 0.03213649455879086}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:20:57,622] Trial 172 finished with value: 0.12933417346234244 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 197, 'learning_rate': 0.0002093577690504151, 'p_miss': 0.02789680865906823}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:21:13,781] Trial 176 finished with value: 0.12470910624883617 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 194, 'learning_rate': 0.00014203832498082487, 'p_miss': 0.03990768607085032}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:21:42,305] Trial 181 finished with value: 0.12612957465012054 and parameters: {'model_name': 'VAE', 'batch_size': 165, 'iterations': 60, 'learning_rate': 0.0001747596978609924, 'p_miss': 0.03575081435912215}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:22:10,959] Trial 183 finished with value: 0.1202478699208932 and parameters: {'model_name': 'VAE', 'batch_size': 130, 'iterations': 56, 'learning_rate': 0.00016937919143623383, 'p_miss': 0.03779910782442259}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:22:27,591] Trial 50 finished with value: 0.217829880395675 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 2440, 'learning_rate': 0.059430356693686286, 'p_miss': 0.07586469353931279}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:23:30,312] Trial 182 finished with value: 0.12056841718839402 and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 68, 'learning_rate': 0.0001689601420339219, 'p_miss': 0.03626836691661685}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:24:13,273] Trial 187 finished with value: 0.12180156469313257 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 47, 'learning_rate': 0.0002378615795365309, 'p_miss': 0.06723123931471026}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:24:14,991] Trial 184 finished with value: 0.11798006963335281 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 63, 'learning_rate': 0.0001693741792729952, 'p_miss': 0.039149950445246766}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:24:37,508] Trial 185 finished with value: 0.12734530153686363 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 55, 'learning_rate': 0.0001744322669394564, 'p_miss': 0.05405318604258219}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:24:50,140] Trial 192 finished with value: 0.21956501472166998 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:25:30,929] Trial 178 finished with value: 0.12194864347697196 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 194, 'learning_rate': 0.00016432404798991796, 'p_miss': 0.019603422752685153}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:25:35,897] Trial 194 finished with value: 0.26088457582273045 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3648, 'weights': 'distance'}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:25:43,704] Trial 189 finished with value: 0.1215544773236293 and parameters: {'model_name': 'VAE', 'batch_size': 140, 'iterations': 41, 'learning_rate': 0.00024321987483990742, 'p_miss': 0.05940451249477757}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:25:52,591] Trial 190 finished with value: 0.12084325186956853 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 33, 'learning_rate': 0.00014102475359934434, 'p_miss': 0.043591597792810764}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:26:56,989] Trial 186 finished with value: 0.12832322045916836 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 114, 'learning_rate': 0.00024742040797735674, 'p_miss': 0.04092365159525907}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:29:45,995] Trial 191 finished with value: 0.11969694638330838 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 101, 'learning_rate': 0.0001300458708887421, 'p_miss': 0.06076180428925544}. Best is trial 179 with value: 0.11748005440784767.
running
[I 2024-10-28 23:30:55,501] Trial 193 finished with value: 0.13014898137647135 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 108, 'learning_rate': 0.00013101498839604463, 'p_miss': 0.06034090544817418}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:31:53,263] Trial 197 finished with value: 0.12499697979550324 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 101, 'learning_rate': 0.0001323102546854056, 'p_miss': 0.0434593104139245}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:33:33,768] Trial 198 finished with value: 0.12472271444811826 and parameters: {'model_name': 'VAE', 'batch_size': 195, 'iterations': 100, 'learning_rate': 0.00012835436019652843, 'p_miss': 0.018959441941618138}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:33:58,240] Trial 199 finished with value: 0.12140044097818578 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 93, 'learning_rate': 0.00012785678277898722, 'p_miss': 0.058576593881133635}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:34:35,585] Trial 52 finished with value: 0.2150545050427743 and parameters: {'model_name': 'VAE', 'batch_size': 119, 'iterations': 2887, 'learning_rate': 0.03699203180743612, 'p_miss': 0.23132304146729304}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:45:52,896] Trial 5 finished with value: 0.21622342267022585 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2476, 'learning_rate': 0.00022683947992969275, 'p_miss': 0.18328679251150187}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-28 23:53:51,908] Trial 41 finished with value: 0.21587163288614777 and parameters: {'model_name': 'VAE', 'batch_size': 769, 'iterations': 2456, 'learning_rate': 0.02729343341345972, 'p_miss': 0.0636978610537453}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 00:41:27,019] Trial 103 finished with value: 0.2139306665774355 and parameters: {'model_name': 'VAE', 'batch_size': 798, 'iterations': 3061, 'learning_rate': 0.00013866348635079479, 'p_miss': 0.28912527440411456}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 01:38:08,073] Trial 89 finished with value: 0.2157406237276172 and parameters: {'model_name': 'VAE', 'batch_size': 503, 'iterations': 5352, 'learning_rate': 0.000148208292302145, 'p_miss': 0.28609616429339096}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 01:45:38,440] Trial 48 finished with value: 0.2172914505081635 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 8322, 'learning_rate': 0.03601231560907223, 'p_miss': 0.04096746460856168}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 01:48:17,159] Trial 196 finished with value: 0.2165118324634303 and parameters: {'model_name': 'VAE', 'batch_size': 223, 'iterations': 5020, 'learning_rate': 0.00013632208271502553, 'p_miss': 0.04268674020883519}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 01:53:08,195] Trial 195 finished with value: 0.21734307032862024 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 5978, 'learning_rate': 0.00013143896976672338, 'p_miss': 0.04398594961637049}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 01:58:11,704] Trial 92 finished with value: 0.21795439711437795 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 7314, 'learning_rate': 0.00015785440185852662, 'p_miss': 0.2991314437092258}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 02:03:10,408] Trial 93 finished with value: 0.216322081520346 and parameters: {'model_name': 'VAE', 'batch_size': 719, 'iterations': 6447, 'learning_rate': 0.0001377213331482386, 'p_miss': 0.28723970614500016}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 02:03:11,007] Trial 188 finished with value: 0.21956604049855355 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 6893, 'learning_rate': 0.00024132287530330174, 'p_miss': 0.05492116772891786}. Best is trial 179 with value: 0.11748005440784767.
[I 2024-10-29 02:05:22,492] Trial 29 finished with value: 0.21569286842016933 and parameters: {'model_name': 'VAE', 'batch_size': 861, 'iterations': 8980, 'learning_rate': 0.03199669429777197, 'p_miss': 0.010444893956872786}. Best is trial 179 with value: 0.11748005440784767.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.11748005440784767
{'model_name': 'VAE', 'batch_size': 124, 'iterations': 59, 'learning_rate': 0.000169355560418881, 'p_miss': 0.03702512969509307}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470c910> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5710655876994555
Generation:   4%|▍         | 1/25 [00:11<04:33, 11.41s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472beb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.5757927323173723
Generation:   8%|▊         | 2/25 [00:32<06:38, 17.31s/it]Generation:  3
Best f1_score score: 0.5764407428869098
Generation:  12%|█▏        | 3/25 [00:43<05:16, 14.38s/it]Generation:  4
Best f1_score score: 0.5773638946415032
Generation:  16%|█▌        | 4/25 [01:03<05:44, 16.42s/it]Generation:  5
Best f1_score score: 0.5777035090437243
Generation:  20%|██        | 5/25 [01:23<05:54, 17.72s/it]Generation:  6
Best f1_score score: 0.5788845433177496
Generation:  24%|██▍       | 6/25 [01:40<05:30, 17.38s/it]Generation:  7
Best f1_score score: 0.5788845433177496
Generation:  28%|██▊       | 7/25 [02:59<11:15, 37.53s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a4f310> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff29e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f1ba90> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5788845433177496
Generation:  32%|███▏      | 8/25 [03:38<10:45, 37.99s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b5b070> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5788845433177496
Generation:  36%|███▌      | 9/25 [03:58<08:41, 32.60s/it]Generation:  10
Best f1_score score: 0.5788845433177496
Generation:  40%|████      | 10/25 [04:16<07:01, 28.12s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465855630> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5788845433177496
Generation:  44%|████▍     | 11/25 [06:21<13:27, 57.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470a410> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.5798883576998912
Generation:  48%|████▊     | 12/25 [08:13<16:05, 74.25s/it]Generation:  13
Best f1_score score: 0.5834272477283844
Generation:  52%|█████▏    | 13/25 [08:36<11:43, 58.64s/it]Generation:  14
Best f1_score score: 0.5834272477283844
Generation:  56%|█████▌    | 14/25 [08:55<08:34, 46.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f38280> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5834272477283844
Generation:  60%|██████    | 15/25 [09:15<06:25, 38.59s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465611930> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5834272477283844
Generation:  64%|██████▍   | 16/25 [09:34<04:55, 32.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465518610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.5834272477283844
Generation:  68%|██████▊   | 17/25 [09:54<03:50, 28.82s/it]Generation:  18
Best f1_score score: 0.5834272477283844
Generation:  72%|███████▏  | 18/25 [10:35<03:47, 32.55s/it]Generation:  19
Best f1_score score: 0.5834272477283844
Generation:  76%|███████▌  | 19/25 [10:56<02:53, 28.99s/it]Generation:  20
Best f1_score score: 0.5834272477283844
Generation:  80%|████████  | 20/25 [11:23<02:22, 28.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c22cb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.5834272477283844
Generation:  84%|████████▍ | 21/25 [11:45<01:45, 26.38s/it]Generation:  22
Best f1_score score: 0.5834272477283844
Generation:  88%|████████▊ | 22/25 [12:17<01:24, 28.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f938b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.5834272477283844
Generation:  92%|█████████▏| 23/25 [12:41<00:53, 26.90s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f7a30> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5834272477283844
Generation:  96%|█████████▌| 24/25 [13:08<00:27, 27.03s/it]Generation:  25
Best f1_score score: 0.5834272477283844
Generation: 100%|██████████| 25/25 [13:32<00:00, 26.04s/it]Generation: 100%|██████████| 25/25 [13:37<00:00, 32.70s/it]
2024-10-29 02:19:08,693 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:39093' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-582d7d183af8cedc419ecc82f5b1ea53', 'ndarray-807aa206cdbc22fd588228f0baff7021'} (stimulus_id='handle-worker-cleanup-1730193548.6935394')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(boosting_type='dart', class_weight='balanced',
                                max_depth=2, n_estimators=75, n_jobs=1,
                                num_leaves=138, verbose=-1))])
score start
train score: {'auroc': 0.6382357138395394, 'accuracy': 0.6005611081886726, 'balanced_accuracy': 0.6006106089399281, 'logloss': 0.6658919556161477, 'f1': 0.6000443196799821}
original test score: {'auroc': 0.6405447512306662, 'accuracy': 0.5827489481065918, 'balanced_accuracy': 0.59179694056272, 'logloss': 0.6823240162715064, 'f1': 0.5776291338178947}
imputed test score: {'auroc': 0.4866448276474874, 'accuracy': 0.4943899018232819, 'balanced_accuracy': 0.49406436784332775, 'logloss': 0.7069613031739105, 'f1': 0.49374235243429554}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.8260476195019111
Generation:   4%|▍         | 1/25 [00:38<15:28, 38.70s/it]Generation:  2
Best f1_score score: 0.8260476195019111
Generation:   8%|▊         | 2/25 [01:01<11:11, 29.20s/it]Generation:  3
Best f1_score score: 0.8307785113189681
Generation:  12%|█▏        | 3/25 [01:26<10:03, 27.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd16c0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  4
Best f1_score score: 0.8307845839174867
Generation:  16%|█▌        | 4/25 [04:13<28:51, 82.46s/it]Generation:  5
Best f1_score score: 0.8314752082394972
Generation:  20%|██        | 5/25 [04:27<19:15, 57.78s/it]Generation:  6
Best f1_score score: 0.8314752082394972
Generation:  24%|██▍       | 6/25 [04:38<13:15, 41.88s/it]Generation:  7
Best f1_score score: 0.8314752082394972
Generation:  28%|██▊       | 7/25 [07:26<24:55, 83.11s/it]Generation:  8
Best f1_score score: 0.8320100527460456
Generation:  32%|███▏      | 8/25 [07:40<17:16, 60.97s/it]Generation:  9
Best f1_score score: 0.8320100527460456
Generation:  36%|███▌      | 9/25 [08:15<14:09, 53.11s/it]Generation:  10
Best f1_score score: 0.8320100527460456
Generation:  40%|████      | 10/25 [11:02<22:03, 88.23s/it]Generation:  11
Best f1_score score: 0.8320100527460456
Generation:  44%|████▍     | 11/25 [11:10<14:48, 63.49s/it]Generation:  12
Best f1_score score: 0.8323605873643507
Generation:  48%|████▊     | 12/25 [14:31<22:50, 105.42s/it]Generation:  13
Best f1_score score: 0.8327082552847219
Generation:  52%|█████▏    | 13/25 [17:17<24:47, 123.92s/it]Generation:  14
Best f1_score score: 0.8327082552847219
Generation:  56%|█████▌    | 14/25 [18:00<18:13, 99.44s/it] Generation:  15
Best f1_score score: 0.8327082552847219
Generation:  60%|██████    | 15/25 [19:27<15:57, 95.72s/it]Generation:  16
Best f1_score score: 0.8327082552847219
Generation:  64%|██████▍   | 16/25 [22:16<17:40, 117.78s/it]Generation:  17
Best f1_score score: 0.8330492299722408
Generation:  68%|██████▊   | 17/25 [22:29<11:28, 86.04s/it] Generation:  18
Best f1_score score: 0.8344586763679092
Generation:  72%|███████▏  | 18/25 [25:23<13:08, 112.65s/it]Generation:  19
Best f1_score score: 0.8344586763679092
Generation:  76%|███████▌  | 19/25 [26:21<09:36, 96.14s/it] WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454e53640> 

Generation:  20
Best f1_score score: 0.8344586763679092
Generation:  80%|████████  | 20/25 [36:27<20:46, 249.37s/it]Generation:  21
Best f1_score score: 0.8344586763679092
Generation:  84%|████████▍ | 21/25 [37:47<13:13, 198.47s/it]Generation:  22
Best f1_score score: 0.8344586763679092
Generation:  88%|████████▊ | 22/25 [40:35<09:28, 189.34s/it]Generation:  23
Best f1_score score: 0.8344586763679092
Generation:  92%|█████████▏| 23/25 [43:22<06:05, 182.64s/it]Generation:  24
Best f1_score score: 0.8344586763679092
Generation:  96%|█████████▌| 24/25 [45:14<02:41, 161.39s/it]Generation:  25
Best f1_score score: 0.8344586763679092
Generation: 100%|██████████| 25/25 [45:30<00:00, 117.83s/it]Generation: 100%|██████████| 25/25 [45:30<00:00, 109.23s/it]
2024-10-29 03:04:47,861 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33803' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-582d7d183af8cedc419ecc82f5b1ea53', 'DataFrame-d138031ac9b9508039d8def745d81df5'} (stimulus_id='handle-worker-cleanup-1730196287.8609707')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=2.8116427605244,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.1214809656939, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=5,
                               max_leaves=None, min_child_weight=7, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9231909554376329, 'accuracy': 0.8413115903910223, 'balanced_accuracy': 0.8441078823524474, 'logloss': 0.3486460808409437, 'f1': 0.8413059499672433}
test score: {'auroc': 0.9177581239769131, 'accuracy': 0.835203366058906, 'balanced_accuracy': 0.838352753473806, 'logloss': 0.367421025644798, 'f1': 0.8352032850170275}
original test score: {'auroc': 0.9774570377522792, 'accuracy': 0.9424964936886395, 'balanced_accuracy': 0.9415816109929646, 'logloss': 0.182577401343411, 'f1': 0.9421889986453482}
score end
803
lvl
0.5
type
MNAR
num_run
1
class_full
finished
all finished
full run takes
5.719203085965581
hours
DONE
