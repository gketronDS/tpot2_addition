Run: 25
/cm/local/apps/slurm/var/spool/job1068967/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MCAR_0.01_2
0.5920131206512451
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 02:03:30,096] A new study created in memory with name: no-name-e11277b3-b52d-432d-99e4-fc957b87f7c9
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 02:03:31,443] Trial 7 finished with value: 0.642092516272718 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.642092516272718.
running
[I 2024-11-22 02:03:32,593] Trial 16 finished with value: 0.5990957537782664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 16 with value: 0.5990957537782664.
running
[I 2024-11-22 02:03:33,519] Trial 17 finished with value: 0.3608175714817685 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 17 with value: 0.3608175714817685.
running
[I 2024-11-22 02:03:40,811] Trial 11 finished with value: 0.3605788496534802 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 11 with value: 0.3605788496534802.
running
[I 2024-11-22 02:03:42,079] Trial 12 finished with value: 0.36057884955048053 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 12 with value: 0.36057884955048053.
running
[I 2024-11-22 02:03:43,023] Trial 20 finished with value: 0.5990957537782664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.36057884955048053.
running
[I 2024-11-22 02:04:00,077] Trial 13 finished with value: 0.36056196543664354 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 13 with value: 0.36056196543664354.
running
[I 2024-11-22 02:04:03,437] Trial 4 finished with value: 0.4108132675020479 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4141, 'weights': 'distance'}. Best is trial 13 with value: 0.36056196543664354.
running
[I 2024-11-22 02:04:07,106] Trial 2 finished with value: 0.37124382390264216 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 2, 'learning_rate': 0.00011526124515335963, 'p_miss': 0.29434022336240945}. Best is trial 13 with value: 0.36056196543664354.
running
[I 2024-11-22 02:04:07,940] Trial 24 finished with value: 0.642092516272718 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 13 with value: 0.36056196543664354.
running
[I 2024-11-22 02:04:08,769] Trial 14 finished with value: 0.4108186354037544 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9134, 'weights': 'distance'}. Best is trial 13 with value: 0.36056196543664354.
running
[I 2024-11-22 02:04:10,784] Trial 19 finished with value: 0.3604414666670073 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4391, 'weights': 'uniform'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:14,546] Trial 3 finished with value: 0.41082169183901207 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29669, 'weights': 'distance'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:15,611] Trial 21 finished with value: 0.3608175714817685 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28771, 'weights': 'uniform'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:18,056] Trial 0 finished with value: 0.3666480997935455 and parameters: {'model_name': 'VAE', 'batch_size': 621, 'iterations': 2, 'learning_rate': 0.025511833411799908, 'p_miss': 0.15117419586420705}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:18,444] Trial 5 finished with value: 0.4108216963786345 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27224, 'weights': 'distance'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:29,549] Trial 6 finished with value: 0.3936723648613925 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:32,699] Trial 1 finished with value: 0.3967019379533356 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:33,295] Trial 26 finished with value: 0.3605914583836871 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:34,300] Trial 8 finished with value: 0.408708202209689 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:35,001] Trial 23 finished with value: 0.3607892586032699 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18118, 'weights': 'uniform'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:47,303] Trial 22 finished with value: 0.36065890324171634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:04:58,278] Trial 9 finished with value: 0.3734606386439935 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 44, 'learning_rate': 0.00013276262495128113, 'p_miss': 0.18112626337386115}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:08:40,897] Trial 18 finished with value: 0.36941160898487874 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 139, 'learning_rate': 0.0001522842848025178, 'p_miss': 0.27027614899228364}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:16:51,121] Trial 34 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7879473887747841, 'alpha': 11, 'iterations': 3144, 'learning_rate': 0.00040848452997607846, 'p_miss': 0.02189338640757879}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:18:24,365] Trial 32 finished with value: 0.36365730908773325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:24:19,713] Trial 10 finished with value: 0.3654657358515146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:27:43,720] Trial 36 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.28308923448280354, 'alpha': 6, 'iterations': 5740, 'learning_rate': 0.0006341611957129076, 'p_miss': 0.013108801722604091}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:25,299] Trial 43 finished with value: 0.6462551859971097 and parameters: {'model_name': 'GAIN', 'batch_size': 932, 'hint_rate': 0.03511718604247038, 'alpha': 100, 'iterations': 109, 'learning_rate': 0.07959114461504639, 'p_miss': 0.11511236407331521}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:30,306] Trial 44 finished with value: 0.36057884964507514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:35,517] Trial 31 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.15808960467031435, 'alpha': 51, 'iterations': 6768, 'learning_rate': 0.0004997331956724011, 'p_miss': 0.019966642476046376}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:41,073] Trial 46 finished with value: 0.36057884964507514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:44,882] Trial 45 finished with value: 0.36057883354847886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:47,475] Trial 47 finished with value: 0.36057884964507514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:30:59,911] Trial 48 finished with value: 0.36057883354847886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:31:03,324] Trial 49 finished with value: 0.36057883354847886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:31:13,855] Trial 50 finished with value: 0.36057883354847886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.3604414666670073.
running
[I 2024-11-22 02:31:20,232] Trial 51 finished with value: 0.3597991467151679 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 836, 'weights': 'uniform'}. Best is trial 51 with value: 0.3597991467151679.
running
[I 2024-11-22 02:31:28,469] Trial 52 finished with value: 0.3594415087101564 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 274, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:31:34,617] Trial 53 finished with value: 0.36007373958187483 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 149, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:31:43,887] Trial 54 finished with value: 0.35964020387902873 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 428, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:31:50,249] Trial 55 finished with value: 0.3595124336764465 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 337, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:31:59,122] Trial 56 finished with value: 0.35948545562280687 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 315, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:04,862] Trial 57 finished with value: 0.36407769430105513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:14,449] Trial 58 finished with value: 0.35984235554573785 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 855, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:19,971] Trial 59 finished with value: 0.35977829110470444 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 747, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:26,636] Trial 37 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.49572150641115764, 'alpha': 39, 'iterations': 7402, 'learning_rate': 0.0005596679638573295, 'p_miss': 0.02728076522567502}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:32,726] Trial 60 finished with value: 0.36062187483948066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7529, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:38,160] Trial 61 finished with value: 0.3606302284470079 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7645, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:45,069] Trial 62 finished with value: 0.3606113129064598 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7263, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:50,450] Trial 63 finished with value: 0.360555444349113 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5974, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:32:55,974] Trial 64 finished with value: 0.36048444252749734 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4860, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:33:03,474] Trial 65 finished with value: 0.3604120225877622 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3858, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:33:06,697] Trial 66 finished with value: 0.3596053162045941 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 436, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:33:11,270] Trial 67 finished with value: 0.3662221364007309 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 33, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:33:18,619] Trial 68 finished with value: 0.3595683938584558 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 382, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:05,820] Trial 69 finished with value: 0.36368542873596654 and parameters: {'model_name': 'VAE', 'batch_size': 147, 'iterations': 15, 'learning_rate': 0.0049555105264035065, 'p_miss': 0.22696764842624512}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:06,732] Trial 70 finished with value: 0.36321837533776385 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 16, 'learning_rate': 0.006694582765771976, 'p_miss': 0.20921262215317052}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:07,436] Trial 71 finished with value: 0.36259069802555316 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 13, 'learning_rate': 0.0053319445805058855, 'p_miss': 0.20894275509634522}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:26,036] Trial 73 finished with value: 0.36076381716011596 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13350, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:26,276] Trial 72 finished with value: 0.3607614050030431 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13511, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:27,244] Trial 74 finished with value: 0.3607612219304499 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12584, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:35,619] Trial 30 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7399475253166197, 'alpha': 81, 'iterations': 8770, 'learning_rate': 0.0006107886216941725, 'p_miss': 0.021254748364120585}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:43,839] Trial 75 finished with value: 0.3603219948446664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2580, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:44,092] Trial 76 finished with value: 0.3603275317659789 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2692, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:44,600] Trial 77 finished with value: 0.3603373160548359 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2726, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:34:54,189] Trial 78 finished with value: 0.36032006546075634 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2755, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:01,735] Trial 79 finished with value: 0.36032228467455585 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2526, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:02,376] Trial 83 finished with value: 0.36741058604152455 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:02,533] Trial 80 finished with value: 0.3603098985624955 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2477, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:04,071] Trial 81 finished with value: 0.3603333234782857 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2736, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:11,769] Trial 82 finished with value: 0.35949965988376137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 301, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:19,575] Trial 85 finished with value: 0.3600870953319889 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 116, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:21,323] Trial 86 finished with value: 0.35964020387902873 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 428, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:23,353] Trial 84 finished with value: 0.3608175714817685 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 35335, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:29,141] Trial 87 finished with value: 0.4107491366013537 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 141, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:41,764] Trial 90 finished with value: 0.41080412527848076 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1931, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:49,896] Trial 88 finished with value: 0.4108218807179192 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23626, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:50,414] Trial 93 finished with value: 0.3608175714817685 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:51,843] Trial 89 finished with value: 0.4108221376226764 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21417, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:35:59,262] Trial 91 finished with value: 0.4108220192027236 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23144, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:01,837] Trial 38 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.10276656744606427, 'alpha': 83, 'iterations': 8760, 'learning_rate': 0.08203293421348568, 'p_miss': 0.023342667690471774}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:03,083] Trial 92 finished with value: 0.410814038208398 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4960, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:10,199] Trial 94 finished with value: 0.36048921634905884 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4962, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:11,415] Trial 95 finished with value: 0.360486111329995 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4925, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:20,037] Trial 96 finished with value: 0.36053616502487495 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5516, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:21,752] Trial 97 finished with value: 0.3605313004254559 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5459, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:21,937] Trial 98 finished with value: 0.3601534496008078 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1589, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:29,028] Trial 99 finished with value: 0.3600604512435183 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1419, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:29,786] Trial 100 finished with value: 0.3600893705845793 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1477, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:31,992] Trial 33 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.4327423577000066, 'alpha': 67, 'iterations': 9090, 'learning_rate': 0.0005138846364329514, 'p_miss': 0.021063604908047817}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:38,601] Trial 101 finished with value: 0.36005991141434135 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1392, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:41,082] Trial 103 finished with value: 0.360155400958979 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1690, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:41,303] Trial 102 finished with value: 0.35983773760977694 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 891, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:47,602] Trial 104 finished with value: 0.3599906396380586 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1202, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:48,997] Trial 106 finished with value: 0.3610626485001057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 80, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:55,044] Trial 107 finished with value: 0.360402988796441 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 104, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:55,834] Trial 112 finished with value: 0.36741058604152455 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:36:56,687] Trial 108 finished with value: 0.3595402640810163 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 255, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:37:50,773] Trial 35 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.25375186066067684, 'alpha': 7, 'iterations': 9521, 'learning_rate': 0.09890450053923922, 'p_miss': 0.016349439640558905}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:38:06,055] Trial 115 finished with value: 0.3604129198606005 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3708, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:44:30,460] Trial 39 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.10040008142053675, 'alpha': 49, 'iterations': 9995, 'learning_rate': 0.07258095123109631, 'p_miss': 0.021841809967836107}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:58:10,696] Trial 114 finished with value: 0.37523867692596835 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 444, 'learning_rate': 0.0016145406702867437, 'p_miss': 0.08302716821343478}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:58:26,263] Trial 118 finished with value: 0.360399027778887 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3731, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:58:39,589] Trial 119 finished with value: 0.4107170154954968 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:58:55,038] Trial 120 finished with value: 0.36042861402997334 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3949, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:09,612] Trial 121 finished with value: 0.3600273480986843 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1367, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:24,906] Trial 122 finished with value: 0.36037745173206853 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3325, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:36,119] Trial 111 finished with value: 0.3733169796479529 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 408, 'learning_rate': 0.001624833202840219, 'p_miss': 0.06520251570977063}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:42,343] Trial 123 finished with value: 0.3607128779813433 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10281, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:51,916] Trial 124 finished with value: 0.3599423620215249 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1122, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 02:59:58,261] Trial 125 finished with value: 0.3599920652164423 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1198, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:08,078] Trial 126 finished with value: 0.35998928047014944 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1199, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:14,834] Trial 127 finished with value: 0.36025376499657696 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2242, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:24,867] Trial 128 finished with value: 0.3603209342881641 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2566, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:29,512] Trial 129 finished with value: 0.3649486937768098 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:39,126] Trial 130 finished with value: 0.36755781760621437 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:49,837] Trial 131 finished with value: 0.36077960618538857 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16458, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:00:55,506] Trial 132 finished with value: 0.36039168266913546 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3408, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:05,766] Trial 133 finished with value: 0.36034412180180075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3066, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:06,714] Trial 135 finished with value: 0.36741058604152455 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:11,389] Trial 134 finished with value: 0.36021456804080193 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2135, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:22,059] Trial 136 finished with value: 0.3598521564637069 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 872, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:27,164] Trial 137 finished with value: 0.3598788354841761 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 924, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:36,683] Trial 138 finished with value: 0.3597608707671024 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 603, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:42,977] Trial 139 finished with value: 0.35978400900621255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 811, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:01:52,526] Trial 140 finished with value: 0.3602057129022688 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2083, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:00,695] Trial 141 finished with value: 0.36056980065035404 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6848, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:05,542] Trial 143 finished with value: 0.6377098294099738 and parameters: {'model_name': 'GAIN', 'batch_size': 366, 'hint_rate': 0.9423791269683685, 'alpha': 26, 'iterations': 1, 'learning_rate': 0.015743545930725664, 'p_miss': 0.13221880158678428}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:08,333] Trial 142 finished with value: 0.36024213858139037 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2200, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:21,394] Trial 144 finished with value: 0.3597993814817402 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 785, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:23,417] Trial 145 finished with value: 0.3597761585734617 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 684, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:36,961] Trial 146 finished with value: 0.35977104977105945 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 715, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:38,960] Trial 147 finished with value: 0.3597799560814732 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 725, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:52,270] Trial 148 finished with value: 0.35976763077325696 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 694, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:02:54,290] Trial 149 finished with value: 0.36016915785567505 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1872, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:08,245] Trial 150 finished with value: 0.360197772801766 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2007, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:08,899] Trial 116 finished with value: 0.37682457985997325 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 492, 'learning_rate': 0.017593675703607314, 'p_miss': 0.09358481491630434}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:11,641] Trial 151 finished with value: 0.3608175714817685 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32048, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:26,349] Trial 152 finished with value: 0.3608175714817685 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30667, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:26,838] Trial 153 finished with value: 0.3604369908539285 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4140, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:29,011] Trial 154 finished with value: 0.3604378965743017 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4156, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:43,471] Trial 156 finished with value: 0.3597762417520689 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 767, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:44,162] Trial 155 finished with value: 0.3604423861301887 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4341, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:45,184] Trial 157 finished with value: 0.3598520173528058 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 862, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:03:59,347] Trial 158 finished with value: 0.3597710522792871 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 642, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:00,180] Trial 159 finished with value: 0.3597366818526634 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 523, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:02,672] Trial 160 finished with value: 0.36033591036541995 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2916, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:15,943] Trial 161 finished with value: 0.3603505778293469 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3004, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:18,664] Trial 162 finished with value: 0.4108106736499456 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3132, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:48,568] Trial 164 finished with value: 0.5098707238295853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:04:50,710] Trial 165 finished with value: 0.5098707238295853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:04,246] Trial 166 finished with value: 0.35974117810565737 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 536, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:05,250] Trial 167 finished with value: 0.4107170154954968 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:19,135] Trial 168 finished with value: 0.36216246917647255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 62, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:21,070] Trial 169 finished with value: 0.3601621431567542 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1811, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:34,726] Trial 170 finished with value: 0.36019442859066303 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1972, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:47,047] Trial 172 finished with value: 0.6366942600060204 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.641966728928977, 'alpha': 30, 'iterations': 6, 'learning_rate': 0.0397692854804586, 'p_miss': 0.24831358001157955}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:05:47,740] Trial 173 finished with value: 0.3608175714817685 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:06:02,182] Trial 174 finished with value: 0.35977034564523575 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 716, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:06:16,997] Trial 175 finished with value: 0.36015635726495876 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1630, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:06:31,471] Trial 176 finished with value: 0.35976512903280816 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 658, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:06:45,859] Trial 177 finished with value: 0.3597762417520689 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 767, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:07:00,471] Trial 178 finished with value: 0.3600717089562735 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1446, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:07:14,987] Trial 179 finished with value: 0.3596968904762318 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 460, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:07:29,536] Trial 180 finished with value: 0.35975559359793297 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 532, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:07:44,101] Trial 181 finished with value: 0.3601135800642831 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1506, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:07:57,642] Trial 182 finished with value: 0.36578903542387475 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 34, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:11,294] Trial 110 finished with value: 0.37503693612488853 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 791, 'learning_rate': 0.001740602494342063, 'p_miss': 0.09379594116370445}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:26,516] Trial 184 finished with value: 0.360297533059153 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2430, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:32,657] Trial 109 finished with value: 0.3722983666370287 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 811, 'learning_rate': 0.001714979511031172, 'p_miss': 0.08136878669481017}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:42,252] Trial 185 finished with value: 0.36008779359280063 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1479, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:47,891] Trial 186 finished with value: 0.35972349435315853 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 571, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:08:57,252] Trial 187 finished with value: 0.3597537569808605 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 476, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:02,663] Trial 188 finished with value: 0.35974481589444574 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 533, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:11,843] Trial 189 finished with value: 0.37727581368563856 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:17,028] Trial 190 finished with value: 0.36216246917647255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 62, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:28,492] Trial 191 finished with value: 0.41079940982777013 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1486, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:33,216] Trial 192 finished with value: 0.41080161315293895 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1655, 'weights': 'distance'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:39,270] Trial 113 finished with value: 0.37523806887774336 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 705, 'learning_rate': 0.002055176564412213, 'p_miss': 0.07943226110227924}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:44,992] Trial 193 finished with value: 0.36028381046307584 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2385, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:49,694] Trial 194 finished with value: 0.36031240759847705 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2474, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:56,000] Trial 195 finished with value: 0.3602428713308133 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2216, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:09:57,469] Trial 183 finished with value: 0.36270144538254484 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 45, 'learning_rate': 0.0021043832110145544, 'p_miss': 0.1729761074088898}. Best is trial 52 with value: 0.3594415087101564.
running
[I 2024-11-22 03:10:01,685] Trial 196 finished with value: 0.3597764169722527 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 702, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:10:06,399] Trial 197 finished with value: 0.3598152884753528 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 846, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:10:12,366] Trial 198 finished with value: 0.35977119730551343 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 690, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:10:13,211] Trial 199 finished with value: 0.3597628744419631 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 692, 'weights': 'uniform'}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:11:01,277] Trial 105 finished with value: 0.37405067375291434 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 777, 'learning_rate': 0.001855950084558072, 'p_miss': 0.08449032610863344}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:17:55,216] Trial 117 finished with value: 0.37337581651867213 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 778, 'learning_rate': 0.0016539823323965064, 'p_miss': 0.07924843171420175}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:18:54,386] Trial 163 finished with value: 0.6356558937301277 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.6504758673414237, 'alpha': 31, 'iterations': 1134, 'learning_rate': 0.035625154632096256, 'p_miss': 0.16489056140350367}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:23:02,772] Trial 171 finished with value: 0.63320831531158 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.6506590164333027, 'alpha': 28, 'iterations': 1335, 'learning_rate': 0.035332305497219746, 'p_miss': 0.2562825339666533}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:31:34,536] Trial 15 finished with value: 0.6397578206712738 and parameters: {'model_name': 'GAIN', 'batch_size': 413, 'hint_rate': 0.9319665605921216, 'alpha': 16, 'iterations': 5096, 'learning_rate': 0.00039282775862415617, 'p_miss': 0.06906833950549021}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:34:41,218] Trial 41 finished with value: 0.6416033306048158 and parameters: {'model_name': 'GAIN', 'batch_size': 888, 'hint_rate': 0.1490136821966655, 'alpha': 100, 'iterations': 4604, 'learning_rate': 0.03626631227782374, 'p_miss': 0.012434153439119966}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:38:04,844] Trial 27 finished with value: 0.6414464914449534 and parameters: {'model_name': 'GAIN', 'batch_size': 550, 'hint_rate': 0.15798330576647368, 'alpha': 56, 'iterations': 5924, 'learning_rate': 0.09379502177149204, 'p_miss': 0.038943830699753754}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:41:02,318] Trial 29 finished with value: 0.6417866713311284 and parameters: {'model_name': 'GAIN', 'batch_size': 617, 'hint_rate': 0.5799695668249348, 'alpha': 43, 'iterations': 6695, 'learning_rate': 0.0855918452824037, 'p_miss': 0.013917211778831207}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:44:34,449] Trial 40 finished with value: 0.6414448044091379 and parameters: {'model_name': 'GAIN', 'batch_size': 388, 'hint_rate': 0.03557843551903278, 'alpha': 96, 'iterations': 8883, 'learning_rate': 0.06427173969357776, 'p_miss': 0.03341248516026392}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:44:35,035] Trial 25 finished with value: 0.641365586762791 and parameters: {'model_name': 'GAIN', 'batch_size': 509, 'hint_rate': 0.672797324975269, 'alpha': 89, 'iterations': 9364, 'learning_rate': 0.09029908386694767, 'p_miss': 0.021062115035018286}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:44:37,422] Trial 28 finished with value: 0.6435080770044083 and parameters: {'model_name': 'GAIN', 'batch_size': 882, 'hint_rate': 0.06376925872571831, 'alpha': 1, 'iterations': 8922, 'learning_rate': 0.0902837105071014, 'p_miss': 0.011087039513135027}. Best is trial 52 with value: 0.3594415087101564.
[I 2024-11-22 03:44:44,719] Trial 42 finished with value: 0.6402073609951788 and parameters: {'model_name': 'GAIN', 'batch_size': 555, 'hint_rate': 0.0721654429586947, 'alpha': 91, 'iterations': 8793, 'learning_rate': 0.05867014303009506, 'p_miss': 0.04586230379689868}. Best is trial 52 with value: 0.3594415087101564.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.3594415087101564
{'model_name': 'KNNImputer', 'n_neighbors': 274, 'weights': 'uniform'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e80> 

Generation:  1
Best f1_score score: 0.7704790105319999
Generation:   4%|▍         | 1/25 [10:03<4:01:12, 603.02s/it]Generation:  2
Best f1_score score: 0.8006612405010213
Generation:   8%|▊         | 2/25 [10:25<1:40:08, 261.26s/it]Generation:  3
Best f1_score score: 0.8006612405010213
Generation:  12%|█▏        | 3/25 [16:54<1:57:13, 319.69s/it]Generation:  4
Best f1_score score: 0.8047449941324093
Generation:  16%|█▌        | 4/25 [17:21<1:11:25, 204.08s/it]Generation:  5
Best f1_score score: 0.8047449941324093
Generation:  20%|██        | 5/25 [17:45<46:23, 139.17s/it]  Generation:  6
Best f1_score score: 0.8047449941324093
Generation:  24%|██▍       | 6/25 [20:50<49:01, 154.84s/it]Generation:  7
Best f1_score score: 0.8047449941324093
Generation:  28%|██▊       | 7/25 [25:15<57:15, 190.86s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b51f60> 

Generation:  8
Best f1_score score: 0.80826268388999
Generation:  32%|███▏      | 8/25 [35:22<1:31:37, 323.39s/it]Generation:  9
Best f1_score score: 0.8442566421274782
Generation:  36%|███▌      | 9/25 [38:49<1:16:30, 286.89s/it]Generation:  10
Best f1_score score: 0.8442566421274782
Generation:  40%|████      | 10/25 [39:35<53:10, 212.72s/it] Generation:  11
Best f1_score score: 0.8442566421274782
Generation:  44%|████▍     | 11/25 [39:51<35:32, 152.34s/it]Generation:  12
Best f1_score score: 0.8442566421274782
Generation:  48%|████▊     | 12/25 [41:11<28:16, 130.53s/it]Generation:  13
Best f1_score score: 0.8442566421274782
Generation:  52%|█████▏    | 13/25 [48:03<43:08, 215.73s/it]Generation:  14
Best f1_score score: 0.8442566421274782
Generation:  56%|█████▌    | 14/25 [56:37<56:01, 305.62s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554673a3ac0> 

Generation:  15
Best f1_score score: 0.8442566421274782
Generation:  60%|██████    | 15/25 [1:06:46<1:06:12, 397.25s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a56d10> 

Generation:  16
Best f1_score score: 0.8442566421274782
Generation:  64%|██████▍   | 16/25 [1:16:56<1:09:12, 461.33s/it]Generation:  17
Best f1_score score: 0.8442566421274782
Generation:  68%|██████▊   | 17/25 [1:19:11<48:25, 363.18s/it]  Generation:  18
Best f1_score score: 0.8442566421274782
Generation:  72%|███████▏  | 18/25 [1:20:36<32:37, 279.60s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29ff0> 

Generation:  19
Best f1_score score: 0.8442566421274782
Generation:  76%|███████▌  | 19/25 [1:30:47<37:53, 378.99s/it]Generation:  20
Best f1_score score: 0.8442566421274782
Generation:  80%|████████  | 20/25 [1:31:36<23:19, 279.98s/it]Generation:  21
Best f1_score score: 0.8442566421274782
Generation:  84%|████████▍ | 21/25 [1:32:18<13:53, 208.49s/it]Generation:  22
Best f1_score score: 0.8442566421274782
Generation:  88%|████████▊ | 22/25 [1:34:25<09:11, 183.93s/it]Generation:  23
Best f1_score score: 0.8552622010217019
Generation:  92%|█████████▏| 23/25 [1:41:54<08:47, 263.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678ed750> 

Generation:  24
Best f1_score score: 0.8552622010217019
Generation:  96%|█████████▌| 24/25 [1:52:06<06:08, 368.20s/it]Generation:  25
Best f1_score score: 0.8552622010217019
Generation: 100%|██████████| 25/25 [1:57:40<00:00, 357.76s/it]Generation: 100%|██████████| 25/25 [1:57:43<00:00, 282.54s/it]
2024-11-22 05:44:15,690 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36635' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-c3f1b880f69423b09749f1c2a85b887c', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732283055.6900685')
Fitted
Pipeline(steps=[('mlpclassifier',
                 MLPClassifier(activation='tanh', alpha=0.0115412206775,
                               hidden_layer_sizes=[191, 191, 191],
                               learning_rate='invscaling',
                               learning_rate_init=0.0091283264736,
                               n_iter_no_change=32))])
score start
train score: {'auroc': 0.9836507323903471, 'accuracy': 0.9031934179333426, 'balanced_accuracy': 0.8908797628714232, 'logloss': 0.21891987337693544, 'f1': 0.8737136307501515}
original test score: {'auroc': 0.9854510720992686, 'accuracy': 0.9001561802766622, 'balanced_accuracy': 0.8932653592528695, 'logloss': 0.20540082962928594, 'f1': 0.8690694778859417}
imputed test score: {'auroc': 0.9790013938169522, 'accuracy': 0.8895582329317269, 'balanced_accuracy': 0.8798443216914902, 'logloss': 0.25322042919883325, 'f1': 0.8557315073622211}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f9120> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1000> 

Generation:  1
Best f1_score score: 0.7606074049615823
Generation:   4%|▍         | 1/25 [10:04<4:01:41, 604.23s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe470> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f31360> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.7606074049615823
Generation:   8%|▊         | 2/25 [11:57<2:00:48, 315.17s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469e5c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fcd390> 

Generation:  3
Best f1_score score: 0.7629781528638874
Generation:  12%|█▏        | 3/25 [22:02<2:44:05, 447.52s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa61d0> 
 Input X contains NaN.
MultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 732, in fit
    X, y = self._check_X_y(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 578, in _check_X_y
    return self._validate_data(X, y, accept_sparse="csr", reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  4
Best f1_score score: 0.8275632242432275
Generation:  16%|█▌        | 4/25 [30:26<2:44:29, 469.98s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d989a0> 

Generation:  5
Best f1_score score: 0.8275632242432275
Generation:  20%|██        | 5/25 [40:31<2:52:55, 518.78s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657fc3a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747156f0> 

Generation:  6
Best f1_score score: 0.8303227452020117
Generation:  24%|██▍       | 6/25 [50:36<2:53:30, 547.94s/it]Generation:  7
Best f1_score score: 0.8354303184875521
Generation:  28%|██▊       | 7/25 [1:00:32<2:49:07, 563.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465857eb0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464bf9c60> 

Generation:  8
Best f1_score score: 0.8354303184875521
Generation:  32%|███▏      | 8/25 [1:10:37<2:43:27, 576.91s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f02290> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554540e7400> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466d1cca0> 

Generation:  9
Best f1_score score: 0.8354303184875521
Generation:  36%|███▌      | 9/25 [1:20:41<2:36:06, 585.44s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546519bd60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe8610> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d64c70> 

Generation:  10
Best f1_score score: 0.8354303184875521
Generation:  40%|████      | 10/25 [1:30:47<2:27:54, 591.62s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466834dc0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2200> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465864520> 

Generation:  11
Best f1_score score: 0.8354303184875521
Generation:  44%|████▍     | 11/25 [1:40:51<2:18:58, 595.58s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554541b15d0> 

Generation:  12
Best f1_score score: 0.8354303184875521
Generation:  48%|████▊     | 12/25 [1:50:57<2:09:41, 598.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464bb49a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554667f7880> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466485cc0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ddace0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eeb250> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bbd5240> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714580> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466a9cd60> 

Generation:  13
Best f1_score score: 0.8369022012747548
Generation:  52%|█████▏    | 13/25 [2:01:03<2:00:12, 601.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655dc280> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469e980> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b86590> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f254e0> 

Generation:  14
Best f1_score score: 0.8369022012747548
Generation:  56%|█████▌    | 14/25 [2:11:08<1:50:23, 602.17s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15543bdac5b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545222d900> 

Generation:  15
Best f1_score score: 0.8369022012747548
Generation:  60%|██████    | 15/25 [2:21:15<1:40:34, 603.47s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545414e980> 

Generation:  16
Best f1_score score: 0.8369022012747548
Generation:  64%|██████▍   | 16/25 [2:31:20<1:30:36, 604.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554656d4fa0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714760> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa5cc0> 

Generation:  17
Best f1_score score: 0.8369022012747548
Generation:  68%|██████▊   | 17/25 [2:41:27<1:20:39, 604.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f04370> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545086eda0> 

Generation:  18
Best f1_score score: 0.8369022012747548
Generation:  72%|███████▏  | 18/25 [2:51:31<1:10:32, 604.60s/it]Generation:  19
Best f1_score score: 0.8369022012747548
Generation:  76%|███████▌  | 19/25 [3:00:43<58:53, 588.92s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554653b0610> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b23520> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554674d67a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546794d1b0> 

Generation:  20
Best f1_score score: 0.8369022012747548
Generation:  80%|████████  | 20/25 [3:10:51<49:32, 594.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f24b80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452de1b10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2080> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554641e11e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465f190> 

Generation:  21
Best f1_score score: 0.8369022012747548
Generation:  84%|████████▍ | 21/25 [3:20:56<39:50, 597.59s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679693f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465854f10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547473b4c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464252980> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546734ed70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474735de0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e68820> 

Generation:  22
Best f1_score score: 0.8369022012747548
Generation:  88%|████████▊ | 22/25 [3:31:04<30:02, 600.75s/it]Generation:  23
Best f1_score score: 0.8369022012747548
Generation:  92%|█████████▏| 23/25 [3:40:08<19:27, 583.81s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652f5750> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450e6e3e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554640e56f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554647828f0> 

Generation:  24
Best f1_score score: 0.8369022012747548
Generation:  96%|█████████▌| 24/25 [3:50:15<09:50, 590.71s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554648a3d30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678df130> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b2fc10> 

Generation:  25
Best f1_score score: 0.8369022012747548
Generation: 100%|██████████| 25/25 [4:00:20<00:00, 595.15s/it]Generation: 100%|██████████| 25/25 [4:00:20<00:00, 576.83s/it]
2024-11-22 09:46:12,361 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35733' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0', 'DataFrame-e01240ee98d8845b10e429dbb73ecf53'} (stimulus_id='handle-worker-cleanup-1732297572.361748')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=63)),
                ('mlpclassifier',
                 MLPClassifier(alpha=0.002052522407, early_stopping=True,
                               hidden_layer_sizes=[247, 247],
                               learning_rate='invscaling',
                               learning_rate_init=0.0132674973052,
                               n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9807077196252375, 'accuracy': 0.8907544275554315, 'balanced_accuracy': 0.8854497593735902, 'logloss': 0.2402739138592924, 'f1': 0.8644153815622783}
test score: {'auroc': 0.9749341177356907, 'accuracy': 0.8759482373940205, 'balanced_accuracy': 0.868944664870314, 'logloss': 0.2785076863846672, 'f1': 0.8459503549989368}
original test score: {'auroc': 0.9811977248121546, 'accuracy': 0.8846497099509147, 'balanced_accuracy': 0.8797011308496027, 'logloss': 0.23146969064996373, 'f1': 0.8562057467490597}
score end
41027
lvl
0.01
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
7.722046894166205
hours
DONE
