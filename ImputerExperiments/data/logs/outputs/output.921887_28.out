Run: 28
/cm/local/apps/slurm/var/spool/job921887/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
starting loops
../data/c/30/30.pkl
working on 
../data/c/30/class_full_MCAR_0.5_2
3.7966063022613525
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-08-13 14:29:26,796] A new study created in memory with name: no-name-fa686497-b9fa-4172-b97a-99cc4af6ab90
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-08-13 14:29:27,240] Trial 12 finished with value: 0.11709622357748665 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 12 with value: 0.11709622357748665.
[I 2024-08-13 14:29:27,348] Trial 11 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 12 with value: 0.11709622357748665.
running
running
[I 2024-08-13 14:29:27,544] Trial 14 finished with value: 0.11709622357748665 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:27,699] Trial 10 finished with value: 0.19527041409743848 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:27,971] Trial 7 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:28,144] Trial 6 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:28,308] Trial 17 finished with value: 0.19527041409743848 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:29,114] Trial 21 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:29,678] Trial 23 finished with value: 0.19527041409743848 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:31,512] Trial 18 finished with value: 0.11709622357748665 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4620, 'weights': 'uniform'}. Best is trial 12 with value: 0.11709622357748665.
running
[I 2024-08-13 14:29:31,670] Trial 2 finished with value: 0.11547845010363048 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 531, 'weights': 'uniform'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:31,868] Trial 9 finished with value: 0.11995007260215615 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 855, 'weights': 'distance'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:32,243] Trial 16 finished with value: 0.120281535889553 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 443, 'weights': 'distance'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:32,539] Trial 22 finished with value: 0.115664183858601 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 445, 'weights': 'uniform'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:32,838] Trial 4 finished with value: 0.12009657497827933 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4913, 'weights': 'distance'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:35,415] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.04083041675744535, 'alpha': 100, 'iterations': 3, 'learning_rate': 0.003331244162719145, 'p_miss': 0.026877377550720644}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:36,170] Trial 30 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.937979355243969, 'alpha': 52, 'iterations': 8, 'learning_rate': 0.0002751581246954764, 'p_miss': 0.09789086549677377}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:38,114] Trial 8 finished with value: 0.21759669693725314 and parameters: {'model_name': 'GAIN', 'batch_size': 831, 'hint_rate': 0.7882713040903259, 'alpha': 97, 'iterations': 1, 'learning_rate': 0.03426889849631039, 'p_miss': 0.2798128830471261}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:39,452] Trial 3 finished with value: 0.20953114193771452 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.4304756106432054, 'alpha': 93, 'iterations': 2, 'learning_rate': 0.020302650225189022, 'p_miss': 0.2126732270931119}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:40,267] Trial 1 finished with value: 0.21269849442226327 and parameters: {'model_name': 'GAIN', 'batch_size': 61, 'hint_rate': 0.16486992263515968, 'alpha': 14, 'iterations': 3, 'learning_rate': 0.09534303062904859, 'p_miss': 0.1620118823935684}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:41,388] Trial 19 finished with value: 0.21375512426164495 and parameters: {'model_name': 'GAIN', 'batch_size': 42, 'hint_rate': 0.8669309407600317, 'alpha': 86, 'iterations': 4, 'learning_rate': 0.009939755045390105, 'p_miss': 0.03821890798858731}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:45,316] Trial 24 finished with value: 0.11604510885702239 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:50,628] Trial 25 finished with value: 0.11551381541103704 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.11547845010363048.
running
[I 2024-08-13 14:29:55,892] Trial 0 finished with value: 0.11437207872681485 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:03,936] Trial 37 finished with value: 0.11604510885702239 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:10,211] Trial 32 finished with value: 0.11450365744961584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:16,698] Trial 28 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8660551535677841, 'alpha': 84, 'iterations': 449, 'learning_rate': 0.0092054236748769, 'p_miss': 0.18735004460408558}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:21,454] Trial 27 finished with value: 0.12270102745883038 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:23,081] Trial 33 finished with value: 0.12608666512336175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:31,996] Trial 13 finished with value: 0.12208056806542769 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 0 with value: 0.11437207872681485.
running
[I 2024-08-13 14:30:32,881] Trial 29 finished with value: 0.11419169531627087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 29 with value: 0.11419169531627087.
running
[I 2024-08-13 14:30:34,143] Trial 39 finished with value: 0.11439509832857135 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.11419169531627087.
running
[I 2024-08-13 14:30:36,152] Trial 26 finished with value: 0.21025384013041665 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.6866699349505828, 'alpha': 53, 'iterations': 60, 'learning_rate': 0.0007653616978609366, 'p_miss': 0.20916970649164326}. Best is trial 29 with value: 0.11419169531627087.
running
[I 2024-08-13 14:30:39,498] Trial 20 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.32366469417739147, 'alpha': 85, 'iterations': 678, 'learning_rate': 0.0693778449222642, 'p_miss': 0.08289725470776353}. Best is trial 29 with value: 0.11419169531627087.
running
[I 2024-08-13 14:31:00,334] Trial 40 finished with value: 0.12490585451232705 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.11419169531627087.
running
[I 2024-08-13 14:31:07,644] Trial 47 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:08,844] Trial 48 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:09,601] Trial 46 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:10,645] Trial 41 finished with value: 0.12748753595861256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:12,953] Trial 49 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:13,512] Trial 15 finished with value: 0.16148184635020707 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:30,033] Trial 50 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:36,359] Trial 35 finished with value: 0.16661602453279417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:38,189] Trial 51 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:38,406] Trial 36 finished with value: 0.16181743892044623 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:43,506] Trial 55 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:46,293] Trial 53 finished with value: 0.11419169531627087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:46,965] Trial 54 finished with value: 0.11419169531627087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:48,128] Trial 52 finished with value: 0.11419169531627087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:31:50,604] Trial 56 finished with value: 0.11419169531627087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:32:01,779] Trial 57 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:32:03,210] Trial 44 finished with value: 0.1605024527497657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:32:06,677] Trial 58 finished with value: 0.11419165482619498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 47 with value: 0.11419165482619498.
running
[I 2024-08-13 14:33:01,697] Trial 59 finished with value: 0.11416715221256887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 14:33:03,630] Trial 60 finished with value: 0.11416715221256887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 14:33:07,722] Trial 70 finished with value: 0.11549093327834459 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3084, 'weights': 'uniform'}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:04:31,596] Trial 38 finished with value: 0.12235505916052766 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:15:35,326] Trial 45 finished with value: 0.12264023339912825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:16:57,219] Trial 73 finished with value: 0.11416715221256887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:18:33,082] Trial 74 finished with value: 0.11420317697017024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:18:37,727] Trial 75 finished with value: 0.11975130722998165 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2214, 'weights': 'distance'}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:19:53,346] Trial 76 finished with value: 0.11416715221256887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:21:28,107] Trial 77 finished with value: 0.11416715221256887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 59 with value: 0.11416715221256887.
running
[I 2024-08-13 15:22:41,930] Trial 78 finished with value: 0.11414826669157019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:24:05,467] Trial 79 finished with value: 0.11414826669157019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:25:30,544] Trial 80 finished with value: 0.11414826669157019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:27:05,838] Trial 81 finished with value: 0.11415606151940891 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:27:06,304] Trial 82 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:28:32,717] Trial 34 finished with value: 0.11517752614105167 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:28:42,114] Trial 42 finished with value: 0.11744619435676402 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:30:40,762] Trial 84 finished with value: 0.11431243434780498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:32:45,352] Trial 86 finished with value: 0.11415606151940891 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:34:51,507] Trial 87 finished with value: 0.11415606151940891 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:43:23,479] Trial 31 finished with value: 0.11485569972724878 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:43:53,823] Trial 64 finished with value: 0.11591534037003029 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:44:14,782] Trial 43 finished with value: 0.1143241877628847 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:44:16,354] Trial 66 finished with value: 0.11612443956648681 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:44:43,592] Trial 62 finished with value: 0.11550003081889719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:44:49,581] Trial 68 finished with value: 0.11526327548846335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:45:09,190] Trial 69 finished with value: 0.11572555695989764 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:45:19,385] Trial 65 finished with value: 0.11552776603587152 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:45:21,158] Trial 63 finished with value: 0.11418951461000941 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:45:22,080] Trial 61 finished with value: 0.11535483514554903 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.11414826669157019.
running
[I 2024-08-13 15:45:27,787] Trial 71 finished with value: 0.11376014968123731 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 71 with value: 0.11376014968123731.
running
[I 2024-08-13 15:49:24,251] Trial 67 finished with value: 0.11340311771168202 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 16:17:24,253] Trial 72 finished with value: 0.1150671106758178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 16:29:21,107] Trial 83 finished with value: 0.11781097283366242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:13:23,839] Trial 98 finished with value: 0.2693569214505135 and parameters: {'model_name': 'GAIN', 'batch_size': 863, 'hint_rate': 0.6120789478023292, 'alpha': 5, 'iterations': 4617, 'learning_rate': 0.0001529351637209253, 'p_miss': 0.29559806772957264}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:13:24,130] Trial 103 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:13:30,019] Trial 104 finished with value: 0.11973136067189874 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3476, 'weights': 'distance'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:32:58,699] Trial 94 finished with value: 0.2745750400254108 and parameters: {'model_name': 'GAIN', 'batch_size': 870, 'hint_rate': 0.5883682886516279, 'alpha': 5, 'iterations': 5308, 'learning_rate': 0.00011537906820338571, 'p_miss': 0.28420907296482867}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:33:33,645] Trial 106 finished with value: 0.11419165550619344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:33:44,746] Trial 107 finished with value: 0.11462009917419196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:34:14,948] Trial 108 finished with value: 0.12724980337263275 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:35:38,857] Trial 109 finished with value: 0.11431243434780498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:36:18,334] Trial 85 finished with value: 0.2741282076197685 and parameters: {'model_name': 'GAIN', 'batch_size': 996, 'hint_rate': 0.5844694541661023, 'alpha': 6, 'iterations': 6191, 'learning_rate': 0.0001033341683047529, 'p_miss': 0.28888431021505956}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:36:21,669] Trial 110 finished with value: 0.11419165550619344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:36:45,334] Trial 92 finished with value: 0.2664837378080171 and parameters: {'model_name': 'GAIN', 'batch_size': 779, 'hint_rate': 0.6557798217827446, 'alpha': 1, 'iterations': 5581, 'learning_rate': 0.0001816861110341804, 'p_miss': 0.2961477999528959}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:36:59,537] Trial 112 finished with value: 0.11419162914101125 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:37:02,782] Trial 111 finished with value: 0.11419165550619344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:37:03,359] Trial 115 finished with value: 0.11709622357748665 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:37:31,963] Trial 113 finished with value: 0.11419165550619344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:38:20,919] Trial 114 finished with value: 0.11431243434780498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:38:23,818] Trial 116 finished with value: 0.11431243434780498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:38:53,380] Trial 117 finished with value: 0.11384278154370642 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:39:19,344] Trial 90 finished with value: 0.2659429457254442 and parameters: {'model_name': 'GAIN', 'batch_size': 833, 'hint_rate': 0.6114400480238742, 'alpha': 1, 'iterations': 5851, 'learning_rate': 0.00018731399641612334, 'p_miss': 0.299080298530198}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:39:39,951] Trial 118 finished with value: 0.11419324686853013 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:39:45,317] Trial 119 finished with value: 0.11412063706622382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:40:06,956] Trial 122 finished with value: 0.1142960040753808 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:40:46,822] Trial 120 finished with value: 0.15881679428162643 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:40:49,587] Trial 123 finished with value: 0.1236986125180696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:40:51,940] Trial 125 finished with value: 0.11522110425196763 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1781, 'weights': 'uniform'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:41:08,977] Trial 121 finished with value: 0.16130709435407023 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:41:12,418] Trial 124 finished with value: 0.12586061028185186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:42:04,106] Trial 126 finished with value: 0.11412063706622382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:42:07,576] Trial 127 finished with value: 0.11412063706622382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:42:17,523] Trial 128 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:42:20,425] Trial 129 finished with value: 0.11412063706622382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:42:22,539] Trial 88 finished with value: 0.27182410460591555 and parameters: {'model_name': 'GAIN', 'batch_size': 947, 'hint_rate': 0.5748374611589094, 'alpha': 0, 'iterations': 6165, 'learning_rate': 0.00011701275007731132, 'p_miss': 0.29638048764360847}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:43:07,284] Trial 130 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:43:08,808] Trial 131 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:43:20,430] Trial 132 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:43:24,497] Trial 133 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:43:26,856] Trial 134 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:44:11,620] Trial 136 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:44:13,205] Trial 135 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:44:30,067] Trial 137 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:44:31,431] Trial 138 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:44:33,830] Trial 139 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:45:31,680] Trial 143 finished with value: 0.11405333541362657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:45:40,465] Trial 140 finished with value: 0.15761881736682606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:45:44,663] Trial 141 finished with value: 0.15696513553597521 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:45:54,973] Trial 142 finished with value: 0.15761881736682606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:45:58,594] Trial 145 finished with value: 0.11438581052875996 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:01,945] Trial 144 finished with value: 0.15761881736682606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:24,013] Trial 102 finished with value: 0.26297824917134793 and parameters: {'model_name': 'GAIN', 'batch_size': 796, 'hint_rate': 0.5974324528276325, 'alpha': 0, 'iterations': 5284, 'learning_rate': 0.00012434826322673675, 'p_miss': 0.2727373913838803}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:41,905] Trial 146 finished with value: 0.11405333541362657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:44,512] Trial 147 finished with value: 0.11405333541362657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:49,183] Trial 148 finished with value: 0.11418789763427428 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:54,252] Trial 149 finished with value: 0.11418789763427428 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:46:54,947] Trial 155 finished with value: 0.19527041409743848 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:47:10,013] Trial 150 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 19:48:11,515] Trial 151 finished with value: 0.11412395349405562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:32:03,670] Trial 99 finished with value: 0.23298371613150382 and parameters: {'model_name': 'GAIN', 'batch_size': 897, 'hint_rate': 0.5757948872553436, 'alpha': 1, 'iterations': 7078, 'learning_rate': 0.00010017449282810324, 'p_miss': 0.10673676114027411}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:34:43,013] Trial 159 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:41:39,280] Trial 154 finished with value: 0.11634273399080135 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:43:47,637] Trial 153 finished with value: 0.11600843460319735 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:43:52,937] Trial 162 finished with value: 0.11572886716349529 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3602, 'weights': 'uniform'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:44:16,525] Trial 161 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:46:05,229] Trial 163 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:46:29,480] Trial 164 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:47:01,008] Trial 96 finished with value: 0.27075425275568465 and parameters: {'model_name': 'GAIN', 'batch_size': 975, 'hint_rate': 0.5871971461057774, 'alpha': 7, 'iterations': 7630, 'learning_rate': 0.00010594897778745105, 'p_miss': 0.28045939400092224}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:48:13,765] Trial 165 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:48:14,709] Trial 97 finished with value: 0.25782600710927844 and parameters: {'model_name': 'GAIN', 'batch_size': 931, 'hint_rate': 0.5827220058259382, 'alpha': 1, 'iterations': 7838, 'learning_rate': 0.0009068902607728638, 'p_miss': 0.26805326233691495}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:48:29,094] Trial 166 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:48:49,193] Trial 167 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:49:50,690] Trial 169 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:49:51,720] Trial 168 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:50:11,058] Trial 170 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:51:00,237] Trial 171 finished with value: 0.11417166183104785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:52:55,938] Trial 172 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:53:09,870] Trial 152 finished with value: 0.11840368658562087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:54:27,108] Trial 156 finished with value: 0.11882671040367061 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:54:42,015] Trial 157 finished with value: 0.11918202430046616 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:55:18,087] Trial 176 finished with value: 0.1142050990963075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:55:21,486] Trial 158 finished with value: 0.11836115072112326 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:55:27,878] Trial 177 finished with value: 0.1142050990963075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:56:02,707] Trial 178 finished with value: 0.1142050990963075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:56:11,797] Trial 179 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:56:36,405] Trial 180 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:56:42,359] Trial 181 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:56:45,341] Trial 182 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:57:19,256] Trial 183 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:57:25,937] Trial 184 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:57:49,756] Trial 185 finished with value: 0.11408540618503507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:03,888] Trial 186 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:04,323] Trial 191 finished with value: 0.21563466196217052 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:10,301] Trial 187 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:39,946] Trial 190 finished with value: 0.125445331651983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:42,039] Trial 192 finished with value: 0.1142960040753808 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:46,214] Trial 194 finished with value: 0.11962098830333194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1700, 'weights': 'distance'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:58:57,618] Trial 193 finished with value: 0.12320046276952212 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:59:04,777] Trial 189 finished with value: 0.11408540618503507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 20:59:10,476] Trial 188 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
running
[I 2024-08-13 21:00:03,410] Trial 195 finished with value: 0.11408540618503507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:00:07,225] Trial 196 finished with value: 0.11408540618503507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:00:18,629] Trial 197 finished with value: 0.11398713743735678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:00:26,032] Trial 198 finished with value: 0.11417166183104785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:00:35,869] Trial 199 finished with value: 0.11417166183104785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:18:01,271] Trial 91 finished with value: 0.2804467945726171 and parameters: {'model_name': 'GAIN', 'batch_size': 828, 'hint_rate': 0.5308831456021212, 'alpha': 2, 'iterations': 9210, 'learning_rate': 0.0001691970833408489, 'p_miss': 0.2963785849890178}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:18:18,366] Trial 93 finished with value: 0.2703937896214489 and parameters: {'model_name': 'GAIN', 'batch_size': 891, 'hint_rate': 0.6071468809147111, 'alpha': 4, 'iterations': 9303, 'learning_rate': 0.00010257595521926705, 'p_miss': 0.2955222486425459}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:22:46,288] Trial 100 finished with value: 0.2719455720543883 and parameters: {'model_name': 'GAIN', 'batch_size': 996, 'hint_rate': 0.6167510725523915, 'alpha': 8, 'iterations': 9154, 'learning_rate': 0.00011586894387972003, 'p_miss': 0.2853845244493225}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:24:16,473] Trial 101 finished with value: 0.26184959792755175 and parameters: {'model_name': 'GAIN', 'batch_size': 888, 'hint_rate': 0.6070876952450766, 'alpha': 0, 'iterations': 8868, 'learning_rate': 0.0001157859498768382, 'p_miss': 0.27696557126090915}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:24:17,995] Trial 89 finished with value: 0.2719551947687272 and parameters: {'model_name': 'GAIN', 'batch_size': 835, 'hint_rate': 0.6371521458110856, 'alpha': 10, 'iterations': 9717, 'learning_rate': 0.0001026874375578475, 'p_miss': 0.28082160776488185}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:24:30,414] Trial 95 finished with value: 0.266907063159209 and parameters: {'model_name': 'GAIN', 'batch_size': 823, 'hint_rate': 0.5679023882304847, 'alpha': 1, 'iterations': 9988, 'learning_rate': 0.0009984485660157892, 'p_miss': 0.28669316390948724}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:25:30,499] Trial 105 finished with value: 0.23569990927615075 and parameters: {'model_name': 'GAIN', 'batch_size': 167, 'hint_rate': 0.2776280959903333, 'alpha': 28, 'iterations': 7795, 'learning_rate': 0.0009312047453410068, 'p_miss': 0.12463747339631813}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:29:01,031] Trial 160 finished with value: 0.11704357449452182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:34:04,170] Trial 174 finished with value: 0.11800069413387178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:34:04,765] Trial 173 finished with value: 0.11708726439109622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.11340311771168202.
[I 2024-08-13 21:34:21,513] Trial 175 finished with value: 0.11769955129877607 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.11340311771168202.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.11340311771168202
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9538221710197904
Generation:   4%|         | 1/25 [09:15<3:42:15, 555.66s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475b47340> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  2
Best f1_score score: 0.9538221710197904
Generation:   8%|         | 2/25 [09:38<1:32:56, 242.48s/it]Generation:  3
Best f1_score score: 0.9538221710197904
Generation:  12%|        | 3/25 [13:22<1:25:47, 233.97s/it]Generation:  4
Best f1_score score: 0.9551367876786688
Generation:  16%|        | 4/25 [15:15<1:05:05, 185.96s/it]Generation:  5
Best f1_score score: 0.9551367876786688
Generation:  20%|        | 5/25 [15:39<42:31, 127.59s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547523a290> 
 Out of bag estimation only available if bootstrap=True 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 66, in inner_f
    return f(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 402, in fit
    return self._fit(X, y, max_samples=self.max_samples, **fit_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 502, in _fit
    raise ValueError("Out of bag estimation only available if bootstrap=True")
ValueError: Out of bag estimation only available if bootstrap=True

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554750260e0> 

Generation:  6
Best f1_score score: 0.9551367876786688
Generation:  24%|       | 6/25 [25:43<1:31:44, 289.72s/it]Generation:  7
Best f1_score score: 0.9551367876786688
Generation:  28%|       | 7/25 [26:35<1:03:36, 212.04s/it]Generation:  8
Best f1_score score: 0.9551367876786688
Generation:  32%|      | 8/25 [27:15<44:34, 157.34s/it]  Generation:  9
Best f1_score score: 0.9551367876786688
Generation:  36%|      | 9/25 [28:08<33:13, 124.60s/it]Generation:  10
Best f1_score score: 0.9551367876786688
Generation:  40%|      | 10/25 [28:42<24:11, 96.75s/it]Generation:  11
Best f1_score score: 0.9562960601785621
Generation:  44%|     | 11/25 [29:12<17:46, 76.20s/it]Generation:  12
Best f1_score score: 0.9562960601785621
Generation:  48%|     | 12/25 [30:00<14:37, 67.53s/it]Generation:  13
Best f1_score score: 0.9562960601785621
Generation:  52%|    | 13/25 [30:37<11:40, 58.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474ef5450> 
 Out of bag estimation only available if bootstrap=True 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 66, in inner_f
    return f(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 402, in fit
    return self._fit(X, y, max_samples=self.max_samples, **fit_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 502, in _fit
    raise ValueError("Out of bag estimation only available if bootstrap=True")
ValueError: Out of bag estimation only available if bootstrap=True

Generation:  14
Best f1_score score: 0.9562960601785621
Generation:  56%|    | 14/25 [31:22<09:58, 54.43s/it]Generation:  15
Best f1_score score: 0.9562960601785621
Generation:  60%|    | 15/25 [32:03<08:23, 50.40s/it]Generation:  16
Best f1_score score: 0.9562960601785621
Generation:  64%|   | 16/25 [32:31<06:30, 43.41s/it]Generation:  17
Best f1_score score: 0.9562960601785621
Generation:  68%|   | 17/25 [33:06<05:27, 40.90s/it]Generation:  18
Best f1_score score: 0.9562960601785621
Generation:  72%|  | 18/25 [33:48<04:49, 41.41s/it]Generation:  19
Best f1_score score: 0.9562960601785621
Generation:  76%|  | 19/25 [34:45<04:36, 46.12s/it]Generation:  20
Best f1_score score: 0.9562960601785621
Generation:  80%|  | 20/25 [36:18<05:01, 60.23s/it]Generation:  21
Best f1_score score: 0.9562960601785621
Generation:  84%| | 21/25 [37:56<04:45, 71.34s/it]Generation:  22
Best f1_score score: 0.9562960601785621
Generation:  88%| | 22/25 [38:33<03:02, 60.99s/it]Generation:  23
Best f1_score score: 0.956607417373774
Generation:  92%|| 23/25 [40:49<02:47, 83.68s/it]Generation:  24
Best f1_score score: 0.9576059355317794
Generation:  96%|| 24/25 [41:39<01:13, 73.66s/it]Generation:  25
Best f1_score score: 0.9576059355317794
Generation: 100%|| 25/25 [42:31<00:00, 67.16s/it]Generation: 100%|| 25/25 [42:34<00:00, 102.20s/it]
2024-08-13 22:20:04,435 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:43087' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-2fe3cc29227dd9f86c0f2526add0c3f8', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723612804.435454')
Fitted
Pipeline(steps=[('baggingclassifier',
                 BaggingClassifier(bootstrap=False,
                                   max_features=0.9814486684762,
                                   max_samples=0.5727137841621, n_estimators=64,
                                   n_jobs=1))])
score start
train score: {'auroc': 0.9999286679610124, 'accuracy': 0.9979695431472081, 'balanced_accuracy': 0.9895363807327421, 'logloss': 0.031967781372873254, 'f1': 0.9979652637760272}
original test score: {'auroc': 0.9920783153420587, 'accuracy': 0.9671532846715328, 'balanced_accuracy': 0.7583641290958364, 'logloss': 0.15771477298107348, 'f1': 0.9665092314297982}
imputed test score: {'auroc': 0.9300985201185192, 'accuracy': 0.9543795620437956, 'balanced_accuracy': 0.5971544715447153, 'logloss': 0.4243018382929756, 'f1': 0.9505268424770426}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155436506200>
Start tpot fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475d3e740> 
 Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 732, in fit
    X, y = self._check_X_y(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 1184, in _check_X_y
    X, y = super()._check_X_y(X, y, reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 578, in _check_X_y
    return self._validate_data(X, y, accept_sparse="csr", reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475d3e3b0> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.937057266761711
Generation:   4%|         | 1/25 [04:47<1:54:52, 287.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475e29840> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.9458030774469675
Generation:   8%|         | 2/25 [07:28<1:21:38, 212.98s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475e29240> 

Generation:  3
Best f1_score score: 0.9458030774469675
Generation:  12%|        | 3/25 [17:32<2:23:32, 391.48s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475e0eef0> 

Generation:  4
Best f1_score score: 0.9458030774469675
Generation:  16%|        | 4/25 [27:34<2:46:08, 474.71s/it]Generation:  5
Best f1_score score: 0.9458030774469675
Generation:  20%|        | 5/25 [28:08<1:45:13, 315.67s/it]Generation:  6
Best f1_score score: 0.9458030774469675
Generation:  24%|       | 6/25 [28:40<1:09:25, 219.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453fac7f0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.9458965335975054
Generation:  28%|       | 7/25 [29:07<46:58, 156.60s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453f4b940> 

Generation:  8
Best f1_score score: 0.9465555590758756
Generation:  32%|      | 8/25 [39:10<1:24:36, 298.63s/it]Generation:  9
Best f1_score score: 0.9500233291863989
Generation:  36%|      | 9/25 [40:03<59:11, 221.95s/it]  Generation:  10
Best f1_score score: 0.9500233291863989
Generation:  40%|      | 10/25 [40:33<40:38, 162.55s/it]Generation:  11
Best f1_score score: 0.9500233291863989
Generation:  44%|     | 11/25 [41:05<28:35, 122.55s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554588e1870> 

Generation:  12
Best f1_score score: 0.9500233291863989
Generation:  48%|     | 12/25 [51:08<58:15, 268.92s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554422c4a30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e91780> 

Generation:  13
Best f1_score score: 0.9500233291863989
Generation:  52%|    | 13/25 [1:01:14<1:14:10, 370.90s/it]Generation:  14
Best f1_score score: 0.9500233291863989
Generation:  56%|    | 14/25 [1:01:39<48:51, 266.54s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553e2f6af80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475a46350> 

Generation:  15
Best f1_score score: 0.9500233291863989
Generation:  60%|    | 15/25 [1:11:45<1:01:28, 368.85s/it]Generation:  16
Best f1_score score: 0.9500233291863989
Generation:  64%|   | 16/25 [1:12:13<39:56, 266.24s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475e27910> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547585e680> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474fe5b40> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554588ea290> 

Generation:  17
Best f1_score score: 0.9500233291863989
Generation:  68%|   | 17/25 [1:22:18<49:03, 367.95s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475418130> 

Generation:  18
Best f1_score score: 0.9500233291863989
Generation:  72%|  | 18/25 [1:32:23<51:14, 439.25s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554756b5c90> 

Generation:  19
Best f1_score score: 0.9500233291863989
Generation:  76%|  | 19/25 [1:42:26<48:50, 488.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453f369b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553c3ec9000> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475d3f8e0> 

Generation:  20
Best f1_score score: 0.9500233291863989
Generation:  80%|  | 20/25 [1:52:32<43:39, 523.84s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475d3f790> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475e258a0> 

Generation:  21
Best f1_score score: 0.9500233291863989
Generation:  84%| | 21/25 [2:02:36<36:30, 547.65s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458774e80> 

Generation:  22
Best f1_score score: 0.9500233291863989
Generation:  88%| | 22/25 [2:12:40<28:14, 564.74s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554582c6fb0> 

Generation:  23
Best f1_score score: 0.9500233291863989
Generation:  92%|| 23/25 [2:22:47<19:14, 577.34s/it]Generation:  24
Best f1_score score: 0.9500233291863989
Generation:  96%|| 24/25 [2:28:20<08:24, 504.17s/it]Generation:  25
Best f1_score score: 0.9500233291863989
Generation: 100%|| 25/25 [2:28:52<00:00, 362.31s/it]Generation: 100%|| 25/25 [2:28:52<00:00, 357.29s/it]
2024-08-14 00:49:07,333 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37381' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-e5f4fe212e722ab92450be29ff2bb515', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723621747.3330169')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=KNeighborsRegressor(),
                                  imputation_order='descending',
                                  initial_strategy='median',
                                  n_nearest_features=74)),
                ('lgbmclassifier',
                 LGBMClassifier(boosting_type='goss', max_depth=8,
                                n_estimators=74, n_jobs=1, num_leaves=115,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.999984388543347, 'accuracy': 0.9995939086294416, 'balanced_accuracy': 0.9974012474012474, 'logloss': 0.011952621448054099, 'f1': 0.9995932923166276}
test score: {'auroc': 0.9644476737515758, 'accuracy': 0.9525547445255474, 'balanced_accuracy': 0.6185636856368564, 'logloss': 0.21320408334760632, 'f1': 0.9495251695806239}
original test score: {'auroc': 0.9960572356410744, 'accuracy': 0.968978102189781, 'balanced_accuracy': 0.7733185513673317, 'logloss': 0.08856308336521106, 'f1': 0.9680632258134532}
score end
30
lvl
0.5
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
10.335692612065209
hours
DONE
