Run: 11
/cm/local/apps/slurm/var/spool/job1043946/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1507/1507.pkl
working on 
../data/c/1507/class_full_MNAR_0.3_1
2.1913561820983887
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-08 03:06:22,205] A new study created in memory with name: no-name-5bb877ff-2ecc-4c4d-a409-c526c45a91ee
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-08 03:06:22,540] Trial 11 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 11 with value: 0.4276730615299645.
running
[I 2024-11-08 03:06:22,844] Trial 5 finished with value: 0.13040797143422697 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.13040797143422697.
[I 2024-11-08 03:06:22,970] Trial 15 finished with value: 0.13040797143422697 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.13040797143422697.
running
running
[I 2024-11-08 03:06:23,317] Trial 3 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:23,543] Trial 8 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:23,812] Trial 9 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:24,337] Trial 21 finished with value: 0.13040797143422697 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:27,463] Trial 10 finished with value: 0.16737945829692716 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5491, 'weights': 'uniform'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:28,656] Trial 7 finished with value: 0.17401229715777608 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1789, 'weights': 'uniform'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:29,094] Trial 24 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:30,408] Trial 2 finished with value: 0.1738178835387047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1992, 'weights': 'distance'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:33,321] Trial 4 finished with value: 0.37213694003474906 and parameters: {'model_name': 'GAIN', 'batch_size': 648, 'hint_rate': 0.18985731076365592, 'alpha': 25, 'iterations': 1, 'learning_rate': 0.0007533747669969055, 'p_miss': 0.2982882385541849}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:33,552] Trial 6 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.2026746414992647, 'alpha': 27, 'iterations': 28, 'learning_rate': 0.05284349512262082, 'p_miss': 0.03903131685869743}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:06:41,854] Trial 26 finished with value: 0.3986403153198602 and parameters: {'model_name': 'GAIN', 'batch_size': 282, 'hint_rate': 0.6463575254123092, 'alpha': 17, 'iterations': 11, 'learning_rate': 0.008091326401236299, 'p_miss': 0.20491839441243234}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:07:06,814] Trial 1 finished with value: 0.16813985906131063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 18, 'imputation_order': 'random'}. Best is trial 5 with value: 0.13040797143422697.
running
[I 2024-11-08 03:07:12,156] Trial 16 finished with value: 0.1258453499028766 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 40, 'learning_rate': 0.000604972418460948, 'p_miss': 0.09529940590696594}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:07:37,790] Trial 12 finished with value: 0.4226513017848002 and parameters: {'model_name': 'GAIN', 'batch_size': 250, 'hint_rate': 0.7412549673003063, 'alpha': 45, 'iterations': 75, 'learning_rate': 0.022205958835465642, 'p_miss': 0.11122197129716532}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:07:53,659] Trial 29 finished with value: 0.18955440687770178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:08:10,724] Trial 23 finished with value: 0.39226898301125024 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.2612172370073784, 'alpha': 80, 'iterations': 162, 'learning_rate': 0.020190043165774964, 'p_miss': 0.2276390311768147}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:08:16,022] Trial 19 finished with value: 0.16860452408198823 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:08:39,857] Trial 18 finished with value: 0.16778910090628923 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:21:15,560] Trial 0 finished with value: 0.41615343406773675 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.8917242040194346, 'alpha': 56, 'iterations': 776, 'learning_rate': 0.01350724344568783, 'p_miss': 0.06711292072800856}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:56:43,109] Trial 13 finished with value: 0.4213217610057347 and parameters: {'model_name': 'GAIN', 'batch_size': 277, 'hint_rate': 0.6999651896402207, 'alpha': 71, 'iterations': 1809, 'learning_rate': 0.00015836691843199512, 'p_miss': 0.09388442830253371}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 03:56:58,427] Trial 38 finished with value: 0.13170809514898033 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 4, 'learning_rate': 0.0011522714557743866, 'p_miss': 0.15700211584797413}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 04:21:10,475] Trial 17 finished with value: 0.17241132188250674 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 04:22:35,618] Trial 25 finished with value: 0.17288802902039027 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 05:03:52,210] Trial 14 finished with value: 0.17038211090702374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 05:22:30,550] Trial 20 finished with value: 0.4230471659116673 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.3053098407605715, 'alpha': 15, 'iterations': 5704, 'learning_rate': 0.0006754950681079623, 'p_miss': 0.08049794855512277}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 05:43:02,105] Trial 43 finished with value: 0.14299546486682474 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 371, 'learning_rate': 0.00025197504749899826, 'p_miss': 0.02222910839500218}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 05:43:07,853] Trial 44 finished with value: 0.1352810187153916 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.002899027132763438, 'p_miss': 0.14812883497389606}. Best is trial 16 with value: 0.1258453499028766.
running
[I 2024-11-08 05:44:00,123] Trial 45 finished with value: 0.12476324805788086 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 12, 'learning_rate': 0.0019831651541551538, 'p_miss': 0.14490669449620347}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:44:40,390] Trial 46 finished with value: 0.12695885666045845 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 10, 'learning_rate': 0.0033385423761743164, 'p_miss': 0.14444683790470053}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:45:26,110] Trial 47 finished with value: 0.12664433940324027 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 9, 'learning_rate': 0.0029590497946404212, 'p_miss': 0.14216873515028094}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:46:12,100] Trial 48 finished with value: 0.13036837584971342 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 12, 'learning_rate': 0.0030796138637092262, 'p_miss': 0.1540225236012993}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:46:35,913] Trial 49 finished with value: 0.12909957594380758 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 6, 'learning_rate': 0.001682305232032974, 'p_miss': 0.12389084811783424}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:48:24,735] Trial 50 finished with value: 0.1808168693555104 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 29, 'learning_rate': 0.0049897989661366535, 'p_miss': 0.1892478863394827}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:48:36,142] Trial 51 finished with value: 0.1331522079141067 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 3, 'learning_rate': 0.00039491879886748, 'p_miss': 0.13311839949459417}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:50:02,715] Trial 52 finished with value: 0.13294527562598582 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 32, 'learning_rate': 0.0020097129277064983, 'p_miss': 0.18404438974711856}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:50:59,351] Trial 53 finished with value: 0.17403241930448426 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 13, 'learning_rate': 0.00593964326463637, 'p_miss': 0.10673343168858335}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:54:20,768] Trial 54 finished with value: 0.14858911378852047 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 57, 'learning_rate': 0.0010981164865591008, 'p_miss': 0.1710373763603392}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:54:35,569] Trial 55 finished with value: 0.1261678177180657 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 2, 'learning_rate': 0.0036652371409199988, 'p_miss': 0.06526866373280403}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:54:53,858] Trial 56 finished with value: 0.12541752334521575 and parameters: {'model_name': 'VAE', 'batch_size': 126, 'iterations': 2, 'learning_rate': 0.003491896810898436, 'p_miss': 0.06041597568685765}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:55:10,548] Trial 57 finished with value: 0.13354231108970344 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 2, 'learning_rate': 0.001981956644785577, 'p_miss': 0.05837670909599469}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:55:33,974] Trial 58 finished with value: 0.1401217580630615 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 2, 'learning_rate': 0.008491789260725321, 'p_miss': 0.04852815145467224}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:55:40,950] Trial 59 finished with value: 0.17736052846725792 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 136, 'weights': 'distance'}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:56:24,069] Trial 60 finished with value: 0.1347336151257982 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 5, 'learning_rate': 0.004259623697316582, 'p_miss': 0.08501441521142733}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:56:29,967] Trial 61 finished with value: 0.13471330980860655 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 1, 'learning_rate': 0.00057572925009657, 'p_miss': 0.032633853502897575}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:56:48,049] Trial 62 finished with value: 0.12966138694236906 and parameters: {'model_name': 'VAE', 'batch_size': 581, 'iterations': 2, 'learning_rate': 0.0014636895282356443, 'p_miss': 0.010460245500980271}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:56:58,777] Trial 63 finished with value: 0.1682957927886158 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5875, 'weights': 'distance'}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 05:58:10,676] Trial 64 finished with value: 0.12877532791471968 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 21, 'learning_rate': 0.002432439227288126, 'p_miss': 0.07164236318792647}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:02:51,306] Trial 65 finished with value: 0.180950883902125 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 75, 'learning_rate': 0.00773798350545028, 'p_miss': 0.1085584659813304}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:03:33,511] Trial 66 finished with value: 0.1275390258868302 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 9, 'learning_rate': 0.003824845320886113, 'p_miss': 0.13039453425557934}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:04:01,733] Trial 67 finished with value: 0.12772754097998068 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 6, 'learning_rate': 0.0033093112277341416, 'p_miss': 0.07184394998034704}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:05:13,753] Trial 68 finished with value: 0.16647736236202784 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 18, 'learning_rate': 0.005514367092711314, 'p_miss': 0.09646708624015207}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:05:27,982] Trial 69 finished with value: 0.12879764428089885 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 3, 'learning_rate': 0.012447857741894105, 'p_miss': 0.14214071961252106}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:09:00,260] Trial 70 finished with value: 0.13770659271093658 and parameters: {'model_name': 'VAE', 'batch_size': 402, 'iterations': 46, 'learning_rate': 0.0010248868497081275, 'p_miss': 0.055516551824179326}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:09:10,393] Trial 71 finished with value: 0.16946144604243846 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3855, 'weights': 'uniform'}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:09:48,331] Trial 72 finished with value: 0.12550676910289355 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 8, 'learning_rate': 0.002465233875633185, 'p_miss': 0.1183639893490213}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:09:53,033] Trial 73 finished with value: 0.1340784682870671 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 1, 'learning_rate': 0.00037776428364242394, 'p_miss': 0.11659642082403589}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:18:15,251] Trial 74 finished with value: 0.17882597356191027 and parameters: {'model_name': 'VAE', 'batch_size': 211, 'iterations': 136, 'learning_rate': 0.0015598028653967594, 'p_miss': 0.09517813643062922}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:18:47,763] Trial 75 finished with value: 0.1361907758129019 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 7, 'learning_rate': 0.0001360940151067276, 'p_miss': 0.2853064561725638}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:19:56,292] Trial 76 finished with value: 0.13563546274934107 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 16, 'learning_rate': 0.0028635432393320512, 'p_miss': 0.1374249585351865}. Best is trial 45 with value: 0.12476324805788086.
running
[I 2024-11-08 06:20:30,766] Trial 77 finished with value: 0.12416463311363438 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 9, 'learning_rate': 0.0021598248354432327, 'p_miss': 0.16964897959895683}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:20:41,844] Trial 78 finished with value: 0.13158066446230415 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.0007641999895555332, 'p_miss': 0.17126414928056172}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:22:38,153] Trial 79 finished with value: 0.13775099079780975 and parameters: {'model_name': 'VAE', 'batch_size': 346, 'iterations': 24, 'learning_rate': 0.0019320901840653073, 'p_miss': 0.16571409842924825}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:22:38,747] Trial 80 finished with value: 0.16737945829692716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:22:51,059] Trial 81 finished with value: 0.4180359171842203 and parameters: {'model_name': 'GAIN', 'batch_size': 168, 'hint_rate': 0.4438852471201452, 'alpha': 96, 'iterations': 5, 'learning_rate': 0.050053826050633354, 'p_miss': 0.08480615796356625}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:23:01,012] Trial 82 finished with value: 0.13372658188929237 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.001320366972618173, 'p_miss': 0.11716510653411817}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:23:23,584] Trial 83 finished with value: 0.16721582409494362 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:23:52,499] Trial 84 finished with value: 0.12674546567835931 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 9, 'learning_rate': 0.002454038049074066, 'p_miss': 0.21478922701381464}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:26:04,916] Trial 85 finished with value: 0.12516203097142276 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 35, 'learning_rate': 0.0008386391484775994, 'p_miss': 0.041990700747002396}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:33:23,764] Trial 86 finished with value: 0.17712793577880112 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 120, 'learning_rate': 0.0008748727562630933, 'p_miss': 0.047330315295834625}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:35:27,088] Trial 87 finished with value: 0.12437618353576727 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 29, 'learning_rate': 0.0004864406612610594, 'p_miss': 0.03438776022430512}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:37:49,039] Trial 88 finished with value: 0.12469321611766222 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 39, 'learning_rate': 0.0005138514737748289, 'p_miss': 0.03119053373272643}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:40:35,082] Trial 89 finished with value: 0.1256492658546912 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 42, 'learning_rate': 0.0005165680982086504, 'p_miss': 0.03638877203453626}. Best is trial 77 with value: 0.12416463311363438.
running
[I 2024-11-08 06:44:31,750] Trial 90 finished with value: 0.12395239696240605 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 81, 'learning_rate': 0.0003727197428379513, 'p_miss': 0.03093203288853745}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 06:44:32,318] Trial 91 finished with value: 0.16737945829692716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 06:49:39,780] Trial 31 finished with value: 0.18198851015859427 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5517, 'learning_rate': 0.00021520482351501, 'p_miss': 0.06511003761970824}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 06:56:36,786] Trial 93 finished with value: 0.4235563408960405 and parameters: {'model_name': 'GAIN', 'batch_size': 95, 'hint_rate': 0.989371484668871, 'alpha': 2, 'iterations': 252, 'learning_rate': 0.00025814036063638145, 'p_miss': 0.025388205289890373}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 06:56:43,930] Trial 94 finished with value: 0.17817926104313747 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 70, 'weights': 'uniform'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 06:59:55,699] Trial 92 finished with value: 0.14717294369440562 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 241, 'learning_rate': 0.00021775795533299645, 'p_miss': 0.02585588153589449}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:01:51,699] Trial 95 finished with value: 0.12835655436971122 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 85, 'learning_rate': 0.0004680920147779376, 'p_miss': 0.013963161566413272}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:01:58,447] Trial 96 finished with value: 0.12676549138142884 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 40, 'learning_rate': 0.0005105443963578436, 'p_miss': 0.01192171940212531}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:04:42,180] Trial 97 finished with value: 0.12443885110616693 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 38, 'learning_rate': 0.0003035659126997609, 'p_miss': 0.0408721558113691}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:04:44,492] Trial 98 finished with value: 0.12782214017689153 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 37, 'learning_rate': 0.000341735245848067, 'p_miss': 0.039987835795731466}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:06:07,365] Trial 99 finished with value: 0.12951315816667716 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 30, 'learning_rate': 0.00033082954840307446, 'p_miss': 0.04472800990153141}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:06:10,729] Trial 100 finished with value: 0.1348434140384937 and parameters: {'model_name': 'VAE', 'batch_size': 199, 'iterations': 24, 'learning_rate': 0.00010425106921193696, 'p_miss': 0.047070078422595515}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:06:52,439] Trial 102 finished with value: 0.19158353163988634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:06:55,250] Trial 101 finished with value: 0.1897574508167696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:07:58,561] Trial 104 finished with value: 0.12949493437635326 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 15, 'learning_rate': 0.000738759150814682, 'p_miss': 0.030968300667855872}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:11:06,523] Trial 103 finished with value: 0.15418804942569514 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 70, 'learning_rate': 0.000884730740201778, 'p_miss': 0.03282485849379222}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:12:19,545] Trial 105 finished with value: 0.12860282058674377 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 61, 'learning_rate': 0.00029602439327935384, 'p_miss': 0.05588105086879554}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:13:58,067] Trial 106 finished with value: 0.125701028650876 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 50, 'learning_rate': 0.00046413065052263103, 'p_miss': 0.021022149949035503}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:16:03,219] Trial 107 finished with value: 0.12619211736625147 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 53, 'learning_rate': 0.00045842928958199353, 'p_miss': 0.03674033188674745}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:20:26,483] Trial 108 finished with value: 0.1552385783599231 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 99, 'learning_rate': 0.0006335153322191051, 'p_miss': 0.034618452530737046}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:22:39,824] Trial 110 finished with value: 0.12795178722005288 and parameters: {'model_name': 'VAE', 'batch_size': 150, 'iterations': 30, 'learning_rate': 0.0001655859847063178, 'p_miss': 0.18957322715728658}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 07:23:40,392] Trial 111 finished with value: 0.12985002803379692 and parameters: {'model_name': 'VAE', 'batch_size': 274, 'iterations': 12, 'learning_rate': 0.0006043461349622427, 'p_miss': 0.06304811693068686}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:06:54,753] Trial 112 finished with value: 0.1806679199515402 and parameters: {'model_name': 'VAE', 'batch_size': 126, 'iterations': 829, 'learning_rate': 0.0012346980775046759, 'p_miss': 0.052738153962036946}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:06:55,242] Trial 113 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:07:58,345] Trial 114 finished with value: 0.12678603801076244 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 16, 'learning_rate': 0.002312149338898746, 'p_miss': 0.019535583172413187}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:08:09,393] Trial 115 finished with value: 0.1696590817207729 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4009, 'weights': 'distance'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:10:44,647] Trial 116 finished with value: 0.12512062857113732 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 48, 'learning_rate': 0.0004243831234912022, 'p_miss': 0.021274918934455312}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:12:34,455] Trial 117 finished with value: 0.12805548641177764 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 36, 'learning_rate': 0.00041635490774807453, 'p_miss': 0.0428734716096342}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:19:36,433] Trial 118 finished with value: 0.1283285890020834 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 97, 'learning_rate': 0.000280692155171306, 'p_miss': 0.1575067708021942}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:21:05,368] Trial 119 finished with value: 0.13516172418606323 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 22, 'learning_rate': 0.0001948136043063397, 'p_miss': 0.02634816682907976}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:25:06,019] Trial 120 finished with value: 0.13070768726421017 and parameters: {'model_name': 'VAE', 'batch_size': 173, 'iterations': 60, 'learning_rate': 0.0005553386877880051, 'p_miss': 0.01736939061644066}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:26:18,091] Trial 121 finished with value: 0.4155451872175521 and parameters: {'model_name': 'GAIN', 'batch_size': 117, 'hint_rate': 0.015836430802144308, 'alpha': 99, 'iterations': 37, 'learning_rate': 0.0003690640691580576, 'p_miss': 0.07196134842450541}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:26:48,185] Trial 122 finished with value: 0.12638203745807966 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 7, 'learning_rate': 0.0006953434243253107, 'p_miss': 0.039915566551371004}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:28:03,920] Trial 123 finished with value: 0.13800824879581733 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 20, 'learning_rate': 0.004353594846400167, 'p_miss': 0.027949046498309905}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:30:43,248] Trial 124 finished with value: 0.1275720467182997 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 45, 'learning_rate': 0.0009496100066211403, 'p_miss': 0.06305726746783068}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:31:23,257] Trial 125 finished with value: 0.12581599641672567 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 10, 'learning_rate': 0.0015913718694196574, 'p_miss': 0.1811626729604174}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:35:18,162] Trial 126 finished with value: 0.1248035836961398 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 50, 'learning_rate': 0.0004568513300316961, 'p_miss': 0.020719440415434415}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:36:06,804] Trial 30 finished with value: 0.24501321274533513 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6919, 'learning_rate': 0.00011221413665973604, 'p_miss': 0.015708352206084797}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:36:26,734] Trial 22 finished with value: 0.25551532692349244 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6730, 'learning_rate': 0.011995578317920426, 'p_miss': 0.29330848701945567}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:36:50,945] Trial 127 finished with value: 0.12806286235701186 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 25, 'learning_rate': 0.00040626577520302027, 'p_miss': 0.03751698832165395}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:37:27,555] Trial 34 finished with value: 0.1814235014637146 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 5693, 'learning_rate': 0.0001251493003523517, 'p_miss': 0.017107467898336698}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:38:00,430] Trial 128 finished with value: 0.12532286489751593 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 27, 'learning_rate': 0.0005453234817873318, 'p_miss': 0.020992583733759493}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:38:51,231] Trial 129 finished with value: 0.12767533594261143 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 28, 'learning_rate': 0.00030486383315865757, 'p_miss': 0.038203934090704716}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:42:00,087] Trial 132 finished with value: 0.12604086137281006 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 75, 'learning_rate': 0.0003149924210124845, 'p_miss': 0.01981125460499267}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:42:43,452] Trial 131 finished with value: 0.12520855227349736 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 72, 'learning_rate': 0.000328205714019303, 'p_miss': 0.05090151112906163}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:42:45,702] Trial 130 finished with value: 0.12835365431822382 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 73, 'learning_rate': 0.00023215764582283107, 'p_miss': 0.05090769723371914}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:42:47,240] Trial 134 finished with value: 0.13319636737324717 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 13, 'learning_rate': 0.00022091098078591163, 'p_miss': 0.02791973466059723}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:49:28,356] Trial 133 finished with value: 0.1789222220738941 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 176, 'learning_rate': 0.0007709248915730283, 'p_miss': 0.010211193369751306}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:50:10,253] Trial 137 finished with value: 0.1331563554424013 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 113, 'learning_rate': 0.00039716421876985085, 'p_miss': 0.010120549184897007}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:50:45,358] Trial 109 finished with value: 0.18077136617068448 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 1578, 'learning_rate': 0.0005929050294808525, 'p_miss': 0.0614669849369964}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:51:02,816] Trial 136 finished with value: 0.1632941055848843 and parameters: {'model_name': 'VAE', 'batch_size': 116, 'iterations': 122, 'learning_rate': 0.0005744900237945301, 'p_miss': 0.0110663465160983}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:51:03,545] Trial 141 finished with value: 0.16737945829692716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:51:11,656] Trial 140 finished with value: 0.12749260406660687 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 4, 'learning_rate': 0.002636741116046353, 'p_miss': 0.15115857062419025}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:51:46,538] Trial 135 finished with value: 0.14031990618657764 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 137, 'learning_rate': 0.00040790664479856364, 'p_miss': 0.011072966308485597}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:52:55,518] Trial 138 finished with value: 0.1816809275351908 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 49, 'learning_rate': 0.002667779041258431, 'p_miss': 0.1537125338043284}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:53:13,250] Trial 143 finished with value: 0.4200499141626909 and parameters: {'model_name': 'GAIN', 'batch_size': 184, 'hint_rate': 0.5137372534462886, 'alpha': 45, 'iterations': 58, 'learning_rate': 0.0018375590353126537, 'p_miss': 0.04602653503161328}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:53:25,221] Trial 144 finished with value: 0.42451075080177175 and parameters: {'model_name': 'GAIN', 'batch_size': 220, 'hint_rate': 0.5057340793084263, 'alpha': 45, 'iterations': 52, 'learning_rate': 0.0018170701021754435, 'p_miss': 0.022586121326242603}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:53:35,745] Trial 145 finished with value: 0.41997188864977025 and parameters: {'model_name': 'GAIN', 'batch_size': 178, 'hint_rate': 0.46695419468152094, 'alpha': 44, 'iterations': 19, 'learning_rate': 0.0018812063823104336, 'p_miss': 0.046180884603634564}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:55:14,823] Trial 142 finished with value: 0.1784335566094441 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 51, 'learning_rate': 0.0018938799764825556, 'p_miss': 0.10172598443274344}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:56:00,414] Trial 146 finished with value: 0.1260577789701683 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 42, 'learning_rate': 0.0005138011293133294, 'p_miss': 0.030318195380548817}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:56:10,690] Trial 147 finished with value: 0.12587744757105884 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 39, 'learning_rate': 0.00052234082245982, 'p_miss': 0.03356467134220063}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:56:18,999] Trial 151 finished with value: 0.17404137963126937 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1773, 'weights': 'uniform'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:56:41,107] Trial 148 finished with value: 0.1261293268175936 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 40, 'learning_rate': 0.0004777016034178517, 'p_miss': 0.032326693639950464}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:56:59,986] Trial 149 finished with value: 0.12622206416401577 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 34, 'learning_rate': 0.00047965236603536403, 'p_miss': 0.03200098009289964}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:57:02,133] Trial 150 finished with value: 0.12425501787808332 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 34, 'learning_rate': 0.0003509045117364386, 'p_miss': 0.03239634333030159}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:57:24,919] Trial 153 finished with value: 0.16866213529114202 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:57:34,360] Trial 155 finished with value: 0.12917611375949195 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 26, 'learning_rate': 0.0002716955552890046, 'p_miss': 0.16067165175847892}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 08:57:42,402] Trial 154 finished with value: 0.16780824924034357 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:01:53,510] Trial 156 finished with value: 0.12784383314616438 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 89, 'learning_rate': 0.0003437793919545394, 'p_miss': 0.07755433002948298}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:02:48,507] Trial 159 finished with value: 0.12868141735100955 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 8, 'learning_rate': 0.003492768027955702, 'p_miss': 0.05431304892896237}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:03:13,320] Trial 157 finished with value: 0.12640141653497802 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 86, 'learning_rate': 0.0003458623103476463, 'p_miss': 0.04180211518217024}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:04:44,434] Trial 160 finished with value: 0.14204463273727108 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 31, 'learning_rate': 0.002240090250432719, 'p_miss': 0.255766599056985}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:05:16,683] Trial 158 finished with value: 0.12942637018990966 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 94, 'learning_rate': 0.0003587875080551587, 'p_miss': 0.05541817455640465}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:06:25,871] Trial 163 finished with value: 0.13177925659207285 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 15, 'learning_rate': 0.00018636941168296366, 'p_miss': 0.023342181088786555}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:07:59,875] Trial 161 finished with value: 0.1795003558175243 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 65, 'learning_rate': 0.002280846531968297, 'p_miss': 0.02228525846708961}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:09:14,054] Trial 162 finished with value: 0.1329005118558041 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 65, 'learning_rate': 0.0006552173825511515, 'p_miss': 0.0228971388721177}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:09:35,005] Trial 165 finished with value: 0.12563602649863648 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 20, 'learning_rate': 0.0006442147657387645, 'p_miss': 0.1737190944231711}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:10:23,428] Trial 164 finished with value: 0.13231806605729618 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 64, 'learning_rate': 0.0006749389169185604, 'p_miss': 0.17674277484456496}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:10:47,812] Trial 166 finished with value: 0.12829379845042546 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 31, 'learning_rate': 0.0004042600998318477, 'p_miss': 0.03846881859618073}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:11:05,864] Trial 167 finished with value: 0.12534083547529531 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 19, 'learning_rate': 0.0008240325282131665, 'p_miss': 0.1263322824673887}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:12:02,368] Trial 168 finished with value: 0.1270974764879606 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 19, 'learning_rate': 0.00044091124293521426, 'p_miss': 0.1276679717957272}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:12:35,651] Trial 170 finished with value: 0.1557579751811505 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 20, 'learning_rate': 0.0030636404337918456, 'p_miss': 0.12249092416442654}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:12:37,320] Trial 169 finished with value: 0.12407263991008402 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 21, 'learning_rate': 0.0008665447424006263, 'p_miss': 0.19669582974915273}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:12:42,947] Trial 171 finished with value: 0.12983020020567373 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 11, 'learning_rate': 0.0008440319883652055, 'p_miss': 0.1419641512415408}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:12:44,219] Trial 174 finished with value: 0.4276730615299645 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:13:42,769] Trial 173 finished with value: 0.12821110431252264 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 15, 'learning_rate': 0.0011088739839133055, 'p_miss': 0.20078582161274405}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:14:06,205] Trial 172 finished with value: 0.12643944786100636 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 24, 'learning_rate': 0.0013893776330185363, 'p_miss': 0.17009694738503423}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:14:27,548] Trial 175 finished with value: 0.13102798713151426 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 24, 'learning_rate': 0.0002628360518010657, 'p_miss': 0.21700326117249696}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:15:00,127] Trial 177 finished with value: 0.1252269401484091 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 13, 'learning_rate': 0.0009582554767179756, 'p_miss': 0.2091337406456131}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:15:25,690] Trial 178 finished with value: 0.1259093813314432 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 13, 'learning_rate': 0.0008212359902162018, 'p_miss': 0.13723583915319817}. Best is trial 90 with value: 0.12395239696240605.
running
[I 2024-11-08 09:15:31,678] Trial 176 finished with value: 0.12301930543481158 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 27, 'learning_rate': 0.0010165442256652346, 'p_miss': 0.19366315719693344}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:16:07,285] Trial 179 finished with value: 0.1257870875746529 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 17, 'learning_rate': 0.0009877837218024265, 'p_miss': 0.20693649229382904}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:16:27,079] Trial 180 finished with value: 0.12803915753670386 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 17, 'learning_rate': 0.001064176211696659, 'p_miss': 0.1940237673744901}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:16:40,480] Trial 183 finished with value: 0.1682957927886158 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4574, 'weights': 'distance'}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:17:45,211] Trial 182 finished with value: 0.1287528190830601 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 28, 'learning_rate': 0.0011955328729027826, 'p_miss': 0.19397643492353284}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:18:11,024] Trial 181 finished with value: 0.1315956754319634 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 32, 'learning_rate': 0.0008871466785232853, 'p_miss': 0.19774997534609162}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:18:47,274] Trial 186 finished with value: 0.1262652829484907 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 12, 'learning_rate': 0.0007467063229717566, 'p_miss': 0.2259644380121052}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:19:10,507] Trial 187 finished with value: 0.13135375425744028 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 5, 'learning_rate': 0.001337258220941746, 'p_miss': 0.20890886878522297}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:19:48,372] Trial 188 finished with value: 0.12727185133042038 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 9, 'learning_rate': 0.0005435628742678522, 'p_miss': 0.11707692160613013}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:20:02,593] Trial 185 finished with value: 0.12335075380613489 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 35, 'learning_rate': 0.0007483602752643057, 'p_miss': 0.22433456852785222}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:22:26,075] Trial 189 finished with value: 0.12744799576574092 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 41, 'learning_rate': 0.0003052344642954867, 'p_miss': 0.017310412481158468}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:22:50,609] Trial 190 finished with value: 0.1327447767099323 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 44, 'learning_rate': 0.0009906965777055942, 'p_miss': 0.2398084623835449}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:24:33,358] Trial 192 finished with value: 0.1269733618888415 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 27, 'learning_rate': 0.000727342055638408, 'p_miss': 0.2313536498061352}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:25:38,692] Trial 191 finished with value: 0.12651442290948298 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 46, 'learning_rate': 0.0007499526962008756, 'p_miss': 0.2206440454723368}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:26:51,642] Trial 193 finished with value: 0.12414310632684497 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 35, 'learning_rate': 0.0005988915599274279, 'p_miss': 0.21554490402386084}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:27:33,928] Trial 194 finished with value: 0.12720514697911628 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 33, 'learning_rate': 0.0005921421543804102, 'p_miss': 0.210696347851221}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:28:50,906] Trial 195 finished with value: 0.1257135364313858 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 33, 'learning_rate': 0.0006065777873806485, 'p_miss': 0.21222995000488679}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:30:19,483] Trial 197 finished with value: 0.13125986674510962 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 22, 'learning_rate': 0.00047504344962454953, 'p_miss': 0.23619062668515867}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:30:20,694] Trial 196 finished with value: 0.18254885348163782 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 35, 'learning_rate': 0.08096607562188564, 'p_miss': 0.22741183728340872}. Best is trial 176 with value: 0.12301930543481158.
running
[I 2024-11-08 09:33:25,704] Trial 198 finished with value: 0.12675092165226665 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 52, 'learning_rate': 0.0008436983478234413, 'p_miss': 0.20383837796523524}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 09:33:54,405] Trial 199 finished with value: 0.18249041729977444 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 53, 'learning_rate': 0.004287782606782773, 'p_miss': 0.18288466993098018}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:09:03,752] Trial 36 finished with value: 0.18159342095349204 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 6162, 'learning_rate': 0.00037120353063133273, 'p_miss': 0.012741330334045897}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:15:47,956] Trial 35 finished with value: 0.18138945043010643 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 7295, 'learning_rate': 0.0001201480020050118, 'p_miss': 0.017797794507348308}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:17:59,741] Trial 32 finished with value: 0.18289072666747455 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8151, 'learning_rate': 0.00014785049986503458, 'p_miss': 0.01357454975045938}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:47:32,207] Trial 27 finished with value: 0.2007623853002595 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 9578, 'learning_rate': 0.07515770928818141, 'p_miss': 0.015354336167902355}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:52:56,336] Trial 33 finished with value: 0.1830315697724897 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8432, 'learning_rate': 0.00012372004846586092, 'p_miss': 0.027330296694304618}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:56:35,432] Trial 41 finished with value: 0.17967555939379345 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 6869, 'learning_rate': 0.00012255680779868242, 'p_miss': 0.012419400588953633}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 10:57:46,483] Trial 37 finished with value: 0.179082293901829 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 8296, 'learning_rate': 0.0001051515132693669, 'p_miss': 0.12499818791184791}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:25:10,510] Trial 40 finished with value: 0.181624161389672 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 7683, 'learning_rate': 0.0001358378493552633, 'p_miss': 0.15488865568425572}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:36:08,913] Trial 42 finished with value: 0.18353881357461627 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 7220, 'learning_rate': 0.00011376157959729557, 'p_miss': 0.1442671713487072}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:37:49,255] Trial 28 finished with value: 0.18154257088611697 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 9914, 'learning_rate': 0.00017030701032371722, 'p_miss': 0.21466430323533897}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:42:06,460] Trial 39 finished with value: 0.18170263129970493 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 9762, 'learning_rate': 0.0001495249426544673, 'p_miss': 0.026408406411836033}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:45:20,684] Trial 139 finished with value: 0.18162659420380511 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 9359, 'learning_rate': 0.002732309974366964, 'p_miss': 0.1510644830322776}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:48:31,494] Trial 184 finished with value: 0.18253491533735397 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 8974, 'learning_rate': 0.0012162492342359266, 'p_miss': 0.21492853736689238}. Best is trial 176 with value: 0.12301930543481158.
[I 2024-11-08 11:48:39,120] Trial 152 finished with value: 0.18077448729327664 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 9445, 'learning_rate': 0.003536546255311786, 'p_miss': 0.05541895133128985}. Best is trial 176 with value: 0.12301930543481158.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.12301930543481158
{'model_name': 'VAE', 'batch_size': 86, 'iterations': 27, 'learning_rate': 0.0010165442256652346, 'p_miss': 0.19366315719693344}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469cf10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0fa0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5938061027978203
Generation:   4%|         | 1/25 [00:52<20:48, 52.01s/it]Generation:  2
Best f1_score score: 0.6046811671918919
Generation:   8%|         | 2/25 [01:26<16:00, 41.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470dae0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.6046811671918919
Generation:  12%|        | 3/25 [01:47<11:46, 32.13s/it]Generation:  4
Best f1_score score: 0.6046811671918919
Generation:  16%|        | 4/25 [03:04<17:25, 49.77s/it]Generation:  5
Best f1_score score: 0.6046811671918919
Generation:  20%|        | 5/25 [04:19<19:43, 59.18s/it]Generation:  6
Best f1_score score: 0.6046811671918919
Generation:  24%|       | 6/25 [07:39<33:48, 106.78s/it]Generation:  7
Best f1_score score: 0.6046811671918919
Generation:  28%|       | 7/25 [08:49<28:30, 95.01s/it] Generation:  8
Best f1_score score: 0.6046811671918919
Generation:  32%|      | 8/25 [09:07<19:55, 70.32s/it]Generation:  9
Best f1_score score: 0.6058751380685379
Generation:  36%|      | 9/25 [09:43<15:56, 59.77s/it]Generation:  10
Best f1_score score: 0.6058751380685379
Generation:  40%|      | 10/25 [10:20<13:10, 52.73s/it]Generation:  11
Best f1_score score: 0.6060423864503598
Generation:  44%|     | 11/25 [11:21<12:51, 55.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f0550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.6085736093191565
Generation:  48%|     | 12/25 [11:48<10:07, 46.73s/it]Generation:  13
Best f1_score score: 0.6085736093191565
Generation:  52%|    | 13/25 [12:30<09:01, 45.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a37af0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.6085736093191565
Generation:  56%|    | 14/25 [13:19<08:29, 46.33s/it]Generation:  15
Best f1_score score: 0.6085736093191565
Generation:  60%|    | 15/25 [14:49<09:55, 59.60s/it]Generation:  16
Best f1_score score: 0.6085736093191565
Generation:  64%|   | 16/25 [15:34<08:15, 55.03s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546509fb20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655d5a50> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  17
Best f1_score score: 0.6085736093191565
Generation:  68%|   | 17/25 [16:18<06:53, 51.71s/it]Generation:  18
Best f1_score score: 0.6085736093191565
Generation:  72%|  | 18/25 [16:59<05:39, 48.57s/it]Generation:  19
Best f1_score score: 0.6085736093191565
Generation:  76%|  | 19/25 [17:44<04:44, 47.47s/it]Generation:  20
Best f1_score score: 0.6085736093191565
Generation:  80%|  | 20/25 [18:29<03:54, 46.87s/it]Generation:  21
Best f1_score score: 0.6085736093191565
Generation:  84%| | 21/25 [19:09<02:58, 44.70s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554651a2020> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658a6260> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.6100686416228883
Generation:  88%| | 22/25 [19:45<02:06, 42.10s/it]Generation:  23
Best f1_score score: 0.6100686416228883
Generation:  92%|| 23/25 [22:58<02:54, 87.47s/it]Generation:  24
Best f1_score score: 0.6100686416228883
Generation:  96%|| 24/25 [24:56<01:36, 96.65s/it]Generation:  25
Best f1_score score: 0.6100686416228883
Generation: 100%|| 25/25 [25:44<00:00, 81.88s/it]Generation: 100%|| 25/25 [25:48<00:00, 61.94s/it]
2024-11-08 12:14:39,740 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38691' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-c2caa01de8a515f4ebc924cc511261d9', 'ndarray-d8b8a177c15b9d764d6c1db847317b9d'} (stimulus_id='handle-worker-cleanup-1731096879.740795')
Fitted
Pipeline(steps=[('adaboostclassifier',
                 AdaBoostClassifier(algorithm='SAMME',
                                    learning_rate=0.5139974547671,
                                    n_estimators=324))])
score start
train score: {'auroc': 0.6719873867729121, 'accuracy': 0.6300675675675675, 'balanced_accuracy': 0.6300710509820358, 'logloss': 0.6636779121961435, 'f1': 0.63005929186692}
original test score: {'auroc': 0.61392734464453, 'accuracy': 0.5560810810810811, 'balanced_accuracy': 0.5557342142699311, 'logloss': 0.6811025658456651, 'f1': 0.5245739006541534}
imputed test score: {'auroc': 0.3753650024927, 'accuracy': 0.41621621621621624, 'balanced_accuracy': 0.41619506244532956, 'logloss': 0.7292818775945991, 'f1': 0.41606266074351184}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474664130> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd1a80> 

Generation:  1
Best f1_score score: 0.9498286748998103
Generation:   4%|         | 1/25 [10:01<4:00:44, 601.85s/it]Generation:  2
Best f1_score score: 0.9499985746934781
Generation:   8%|         | 2/25 [10:41<1:43:55, 271.11s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ffa59c0> 

Generation:  3
Best f1_score score: 0.9499985746934781
Generation:  12%|        | 3/25 [20:45<2:35:08, 423.09s/it]Generation:  4
Best f1_score score: 0.9506743115655123
Generation:  16%|        | 4/25 [22:24<1:43:16, 295.09s/it]Generation:  5
Best f1_score score: 0.9511814724081461
Generation:  20%|        | 5/25 [23:54<1:13:44, 221.20s/it]Generation:  6
Best f1_score score: 0.9511814724081461
Generation:  24%|       | 6/25 [24:24<49:27, 156.16s/it]  Generation:  7
Best f1_score score: 0.9521951413535741
Generation:  28%|       | 7/25 [26:27<43:37, 145.42s/it]Generation:  8
Best f1_score score: 0.9521951413535741
Generation:  32%|      | 8/25 [28:16<37:52, 133.69s/it]Generation:  9
Best f1_score score: 0.9537155563550271
Generation:  36%|      | 9/25 [30:49<37:18, 139.90s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc0aec0> 

Generation:  10
Best f1_score score: 0.9537155563550271
Generation:  40%|      | 10/25 [40:58<1:11:07, 284.52s/it]Generation:  11
Best f1_score score: 0.9537155563550271
Generation:  44%|     | 11/25 [47:42<1:14:54, 321.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fee5d50> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ba18070> 

Generation:  12
Best f1_score score: 0.9537155563550271
Generation:  48%|     | 12/25 [57:49<1:28:27, 408.25s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b788040> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452d5ac50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d47160> 

Generation:  13
Best f1_score score: 0.9537155563550271
Generation:  52%|    | 13/25 [1:07:58<1:33:48, 469.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ba3e560> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.9537155563550271
Generation:  56%|    | 14/25 [1:09:16<1:04:19, 350.87s/it]Generation:  15
Best f1_score score: 0.9537155563550271
Generation:  60%|    | 15/25 [1:10:08<43:29, 260.94s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452b91a80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545dc67460> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545c53b640> 

Generation:  16
Best f1_score score: 0.9537155563550271
Generation:  64%|   | 16/25 [1:20:18<54:52, 365.85s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545c46c760> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456f7df00> 

Exception in thread Thread-19 (funcwrap):
Traceback (most recent call last):
  File "/home/ketrong/miniconda3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/ketrong/miniconda3/lib/python3.10/threading.py", line 953, in run
WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554527b10f0> 

    self._target(*self._args, **self._kwargs)
func_timeout.dafunc.FunctionTimedOut-2340504273052904067: Function objective_function (args=[<tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554527b10f0>]) (kwargs={'budget': None, 'X':             0   ...        19
0     0.275080  ...  0.545652
1     0.618135  ...  0.516974
2     0.499380  ...       NaN
3     0.382338  ...  0.430533
4     0.449916  ...  0.598219
...        ...  ...       ...
5915       NaN  ...  0.552561
5916  0.581178  ...  0.421577
5917       NaN  ...  0.396187
5918  0.699932  ...       NaN
5919  0.508246  ...  0.544424

[5920 rows x 20 columns], 'y': array([0, 0, 0, ..., 1, 1, 1])}) timed out after 600.000000 seconds.

Generation:  17
Best f1_score score: 0.9537155563550271
Generation:  68%|   | 17/25 [1:30:28<58:34, 439.28s/it]Generation:  18
Best f1_score score: 0.9537155563550271
Generation:  72%|  | 18/25 [1:30:54<36:45, 315.10s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1552b3b78f70> 

Generation:  19
Best f1_score score: 0.9537155563550271
Generation:  76%|  | 19/25 [1:41:02<40:19, 403.17s/it]Generation:  20
Best f1_score score: 0.9542223756495757
Generation:  80%|  | 20/25 [1:42:28<25:38, 307.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ffb3f70> 

Generation:  21
Best f1_score score: 0.9542223756495757
Generation:  84%| | 21/25 [1:52:35<26:30, 397.62s/it]Generation:  22
Best f1_score score: 0.9542223756495757
Generation:  88%| | 22/25 [1:53:05<14:21, 287.22s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554547db4c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554523ade10> 

Generation:  23
Best f1_score score: 0.9542223756495757
Generation:  92%|| 23/25 [2:03:11<12:46, 383.04s/it]Generation:  24
Best f1_score score: 0.9542223756495757
Generation:  96%|| 24/25 [2:05:37<05:11, 311.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456f9f580> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  25
Best f1_score score: 0.9542223756495757
Generation: 100%|| 25/25 [2:06:07<00:00, 227.45s/it]Generation: 100%|| 25/25 [2:06:07<00:00, 302.72s/it]
2024-11-08 14:20:57,279 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45365' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-d18d74a21f1ef4a25662a1f731882e0d', 'ndarray-d8b8a177c15b9d764d6c1db847317b9d'} (stimulus_id='handle-worker-cleanup-1731104457.2797818')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('svc',
                 SVC(C=1805.589740851198, class_weight='balanced',
                     coef0=0.1477063167325, gamma=0.028982626865, kernel='poly',
                     max_iter=3000, probability=True, shrinking=False))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9907565927486272, 'accuracy': 0.956081081081081, 'balanced_accuracy': 0.9560824306439146, 'logloss': 0.1214536069496424, 'f1': 0.95608100087838}
test score: {'auroc': 0.9916636078590355, 'accuracy': 0.9452702702702702, 'balanced_accuracy': 0.9452783880175091, 'logloss': 0.11970247315674168, 'f1': 0.9452690459200375}
original test score: {'auroc': 0.9975018215884252, 'accuracy': 0.9756756756756757, 'balanced_accuracy': 0.9756756312557182, 'logloss': 0.06405520402254945, 'f1': 0.9756756312557182}
score end
1507
lvl
0.3
type
MNAR
num_run
1
class_full
finished
all finished
full run takes
11.247465692692332
hours
DONE
