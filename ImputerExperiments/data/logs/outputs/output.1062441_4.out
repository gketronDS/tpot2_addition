Run: 4
/cm/local/apps/slurm/var/spool/job1062441/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40685/40685.pkl
working on 
../data/c/40685/class_full_MCAR_0.5_1
1.7974045276641846
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-18 20:33:07,876] A new study created in memory with name: no-name-bb5d6b0c-f761-48f0-a88a-53320464f1a6
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-18 20:33:08,496] Trial 8 finished with value: 0.37520148311890406 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.37520148311890406.
running
[I 2024-11-18 20:33:08,841] Trial 7 finished with value: 0.19085992936447888 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:33:23,702] Trial 10 finished with value: 0.34773672421873625 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.23768015592791925, 'alpha': 89, 'iterations': 5, 'learning_rate': 0.000810780259931909, 'p_miss': 0.1582504660791018}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:33:25,342] Trial 1 finished with value: 0.3360924303695061 and parameters: {'model_name': 'GAIN', 'batch_size': 42, 'hint_rate': 0.7129003167604416, 'alpha': 56, 'iterations': 7, 'learning_rate': 0.007116575907632923, 'p_miss': 0.24958230727018854}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:33:52,433] Trial 9 finished with value: 0.19091100115812404 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4312, 'weights': 'uniform'}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:33:53,217] Trial 6 finished with value: 0.21837603622346805 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1117, 'weights': 'distance'}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:33:55,127] Trial 0 finished with value: 0.19092297753406914 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5176, 'weights': 'uniform'}. Best is trial 7 with value: 0.19085992936447888.
running
[I 2024-11-18 20:34:10,114] Trial 2 finished with value: 0.1116466484694828 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 38, 'learning_rate': 0.0006120315672221525, 'p_miss': 0.05095815595404792}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:10,317] Trial 21 finished with value: 0.1907603279103016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:23,506] Trial 17 finished with value: 0.21628493646396438 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20042, 'weights': 'distance'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:25,231] Trial 14 finished with value: 0.21630386104782406 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19193, 'weights': 'distance'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:38,971] Trial 4 finished with value: 0.20275230861561716 and parameters: {'model_name': 'VAE', 'batch_size': 200, 'iterations': 26, 'learning_rate': 0.0071433276157146265, 'p_miss': 0.06844862788441702}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:40,270] Trial 26 finished with value: 0.1907603279103016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:52,373] Trial 18 finished with value: 0.21618352926024703 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 26033, 'weights': 'distance'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:34:55,639] Trial 27 finished with value: 0.1907603279103016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:35:00,192] Trial 20 finished with value: 0.19096925071636212 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14178, 'weights': 'uniform'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:35:37,725] Trial 3 finished with value: 0.22433499929232012 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:35:39,395] Trial 23 finished with value: 0.19075459391602587 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:35:43,040] Trial 24 finished with value: 0.20850650337871618 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:36:00,373] Trial 16 finished with value: 0.1990454093814005 and parameters: {'model_name': 'VAE', 'batch_size': 837, 'iterations': 33, 'learning_rate': 0.008615689285409532, 'p_miss': 0.18995235058876717}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:36:24,561] Trial 29 finished with value: 0.21225215999479907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:42:07,340] Trial 5 finished with value: 0.11452268435604267 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 301, 'learning_rate': 0.0002310801122649675, 'p_miss': 0.10993916518118768}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:49:50,473] Trial 13 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.203806878501234, 'alpha': 36, 'iterations': 4520, 'learning_rate': 0.00011973611262140692, 'p_miss': 0.07944753655119154}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 20:51:40,079] Trial 15 finished with value: 0.22196504024629804 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 480, 'learning_rate': 0.004546124902454105, 'p_miss': 0.1396016773530488}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 21:08:18,734] Trial 39 finished with value: 0.14078705884806744 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 408, 'learning_rate': 0.00038791757163670563, 'p_miss': 0.023440255085603948}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 21:14:56,882] Trial 38 finished with value: 0.1783398540593762 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 666, 'learning_rate': 0.0005172047693469621, 'p_miss': 0.03504432715875845}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 21:21:43,869] Trial 40 finished with value: 0.12844911866761904 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 318, 'learning_rate': 0.00038301365543314604, 'p_miss': 0.021700422591353352}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 21:26:37,674] Trial 41 finished with value: 0.12289403863122525 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 310, 'learning_rate': 0.0003364213860926009, 'p_miss': 0.022725362902471898}. Best is trial 2 with value: 0.1116466484694828.
running
[I 2024-11-18 21:27:21,282] Trial 42 finished with value: 0.11081587458034889 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 136, 'learning_rate': 0.0001215772920531059, 'p_miss': 0.09415815904578913}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:18,751] Trial 43 finished with value: 0.20411831592510307 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 95, 'learning_rate': 0.09586956358934141, 'p_miss': 0.10039503797682786}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:24,187] Trial 45 finished with value: 0.11353856949750751 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.000122571898757022, 'p_miss': 0.12018241968323456}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:30,558] Trial 46 finished with value: 0.11150159830377562 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 1, 'learning_rate': 0.00011719386633147699, 'p_miss': 0.11640349533702837}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:36,559] Trial 47 finished with value: 0.1159915750928265 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.00010746737367872743, 'p_miss': 0.13111383834258492}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:42,220] Trial 48 finished with value: 0.11457900738408475 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.0010175779538345805, 'p_miss': 0.07046901951249027}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:30:56,662] Trial 49 finished with value: 0.11473709181434329 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 4, 'learning_rate': 0.00010139972465476566, 'p_miss': 0.10214173481803417}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:31:04,844] Trial 50 finished with value: 0.11560254497281323 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.0017330351410189617, 'p_miss': 0.17105056711329641}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:31:49,738] Trial 51 finished with value: 0.11185235895512871 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 14, 'learning_rate': 0.00020209507230058025, 'p_miss': 0.05980095126344586}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:31:50,937] Trial 52 finished with value: 0.23538243359814742 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:32:16,982] Trial 53 finished with value: 0.3667697509447613 and parameters: {'model_name': 'GAIN', 'batch_size': 27, 'hint_rate': 0.8660265259842829, 'alpha': 7, 'iterations': 17, 'learning_rate': 0.00021628688814040052, 'p_miss': 0.05740123960909922}. Best is trial 42 with value: 0.11081587458034889.
running
[I 2024-11-18 21:32:23,275] Trial 44 finished with value: 0.11056898654672671 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 97, 'learning_rate': 0.00011631954793099429, 'p_miss': 0.10066910323751294}. Best is trial 44 with value: 0.11056898654672671.
running
[I 2024-11-18 21:32:25,083] Trial 55 finished with value: 0.37520148311890406 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 44 with value: 0.11056898654672671.
running
[I 2024-11-18 21:35:22,393] Trial 54 finished with value: 0.1121743367712861 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 72, 'learning_rate': 0.00020462429569797342, 'p_miss': 0.049881543203761744}. Best is trial 44 with value: 0.11056898654672671.
running
[I 2024-11-18 21:37:26,381] Trial 56 finished with value: 0.11822132939927252 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 84, 'learning_rate': 0.00019626437097175446, 'p_miss': 0.08765343580191809}. Best is trial 44 with value: 0.11056898654672671.
running
[I 2024-11-18 21:38:03,022] Trial 58 finished with value: 0.11055052213548436 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 14, 'learning_rate': 0.00018434709286389685, 'p_miss': 0.08876292684134972}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:40:45,385] Trial 57 finished with value: 0.11171674629001856 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 122, 'learning_rate': 0.0001908760258217411, 'p_miss': 0.09003362327264122}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:42:33,253] Trial 60 finished with value: 0.11304363459116851 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 35, 'learning_rate': 0.0007028664491117209, 'p_miss': 0.12446581559970275}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:43:28,761] Trial 59 finished with value: 0.12976954984458017 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 134, 'learning_rate': 0.0006383251114931738, 'p_miss': 0.09051212201145781}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:47:14,224] Trial 61 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.010384919443923557, 'alpha': 100, 'iterations': 1162, 'learning_rate': 0.0013956315903129546, 'p_miss': 0.1477508660232534}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:47:53,562] Trial 63 finished with value: 0.11391648487922428 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 12, 'learning_rate': 0.00015097530216101965, 'p_miss': 0.04809041804500433}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:47:55,464] Trial 64 finished with value: 0.37520148311890406 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:49:51,075] Trial 65 finished with value: 0.11335638922878914 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 44, 'learning_rate': 0.0003096598946681476, 'p_miss': 0.24388178669836302}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:49:54,599] Trial 37 finished with value: 0.1719141836655683 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1903, 'learning_rate': 0.00012893693529012442, 'p_miss': 0.02866545060214383}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:53:00,924] Trial 12 finished with value: 0.3582929047147646 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.4832197601248244, 'alpha': 28, 'iterations': 4022, 'learning_rate': 0.005622666213314389, 'p_miss': 0.15592581607627073}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:56:20,667] Trial 67 finished with value: 0.11756332558849927 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 134, 'learning_rate': 0.00017455750600192126, 'p_miss': 0.08335319658921453}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:59:14,578] Trial 66 finished with value: 0.11276254948498832 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 151, 'learning_rate': 0.00016023017841904137, 'p_miss': 0.08662457782384309}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 21:59:52,267] Trial 68 finished with value: 0.1119951735999053 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 155, 'learning_rate': 0.00016955673536039978, 'p_miss': 0.08236453038658116}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:00:14,732] Trial 71 finished with value: 0.11348996760376609 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 7, 'learning_rate': 0.0002934165215777728, 'p_miss': 0.11420013898178512}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:00:54,722] Trial 72 finished with value: 0.19085992936447885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46003, 'weights': 'uniform'}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:01:28,379] Trial 70 finished with value: 0.11384492227761482 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 52, 'learning_rate': 0.0002800401617962834, 'p_miss': 0.11098947171679488}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:02:04,880] Trial 74 finished with value: 0.36537574588679844 and parameters: {'model_name': 'GAIN', 'batch_size': 28, 'hint_rate': 0.9432033995473843, 'alpha': 68, 'iterations': 24, 'learning_rate': 0.00048644141346334006, 'p_miss': 0.06619440810539895}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:02:14,317] Trial 75 finished with value: 0.11371450887822136 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 2, 'learning_rate': 0.00011229144263200519, 'p_miss': 0.10194422555483836}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:02:58,583] Trial 76 finished with value: 0.11628483806968155 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 17, 'learning_rate': 0.00022841478392729704, 'p_miss': 0.06158663466660809}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:03:15,724] Trial 73 finished with value: 0.20365394083688299 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 57, 'learning_rate': 0.012793204010918722, 'p_miss': 0.1086560452111339}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:03:32,521] Trial 77 finished with value: 0.11309309383201968 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 13, 'learning_rate': 0.0001539941293011536, 'p_miss': 0.043169835954952045}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:03:57,414] Trial 78 finished with value: 0.11316162937192853 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 11, 'learning_rate': 0.0001590218135024698, 'p_miss': 0.04675509836652186}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:04:48,026] Trial 69 finished with value: 0.12120064121467075 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 180, 'learning_rate': 0.00027320889410731004, 'p_miss': 0.10905106654044898}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:04:58,788] Trial 80 finished with value: 0.11177400818032415 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 25, 'learning_rate': 0.00024592775279425337, 'p_miss': 0.010109688608825142}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:05:51,162] Trial 82 finished with value: 0.21609155208374337 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46277, 'weights': 'distance'}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:06:02,342] Trial 81 finished with value: 0.11181780719003236 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 30, 'learning_rate': 0.0004142664245426788, 'p_miss': 0.06971470002427019}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:06:03,151] Trial 84 finished with value: 0.19085992936447888 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:07:20,570] Trial 62 finished with value: 0.3356168305098606 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.49861278701071926, 'alpha': 100, 'iterations': 1158, 'learning_rate': 0.00030580811957425417, 'p_miss': 0.296153451086654}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:08:21,184] Trial 86 finished with value: 0.11221098981509817 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 22, 'learning_rate': 0.00047330845075564166, 'p_miss': 0.07202499440621357}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:11:24,894] Trial 36 finished with value: 0.18190025676446897 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2514, 'learning_rate': 0.00010069523744698963, 'p_miss': 0.02243827705438717}. Best is trial 58 with value: 0.11055052213548436.
running
[I 2024-11-18 22:12:37,271] Trial 88 finished with value: 0.10920581738410104 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 29, 'learning_rate': 0.0004043346153179031, 'p_miss': 0.015169838601785966}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:14:31,720] Trial 79 finished with value: 0.11627528538557337 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 236, 'learning_rate': 0.00010393021584663164, 'p_miss': 0.0733775382839825}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:16:37,313] Trial 85 finished with value: 0.11478709791477053 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 233, 'learning_rate': 0.00010127579074956352, 'p_miss': 0.2999839434462643}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:17:04,525] Trial 89 finished with value: 0.11073922835718779 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 95, 'learning_rate': 0.0001346232339801494, 'p_miss': 0.015340419386694129}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:18:40,837] Trial 87 finished with value: 0.14123812560129223 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 245, 'learning_rate': 0.0004215847468532295, 'p_miss': 0.0954953199061086}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:21:12,190] Trial 25 finished with value: 0.1883999445553382 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2797, 'learning_rate': 0.00010663149951682703, 'p_miss': 0.027000073338011715}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:21:23,742] Trial 32 finished with value: 0.1966304710030204 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2756, 'learning_rate': 0.00012363575986464896, 'p_miss': 0.01682415476078377}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:22:09,864] Trial 35 finished with value: 0.2047921320467454 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2797, 'learning_rate': 0.00014081972317859823, 'p_miss': 0.01686128510652897}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:25:44,833] Trial 96 finished with value: 0.11160277366083837 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 97, 'learning_rate': 0.0001443080248191967, 'p_miss': 0.010440738049196093}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:27:14,742] Trial 19 finished with value: 0.20067109190878202 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:28:12,296] Trial 11 finished with value: 0.2006042864687238 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:28:44,513] Trial 22 finished with value: 0.201076016575756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:30:20,219] Trial 98 finished with value: 0.11135653306094495 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 101, 'learning_rate': 0.00013228991325538186, 'p_miss': 0.0356734196461686}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:31:12,712] Trial 100 finished with value: 0.11307059714654347 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 69, 'learning_rate': 0.00013481392087619635, 'p_miss': 0.03683909504819737}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:32:00,104] Trial 99 finished with value: 0.12056553618214401 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 100, 'learning_rate': 0.00013229125781727524, 'p_miss': 0.03063371131151529}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:32:48,134] Trial 103 finished with value: 0.19091455019266199 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31545, 'weights': 'uniform'}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:32:54,714] Trial 102 finished with value: 0.11219459550911226 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 43, 'learning_rate': 0.00013291476708816624, 'p_miss': 0.032579568316288735}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:34:14,054] Trial 101 finished with value: 0.11143131650714155 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 93, 'learning_rate': 0.00014001669686766017, 'p_miss': 0.028406302833117292}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:34:31,297] Trial 104 finished with value: 0.13927205498132963 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 44, 'learning_rate': 0.0023623064689012314, 'p_miss': 0.012726147380951562}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:36:21,191] Trial 105 finished with value: 0.18111671105177668 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 91, 'learning_rate': 0.0022006249489757482, 'p_miss': 0.014949667651765856}. Best is trial 88 with value: 0.10920581738410104.
running
[I 2024-11-18 22:38:27,098] Trial 107 finished with value: 0.1087866883934013 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 98, 'learning_rate': 0.0002058348975848057, 'p_miss': 0.020868597273570613}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:40:27,815] Trial 108 finished with value: 0.11535732607436092 and parameters: {'model_name': 'VAE', 'batch_size': 816, 'iterations': 67, 'learning_rate': 0.00021391745392601678, 'p_miss': 0.024678794251658885}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:40:49,172] Trial 109 finished with value: 0.11717166049388913 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 65, 'learning_rate': 0.000221503626211252, 'p_miss': 0.025301666723639274}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:41:59,617] Trial 28 finished with value: 0.20289479990789827 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3389, 'learning_rate': 0.00010196974682203619, 'p_miss': 0.0116074236675456}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:42:09,747] Trial 110 finished with value: 0.11061428916832076 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 108, 'learning_rate': 0.00012999731506335138, 'p_miss': 0.03882486881799115}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:42:23,816] Trial 111 finished with value: 0.27224408909378817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:42:24,523] Trial 114 finished with value: 0.37520148311890406 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:43:46,260] Trial 112 finished with value: 0.27224408909378817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:43:52,149] Trial 113 finished with value: 0.27224408909378817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:47:21,583] Trial 116 finished with value: 0.11164994456135183 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 99, 'learning_rate': 0.00013424652448269618, 'p_miss': 0.03798518246449078}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:53:58,743] Trial 31 finished with value: 0.2220836972399914 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4048, 'learning_rate': 0.00011724964155506808, 'p_miss': 0.03078711284889024}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:54:37,762] Trial 118 finished with value: 0.11147922582029272 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 186, 'learning_rate': 0.0001776908368952128, 'p_miss': 0.017444170528733392}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:57:41,186] Trial 119 finished with value: 0.11036910322369782 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 111, 'learning_rate': 0.00017459232407867858, 'p_miss': 0.0174438098603426}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 22:57:47,889] Trial 115 finished with value: 0.13756454564415216 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 473, 'learning_rate': 0.0001809228036899497, 'p_miss': 0.13458592497917699}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:04:43,431] Trial 122 finished with value: 0.11522198495435085 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 199, 'learning_rate': 0.000246123637706712, 'p_miss': 0.040775831492596046}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:07:07,054] Trial 30 finished with value: 0.22110424576505724 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4630, 'learning_rate': 0.00011399420500362645, 'p_miss': 0.010038033961376189}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:12:35,377] Trial 121 finished with value: 0.1244160141662017 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 411, 'learning_rate': 0.00016975535497342758, 'p_miss': 0.019061456401729602}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:14:53,817] Trial 34 finished with value: 0.22591779514776994 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4253, 'learning_rate': 0.00012770402299018703, 'p_miss': 0.013429921678544926}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:17:09,532] Trial 125 finished with value: 0.11632345129235463 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 124, 'learning_rate': 0.00034523132127626047, 'p_miss': 0.05439386667941331}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:19:18,681] Trial 123 finished with value: 0.13334363376254388 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 325, 'learning_rate': 0.00019119124077036494, 'p_miss': 0.01999843867871337}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:19:19,818] Trial 126 finished with value: 0.11619270733015492 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 124, 'learning_rate': 0.00012281875837038392, 'p_miss': 0.028006458752432465}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:20:56,067] Trial 124 finished with value: 0.12625997687835272 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 359, 'learning_rate': 0.00018022494255862876, 'p_miss': 0.01922477233484005}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:23:33,922] Trial 127 finished with value: 0.11287856748040637 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 170, 'learning_rate': 0.00012590703632331542, 'p_miss': 0.027204604397683574}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:23:51,636] Trial 131 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.6825628971541214, 'alpha': 0, 'iterations': 78, 'learning_rate': 0.012960483847477104, 'p_miss': 0.03538502403357962}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:25:21,236] Trial 128 finished with value: 0.1131041218471347 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 164, 'learning_rate': 0.0001189297266692115, 'p_miss': 0.029868331895102518}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:26:29,337] Trial 130 finished with value: 0.11073789467348102 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 183, 'learning_rate': 0.00011874853513061199, 'p_miss': 0.03425843649449474}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:28:11,783] Trial 134 finished with value: 0.11313626210682379 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 53, 'learning_rate': 0.0001574598423158451, 'p_miss': 0.04854717626847205}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:32:36,167] Trial 135 finished with value: 0.1152290793589811 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 106, 'learning_rate': 0.00025812056230644303, 'p_miss': 0.16697794472525063}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:44:09,824] Trial 90 finished with value: 0.20429834002865105 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:45:10,881] Trial 91 finished with value: 0.2039316384164068 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:47:04,711] Trial 92 finished with value: 0.20431326631256316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:48:31,481] Trial 93 finished with value: 0.20353953958202617 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:51:15,427] Trial 94 finished with value: 0.20416661294538865 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:51:32,642] Trial 95 finished with value: 0.20397463535865956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:51:48,044] Trial 142 finished with value: 0.11269981616337747 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.00015256712350773005, 'p_miss': 0.0379999528862895}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:55:11,429] Trial 138 finished with value: 0.11087065433472434 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 196, 'learning_rate': 0.0001012278087270653, 'p_miss': 0.04160472918496418}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:56:29,059] Trial 97 finished with value: 0.20409659031104432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:57:41,241] Trial 139 finished with value: 0.11371068741735287 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 198, 'learning_rate': 0.0001462705746349421, 'p_miss': 0.12171441922113856}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-18 23:58:24,806] Trial 140 finished with value: 0.11523729803548348 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 202, 'learning_rate': 0.0001475791611159946, 'p_miss': 0.19114145511138547}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:00:33,578] Trial 141 finished with value: 0.1145502313651511 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 213, 'learning_rate': 0.00010135033076599215, 'p_miss': 0.018381868591161712}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:02:04,749] Trial 143 finished with value: 0.11194025166901392 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 197, 'learning_rate': 0.00010133330102734746, 'p_miss': 0.018553300768907266}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:03:12,489] Trial 145 finished with value: 0.11876873928749312 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 137, 'learning_rate': 0.0001476500980417171, 'p_miss': 0.1906449763995546}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:05:03,381] Trial 144 finished with value: 0.11002282146624982 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 192, 'learning_rate': 0.0001073548095033003, 'p_miss': 0.043384230498320936}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:07:06,354] Trial 148 finished with value: 0.11598587715365478 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 136, 'learning_rate': 0.00011659126202961979, 'p_miss': 0.045112693919093616}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:10:44,149] Trial 147 finished with value: 0.11113252349863392 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 269, 'learning_rate': 0.00010390826852525987, 'p_miss': 0.043227541731531705}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:11:16,919] Trial 152 finished with value: 0.11057355188691047 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 82, 'learning_rate': 0.00018296092746502521, 'p_miss': 0.05150517456123835}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:11:17,588] Trial 146 finished with value: 0.11402994482650268 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 266, 'learning_rate': 0.00010305392723667995, 'p_miss': 0.1996512495156361}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:11:24,582] Trial 153 finished with value: 0.19085992936447885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 36118, 'weights': 'uniform'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:11:58,395] Trial 155 finished with value: 0.19085992936447885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38431, 'weights': 'uniform'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:14:02,899] Trial 149 finished with value: 0.11283285030532479 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 268, 'learning_rate': 0.00011797604430589253, 'p_miss': 0.04251439096224756}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:15:09,584] Trial 157 finished with value: 0.1109093181790108 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 77, 'learning_rate': 0.00011878835480435689, 'p_miss': 0.05841169380500672}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:15:41,166] Trial 159 finished with value: 0.1159766001722394 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9, 'learning_rate': 0.000198672874391996, 'p_miss': 0.058519772490485046}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:16:04,065] Trial 150 finished with value: 0.1169847969168325 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 279, 'learning_rate': 0.000120714450073133, 'p_miss': 0.0936544089522045}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:17:47,659] Trial 158 finished with value: 0.11667607613028497 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 81, 'learning_rate': 0.00021717952036556616, 'p_miss': 0.05649919550765185}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:17:49,259] Trial 162 finished with value: 0.23538243359814742 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:19:14,932] Trial 160 finished with value: 0.1144142216136419 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 79, 'learning_rate': 0.00012060465050431038, 'p_miss': 0.053669023332519536}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:21:15,934] Trial 137 finished with value: 0.13821930614557515 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 663, 'learning_rate': 0.00010148638839650228, 'p_miss': 0.04065711320411082}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:21:23,083] Trial 161 finished with value: 0.11194016368472667 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 117, 'learning_rate': 0.00017612562875806524, 'p_miss': 0.05405220664023253}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:21:44,195] Trial 164 finished with value: 0.11262049017258147 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 56, 'learning_rate': 0.0001630691877632769, 'p_miss': 0.06569714751585598}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:26:01,543] Trial 166 finished with value: 0.11033309562237177 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 110, 'learning_rate': 0.00013881182897447999, 'p_miss': 0.0636703904922004}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:26:37,196] Trial 165 finished with value: 0.11222651866858077 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 112, 'learning_rate': 0.0001647604137623126, 'p_miss': 0.07754464848688175}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:28:04,240] Trial 167 finished with value: 0.11502198547234191 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 110, 'learning_rate': 0.0001375294130543453, 'p_miss': 0.07741253896671499}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:28:49,754] Trial 170 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.3213342059494269, 'alpha': 74, 'iterations': 159, 'learning_rate': 0.00013524042742532616, 'p_miss': 0.03388471756361216}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:30:34,441] Trial 168 finished with value: 0.21137785314550434 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 115, 'learning_rate': 0.04214576995495298, 'p_miss': 0.07908474212434026}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:32:02,608] Trial 171 finished with value: 0.20765699708607213 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 63, 'learning_rate': 0.004946883700132252, 'p_miss': 0.06469834147116643}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:33:55,448] Trial 169 finished with value: 0.20208862708183317 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 156, 'learning_rate': 0.08180687617509944, 'p_miss': 0.06276822458999227}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:33:58,022] Trial 172 finished with value: 0.11552949869828141 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 64, 'learning_rate': 0.00011344601701207126, 'p_miss': 0.062279825327335475}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:34:44,900] Trial 151 finished with value: 0.12175993170672454 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 627, 'learning_rate': 0.00011545709723528665, 'p_miss': 0.042558528374198504}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:36:00,055] Trial 175 finished with value: 0.11197431601304789 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 34, 'learning_rate': 0.00019603190524052053, 'p_miss': 0.04720092666851472}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:37:40,252] Trial 33 finished with value: 0.2370835754983017 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6611, 'learning_rate': 0.00017196069903115024, 'p_miss': 0.019396267273995557}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:38:17,550] Trial 174 finished with value: 0.11839566238057816 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 86, 'learning_rate': 0.00011150339635422365, 'p_miss': 0.04892793950102056}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:39:16,649] Trial 176 finished with value: 0.11467472279561024 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 95, 'learning_rate': 0.00013810885584441307, 'p_miss': 0.050105173953493905}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:40:06,410] Trial 154 finished with value: 0.14395451476079996 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 664, 'learning_rate': 0.0002064129497271621, 'p_miss': 0.05632382315023865}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:41:28,754] Trial 177 finished with value: 0.11293219498662573 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 91, 'learning_rate': 0.0001381159776680246, 'p_miss': 0.025423161420160125}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:41:36,803] Trial 156 finished with value: 0.12691667666163475 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 682, 'learning_rate': 0.00011847635664834643, 'p_miss': 0.04346796090672457}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:41:38,479] Trial 178 finished with value: 0.11218785357705967 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 87, 'learning_rate': 0.00013659879540140404, 'p_miss': 0.03250760091724992}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:42:00,257] Trial 179 finished with value: 0.11622745224946333 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 94, 'learning_rate': 0.00013652172698386486, 'p_miss': 0.026329690345391545}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:43:04,583] Trial 180 finished with value: 0.1116124514267546 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 79, 'learning_rate': 0.00013388100807925555, 'p_miss': 0.02556196854097429}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:43:36,229] Trial 183 finished with value: 0.11456662522154074 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 47, 'learning_rate': 0.0002443963266569712, 'p_miss': 0.031992724267709396}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:43:38,736] Trial 184 finished with value: 0.11229658894000187 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 42, 'learning_rate': 0.00024002347011573767, 'p_miss': 0.024405811469814825}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:43:57,266] Trial 182 finished with value: 0.11462604300159143 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 50, 'learning_rate': 0.0002379713537573014, 'p_miss': 0.03157148379860638}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:44:38,608] Trial 185 finished with value: 0.1184829024276235 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 49, 'learning_rate': 0.00023818516135867002, 'p_miss': 0.03537616872106974}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:44:41,332] Trial 181 finished with value: 0.11182050963347771 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 79, 'learning_rate': 0.00013631680684139915, 'p_miss': 0.03212176753848105}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:45:09,716] Trial 186 finished with value: 0.11358141732584856 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 46, 'learning_rate': 0.0001745602726288007, 'p_miss': 0.012632955459700761}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:45:11,741] Trial 192 finished with value: 0.37520148311890406 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:50:37,202] Trial 189 finished with value: 0.11464620033269637 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 146, 'learning_rate': 0.00017785693746155294, 'p_miss': 0.015485806039114158}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:50:43,985] Trial 190 finished with value: 0.11317973549049154 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 144, 'learning_rate': 0.0001767546809020157, 'p_miss': 0.015781462102065505}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:51:12,270] Trial 187 finished with value: 0.11251650629115 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 146, 'learning_rate': 0.00017513062931957335, 'p_miss': 0.014527333268734607}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:51:41,666] Trial 188 finished with value: 0.11293146210176899 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 144, 'learning_rate': 0.00017075869723687074, 'p_miss': 0.010576559994159289}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:52:07,573] Trial 193 finished with value: 0.16532340319429745 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 145, 'learning_rate': 0.0008713207594238483, 'p_miss': 0.016463003609926974}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:53:11,418] Trial 191 finished with value: 0.11366813296397363 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 171, 'learning_rate': 0.00016984244995542057, 'p_miss': 0.014734801429624255}. Best is trial 107 with value: 0.1087866883934013.
running
[I 2024-11-19 00:53:33,010] Trial 199 finished with value: 0.10977065438597926 and parameters: {'model_name': 'VAE', 'batch_size': 216, 'iterations': 5, 'learning_rate': 0.00010258351620624809, 'p_miss': 0.10589593963153336}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 00:57:32,444] Trial 194 finished with value: 0.11304964490341021 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 164, 'learning_rate': 0.00015927406162538402, 'p_miss': 0.098758435249785}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 00:59:04,745] Trial 195 finished with value: 0.11783460995610107 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 173, 'learning_rate': 0.0001539447229164219, 'p_miss': 0.03896342016418602}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 00:59:08,842] Trial 196 finished with value: 0.11500782402816985 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 181, 'learning_rate': 0.0001552335990310909, 'p_miss': 0.10104201946650081}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 00:59:36,033] Trial 197 finished with value: 0.11362731897524685 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 192, 'learning_rate': 0.0001017623725889975, 'p_miss': 0.0394225813047678}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 01:00:47,695] Trial 198 finished with value: 0.11144000889875685 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 200, 'learning_rate': 0.00010062424541443704, 'p_miss': 0.038403306141636936}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:06:57,477] Trial 106 finished with value: 0.2193412369239653 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7918, 'learning_rate': 0.0002315592845073578, 'p_miss': 0.01778531889461849}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:17:14,044] Trial 120 finished with value: 0.20164204058697438 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 6282, 'learning_rate': 0.00017593193497677064, 'p_miss': 0.0420678930066704}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:31:52,388] Trial 133 finished with value: 0.21092395448363707 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6623, 'learning_rate': 0.00014728783335033247, 'p_miss': 0.16948266170153986}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:41:25,937] Trial 83 finished with value: 0.21509782621519236 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9091, 'learning_rate': 0.00040352172693213466, 'p_miss': 0.07311915324470591}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:43:10,411] Trial 129 finished with value: 0.20840235499202878 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7435, 'learning_rate': 0.00015112811771624888, 'p_miss': 0.03049252363540271}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:47:21,926] Trial 163 finished with value: 0.21092958487904961 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 6020, 'learning_rate': 0.08813910008854897, 'p_miss': 0.0526641885393687}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:49:13,959] Trial 117 finished with value: 0.2053843700502961 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9287, 'learning_rate': 0.0001351171784439852, 'p_miss': 0.04068203123636387}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:49:49,847] Trial 132 finished with value: 0.20489587301770684 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6889, 'learning_rate': 0.0001436700067816973, 'p_miss': 0.17248055703533427}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:50:12,415] Trial 173 finished with value: 0.21585760510319524 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7448, 'learning_rate': 0.00011596930205409689, 'p_miss': 0.04987872611165843}. Best is trial 107 with value: 0.1087866883934013.
[I 2024-11-19 02:50:39,970] Trial 136 finished with value: 0.20198289455986593 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 8169, 'learning_rate': 0.00010040160374045723, 'p_miss': 0.019198894182097307}. Best is trial 107 with value: 0.1087866883934013.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0.1087866883934013
{'model_name': 'VAE', 'batch_size': 3, 'iterations': 98, 'learning_rate': 0.0002058348975848057, 'p_miss': 0.020868597273570613}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.1428541171769157
Generation:   4%|▍         | 1/25 [08:21<3:20:34, 501.42s/it]Generation:  2
Best f1_score score: 0.1428541171769157
Generation:   8%|▊         | 2/25 [14:53<2:47:38, 437.31s/it]Generation:  3
Best f1_score score: 0.14399940549699636
Generation:  12%|█▏        | 3/25 [21:46<2:36:13, 426.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474711990> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.14399940549699636
Generation:  16%|█▌        | 4/25 [26:45<2:11:29, 375.70s/it]Generation:  5
Best f1_score score: 0.14399940549699636
Generation:  20%|██        | 5/25 [35:34<2:23:44, 431.23s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ef27d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.14418415492967912
Generation:  24%|██▍       | 6/25 [41:56<2:11:12, 414.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467873160> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.14418415492967912
Generation:  28%|██▊       | 7/25 [51:35<2:20:26, 468.11s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3af0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465d930> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2680> 

Generation:  8
Best f1_score score: 0.14418415492967912
Generation:  32%|███▏      | 8/25 [1:01:45<2:25:25, 513.27s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467aeec80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe81f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.14440600768445666
Generation:  36%|███▌      | 9/25 [1:08:54<2:09:53, 487.11s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466d28fa0> 

Generation:  10
Best f1_score score: 0.1449246052219335
Generation:  40%|████      | 10/25 [1:19:05<2:11:18, 525.22s/it]Generation:  11
Best f1_score score: 0.1449246052219335
Generation:  44%|████▍     | 11/25 [1:23:34<1:44:17, 446.99s/it]Generation:  12
Best f1_score score: 0.1449246052219335
Generation:  48%|████▊     | 12/25 [1:30:35<1:35:06, 438.95s/it]Generation:  13
Best f1_score score: 0.1449246052219335
Generation:  52%|█████▏    | 13/25 [1:37:44<1:27:12, 436.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d35d20> 

Generation:  14
Best f1_score score: 0.1449246052219335
Generation:  56%|█████▌    | 14/25 [1:47:58<1:29:46, 489.68s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d181c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.1449246052219335
Generation:  60%|██████    | 15/25 [1:56:10<1:21:43, 490.39s/it]Generation:  16
Best f1_score score: 0.1449246052219335
Generation:  64%|██████▍   | 16/25 [2:01:52<1:06:52, 445.82s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546760f340> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464bebac0> 

Generation:  17
Best f1_score score: 0.1449246052219335
Generation:  68%|██████▊   | 17/25 [2:12:08<1:06:15, 496.89s/it]Generation:  18
Best f1_score score: 0.1449246052219335
Generation:  72%|███████▏  | 18/25 [2:16:31<49:46, 426.63s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f7c670> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.1449246052219335
Generation:  76%|███████▌  | 19/25 [2:20:46<37:29, 374.99s/it]Generation:  20
Best f1_score score: 0.1449246052219335
Generation:  80%|████████  | 20/25 [2:27:45<32:21, 388.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466a73790> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.1449246052219335
Generation:  84%|████████▍ | 21/25 [2:34:35<26:19, 394.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466eeabc0> 

Generation:  22
Best f1_score score: 0.1449246052219335
Generation:  88%|████████▊ | 22/25 [2:44:46<22:59, 459.81s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467398c10> 

Generation:  23
Best f1_score score: 0.1449246052219335
Generation:  92%|█████████▏| 23/25 [2:54:59<16:51, 505.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474711d50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464bc0670> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.1449246052219335
Generation:  96%|█████████▌| 24/25 [3:02:30<08:09, 489.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d6d630> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.1449246052219335
Generation: 100%|██████████| 25/25 [3:10:47<00:00, 491.49s/it]Generation: 100%|██████████| 25/25 [3:10:50<00:00, 458.02s/it]
2024-11-19 06:01:42,941 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:39953' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-5d6f715f335dc046978a9902c6651b83', 'ndarray-08e2b28cd26b443d1296bc2cda8a08c0'} (stimulus_id='handle-worker-cleanup-1732024902.9417815')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      max_features=0.9536105259048,
                                      min_samples_leaf=12, min_samples_split=11,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.960372573495583, 'accuracy': 0.8782112068965517, 'balanced_accuracy': 0.9489702115021498, 'logloss': 0.9856239165710338, 'f1': 0.7993802254549001}
original test score: {'auroc': 0.6273576559670628, 'accuracy': 0.7569827586206896, 'balanced_accuracy': 0.147079992397435, 'logloss': 1.030779424658935, 'f1': 0.1402287971717176}
imputed test score: {'auroc': 0.5548538422019439, 'accuracy': 0.660948275862069, 'balanced_accuracy': 0.14578010820483828, 'logloss': 1.0891918058847099, 'f1': 0.14570826225577438}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e50> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1810> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1360> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1060> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0b20> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0250> 

Generation:  1
Best f1_score score: 0.440163814031526
Generation:   4%|▍         | 1/25 [10:03<4:01:19, 603.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f98a0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15548648b100> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fdfc0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2f070> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474706050> 

Generation:  2
Best f1_score score: 0.6544318472415782
Generation:   8%|▊         | 2/25 [20:08<3:51:39, 604.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fc74c0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e277c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546788ddb0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fac550> 

Generation:  3
Best f1_score score: 0.6874831479652388
Generation:  12%|█▏        | 3/25 [30:12<3:41:37, 604.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f61510> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f05270> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2f80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3c10> 

Generation:  4
Best f1_score score: 0.6874831479652388
Generation:  16%|█▌        | 4/25 [40:18<3:31:40, 604.79s/it]Generation:  5
Best f1_score score: 0.6926849694574314
Generation:  20%|██        | 5/25 [43:25<2:31:24, 454.24s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b63f4f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466c21c30> 

Generation:  6
Best f1_score score: 0.6926849694574314
Generation:  24%|██▍       | 6/25 [53:31<2:40:10, 505.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553f988aa10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451ef2b60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452e37130> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554525191b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466bb17b0> 

Generation:  7
Best f1_score score: 0.6940635228574706
Generation:  28%|██▊       | 7/25 [1:03:37<2:41:32, 538.45s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e6d7e0> 

Generation:  8
Best f1_score score: 0.7061107789046057
Generation:  32%|███▏      | 8/25 [1:13:41<2:38:30, 559.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452c5fc10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545264ca60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e02c50> 

Generation:  9
Best f1_score score: 0.7061107789046057
Generation:  36%|███▌      | 9/25 [1:23:47<2:33:03, 573.94s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b9ca110> 

Generation:  10
Best f1_score score: 0.7193070619599504
Generation:  40%|████      | 10/25 [1:33:54<2:26:02, 584.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546486d8d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467781b10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554669ffe20> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545243fe50> 

Generation:  11
Best f1_score score: 0.7314821625951071
Generation:  44%|████▍     | 11/25 [1:44:01<2:17:54, 591.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b50e980> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c2a890> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e4e080> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fd600> 

Generation:  12
Best f1_score score: 0.7314821625951071
Generation:  48%|████▊     | 12/25 [1:54:07<2:09:04, 595.73s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f73d30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554525c2e60> 

Generation:  13
Best f1_score score: 0.7314821625951071
Generation:  52%|█████▏    | 13/25 [2:04:14<1:59:48, 599.07s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554666c1e70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458ee4fa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546794f970> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467032980> 

Generation:  14
Best f1_score score: 0.7332189973658727
Generation:  56%|█████▌    | 14/25 [2:14:21<1:50:17, 601.58s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467947eb0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554224c9330> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1390> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465008400> 

Generation:  15
Best f1_score score: 0.7332189973658727
Generation:  60%|██████    | 15/25 [2:24:28<1:40:32, 603.26s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547473b700> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545301fcd0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544cb931f0> 

Generation:  16
Best f1_score score: 0.7332189973658727
Generation:  64%|██████▍   | 16/25 [2:34:36<1:30:40, 604.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467faf280> 

Generation:  17
Best f1_score score: 0.7572592769081827
Generation:  68%|██████▊   | 17/25 [2:44:43<1:20:42, 605.35s/it]Generation:  18
Best f1_score score: 0.7572592769081827
Generation:  72%|███████▏  | 18/25 [2:52:26<1:05:38, 562.68s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544bce0c40> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466fab070> 

Generation:  19
Best f1_score score: 0.7572592769081827
Generation:  76%|███████▌  | 19/25 [3:02:34<57:37, 576.23s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5a440> 

Generation:  20
Best f1_score score: 0.7572592769081827
Generation:  80%|████████  | 20/25 [3:12:40<48:46, 585.22s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553e8a56dd0> 

Generation:  21
Best f1_score score: 0.7572592769081827
Generation:  84%|████████▍ | 21/25 [3:22:47<39:27, 591.78s/it]