Run: 28
/cm/local/apps/slurm/var/spool/job1050034/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1459/1459.pkl
working on 
../data/c/1459/class_full_MCAR_0.5_2
0.9946975708007812
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-14 20:21:29,938] A new study created in memory with name: no-name-b8e6d8f7-945c-4199-8caf-8a89f6c1aa7a
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-14 20:21:30,198] Trial 5 finished with value: 0.17248452224973504 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 5 with value: 0.17248452224973504.
running
[I 2024-11-14 20:21:30,450] Trial 15 finished with value: 0.17248452224973504 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 5 with value: 0.17248452224973504.
running
[I 2024-11-14 20:21:30,798] Trial 3 finished with value: 0.24750733556850077 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 5 with value: 0.17248452224973504.
running
[I 2024-11-14 20:21:30,959] Trial 17 finished with value: 0.23920140907343773 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.17248452224973504.
running
[I 2024-11-14 20:21:33,131] Trial 4 finished with value: 0.1690512397806834 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 193, 'weights': 'uniform'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:33,893] Trial 8 finished with value: 0.17248452224973504 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6461, 'weights': 'uniform'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:34,045] Trial 11 finished with value: 0.17590611440035667 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2364, 'weights': 'uniform'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:34,452] Trial 12 finished with value: 0.17461867633286074 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5348, 'weights': 'uniform'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:34,577] Trial 14 finished with value: 0.176193768205498 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3717, 'weights': 'uniform'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:35,238] Trial 13 finished with value: 0.1867510393018969 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7572, 'weights': 'distance'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:41,162] Trial 22 finished with value: 0.18692904285994233 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5797, 'weights': 'distance'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:42,281] Trial 7 finished with value: 0.230643947093416 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.3884264679613708, 'alpha': 38, 'iterations': 1, 'learning_rate': 0.00022460216650088734, 'p_miss': 0.28558086813867617}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:42,804] Trial 0 finished with value: 0.2352297743673029 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.6130429292513846, 'alpha': 81, 'iterations': 1, 'learning_rate': 0.0012560215736581153, 'p_miss': 0.2173724580475312}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:46,174] Trial 1 finished with value: 0.23763153983784324 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.8300701980582821, 'alpha': 10, 'iterations': 12, 'learning_rate': 0.006213086801348498, 'p_miss': 0.15818696084139047}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:47,008] Trial 2 finished with value: 0.17295538917428008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:49,725] Trial 16 finished with value: 0.23882604638351257 and parameters: {'model_name': 'GAIN', 'batch_size': 72, 'hint_rate': 0.2784982561617417, 'alpha': 11, 'iterations': 20, 'learning_rate': 0.0010798541294261498, 'p_miss': 0.14945276403987545}. Best is trial 4 with value: 0.1690512397806834.
running
[I 2024-11-14 20:21:55,767] Trial 28 finished with value: 0.16620239748308838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:21:58,850] Trial 21 finished with value: 0.1915995677114321 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:22:12,385] Trial 27 finished with value: 0.16863155644082636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:22:58,928] Trial 23 finished with value: 0.17559043325955676 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 61, 'learning_rate': 0.09006278726703305, 'p_miss': 0.09763020688897352}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:23:17,105] Trial 35 finished with value: 0.16638168624528493 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:23:34,154] Trial 36 finished with value: 0.16638168624528493 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:23:40,501] Trial 37 finished with value: 0.16625067393843754 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:23:46,908] Trial 38 finished with value: 0.16625067393843754 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 28 with value: 0.16620239748308838.
running
[I 2024-11-14 20:23:50,610] Trial 26 finished with value: 0.15864851102501404 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 105, 'learning_rate': 0.001358470139409003, 'p_miss': 0.12340362338160124}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:23:53,223] Trial 39 finished with value: 0.16625096602450698 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:25:42,562] Trial 25 finished with value: 0.1803451975916323 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 152, 'learning_rate': 0.0021557046222745666, 'p_miss': 0.23829004550463018}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:26:25,452] Trial 19 finished with value: 0.24475540000492355 and parameters: {'model_name': 'GAIN', 'batch_size': 470, 'hint_rate': 0.7619851528519916, 'alpha': 13, 'iterations': 226, 'learning_rate': 0.05353851560622023, 'p_miss': 0.15112626649388033}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:30:37,630] Trial 18 finished with value: 0.1809652894785764 and parameters: {'model_name': 'VAE', 'batch_size': 240, 'iterations': 132, 'learning_rate': 0.0003442677428328184, 'p_miss': 0.18068183854685824}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:40:58,319] Trial 10 finished with value: 0.1713655382138695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:41:39,230] Trial 9 finished with value: 0.17378910419794805 and parameters: {'model_name': 'VAE', 'batch_size': 654, 'iterations': 257, 'learning_rate': 0.001736071143853977, 'p_miss': 0.1949021797705441}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:41:44,338] Trial 46 finished with value: 0.16625067186188208 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:41:57,879] Trial 47 finished with value: 0.16629909759841116 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:46:27,195] Trial 24 finished with value: 0.16374601432625663 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 20:46:42,438] Trial 29 finished with value: 0.16348348189123282 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-14 21:35:09,678] Trial 20 finished with value: 0.1609892558811594 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1145, 'learning_rate': 0.00016068898617821152, 'p_miss': 0.2507315653075999}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 01:03:05,290] Trial 48 finished with value: 0.1761752154662894 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 4764, 'learning_rate': 0.012547713962707712, 'p_miss': 0.018955954028251704}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 01:22:25,764] Trial 50 finished with value: 0.1767122085775044 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 4252, 'learning_rate': 0.013248747532279425, 'p_miss': 0.034843773176477216}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 01:31:23,845] Trial 42 finished with value: 0.17454934009983197 and parameters: {'model_name': 'VAE', 'batch_size': 716, 'iterations': 3968, 'learning_rate': 0.00010020142814347643, 'p_miss': 0.010672424633562938}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:05:07,225] Trial 44 finished with value: 0.17653374265436936 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 5301, 'learning_rate': 0.011336487240886945, 'p_miss': 0.016952650399410046}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:23:42,662] Trial 41 finished with value: 0.17526815534499426 and parameters: {'model_name': 'VAE', 'batch_size': 637, 'iterations': 4829, 'learning_rate': 0.011224869583732975, 'p_miss': 0.08687898492655713}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:32:39,412] Trial 54 finished with value: 0.17570498773825521 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 969, 'learning_rate': 0.0005271611051511428, 'p_miss': 0.1003105005159224}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:41:28,424] Trial 53 finished with value: 0.16809963995689198 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1347, 'learning_rate': 0.00010202291202947633, 'p_miss': 0.09336694694159525}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:42:56,067] Trial 56 finished with value: 0.1632795448173339 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:50:25,824] Trial 40 finished with value: 0.1750594088038685 and parameters: {'model_name': 'VAE', 'batch_size': 679, 'iterations': 5562, 'learning_rate': 0.010762374174901859, 'p_miss': 0.010364368884179742}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:52:40,351] Trial 57 finished with value: 0.16376575435812485 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 02:52:40,662] Trial 61 finished with value: 0.24750733556850077 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:00:52,774] Trial 55 finished with value: 0.1776277259161329 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 852, 'learning_rate': 0.000498586445722356, 'p_miss': 0.09598873827352403}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:01:02,988] Trial 58 finished with value: 0.16252303014449096 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:01:04,476] Trial 63 finished with value: 0.22983518880701398 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.01204864014891005, 'alpha': 99, 'iterations': 5, 'learning_rate': 0.004248797735550144, 'p_miss': 0.29600113250939697}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:01:14,229] Trial 64 finished with value: 0.23211499702883556 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.02114624401112769, 'alpha': 98, 'iterations': 5, 'learning_rate': 0.00020859341911586918, 'p_miss': 0.2696603662360074}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:02:24,530] Trial 59 finished with value: 0.1634057251497421 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:09:34,289] Trial 60 finished with value: 0.16253602862747488 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:15:12,595] Trial 62 finished with value: 0.23818858767261414 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.04320735678789661, 'alpha': 94, 'iterations': 805, 'learning_rate': 0.0006518308136915043, 'p_miss': 0.29284574661459434}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:19:04,725] Trial 65 finished with value: 0.1676292434757555 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:19:42,567] Trial 52 finished with value: 0.16231933358923545 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2276, 'learning_rate': 0.00012694619220883363, 'p_miss': 0.08889967307906796}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:19:42,957] Trial 71 finished with value: 0.24750733556850077 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:20:26,206] Trial 67 finished with value: 0.16600079280331642 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:20:38,092] Trial 66 finished with value: 0.16410059525042145 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:27:26,687] Trial 68 finished with value: 0.1667497135293256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:32:24,602] Trial 6 finished with value: 0.17514614898197695 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 6812, 'learning_rate': 0.0065138039217613455, 'p_miss': 0.12256678308057573}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:33:34,248] Trial 69 finished with value: 0.16636640301593383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:36:33,509] Trial 70 finished with value: 0.1705749692133495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:46:51,208] Trial 74 finished with value: 0.17328176762499467 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 425, 'learning_rate': 0.00019246820085426573, 'p_miss': 0.055685303558064475}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:46:54,445] Trial 79 finished with value: 0.18411087863272085 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 147, 'weights': 'distance'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:47:47,813] Trial 72 finished with value: 0.17027033443712125 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 443, 'learning_rate': 0.00018828583616642191, 'p_miss': 0.06765857138932348}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:52:16,830] Trial 45 finished with value: 0.17572320323777343 and parameters: {'model_name': 'VAE', 'batch_size': 96, 'iterations': 7335, 'learning_rate': 0.008899451105234171, 'p_miss': 0.03612015947190557}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:52:17,384] Trial 82 finished with value: 0.23920140907343773 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:52:43,729] Trial 30 finished with value: 0.17559629585651537 and parameters: {'model_name': 'VAE', 'batch_size': 921, 'iterations': 5530, 'learning_rate': 0.05379767775265909, 'p_miss': 0.013081491114457694}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:55:19,385] Trial 75 finished with value: 0.17233961197684378 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 451, 'learning_rate': 0.00019982181493284927, 'p_miss': 0.059242338242825}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 03:58:31,284] Trial 77 finished with value: 0.17072252508144986 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 428, 'learning_rate': 0.00021914820165632853, 'p_miss': 0.05726037766978476}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:01:26,068] Trial 76 finished with value: 0.16664078988752334 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 431, 'learning_rate': 0.00019768090031465574, 'p_miss': 0.054488719390413644}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:02:24,253] Trial 78 finished with value: 0.1739978936755032 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 461, 'learning_rate': 0.00021133928193371732, 'p_miss': 0.05797729160915765}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:09:57,226] Trial 51 finished with value: 0.1768360539307016 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 6581, 'learning_rate': 0.00010049116796172174, 'p_miss': 0.02078093465843825}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:11:10,042] Trial 83 finished with value: 0.16258920805360297 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:11:21,849] Trial 84 finished with value: 0.16371336214354631 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:14:13,283] Trial 85 finished with value: 0.16431167305818792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:19:28,091] Trial 86 finished with value: 0.16355281320656076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:22:40,908] Trial 87 finished with value: 0.1627139025562479 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:22:47,754] Trial 94 finished with value: 0.18659886096794576 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2515, 'weights': 'distance'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:22:57,222] Trial 88 finished with value: 0.1630697635038167 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:30:30,655] Trial 91 finished with value: 0.16386350316961446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:30:36,520] Trial 90 finished with value: 0.16353355806365957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:30:50,154] Trial 97 finished with value: 0.173789663050551 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:30:54,735] Trial 89 finished with value: 0.1642927663545026 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:30:56,254] Trial 98 finished with value: 0.173789663050551 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:31:10,828] Trial 100 finished with value: 0.18575225263363976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:33:31,597] Trial 92 finished with value: 0.16199519482030433 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:39:19,341] Trial 93 finished with value: 0.161911368170978 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:42:54,906] Trial 101 finished with value: 0.16921453962253577 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:43:01,722] Trial 105 finished with value: 0.1867510393018969 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8056, 'weights': 'distance'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:43:57,305] Trial 96 finished with value: 0.16313632285785049 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:44:41,585] Trial 95 finished with value: 0.16325100945909682 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:49:30,731] Trial 103 finished with value: 0.17156995738748654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:50:12,191] Trial 109 finished with value: 0.22037147470217072 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:51:45,855] Trial 99 finished with value: 0.16491318885793718 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:51:46,919] Trial 111 finished with value: 0.24750733556850077 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:52:19,604] Trial 102 finished with value: 0.164387429148583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:55:49,318] Trial 104 finished with value: 0.16948588585270147 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 04:57:17,792] Trial 114 finished with value: 0.2407020318170973 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.9869987829615482, 'alpha': 62, 'iterations': 54, 'learning_rate': 0.0009273358218552809, 'p_miss': 0.13270318007469198}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:01:39,558] Trial 107 finished with value: 0.1705689666898834 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:02:50,860] Trial 108 finished with value: 0.1694235645177836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:03:59,511] Trial 106 finished with value: 0.16193911293065674 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:04:43,044] Trial 118 finished with value: 0.21850380889195203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:09:18,924] Trial 110 finished with value: 0.161651064820603 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:11:32,788] Trial 119 finished with value: 0.1895802158540842 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 104, 'learning_rate': 0.00036703371406347123, 'p_miss': 0.2193372915785532}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:14:39,403] Trial 73 finished with value: 0.1666329286195331 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1610, 'learning_rate': 0.0001734478020152557, 'p_miss': 0.05709127727806765}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:15:13,946] Trial 43 finished with value: 0.17610086927078786 and parameters: {'model_name': 'VAE', 'batch_size': 235, 'iterations': 7913, 'learning_rate': 0.00010046969965575708, 'p_miss': 0.016756332360617604}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:21:46,384] Trial 116 finished with value: 0.1637914454526172 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:23:18,390] Trial 117 finished with value: 0.16403222037604498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:25:59,498] Trial 81 finished with value: 0.1794703782632487 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 1804, 'learning_rate': 0.0008315196209857804, 'p_miss': 0.12655558741225859}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:33:07,817] Trial 122 finished with value: 0.16408321123858274 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:33:52,469] Trial 123 finished with value: 0.16206551775634515 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:38:25,765] Trial 112 finished with value: 0.24340028714891196 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.9559565312916859, 'alpha': 62, 'iterations': 1948, 'learning_rate': 0.000967450742184619, 'p_miss': 0.12933045747265795}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:38:46,096] Trial 34 finished with value: 0.17501446198649712 and parameters: {'model_name': 'VAE', 'batch_size': 837, 'iterations': 6516, 'learning_rate': 0.07965961029901855, 'p_miss': 0.04435671659109075}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:39:59,199] Trial 124 finished with value: 0.16341752949626492 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:40:20,551] Trial 31 finished with value: 0.17522823161723938 and parameters: {'model_name': 'VAE', 'batch_size': 570, 'iterations': 8725, 'learning_rate': 0.06535758876244567, 'p_miss': 0.010409173276805767}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:42:02,993] Trial 113 finished with value: 0.2430107657709673 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.5921063429879377, 'alpha': 57, 'iterations': 2043, 'learning_rate': 0.0008879921133222006, 'p_miss': 0.11493591622303309}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:44:41,038] Trial 126 finished with value: 0.1631419397629153 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:45:41,496] Trial 80 finished with value: 0.17234813845098024 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1847, 'learning_rate': 0.00028708636952798545, 'p_miss': 0.059307165794232605}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:51:49,679] Trial 127 finished with value: 0.16279825330195608 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:52:49,201] Trial 128 finished with value: 0.16295700227749135 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:57:01,384] Trial 129 finished with value: 0.1630450628768093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:58:19,850] Trial 130 finished with value: 0.16268765517818695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:58:37,231] Trial 139 finished with value: 0.1663965487102373 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 05:59:08,765] Trial 131 finished with value: 0.16317638511560045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:00:00,397] Trial 132 finished with value: 0.1622802230084274 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:00:00,785] Trial 142 finished with value: 0.17248452224973504 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:01:02,750] Trial 133 finished with value: 0.1619852647795777 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:01:08,093] Trial 144 finished with value: 0.17599057132210488 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4179, 'weights': 'uniform'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:04:11,720] Trial 134 finished with value: 0.16497897520304242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:05:07,338] Trial 135 finished with value: 0.165543405215039 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:11:25,670] Trial 136 finished with value: 0.16215872081245206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:12:19,532] Trial 137 finished with value: 0.1629724864735007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:15:58,838] Trial 138 finished with value: 0.16423024913117668 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:16:46,601] Trial 141 finished with value: 0.1672658969457675 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:07,006] Trial 143 finished with value: 0.17084641665341752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:07,717] Trial 150 finished with value: 0.18332296636947337 and parameters: {'model_name': 'VAE', 'batch_size': 160, 'iterations': 29, 'learning_rate': 0.0016581719978524998, 'p_miss': 0.1903804987204804}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:15,924] Trial 151 finished with value: 0.19588702987144724 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 31, 'learning_rate': 0.0014949540714479159, 'p_miss': 0.17057662305517446}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:19,508] Trial 140 finished with value: 0.1638143048645976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:21,222] Trial 145 finished with value: 0.16819727668563939 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:39,150] Trial 152 finished with value: 0.17902357388657097 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 38, 'learning_rate': 0.0016334704802300364, 'p_miss': 0.167133273367369}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:40,358] Trial 153 finished with value: 0.21360343236891363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:49,285] Trial 154 finished with value: 0.21360343236891363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:18:53,930] Trial 155 finished with value: 0.21767273474884713 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:21:51,752] Trial 49 finished with value: 0.17652404606599456 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 8625, 'learning_rate': 0.01124733468323284, 'p_miss': 0.03336083407242002}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:22:36,840] Trial 125 finished with value: 0.24294673235558487 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.2563537233223716, 'alpha': 45, 'iterations': 2190, 'learning_rate': 0.0023123244305108944, 'p_miss': 0.173861884816995}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:23:26,222] Trial 147 finished with value: 0.17067231029224117 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:24:15,562] Trial 146 finished with value: 0.16271808618823913 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:24:34,518] Trial 164 finished with value: 0.1663755121716434 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:24:55,683] Trial 165 finished with value: 0.1721100425252578 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:30:00,602] Trial 148 finished with value: 0.16885362092681633 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:31:08,945] Trial 149 finished with value: 0.1674954498501175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:32:56,223] Trial 159 finished with value: 0.16880607592283206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:38:08,271] Trial 156 finished with value: 0.16345912541967245 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:38:14,618] Trial 158 finished with value: 0.1633624739754347 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:39:04,602] Trial 157 finished with value: 0.1638579565291637 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:39:18,079] Trial 160 finished with value: 0.16265164066897358 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:41:23,547] Trial 161 finished with value: 0.16252242951853973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:41:24,462] Trial 174 finished with value: 0.24750733556850077 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:42:46,750] Trial 162 finished with value: 0.16311532433095266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:43:23,168] Trial 163 finished with value: 0.16290320271963102 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:44:29,704] Trial 166 finished with value: 0.16297296429131952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:47:09,669] Trial 115 finished with value: 0.1757154782255088 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 2189, 'learning_rate': 0.0003275012151681317, 'p_miss': 0.22495282151529872}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:49:19,098] Trial 167 finished with value: 0.16284772615626286 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:49:25,265] Trial 180 finished with value: 0.18630134002710136 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1904, 'weights': 'distance'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:50:48,272] Trial 168 finished with value: 0.16395398442210524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:53:35,337] Trial 169 finished with value: 0.16371020206486508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:57:53,429] Trial 173 finished with value: 0.18074475040729526 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 216, 'learning_rate': 0.028403204808301306, 'p_miss': 0.2691195353858962}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:58:21,879] Trial 171 finished with value: 0.16320597867490677 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:58:31,675] Trial 170 finished with value: 0.16384321562347431 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 06:58:53,720] Trial 175 finished with value: 0.18217879357943834 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 231, 'learning_rate': 0.004284365932643367, 'p_miss': 0.2561343141767114}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:00:03,565] Trial 172 finished with value: 0.16468515412539417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:02:22,966] Trial 176 finished with value: 0.16227385700195587 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:02:43,569] Trial 177 finished with value: 0.16334420425166857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:04:02,582] Trial 178 finished with value: 0.16392759901595863 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:06:52,486] Trial 179 finished with value: 0.1623452082564112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:07:12,653] Trial 192 finished with value: 0.1707533803555143 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:08:09,403] Trial 120 finished with value: 0.17626375439790215 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 2078, 'learning_rate': 0.0016779073623954981, 'p_miss': 0.22021990432007302}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:08:45,279] Trial 181 finished with value: 0.1627562355740208 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:10:30,490] Trial 182 finished with value: 0.16332635814108667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:13:09,526] Trial 183 finished with value: 0.1636023631941732 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:17:34,066] Trial 185 finished with value: 0.16304297900745388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:18:04,983] Trial 186 finished with value: 0.16358106669066697 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
running
[I 2024-11-15 07:18:12,560] Trial 184 finished with value: 0.16440383929947297 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:18:12,929] Trial 187 finished with value: 0.16473582429144845 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:21:32,371] Trial 188 finished with value: 0.1635503882428922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:21:55,167] Trial 189 finished with value: 0.16394305768857176 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:22:09,461] Trial 190 finished with value: 0.1620766447681506 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:22:58,895] Trial 191 finished with value: 0.16330123595828122 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:25:12,622] Trial 193 finished with value: 0.1669568499239225 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:25:30,425] Trial 194 finished with value: 0.16462234690834726 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:25:58,962] Trial 195 finished with value: 0.16609812589554998 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:27:02,575] Trial 196 finished with value: 0.16412770174909583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:27:45,168] Trial 121 finished with value: 0.17507532993297373 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 2067, 'learning_rate': 0.0017003704691493156, 'p_miss': 0.17348199569170109}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:28:23,450] Trial 197 finished with value: 0.16233651972061788 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:30:44,728] Trial 198 finished with value: 0.1638289525232918 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:31:01,548] Trial 199 finished with value: 0.1624759178023798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:32:32,666] Trial 33 finished with value: 0.17577264245924515 and parameters: {'model_name': 'VAE', 'batch_size': 931, 'iterations': 7341, 'learning_rate': 0.09402957993081204, 'p_miss': 0.0230760566386726}. Best is trial 26 with value: 0.15864851102501404.
[I 2024-11-15 07:32:45,583] Trial 32 finished with value: 0.1758804188803854 and parameters: {'model_name': 'VAE', 'batch_size': 965, 'iterations': 7767, 'learning_rate': 0.05718193551551148, 'p_miss': 0.022449064815879938}. Best is trial 26 with value: 0.15864851102501404.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
dtype: int64
0.15864851102501404
{'model_name': 'VAE', 'batch_size': 76, 'iterations': 105, 'learning_rate': 0.001358470139409003, 'p_miss': 0.12340362338160124}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c4c700> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a01c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0be0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.09922619183833037
Generation:   4%|         | 1/25 [00:38<15:24, 38.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474711de0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.09922619183833037
Generation:   8%|         | 2/25 [01:13<13:59, 36.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f7460> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.09922619183833037
Generation:  12%|        | 3/25 [03:18<28:11, 76.91s/it]Generation:  4
Best f1_score score: 0.09922619183833037
Generation:  16%|        | 4/25 [03:58<21:50, 62.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658f0b80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.09973870352802724
Generation:  20%|        | 5/25 [05:19<23:03, 69.20s/it]Generation:  6
Best f1_score score: 0.09973870352802724
Generation:  24%|       | 6/25 [07:43<29:56, 94.53s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f25ea0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f11ed0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.10238417800816771
Generation:  28%|       | 7/25 [08:25<23:12, 77.39s/it]Generation:  8
Best f1_score score: 0.10238417800816771
Generation:  32%|      | 8/25 [10:20<25:17, 89.27s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546596a3b0> 
 Out of bag estimation only available if bootstrap=True 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 66, in inner_f
    return f(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 402, in fit
    return self._fit(X, y, max_samples=self.max_samples, **fit_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 502, in _fit
    raise ValueError("Out of bag estimation only available if bootstrap=True")
ValueError: Out of bag estimation only available if bootstrap=True

Generation:  9
Best f1_score score: 0.10238417800816771
Generation:  36%|      | 9/25 [11:46<23:32, 88.26s/it]Generation:  10
Best f1_score score: 0.10238417800816771
Generation:  40%|      | 10/25 [13:47<24:34, 98.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155485ed6b60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.10238417800816771
Generation:  44%|     | 11/25 [15:07<21:37, 92.70s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474730b20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.10238417800816771
Generation:  48%|     | 12/25 [16:52<20:52, 96.35s/it]Generation:  13
Best f1_score score: 0.10238417800816771
Generation:  52%|    | 13/25 [19:13<22:01, 110.14s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2e60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.10238417800816771
Generation:  56%|    | 14/25 [20:13<17:22, 94.82s/it] Generation:  15
Best f1_score score: 0.10238417800816771
Generation:  60%|    | 15/25 [21:16<14:13, 85.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c4e830> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.10238417800816771
Generation:  64%|   | 16/25 [23:01<13:41, 91.27s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676f8b50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.10238417800816771
Generation:  68%|   | 17/25 [23:56<10:43, 80.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f06f50> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  18
Best f1_score score: 0.10348402151778387
Generation:  72%|  | 18/25 [24:28<07:40, 65.77s/it]Generation:  19
Best f1_score score: 0.10348402151778387
Generation:  76%|  | 19/25 [27:30<10:03, 100.57s/it]Generation:  20
Best f1_score score: 0.10348402151778387
Generation:  80%|  | 20/25 [28:44<07:43, 92.80s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465904ee0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.10348402151778387
Generation:  84%| | 21/25 [29:28<05:12, 78.09s/it]Generation:  22
Best f1_score score: 0.10348402151778387
Generation:  88%| | 22/25 [30:42<03:50, 76.81s/it]Generation:  23
Best f1_score score: 0.10348402151778387
Generation:  92%|| 23/25 [31:49<02:27, 73.96s/it]Generation:  24
Best f1_score score: 0.10432543140517037
Generation:  96%|| 24/25 [35:21<01:55, 115.34s/it]Generation:  25
Best f1_score score: 0.10432543140517037
Generation: 100%|| 25/25 [37:03<00:00, 111.39s/it]Generation: 100%|| 25/25 [37:07<00:00, 89.12s/it] 
2024-11-15 08:10:17,183 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34413' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-26814314f5e56af0d614d2cc0f809fa3', 'ndarray-8ea3c1164f68cb30edbe6dde013c9407'} (stimulus_id='handle-worker-cleanup-1731687017.183069')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.4693760224128,
                                        min_samples_leaf=10,
                                        min_samples_split=5,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9902135574550931, 'accuracy': 0.8782725715683876, 'balanced_accuracy': 0.8936352375993122, 'logloss': 1.7166086639137068, 'f1': 0.8788065283726081}
original test score: {'auroc': 0.5274286607086791, 'accuracy': 0.13111545988258316, 'balanced_accuracy': 0.12222477841763062, 'logloss': 2.2910284829774317, 'f1': 0.12417297976891042}
imputed test score: {'auroc': 0.5038264284390048, 'accuracy': 0.10176125244618395, 'balanced_accuracy': 0.10004706051863117, 'logloss': 2.324750756496103, 'f1': 0.09988683871720434}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.2515974853686199
Generation:   4%|         | 1/25 [05:48<2:19:22, 348.45s/it]Generation:  2
Best f1_score score: 0.3431116667586464
Generation:   8%|         | 2/25 [07:03<1:11:55, 187.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d50df0> 
 l1_ratio must be specified when penalty is elasticnet. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1204, in fit
    raise ValueError("l1_ratio must be specified when penalty is elasticnet.")
ValueError: l1_ratio must be specified when penalty is elasticnet.

Generation:  3
Best f1_score score: 0.3431116667586464
Generation:  12%|        | 3/25 [13:04<1:37:52, 266.93s/it]Generation:  4
Best f1_score score: 0.3431116667586464
Generation:  16%|        | 4/25 [18:55<1:44:56, 299.84s/it]Generation:  5
Best f1_score score: 0.4211131773080356
Generation:  20%|        | 5/25 [19:35<1:08:48, 206.41s/it]Generation:  6
Best f1_score score: 0.4211131773080356
Generation:  24%|       | 6/25 [20:23<48:15, 152.41s/it]  Generation:  7
Best f1_score score: 0.4211131773080356
Generation:  28%|       | 7/25 [21:11<35:26, 118.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f7ee680> 
 Out of bag estimation only available if bootstrap=True 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 66, in inner_f
    return f(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 402, in fit
    return self._fit(X, y, max_samples=self.max_samples, **fit_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py", line 502, in _fit
    raise ValueError("Out of bag estimation only available if bootstrap=True")
ValueError: Out of bag estimation only available if bootstrap=True

Generation:  8
Best f1_score score: 0.49045370550883727
Generation:  32%|      | 8/25 [21:52<26:32, 93.70s/it] Generation:  9
Best f1_score score: 0.5267484020756767
Generation:  36%|      | 9/25 [22:32<20:29, 76.83s/it]Generation:  10
Best f1_score score: 0.5267484020756767
Generation:  40%|      | 10/25 [23:10<16:13, 64.92s/it]Generation:  11
Best f1_score score: 0.5350825079204611
Generation:  44%|     | 11/25 [23:48<13:12, 56.57s/it]Generation:  12
Best f1_score score: 0.5350825079204611
Generation:  48%|     | 12/25 [25:44<16:11, 74.70s/it]Generation:  13
Best f1_score score: 0.5350825079204611
Generation:  52%|    | 13/25 [26:50<14:26, 72.19s/it]Generation:  14
Best f1_score score: 0.5350825079204611
Generation:  56%|    | 14/25 [27:48<12:27, 67.94s/it]Generation:  15
Best f1_score score: 0.5350825079204611
Generation:  60%|    | 15/25 [28:12<09:05, 54.58s/it]Generation:  16
Best f1_score score: 0.5350825079204611
Generation:  64%|   | 16/25 [34:20<22:20, 148.90s/it]Generation:  17
Best f1_score score: 0.5350825079204611
Generation:  68%|   | 17/25 [40:29<28:41, 215.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459c64d90> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  18
Best f1_score score: 0.5350825079204611
Generation:  72%|  | 18/25 [41:05<18:49, 161.34s/it]Generation:  19
Best f1_score score: 0.5350825079204611
Generation:  76%|  | 19/25 [41:43<12:25, 124.25s/it]Generation:  20
Best f1_score score: 0.5350825079204611
Generation:  80%|  | 20/25 [42:15<08:03, 96.65s/it] Generation:  21
Best f1_score score: 0.5350825079204611
Generation:  84%| | 21/25 [44:37<07:20, 110.25s/it]Generation:  22
Best f1_score score: 0.5350825079204611
Generation:  88%| | 22/25 [47:44<06:39, 133.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fd18730> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  23
Best f1_score score: 0.5350825079204611
Generation:  92%|| 23/25 [48:15<03:25, 102.61s/it]Generation:  24
Best f1_score score: 0.5350825079204611
Generation:  96%|| 24/25 [50:03<01:44, 104.06s/it]Generation:  25
Best f1_score score: 0.5350825079204611
Generation: 100%|| 25/25 [50:40<00:00, 83.90s/it] Generation: 100%|| 25/25 [50:40<00:00, 121.61s/it]
2024-11-15 09:01:07,411 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35533' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-26814314f5e56af0d614d2cc0f809fa3', 'DataFrame-b096ed91abdd6dfef906aadda50a8c38'} (stimulus_id='handle-worker-cleanup-1731690067.4115832')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('baggingclassifier',
                 BaggingClassifier(bootstrap=False, bootstrap_features=True,
                                   max_features=0.4661469911542,
                                   max_samples=0.8875548859021, n_estimators=80,
                                   n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9845331181400427, 'accuracy': 0.8687301198923416, 'balanced_accuracy': 0.8568092284522579, 'logloss': 1.0091131845502053, 'f1': 0.8678614827956554}
test score: {'auroc': 0.9030767319118341, 'accuracy': 0.5596868884540117, 'balanced_accuracy': 0.5367451570345564, 'logloss': 1.4883744746736887, 'f1': 0.5437542935661124}
original test score: {'auroc': 0.9793732976583811, 'accuracy': 0.8233855185909981, 'balanced_accuracy': 0.8107214407981098, 'logloss': 0.9108888357594791, 'f1': 0.8144601676484614}
score end
1459
lvl
0.5
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
12.664770886633132
hours
DONE
