Run: 52
/cm/local/apps/slurm/var/spool/job1030390/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/803/803.pkl
working on 
../data/c/803/class_full_MCAR_0.5_3
3.5555224418640137
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-29 10:04:15,013] A new study created in memory with name: no-name-5c70cf64-d4dd-4d6d-b684-90ac593bee4b
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-29 10:04:15,221] Trial 9 finished with value: 0.2063806308007104 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 9 with value: 0.2063806308007104.
running
[I 2024-10-29 10:04:16,630] Trial 8 finished with value: 0.2063806308007104 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5234, 'weights': 'uniform'}. Best is trial 9 with value: 0.2063806308007104.
running
[I 2024-10-29 10:04:16,846] Trial 14 finished with value: 0.21350519559421294 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 196, 'weights': 'distance'}. Best is trial 9 with value: 0.2063806308007104.
running
[I 2024-10-29 10:04:17,033] Trial 3 finished with value: 0.20579878368562152 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1813, 'weights': 'uniform'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:17,432] Trial 6 finished with value: 0.21363688889969618 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1299, 'weights': 'distance'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:17,743] Trial 0 finished with value: 0.2138129831481573 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3883, 'weights': 'distance'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:18,539] Trial 10 finished with value: 0.20654331472247894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:18,855] Trial 17 finished with value: 0.20600902151753592 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3217, 'weights': 'uniform'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:19,054] Trial 20 finished with value: 0.2067027270538082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:19,268] Trial 18 finished with value: 0.20611360645336624 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3901, 'weights': 'uniform'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:19,434] Trial 24 finished with value: 0.3799849488736301 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:19,649] Trial 23 finished with value: 0.33974209792625537 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:21,875] Trial 22 finished with value: 0.20588663586284417 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2745, 'weights': 'uniform'}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:25,790] Trial 19 finished with value: 0.29037901315934345 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 3 with value: 0.20579878368562152.
running
[I 2024-10-29 10:04:30,556] Trial 29 finished with value: 0.1192619856084082 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.0011324439165245881, 'p_miss': 0.1900137754158952}. Best is trial 29 with value: 0.1192619856084082.
running
[I 2024-10-29 10:04:32,530] Trial 16 finished with value: 0.16411848485894126 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 3, 'learning_rate': 0.040166838802497856, 'p_miss': 0.14907187009360953}. Best is trial 29 with value: 0.1192619856084082.
running
[I 2024-10-29 10:04:35,926] Trial 30 finished with value: 0.12355907704676865 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.001210494852394292, 'p_miss': 0.19189994167388388}. Best is trial 29 with value: 0.1192619856084082.
running
[I 2024-10-29 10:04:36,614] Trial 31 finished with value: 0.11645524807632138 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.002271616090578577, 'p_miss': 0.16416570575060324}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:04:38,998] Trial 32 finished with value: 0.12054325853447057 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0005639567639037054, 'p_miss': 0.2139527424002898}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:04:51,795] Trial 2 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6626091498055579, 'alpha': 71, 'iterations': 118, 'learning_rate': 0.07282192746879305, 'p_miss': 0.06814384026460718}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:06:58,830] Trial 27 finished with value: 0.33055584357829504 and parameters: {'model_name': 'GAIN', 'batch_size': 569, 'hint_rate': 0.08402337765262674, 'alpha': 89, 'iterations': 100, 'learning_rate': 0.00042271622417992116, 'p_miss': 0.11047919030561437}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:07:02,664] Trial 36 finished with value: 0.11832986856722039 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.0030370697246191645, 'p_miss': 0.26621316615847146}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:07:57,874] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.2807963611670647, 'alpha': 76, 'iterations': 821, 'learning_rate': 0.0014260440474577652, 'p_miss': 0.22628734532396508}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:08:24,576] Trial 38 finished with value: 0.12209306689694308 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 7, 'learning_rate': 0.006215597667898334, 'p_miss': 0.24222455394978562}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:08:55,405] Trial 39 finished with value: 0.12736848935938266 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 10, 'learning_rate': 0.005380213658820117, 'p_miss': 0.2775429378953648}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:08:59,183] Trial 40 finished with value: 0.11743475365028852 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 1, 'learning_rate': 0.00014481195249412793, 'p_miss': 0.15448422313055382}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:09:21,846] Trial 15 finished with value: 0.15180681273446467 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 123, 'learning_rate': 0.0009313112574632054, 'p_miss': 0.21908731043493446}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:09:48,795] Trial 42 finished with value: 0.12534791591447866 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 9, 'learning_rate': 0.00012395802146675973, 'p_miss': 0.13647602487386498}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:10:04,034] Trial 41 finished with value: 0.12175178887851576 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 18, 'learning_rate': 0.00010588211314290432, 'p_miss': 0.018192863376937735}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:10:09,985] Trial 43 finished with value: 0.14545801139516884 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 3, 'learning_rate': 0.016032129254191115, 'p_miss': 0.2914439370308854}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:10:14,145] Trial 45 finished with value: 0.12472810006314931 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 1, 'learning_rate': 0.002962176130345491, 'p_miss': 0.09310501612919644}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:10:17,740] Trial 46 finished with value: 0.11969412734786607 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.003066169440349915, 'p_miss': 0.17380003062959182}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:10:28,077] Trial 47 finished with value: 0.12204003239598785 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.00028549011419427557, 'p_miss': 0.16586436449464473}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:11:12,442] Trial 34 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.38910440754089975, 'alpha': 42, 'iterations': 1415, 'learning_rate': 0.00685664555714716, 'p_miss': 0.022823860598550766}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:11:20,636] Trial 49 finished with value: 0.1286044706759341 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2, 'learning_rate': 0.0019622560036266297, 'p_miss': 0.12482702553458569}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:11:21,148] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.6214886290737968, 'alpha': 78, 'iterations': 1546, 'learning_rate': 0.0002304112293617915, 'p_miss': 0.18889231447888302}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:12:02,155] Trial 26 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5423857349396104, 'alpha': 68, 'iterations': 1724, 'learning_rate': 0.03580219961284514, 'p_miss': 0.07325544680360581}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:12:50,238] Trial 50 finished with value: 0.12574323908038915 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 31, 'learning_rate': 0.00023799229226953024, 'p_miss': 0.2542100786881999}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:01,822] Trial 53 finished with value: 0.119338868032781 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 2, 'learning_rate': 0.012734752432243418, 'p_miss': 0.1928954034538816}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:07,168] Trial 54 finished with value: 0.11710247024650519 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.000674329824016342, 'p_miss': 0.15433179681759093}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:08,073] Trial 55 finished with value: 0.3799849488736301 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:14,254] Trial 56 finished with value: 0.11664676695079682 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.0007388173683016024, 'p_miss': 0.1525303412546675}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:34,086] Trial 57 finished with value: 0.12111899988905803 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 5, 'learning_rate': 0.0006573025629903864, 'p_miss': 0.1518594396990428}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:13:41,811] Trial 58 finished with value: 0.11696454545238115 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 2, 'learning_rate': 0.0020808308065566705, 'p_miss': 0.1260926196824847}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:17:01,558] Trial 13 finished with value: 0.22458400255801836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:17:09,635] Trial 60 finished with value: 0.12196517323666307 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 2, 'learning_rate': 0.001977940387300303, 'p_miss': 0.12778371300034821}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:17:16,774] Trial 61 finished with value: 0.11680576770291304 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 2, 'learning_rate': 0.0007250990123497071, 'p_miss': 0.10737234380990757}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:17:28,468] Trial 62 finished with value: 0.1277970168337741 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4, 'learning_rate': 0.0007431129230862238, 'p_miss': 0.10223028061181559}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:17:38,800] Trial 63 finished with value: 0.22199093145396048 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:18:39,275] Trial 28 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5533969287473027, 'alpha': 74, 'iterations': 3289, 'learning_rate': 0.09935635431317709, 'p_miss': 0.2790095546657646}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:18:46,188] Trial 65 finished with value: 0.11676669178842973 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0003768645012530133, 'p_miss': 0.08748362053798643}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:18:52,170] Trial 66 finished with value: 0.12463191402814928 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0003846499843307516, 'p_miss': 0.08132445634876918}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:25:49,769] Trial 33 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.5336306209566583, 'alpha': 64, 'iterations': 4608, 'learning_rate': 0.0009055018332779631, 'p_miss': 0.2570578883922379}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:26:43,597] Trial 59 finished with value: 0.22306560427758723 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:26:50,446] Trial 69 finished with value: 0.12393220039686743 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0004502080587335173, 'p_miss': 0.04223968252751344}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:28:48,211] Trial 11 finished with value: 0.12573501026961548 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 455, 'learning_rate': 0.00010906591905670581, 'p_miss': 0.23828826573161552}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:28:48,938] Trial 71 finished with value: 0.3799849488736301 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:28:51,557] Trial 72 finished with value: 0.21385380430885345 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5661, 'weights': 'distance'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:29:08,176] Trial 73 finished with value: 0.13191134853373412 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 5, 'learning_rate': 0.0014544936917866426, 'p_miss': 0.11561751069884671}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:29:14,846] Trial 74 finished with value: 0.11750600666632474 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 2, 'learning_rate': 0.0018420306077828554, 'p_miss': 0.05476943566527404}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:29:50,645] Trial 67 finished with value: 0.2112144971792846 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 219, 'learning_rate': 0.001848250871249796, 'p_miss': 0.048924195792760236}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:29:55,516] Trial 76 finished with value: 0.11810461625692503 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 1, 'learning_rate': 0.00016420494366963559, 'p_miss': 0.1508136220128481}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:07,101] Trial 77 finished with value: 0.11733433357435467 and parameters: {'model_name': 'VAE', 'batch_size': 193, 'iterations': 3, 'learning_rate': 0.00029009362348513483, 'p_miss': 0.17155812455003364}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:12,886] Trial 75 finished with value: 0.12223562825635796 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 16, 'learning_rate': 0.0003211471456166424, 'p_miss': 0.14254403613973116}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:34,534] Trial 79 finished with value: 0.12443941381466687 and parameters: {'model_name': 'VAE', 'batch_size': 317, 'iterations': 4, 'learning_rate': 0.00046335036221645677, 'p_miss': 0.16466284602138528}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:41,826] Trial 80 finished with value: 0.1168928388800115 and parameters: {'model_name': 'VAE', 'batch_size': 257, 'iterations': 2, 'learning_rate': 0.0008363277240635488, 'p_miss': 0.17456382353960673}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:43,727] Trial 81 finished with value: 0.21349801517885236 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 176, 'weights': 'distance'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:51,070] Trial 82 finished with value: 0.1257842881857422 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.0006740072987101148, 'p_miss': 0.20679737286996214}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:30:51,468] Trial 83 finished with value: 0.3799849488736301 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:31:05,530] Trial 78 finished with value: 0.13202549092443852 and parameters: {'model_name': 'VAE', 'batch_size': 852, 'iterations': 14, 'learning_rate': 0.0003197922911808184, 'p_miss': 0.17261065791705515}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:31:12,328] Trial 84 finished with value: 0.11730043629756129 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.0009771195204364203, 'p_miss': 0.09064019829782538}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:31:15,184] Trial 85 finished with value: 0.21188929772614779 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:31:19,686] Trial 87 finished with value: 0.12003649275856967 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0009786694656562192, 'p_miss': 0.08659033491746122}. Best is trial 31 with value: 0.11645524807632138.
running
[I 2024-10-29 10:31:42,206] Trial 88 finished with value: 0.11495400272753345 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 6, 'learning_rate': 0.0013576026760953768, 'p_miss': 0.10811810655425166}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:33:24,390] Trial 86 finished with value: 0.12011339087931468 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 49, 'learning_rate': 0.0010270682103542441, 'p_miss': 0.09348213524717693}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:33:34,844] Trial 90 finished with value: 0.11804708076593232 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.0013690892733767136, 'p_miss': 0.11004603334569692}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:33:39,622] Trial 91 finished with value: 0.32826390583456205 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.9692375736194472, 'alpha': 1, 'iterations': 2, 'learning_rate': 0.0005309877238902767, 'p_miss': 0.13094133536530628}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:33:44,015] Trial 92 finished with value: 0.11691683029997293 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 1, 'learning_rate': 0.004287713820834096, 'p_miss': 0.118696142855334}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:33:52,067] Trial 1 finished with value: 0.2101172840629844 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 564, 'learning_rate': 0.0009594820473633138, 'p_miss': 0.25366297892596873}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:01,724] Trial 93 finished with value: 0.1257751065849924 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 5, 'learning_rate': 0.004390252530004092, 'p_miss': 0.0738992995422034}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:08,208] Trial 94 finished with value: 0.11990259213103441 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 5, 'learning_rate': 0.00450690216591096, 'p_miss': 0.07054672395324493}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:11,438] Trial 95 finished with value: 0.1236207745671846 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 3, 'learning_rate': 0.0023654355784369593, 'p_miss': 0.11988814087249743}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:13,137] Trial 96 finished with value: 0.127037893243708 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 1, 'learning_rate': 0.0007803311083534464, 'p_miss': 0.1180679913190588}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:14,898] Trial 89 finished with value: 0.14115341211975552 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 44, 'learning_rate': 0.0013342861997379261, 'p_miss': 0.10797751611005207}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:15,981] Trial 97 finished with value: 0.11959600498864882 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.001435040250277582, 'p_miss': 0.14051309312419183}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:18,719] Trial 99 finished with value: 0.12288031171520035 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.008059789057208082, 'p_miss': 0.13808082797656898}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:19,316] Trial 98 finished with value: 0.12807266981822232 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.0012297124954904937, 'p_miss': 0.10340074111756807}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:20,421] Trial 100 finished with value: 0.12007556526475124 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 1, 'learning_rate': 0.0005604237088473544, 'p_miss': 0.18568036179833683}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:22,517] Trial 103 finished with value: 0.2063806308007104 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4591, 'weights': 'uniform'}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:27,889] Trial 101 finished with value: 0.12289827632245205 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 3, 'learning_rate': 0.0006292590436905863, 'p_miss': 0.1611047960496705}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:28,269] Trial 105 finished with value: 0.2063806308007104 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:32,819] Trial 102 finished with value: 0.12073629005482897 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 3, 'learning_rate': 0.002445312067696642, 'p_miss': 0.15803525646931924}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:47,844] Trial 106 finished with value: 0.1292156722815375 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.000851627686072864, 'p_miss': 0.09607104965572766}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:49,595] Trial 104 finished with value: 0.1257740095126296 and parameters: {'model_name': 'VAE', 'batch_size': 389, 'iterations': 3, 'learning_rate': 0.0040230437191741165, 'p_miss': 0.16387763336983818}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:50,328] Trial 4 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.8760572017908018, 'alpha': 75, 'iterations': 6769, 'learning_rate': 0.0001870589252404817, 'p_miss': 0.054802181885677474}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:54,920] Trial 108 finished with value: 0.115627881102915 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0009192426075173085, 'p_miss': 0.18351139778524633}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:58,543] Trial 107 finished with value: 0.11773964050163724 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 8, 'learning_rate': 0.00087173982193694, 'p_miss': 0.09076562608536622}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:34:59,211] Trial 111 finished with value: 0.11943093495926145 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0023913160874861113, 'p_miss': 0.18065662514192246}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:01,807] Trial 110 finished with value: 0.11543420765471377 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 7, 'learning_rate': 0.0010017742880444685, 'p_miss': 0.08306773150194473}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:02,829] Trial 109 finished with value: 0.12787542854463269 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9, 'learning_rate': 0.0010371059010087884, 'p_miss': 0.08637840320283725}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:07,691] Trial 112 finished with value: 0.20649858507596086 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:08,240] Trial 113 finished with value: 0.2065418692000905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:10,872] Trial 116 finished with value: 0.12643942110067583 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 4, 'learning_rate': 0.00039038720797444313, 'p_miss': 0.2011029240250514}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:11,523] Trial 114 finished with value: 0.2065418692000905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:15,082] Trial 117 finished with value: 0.12099400241971929 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 4, 'learning_rate': 0.001554825886592443, 'p_miss': 0.1458415388500729}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:17,310] Trial 118 finished with value: 0.11909891941706555 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 2, 'learning_rate': 0.0015146362976709471, 'p_miss': 0.14509818670598307}. Best is trial 88 with value: 0.11495400272753345.
running
[I 2024-10-29 10:35:18,586] Trial 119 finished with value: 0.11288776193798493 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 2, 'learning_rate': 0.0015175644619358605, 'p_miss': 0.14825977437206234}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:35:19,046] Trial 120 finished with value: 0.3310431827025883 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.017795717484449414, 'alpha': 33, 'iterations': 2, 'learning_rate': 0.0005419432102395177, 'p_miss': 0.1291915073264534}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:35:32,009] Trial 68 finished with value: 0.20331071018763108 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 198, 'learning_rate': 0.0016600092494451443, 'p_miss': 0.05380858367254274}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:35:47,520] Trial 121 finished with value: 0.3241948633215406 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.04397664682197672, 'alpha': 27, 'iterations': 21, 'learning_rate': 0.0007446042928616464, 'p_miss': 0.18009769104270243}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:36:05,304] Trial 125 finished with value: 0.11980644400897407 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 6, 'learning_rate': 0.0034293523684827383, 'p_miss': 0.06420687056931457}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:36:16,939] Trial 124 finished with value: 0.1186849862215672 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 11, 'learning_rate': 0.0011544023109664335, 'p_miss': 0.179345225178794}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:36:25,215] Trial 127 finished with value: 0.1253247504110252 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2, 'learning_rate': 0.0028083038478964525, 'p_miss': 0.15389316817213974}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:36:46,126] Trial 126 finished with value: 0.12775289086109706 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 13, 'learning_rate': 0.0011917364117865047, 'p_miss': 0.10111069250071492}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:37:01,487] Trial 129 finished with value: 0.1184592197468846 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 4, 'learning_rate': 0.0021370051898829596, 'p_miss': 0.13346079130964109}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:37:09,028] Trial 130 finished with value: 0.12329128302077588 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.0006618347521630591, 'p_miss': 0.07908562684355772}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:38:26,026] Trial 131 finished with value: 0.1252795827938008 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 26, 'learning_rate': 0.001813000140332842, 'p_miss': 0.11315191586597777}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:38:35,454] Trial 122 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.02095773899329817, 'alpha': 29, 'iterations': 150, 'learning_rate': 0.0035896774052116493, 'p_miss': 0.07814266167314537}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:38:48,474] Trial 133 finished with value: 0.11519494983565606 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 3, 'learning_rate': 0.00047665091301344063, 'p_miss': 0.12541950803519172}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:38:51,179] Trial 134 finished with value: 0.21366633467863885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1853, 'weights': 'distance'}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:41:26,172] Trial 25 finished with value: 0.19818378168362405 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 740, 'learning_rate': 0.00032906644715251866, 'p_miss': 0.017502442917132183}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:41:40,447] Trial 136 finished with value: 0.11705294498466831 and parameters: {'model_name': 'VAE', 'batch_size': 145, 'iterations': 3, 'learning_rate': 0.00021521137607301736, 'p_miss': 0.1222133192121603}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:42:03,596] Trial 137 finished with value: 0.11867145594503922 and parameters: {'model_name': 'VAE', 'batch_size': 189, 'iterations': 4, 'learning_rate': 0.00019601916034684598, 'p_miss': 0.1225554837958161}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:48:22,172] Trial 70 finished with value: 0.21103646657123334 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 411, 'learning_rate': 0.0015638775396128704, 'p_miss': 0.1118777712473512}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:48:49,152] Trial 139 finished with value: 0.12565499712605346 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 6, 'learning_rate': 0.0004933626081980635, 'p_miss': 0.09910082735939904}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:49:17,507] Trial 115 finished with value: 0.21234291296803334 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 323, 'learning_rate': 0.003465613819505841, 'p_miss': 0.194604630382318}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:49:27,853] Trial 141 finished with value: 0.1177120266592433 and parameters: {'model_name': 'VAE', 'batch_size': 263, 'iterations': 3, 'learning_rate': 0.00021983972512470198, 'p_miss': 0.12077092024752487}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:49:38,458] Trial 142 finished with value: 0.1278961700547114 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 3, 'learning_rate': 0.0002587074331931111, 'p_miss': 0.10544896914128359}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 10:49:38,830] Trial 143 finished with value: 0.33974209792625537 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:09:31,957] Trial 128 finished with value: 0.21230085096963247 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 578, 'learning_rate': 0.0021711798759050096, 'p_miss': 0.09970838263758976}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:09:47,362] Trial 145 finished with value: 0.11790826339409351 and parameters: {'model_name': 'VAE', 'batch_size': 229, 'iterations': 4, 'learning_rate': 0.0009428487362264259, 'p_miss': 0.12640363298561483}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:09:55,722] Trial 146 finished with value: 0.11979941845012318 and parameters: {'model_name': 'VAE', 'batch_size': 405, 'iterations': 2, 'learning_rate': 0.0004087018524760836, 'p_miss': 0.17285474513803517}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:11:02,158] Trial 138 finished with value: 0.20385861579674502 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 550, 'learning_rate': 0.0004797808866589828, 'p_miss': 0.1244388004184743}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:19:50,947] Trial 7 finished with value: 0.27499272303053496 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1487, 'learning_rate': 0.09458721872134826, 'p_miss': 0.29743310320969774}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:25:42,391] Trial 132 finished with value: 0.2173314747109117 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 848, 'learning_rate': 0.0008373439050742049, 'p_miss': 0.12210951394078845}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:25:47,486] Trial 150 finished with value: 0.116643810232359 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.0006154054352867847, 'p_miss': 0.1355723717405037}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:26:04,992] Trial 151 finished with value: 0.13623222471839325 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6, 'learning_rate': 0.0006190065268108613, 'p_miss': 0.13525483129356317}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:26:24,748] Trial 152 finished with value: 0.11709186378801979 and parameters: {'model_name': 'VAE', 'batch_size': 273, 'iterations': 5, 'learning_rate': 0.0007615124071907846, 'p_miss': 0.16850130146205008}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:26:30,923] Trial 153 finished with value: 0.1213360212198932 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 2, 'learning_rate': 0.0003413440283330237, 'p_miss': 0.14799754926829964}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:30:00,036] Trial 154 finished with value: 0.14229804687007597 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 78, 'learning_rate': 0.001129984143896941, 'p_miss': 0.11400214872079677}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:30:13,385] Trial 155 finished with value: 0.11781528214618509 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 3, 'learning_rate': 0.0005838911048022625, 'p_miss': 0.1383695818073426}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:30:30,465] Trial 156 finished with value: 0.1173235689422409 and parameters: {'model_name': 'VAE', 'batch_size': 243, 'iterations': 5, 'learning_rate': 0.0007748711722869949, 'p_miss': 0.1677081114248936}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:30:49,261] Trial 157 finished with value: 0.23587103856643393 and parameters: {'model_name': 'VAE', 'batch_size': 310, 'iterations': 4, 'learning_rate': 0.060636660344093186, 'p_miss': 0.16142716893181325}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:31:20,682] Trial 158 finished with value: 0.11620720762400998 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 5, 'learning_rate': 0.002684528955183744, 'p_miss': 0.06275855669837911}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:31:33,095] Trial 159 finished with value: 0.1319929146646606 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 3, 'learning_rate': 0.001323475971145052, 'p_miss': 0.10894862090139038}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:31:57,246] Trial 160 finished with value: 0.11793366493314046 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 8, 'learning_rate': 0.002713707493632051, 'p_miss': 0.13200768448887235}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:32:01,832] Trial 161 finished with value: 0.11451235285147669 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 1, 'learning_rate': 0.0001301611866947182, 'p_miss': 0.1407154546714673}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:13,015] Trial 135 finished with value: 0.2144386512179465 and parameters: {'model_name': 'VAE', 'batch_size': 238, 'iterations': 1085, 'learning_rate': 0.0008372616303461216, 'p_miss': 0.12655430288928676}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:16,836] Trial 163 finished with value: 0.12041788386659183 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 1, 'learning_rate': 0.0001316003886795642, 'p_miss': 0.15593166693543148}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:19,106] Trial 164 finished with value: 0.20576320848190552 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1078, 'weights': 'uniform'}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:19,302] Trial 144 finished with value: 0.2122295616664172 and parameters: {'model_name': 'VAE', 'batch_size': 280, 'iterations': 1050, 'learning_rate': 0.00039066224123323175, 'p_miss': 0.12641644531368654}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:23,687] Trial 166 finished with value: 0.12249574535113876 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 1, 'learning_rate': 0.00018249995797960206, 'p_miss': 0.14220468847383705}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:32,466] Trial 167 finished with value: 0.13083785104367912 and parameters: {'model_name': 'VAE', 'batch_size': 130, 'iterations': 2, 'learning_rate': 0.0018274101287386975, 'p_miss': 0.06374579934175519}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 11:47:36,498] Trial 168 finished with value: 0.1191599012664791 and parameters: {'model_name': 'VAE', 'batch_size': 206, 'iterations': 1, 'learning_rate': 0.00010047869831924264, 'p_miss': 0.11583152528787216}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:22:43,524] Trial 149 finished with value: 0.2085241198842483 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1210, 'learning_rate': 0.0006241226927898417, 'p_miss': 0.13631328511292296}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:23:03,048] Trial 170 finished with value: 0.12220124496373486 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 4, 'learning_rate': 0.0009736706525251075, 'p_miss': 0.1503150764788346}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:23:15,450] Trial 171 finished with value: 0.11622496536435478 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 3, 'learning_rate': 0.0052640828409738685, 'p_miss': 0.14498288000353943}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:23:15,774] Trial 172 finished with value: 0.2063806308007104 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:23:24,521] Trial 173 finished with value: 0.12192022551242432 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 2, 'learning_rate': 0.006255568809096346, 'p_miss': 0.18600784385407193}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:50:14,694] Trial 35 finished with value: 0.21350389490042465 and parameters: {'model_name': 'VAE', 'batch_size': 923, 'iterations': 2314, 'learning_rate': 0.004368583181981055, 'p_miss': 0.27486816130946845}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:50:32,773] Trial 175 finished with value: 0.11577971145467407 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 5, 'learning_rate': 0.0051855623567226795, 'p_miss': 0.044425183856103306}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:51:15,833] Trial 176 finished with value: 0.14695239571929586 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 11, 'learning_rate': 0.008046411363374185, 'p_miss': 0.03705850603949401}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 12:51:34,751] Trial 177 finished with value: 0.12148704274127069 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 6, 'learning_rate': 0.006566397507017504, 'p_miss': 0.058905797244446216}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:31:09,803] Trial 21 finished with value: 0.21335879951724185 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3348, 'learning_rate': 0.00016125852975108063, 'p_miss': 0.09317556456619003}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:31:31,514] Trial 179 finished with value: 0.12283496932259211 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 7, 'learning_rate': 0.00495321997195956, 'p_miss': 0.08366704867499067}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:51:27,727] Trial 48 finished with value: 0.21448756010937756 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 4030, 'learning_rate': 0.002560251439748531, 'p_miss': 0.12866631067280387}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:51:47,931] Trial 181 finished with value: 0.11724414894038755 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 5, 'learning_rate': 0.00367971779541312, 'p_miss': 0.14357150399915355}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:00,572] Trial 182 finished with value: 0.12812211924568892 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 3, 'learning_rate': 0.00545470866037312, 'p_miss': 0.037987870080366734}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:14,748] Trial 183 finished with value: 0.12445911974677934 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 4, 'learning_rate': 0.0016557587235108927, 'p_miss': 0.15808900122880065}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:24,357] Trial 184 finished with value: 0.12242547905003096 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 2, 'learning_rate': 0.007361369343038832, 'p_miss': 0.03340125027354546}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:29,547] Trial 185 finished with value: 0.1195129755462769 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 1, 'learning_rate': 0.004736018544549236, 'p_miss': 0.04776135745047895}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:39,874] Trial 186 finished with value: 0.12590416256333842 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 3, 'learning_rate': 0.0001275507929635908, 'p_miss': 0.14844056716006784}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 13:52:54,646] Trial 187 finished with value: 0.12232243315974571 and parameters: {'model_name': 'VAE', 'batch_size': 118, 'iterations': 3, 'learning_rate': 0.005582729661628837, 'p_miss': 0.11830013169334276}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:35:07,169] Trial 147 finished with value: 0.21348668663880868 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 3134, 'learning_rate': 0.0006127088275821966, 'p_miss': 0.13402609143008345}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:35:20,758] Trial 189 finished with value: 0.11805806689898428 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 4, 'learning_rate': 0.0001605674565223835, 'p_miss': 0.07313076818973058}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:35:38,712] Trial 190 finished with value: 0.1269122705977515 and parameters: {'model_name': 'VAE', 'batch_size': 164, 'iterations': 2, 'learning_rate': 0.010246436790792412, 'p_miss': 0.1087135629740828}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:35:57,269] Trial 191 finished with value: 0.12012330324762124 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 5, 'learning_rate': 0.0022276304191641, 'p_miss': 0.13964044520897717}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:36:04,932] Trial 192 finished with value: 0.11919502637387211 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 2, 'learning_rate': 0.002984500963497621, 'p_miss': 0.1300616416077234}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:36:26,621] Trial 193 finished with value: 0.11568474225919971 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 7, 'learning_rate': 0.001071036973433818, 'p_miss': 0.17741110961871862}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:36:38,367] Trial 194 finished with value: 0.21536729843597588 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:37:08,367] Trial 195 finished with value: 0.12309084541307444 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7, 'learning_rate': 0.0010668516546908384, 'p_miss': 0.17673742311189208}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:37:42,202] Trial 196 finished with value: 0.12260776260245021 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9, 'learning_rate': 0.0012742578890291955, 'p_miss': 0.19748698685289268}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:38:01,769] Trial 197 finished with value: 0.11930602650494174 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 6, 'learning_rate': 0.0007195822738669347, 'p_miss': 0.011829174761345235}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:38:40,049] Trial 198 finished with value: 0.11889710926787438 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 13, 'learning_rate': 0.000843457194420177, 'p_miss': 0.028717204380891287}. Best is trial 119 with value: 0.11288776193798493.
running
[I 2024-10-29 14:38:54,917] Trial 199 finished with value: 0.11462777931350103 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.00407034254480697, 'p_miss': 0.182193782811603}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 14:40:42,326] Trial 165 finished with value: 0.2123467086773243 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 3031, 'learning_rate': 0.001771621283780367, 'p_miss': 0.030773962969769496}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 14:42:01,552] Trial 44 finished with value: 0.21472092857455277 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4579, 'learning_rate': 0.015258061299273151, 'p_miss': 0.2979381876325803}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 14:57:13,137] Trial 51 finished with value: 0.22632452938512046 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6519, 'learning_rate': 0.0007501329242773502, 'p_miss': 0.2576582154695108}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 15:51:42,159] Trial 37 finished with value: 0.20988121448361746 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 6980, 'learning_rate': 0.003031356720076379, 'p_miss': 0.29203402595804673}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 16:01:45,477] Trial 174 finished with value: 0.21447008425915146 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 5760, 'learning_rate': 0.00551210223243012, 'p_miss': 0.1448308162989627}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 16:08:24,975] Trial 162 finished with value: 0.2139456758154284 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 5604, 'learning_rate': 0.001744871030501519, 'p_miss': 0.04420394696296317}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 16:16:55,278] Trial 64 finished with value: 0.21336474087367838 and parameters: {'model_name': 'VAE', 'batch_size': 209, 'iterations': 7605, 'learning_rate': 0.001678255833725208, 'p_miss': 0.07749775989779999}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 16:22:40,619] Trial 123 finished with value: 0.21236994247839158 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 8850, 'learning_rate': 0.0034148441678791106, 'p_miss': 0.06404337273144761}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 16:54:25,622] Trial 52 finished with value: 0.2127005245554646 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 9999, 'learning_rate': 0.0006981978217564007, 'p_miss': 0.260729199251682}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:04:19,108] Trial 148 finished with value: 0.2114887571298822 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7642, 'learning_rate': 0.0007648084406626718, 'p_miss': 0.15681708077996992}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:05:43,874] Trial 188 finished with value: 0.21304876068104 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 7042, 'learning_rate': 0.0021544577617870634, 'p_miss': 0.13293634637805535}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:06:09,322] Trial 140 finished with value: 0.2137909233620831 and parameters: {'model_name': 'VAE', 'batch_size': 319, 'iterations': 8608, 'learning_rate': 0.00025436983225458486, 'p_miss': 0.12294989786701181}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:06:48,438] Trial 169 finished with value: 0.21039328128782006 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 9710, 'learning_rate': 0.00015517057932813537, 'p_miss': 0.03225671044476239}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:07:47,698] Trial 180 finished with value: 0.21136354101937532 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 6944, 'learning_rate': 0.0056232609546427665, 'p_miss': 0.04283376072083053}. Best is trial 119 with value: 0.11288776193798493.
[I 2024-10-29 17:09:06,867] Trial 178 finished with value: 0.2111687824015112 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 9983, 'learning_rate': 0.0053063744732007095, 'p_miss': 0.04069453918155841}. Best is trial 119 with value: 0.11288776193798493.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.11288776193798493
{'model_name': 'VAE', 'batch_size': 10, 'iterations': 2, 'learning_rate': 0.0015175644619358605, 'p_miss': 0.14825977437206234}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0b50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474734400> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714310> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5030726522702442
Generation:   4%|▍         | 1/25 [00:34<13:49, 34.58s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2d70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.5032230199099555
Generation:   8%|▊         | 2/25 [00:46<08:02, 20.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547473be20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.5083300565324234
Generation:  12%|█▏        | 3/25 [01:08<08:00, 21.85s/it]Generation:  4
Best f1_score score: 0.5102569833886936
Generation:  16%|█▌        | 4/25 [01:27<07:09, 20.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fd300> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.5114977987849068
Generation:  20%|██        | 5/25 [01:47<06:49, 20.48s/it]Generation:  6
Best f1_score score: 0.5152897525767066
Generation:  24%|██▍       | 6/25 [03:14<13:37, 43.01s/it]Generation:  7
Best f1_score score: 0.5152897525767066
Generation:  28%|██▊       | 7/25 [03:38<11:04, 36.89s/it]Generation:  8
Best f1_score score: 0.5152897525767066
Generation:  32%|███▏      | 8/25 [04:03<09:23, 33.16s/it]Generation:  9
Best f1_score score: 0.5152897525767066
Generation:  36%|███▌      | 9/25 [04:29<08:11, 30.69s/it]Generation:  10
Best f1_score score: 0.5154652681878613
Generation:  40%|████      | 10/25 [05:01<07:48, 31.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b41570> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff7b50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5154652681878613
Generation:  44%|████▍     | 11/25 [05:19<06:18, 27.02s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474734b50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.5154652681878613
Generation:  48%|████▊     | 12/25 [05:45<05:46, 26.69s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474712470> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.5154652681878613
Generation:  52%|█████▏    | 13/25 [06:06<05:01, 25.13s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a4b400> 
 l1_ratio must be specified when penalty is elasticnet. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1204, in fit
    raise ValueError("l1_ratio must be specified when penalty is elasticnet.")
ValueError: l1_ratio must be specified when penalty is elasticnet.

Generation:  14
Best f1_score score: 0.5154652681878613
Generation:  56%|█████▌    | 14/25 [06:30<04:33, 24.90s/it]Generation:  15
Best f1_score score: 0.5154652681878613
Generation:  60%|██████    | 15/25 [06:49<03:48, 22.83s/it]Generation:  16
Best f1_score score: 0.5154652681878613
Generation:  64%|██████▍   | 16/25 [07:04<03:05, 20.56s/it]Generation:  17
Best f1_score score: 0.5154652681878613
Generation:  68%|██████▊   | 17/25 [08:02<04:16, 32.02s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b29cc0> 
 l1_ratio must be specified when penalty is elasticnet. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1204, in fit
    raise ValueError("l1_ratio must be specified when penalty is elasticnet.")
ValueError: l1_ratio must be specified when penalty is elasticnet.

Generation:  18
Best f1_score score: 0.5154652681878613
Generation:  72%|███████▏  | 18/25 [08:18<03:09, 27.07s/it]Generation:  19
Best f1_score score: 0.5154652681878613
Generation:  76%|███████▌  | 19/25 [08:36<02:25, 24.24s/it]Generation:  20
Best f1_score score: 0.5154652681878613
Generation:  80%|████████  | 20/25 [09:08<02:13, 26.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546537c4c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.5154652681878613
Generation:  84%|████████▍ | 21/25 [09:35<01:47, 26.81s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546589c9a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465725f00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.5154652681878613
Generation:  88%|████████▊ | 22/25 [10:15<01:31, 30.66s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465364af0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.5154652681878613
Generation:  92%|█████████▏| 23/25 [10:33<00:53, 26.81s/it]Generation:  24
Best f1_score score: 0.5154652681878613
Generation:  96%|█████████▌| 24/25 [10:47<00:23, 23.16s/it]Generation:  25
Best f1_score score: 0.5154652681878613
Generation: 100%|██████████| 25/25 [11:15<00:00, 24.38s/it]Generation: 100%|██████████| 25/25 [11:19<00:00, 27.17s/it]
2024-10-29 17:20:38,644 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45531' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-967265ec1f562c603780f9985bb7df07', 'ndarray-582d7d183af8cedc419ecc82f5b1ea53'} (stimulus_id='handle-worker-cleanup-1730247638.6442099')
Fitted
Pipeline(steps=[('logisticregression',
                 LogisticRegression(C=0.1900881978779, class_weight='balanced',
                                    max_iter=1000, n_jobs=1, solver='saga'))])
score start
train score: {'auroc': 0.5233890641707863, 'accuracy': 0.5176223040504997, 'balanced_accuracy': 0.5178662647541503, 'logloss': 0.6922789005214228, 'f1': 0.517251770002657}
original test score: {'auroc': 0.9484650486836363, 'accuracy': 0.8899018232819075, 'balanced_accuracy': 0.8866572675951212, 'logloss': 0.6894843193378237, 'f1': 0.8886196330769074}
imputed test score: {'auroc': 0.5381462108511886, 'accuracy': 0.532258064516129, 'balanced_accuracy': 0.5328592331068474, 'logloss': 0.6917118893968001, 'f1': 0.5320074375598742}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4ca0> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d30> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d3d420> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.8164913148276591
Generation:   4%|▍         | 1/25 [07:14<2:53:45, 434.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1c7c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547456fac0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.8164913148276591
Generation:   8%|▊         | 2/25 [10:04<1:46:55, 278.94s/it]Generation:  3
Best f1_score score: 0.8164913148276591
Generation:  12%|█▏        | 3/25 [12:58<1:24:44, 231.12s/it]Generation:  4
Best f1_score score: 0.8164913148276591
Generation:  16%|█▌        | 4/25 [13:18<51:41, 147.71s/it]  Generation:  5
Best f1_score score: 0.8194319566932332
Generation:  20%|██        | 5/25 [13:38<33:55, 101.79s/it]Generation:  6
Best f1_score score: 0.8194319566932332
Generation:  24%|██▍       | 6/25 [14:10<24:41, 77.95s/it] Generation:  7
Best f1_score score: 0.8194319566932332
Generation:  28%|██▊       | 7/25 [14:29<17:34, 58.57s/it]Generation:  8
Best f1_score score: 0.8198049511437141
Generation:  32%|███▏      | 8/25 [14:52<13:24, 47.32s/it]Generation:  9
Best f1_score score: 0.8198049511437141
Generation:  36%|███▌      | 9/25 [15:42<12:50, 48.14s/it]Generation:  10
Best f1_score score: 0.8200744148424395
Generation:  40%|████      | 10/25 [16:54<13:52, 55.50s/it]Generation:  11
Best f1_score score: 0.8242882144650837
Generation:  44%|████▍     | 11/25 [19:41<20:57, 89.79s/it]Generation:  12
Best f1_score score: 0.8242882144650837
Generation:  48%|████▊     | 12/25 [21:03<18:54, 87.28s/it]Generation:  13
Best f1_score score: 0.8242882144650837
Generation:  52%|█████▏    | 13/25 [22:41<18:05, 90.44s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f4a2380> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 589, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.8242882144650837
Generation:  56%|█████▌    | 14/25 [23:05<12:54, 70.44s/it]Generation:  15
Best f1_score score: 0.8242882144650837
Generation:  60%|██████    | 15/25 [23:39<09:54, 59.42s/it]Generation:  16
Best f1_score score: 0.8242882144650837
Generation:  64%|██████▍   | 16/25 [26:25<13:44, 91.56s/it]Generation:  17
Best f1_score score: 0.8242882144650837
Generation:  68%|██████▊   | 17/25 [30:23<18:05, 135.67s/it]Generation:  18
Best f1_score score: 0.8242882144650837
Generation:  72%|███████▏  | 18/25 [33:11<16:57, 145.40s/it]Generation:  19
Best f1_score score: 0.8242882144650837
Generation:  76%|███████▌  | 19/25 [33:29<10:42, 107.08s/it]Generation:  20
Best f1_score score: 0.8242882144650837
Generation:  80%|████████  | 20/25 [35:14<08:51, 106.39s/it]Generation:  21
Best f1_score score: 0.8242882144650837
Generation:  84%|████████▍ | 21/25 [35:40<05:28, 82.20s/it] Generation:  22
Best f1_score score: 0.8242882144650837
Generation:  88%|████████▊ | 22/25 [36:36<03:42, 74.27s/it]Generation:  23
Best f1_score score: 0.8242882144650837
Generation:  92%|█████████▏| 23/25 [36:52<01:53, 56.87s/it]Generation:  24
Best f1_score score: 0.8242882144650837
Generation:  96%|█████████▌| 24/25 [43:42<02:42, 162.80s/it]Generation:  25
Best f1_score score: 0.8242882144650837
Generation: 100%|██████████| 25/25 [44:08<00:00, 121.84s/it]Generation: 100%|██████████| 25/25 [44:08<00:00, 105.94s/it]
2024-10-29 18:04:57,389 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34449' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-4e3af436f5bf5cf8e292358010b2b2e3', 'ndarray-582d7d183af8cedc419ecc82f5b1ea53'} (stimulus_id='handle-worker-cleanup-1730250297.3895159')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=85)),
                ('lgbmclassifier',
                 LGBMClassifier(boosting_type='goss', class_weight='balanced',
                                max_depth=2, n_estimators=95, n_jobs=1,
                                num_leaves=95, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9084561246188863, 'accuracy': 0.8292126950727687, 'balanced_accuracy': 0.8275151649223107, 'logloss': 0.3833256439083342, 'f1': 0.8281569959535212}
test score: {'auroc': 0.9077844453264301, 'accuracy': 0.8183730715287517, 'balanced_accuracy': 0.8173746576546157, 'logloss': 0.38197889753692443, 'f1': 0.8175633789111221}
original test score: {'auroc': 0.9765210797874546, 'accuracy': 0.9403927068723703, 'balanced_accuracy': 0.9400345159181964, 'logloss': 0.19345068429417883, 'f1': 0.9401489733087431}
score end
803
lvl
0.5
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
8.019560591975848
hours
DONE
