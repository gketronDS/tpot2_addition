Run: 58
/cm/local/apps/slurm/var/spool/job957966/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
starting loops
../data/r/189/189.pkl
working on 
../data/r/189/reg_full_MNAR_0.1_3
4.563879013061523
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-09-19 23:13:05,371] A new study created in memory with name: no-name-c63afc03-fd38-4bea-a911-8ecfa49eb6c4
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-09-19 23:13:06,050] Trial 13 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 13 with value: 0.5497302687516779.
running
[I 2024-09-19 23:13:06,493] Trial 9 finished with value: 0.279307971997143 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:06,694] Trial 14 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:07,057] Trial 10 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:07,338] Trial 0 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:07,924] Trial 17 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:08,268] Trial 18 finished with value: 0.28020283737907764 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:10,623] Trial 11 finished with value: 0.2793079719971431 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5204, 'weights': 'uniform'}. Best is trial 9 with value: 0.279307971997143.
running
[I 2024-09-19 23:13:11,311] Trial 20 finished with value: 0.27815630488518844 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1056, 'weights': 'uniform'}. Best is trial 20 with value: 0.27815630488518844.
running
[I 2024-09-19 23:13:11,673] Trial 8 finished with value: 0.2789962546044734 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5020, 'weights': 'distance'}. Best is trial 20 with value: 0.27815630488518844.
running
[I 2024-09-19 23:13:14,498] Trial 3 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:18,520] Trial 1 finished with value: 0.3072061649507258 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:19,646] Trial 26 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:20,740] Trial 28 finished with value: 0.2782211758233569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:22,257] Trial 5 finished with value: 0.40559662864613744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:22,751] Trial 25 finished with value: 0.4052586389082912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:23,276] Trial 16 finished with value: 0.30912741494496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:45,314] Trial 24 finished with value: 0.45903830876469554 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.11043925137187151, 'alpha': 95, 'iterations': 3, 'learning_rate': 0.01294006997636576, 'p_miss': 0.28597010699714487}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:13:54,383] Trial 30 finished with value: 0.2804597519544 and parameters: {'model_name': 'VAE', 'batch_size': 202, 'iterations': 1, 'learning_rate': 0.0021801406179192133, 'p_miss': 0.11679259066351116}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:14:19,773] Trial 7 finished with value: 0.49704423857199675 and parameters: {'model_name': 'GAIN', 'batch_size': 519, 'hint_rate': 0.371801232749119, 'alpha': 69, 'iterations': 23, 'learning_rate': 0.0443939551826914, 'p_miss': 0.13033366211813868}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:14:31,735] Trial 22 finished with value: 0.48369280853671553 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.5719783451496523, 'alpha': 5, 'iterations': 33, 'learning_rate': 0.025255138395175708, 'p_miss': 0.14916012537898715}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:14:34,517] Trial 36 finished with value: 0.28054444229770514 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 53, 'weights': 'uniform'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:30,382] Trial 19 finished with value: 0.3002082066537623 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 32, 'learning_rate': 0.00728099516249568, 'p_miss': 0.06723163800565023}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:32,916] Trial 27 finished with value: 0.48148263125423296 and parameters: {'model_name': 'GAIN', 'batch_size': 206, 'hint_rate': 0.614312755618917, 'alpha': 8, 'iterations': 67, 'learning_rate': 0.0001661353501006168, 'p_miss': 0.1589363412938181}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:33,778] Trial 38 finished with value: 0.2782703147508941 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 916, 'weights': 'uniform'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:36,818] Trial 39 finished with value: 0.27828938389510094 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 865, 'weights': 'uniform'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:38,107] Trial 23 finished with value: 0.28365914161863126 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 30, 'learning_rate': 0.03835648147142845, 'p_miss': 0.19926318096996115}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:52,485] Trial 40 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:52,701] Trial 12 finished with value: 0.4961711231340039 and parameters: {'model_name': 'GAIN', 'batch_size': 54, 'hint_rate': 0.16523865857599057, 'alpha': 36, 'iterations': 101, 'learning_rate': 0.001692880972730527, 'p_miss': 0.04214028670101014}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:57,512] Trial 41 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:15:57,786] Trial 42 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:07,383] Trial 32 finished with value: 0.28172290587950233 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 76, 'learning_rate': 0.000455704298174718, 'p_miss': 0.26344159423105723}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:13,360] Trial 43 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:14,117] Trial 44 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:18,266] Trial 45 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:19,417] Trial 46 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:28,822] Trial 47 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:34,580] Trial 49 finished with value: 0.27839132611933043 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:35,378] Trial 48 finished with value: 0.27825241597876876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:16:44,530] Trial 4 finished with value: 0.2835576989070036 and parameters: {'model_name': 'VAE', 'batch_size': 258, 'iterations': 60, 'learning_rate': 0.0002202737691716762, 'p_miss': 0.0472945152269003}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:19:05,276] Trial 6 finished with value: 0.3183947089022296 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 155, 'learning_rate': 0.058032092832850456, 'p_miss': 0.10925024999707626}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:27:19,012] Trial 31 finished with value: 0.28375672718971856 and parameters: {'model_name': 'VAE', 'batch_size': 407, 'iterations': 245, 'learning_rate': 0.00433251405527407, 'p_miss': 0.018614213496371906}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:34:48,587] Trial 29 finished with value: 0.5043424592559432 and parameters: {'model_name': 'GAIN', 'batch_size': 105, 'hint_rate': 0.8040424117693192, 'alpha': 78, 'iterations': 923, 'learning_rate': 0.004652511858614044, 'p_miss': 0.09891542490078503}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:48:34,611] Trial 2 finished with value: 0.282004523841976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:48:58,043] Trial 59 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:49:07,514] Trial 60 finished with value: 0.2782211758233569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:49:33,110] Trial 61 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:51:54,608] Trial 51 finished with value: 0.281602061527671 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:52:05,357] Trial 63 finished with value: 0.27904708788632854 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:52:17,380] Trial 64 finished with value: 0.2782211761308059 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:52:33,198] Trial 52 finished with value: 0.28197085034178093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:52:43,031] Trial 65 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:52:57,363] Trial 66 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:08,810] Trial 67 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:17,752] Trial 69 finished with value: 0.2782211758233569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:25,053] Trial 68 finished with value: 0.2781364670029089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:33,073] Trial 34 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9346930621521561, 'alpha': 3, 'iterations': 9694, 'learning_rate': 0.00011200242809837031, 'p_miss': 0.034367362196853476}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:42,419] Trial 70 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:48,793] Trial 71 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:49,505] Trial 74 finished with value: 0.279307971997143 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:53:59,990] Trial 72 finished with value: 0.27830742790318597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:11,294] Trial 73 finished with value: 0.30939403702645313 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:21,766] Trial 75 finished with value: 0.3100662838771791 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:25,678] Trial 54 finished with value: 0.2808335764165396 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:28,433] Trial 76 finished with value: 0.3064023288127958 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:29,867] Trial 55 finished with value: 0.28114709516025965 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:30,180] Trial 50 finished with value: 0.2813607212112528 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:31,200] Trial 82 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 3 with value: 0.2781364670029089.
[I 2024-09-19 23:54:31,360] Trial 77 finished with value: 0.2782340901147286 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.2781364670029089.
running
running
[I 2024-09-19 23:54:38,681] Trial 78 finished with value: 0.27819827377336553 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:39,004] Trial 53 finished with value: 0.2811048853105112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:54:55,617] Trial 86 finished with value: 0.27847383763937006 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:55:07,869] Trial 81 finished with value: 0.27845835322753026 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 3 with value: 0.2781364670029089.
running
[I 2024-09-19 23:55:09,429] Trial 83 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-19 23:55:09,737] Trial 84 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-19 23:55:11,788] Trial 79 finished with value: 0.27829070525088556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-19 23:55:15,169] Trial 80 finished with value: 0.27829070525088556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-19 23:55:36,586] Trial 87 finished with value: 0.2784699853243061 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-19 23:56:21,349] Trial 56 finished with value: 0.28134491554171615 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:04:46,864] Trial 57 finished with value: 0.2822243475003622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:09:37,927] Trial 62 finished with value: 0.33021776222183596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:10:16,501] Trial 96 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:11:50,729] Trial 58 finished with value: 0.28106216433585696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:11:55,837] Trial 98 finished with value: 0.27899658031885666 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6523, 'weights': 'distance'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:52:19,261] Trial 21 finished with value: 0.29667520042720974 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2197, 'learning_rate': 0.00016519765846375017, 'p_miss': 0.12120367751719707}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 00:52:29,423] Trial 100 finished with value: 0.46925351229242207 and parameters: {'model_name': 'GAIN', 'batch_size': 31, 'hint_rate': 0.3221492762063559, 'alpha': 41, 'iterations': 5, 'learning_rate': 0.0007548730588092274, 'p_miss': 0.22089745573023467}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 01:25:04,421] Trial 101 finished with value: 0.28716498242930105 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 588, 'learning_rate': 0.0008522397914183428, 'p_miss': 0.20761065002614504}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 01:25:05,120] Trial 102 finished with value: 0.28020283737907764 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 01:25:33,563] Trial 103 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:38:08,340] Trial 15 finished with value: 0.2842920223867796 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 4308, 'learning_rate': 0.00801712759330908, 'p_miss': 0.11065185216048055}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:38:13,486] Trial 105 finished with value: 0.2785059291237656 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2927, 'weights': 'distance'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:38:27,696] Trial 106 finished with value: 0.27808880328886776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:38:42,660] Trial 107 finished with value: 0.27808880328886776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:38:56,603] Trial 108 finished with value: 0.27808880328886776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:39:12,617] Trial 109 finished with value: 0.27808880328886776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:39:25,733] Trial 110 finished with value: 0.27808880328886776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:39:43,959] Trial 111 finished with value: 0.48023463244982245 and parameters: {'model_name': 'GAIN', 'batch_size': 909, 'hint_rate': 0.7592954224289274, 'alpha': 60, 'iterations': 8, 'learning_rate': 0.0859275616846503, 'p_miss': 0.247612126816948}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:40:17,819] Trial 112 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:40:49,525] Trial 113 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:41:21,090] Trial 114 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:41:49,291] Trial 115 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:42:16,639] Trial 116 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:42:44,548] Trial 117 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:43:09,761] Trial 118 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:43:39,564] Trial 119 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:44:05,465] Trial 120 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:44:32,745] Trial 121 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:45:02,754] Trial 122 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:45:09,441] Trial 123 finished with value: 0.27968453590010733 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.015750330900527944, 'p_miss': 0.07851876079269353}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:45:37,454] Trial 124 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:46:07,287] Trial 125 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:46:38,128] Trial 126 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:47:06,765] Trial 127 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:47:10,230] Trial 93 finished with value: 0.5031510834636927 and parameters: {'model_name': 'GAIN', 'batch_size': 51, 'hint_rate': 0.3506979179740378, 'alpha': 39, 'iterations': 7135, 'learning_rate': 0.001133238867308721, 'p_miss': 0.22622333639805403}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:47:34,487] Trial 128 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:47:41,036] Trial 129 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:48:07,871] Trial 130 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:48:11,410] Trial 131 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:48:40,055] Trial 132 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:48:43,210] Trial 133 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:05,006] Trial 37 finished with value: 0.35302030708132887 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5359, 'learning_rate': 0.00011871815397093062, 'p_miss': 0.29153523533901793}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:13,074] Trial 134 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:15,313] Trial 135 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:35,441] Trial 136 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:43,122] Trial 137 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:45,697] Trial 138 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:49:51,774] Trial 141 finished with value: 0.27852166999208877 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3169, 'weights': 'distance'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:05,527] Trial 139 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:06,008] Trial 143 finished with value: 0.28020283737907764 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:09,303] Trial 140 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:15,784] Trial 142 finished with value: 0.2781945501949753 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:35,970] Trial 144 finished with value: 0.2782670065216779 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:41,465] Trial 145 finished with value: 0.27811558776656853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:50:46,382] Trial 146 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:06,825] Trial 147 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:22,634] Trial 148 finished with value: 0.4052586389082912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:26,597] Trial 149 finished with value: 0.4124708467971606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:39,163] Trial 150 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:52,166] Trial 151 finished with value: 0.2780591904816496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:51:56,505] Trial 152 finished with value: 0.27846305495024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 83 with value: 0.2780591904816496.
running
[I 2024-09-20 02:52:08,795] Trial 153 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:52:22,642] Trial 154 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:52:28,698] Trial 155 finished with value: 0.27831559052941685 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:52:38,739] Trial 156 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:52:51,838] Trial 157 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:52:56,990] Trial 158 finished with value: 0.2784738310540503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:53:08,610] Trial 159 finished with value: 0.2784738310540503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:53:20,652] Trial 160 finished with value: 0.2784738310540503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 02:53:27,886] Trial 161 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:07:40,813] Trial 91 finished with value: 0.28881113739899644 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 4517, 'learning_rate': 0.0009664265850197623, 'p_miss': 0.20270907352272027}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:11:07,646] Trial 165 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.0253158971283986, 'alpha': 100, 'iterations': 594, 'learning_rate': 0.00039884571138260614, 'p_miss': 0.17535069933759467}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:11:40,083] Trial 166 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:10,208] Trial 167 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:17,845] Trial 163 finished with value: 0.289661502728677 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 391, 'learning_rate': 0.0004809979535442762, 'p_miss': 0.1826855434481422}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:21,961] Trial 168 finished with value: 0.30859217796462246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:27,619] Trial 164 finished with value: 0.29715868123241235 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 385, 'learning_rate': 0.0003261404943812351, 'p_miss': 0.16418617650963396}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:38,518] Trial 169 finished with value: 0.30859217796462246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:54,506] Trial 170 finished with value: 0.27909447756065636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:12:58,895] Trial 171 finished with value: 0.27909447756065636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:04,714] Trial 174 finished with value: 0.2783112677855324 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2167, 'weights': 'distance'}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:11,490] Trial 172 finished with value: 0.27909447756065636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:22,082] Trial 162 finished with value: 0.30446267917563524 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 513, 'learning_rate': 0.000431233509878639, 'p_miss': 0.176135878687073}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:24,524] Trial 173 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:35,086] Trial 175 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:38,295] Trial 176 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:50,398] Trial 177 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:50,881] Trial 178 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:13:51,661] Trial 182 finished with value: 0.5497302687516779 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:03,139] Trial 179 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:07,044] Trial 180 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:17,760] Trial 181 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:21,636] Trial 183 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:30,964] Trial 184 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:38,701] Trial 185 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:48,004] Trial 186 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:14:50,083] Trial 187 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:00,095] Trial 188 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:07,197] Trial 189 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:17,019] Trial 190 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:18,186] Trial 191 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:27,152] Trial 192 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:36,242] Trial 193 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:44,970] Trial 194 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:47,302] Trial 195 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
running
[I 2024-09-20 03:15:57,357] Trial 196 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 03:16:05,485] Trial 197 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 03:16:13,975] Trial 198 finished with value: 0.2778374842983272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 03:16:15,262] Trial 199 finished with value: 0.2784738310540503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 03:43:59,353] Trial 95 finished with value: 0.28488079144986056 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 5790, 'learning_rate': 0.0009225708257110086, 'p_miss': 0.19873219197407127}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:15:41,852] Trial 92 finished with value: 0.2865181570823528 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 7206, 'learning_rate': 0.000689448308260842, 'p_miss': 0.2236756290509096}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:20:10,793] Trial 85 finished with value: 0.28607224959780175 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 6279, 'learning_rate': 0.0008594823250865679, 'p_miss': 0.2265748720614048}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:35:21,706] Trial 99 finished with value: 0.2883730650687878 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 6807, 'learning_rate': 0.0006792829694601693, 'p_miss': 0.22547499201095794}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:37:31,848] Trial 35 finished with value: 0.3352323155226816 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8077, 'learning_rate': 0.00017539818199327408, 'p_miss': 0.010388068113012822}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:48:25,042] Trial 104 finished with value: 0.4989077352175248 and parameters: {'model_name': 'GAIN', 'batch_size': 949, 'hint_rate': 0.9888561319569855, 'alpha': 60, 'iterations': 9493, 'learning_rate': 0.09870507870946411, 'p_miss': 0.24211959549114814}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:55:42,999] Trial 88 finished with value: 0.2885122781099073 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7790, 'learning_rate': 0.0009298380267974358, 'p_miss': 0.22378586745645376}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 04:59:26,273] Trial 94 finished with value: 0.2870986912801583 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 9162, 'learning_rate': 0.0006523565383771843, 'p_miss': 0.22626051232800132}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 05:02:57,753] Trial 97 finished with value: 0.28558767208700775 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 8996, 'learning_rate': 0.0009029037642992764, 'p_miss': 0.2124924605261866}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 05:03:54,955] Trial 89 finished with value: 0.2877999235042317 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 9365, 'learning_rate': 0.0008909305358322955, 'p_miss': 0.22493360358781864}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 05:12:45,524] Trial 90 finished with value: 0.28365146994637297 and parameters: {'model_name': 'VAE', 'batch_size': 958, 'iterations': 6540, 'learning_rate': 0.0009586876822641653, 'p_miss': 0.2205289965194045}. Best is trial 153 with value: 0.2778374842983272.
[I 2024-09-20 05:19:03,862] Trial 33 finished with value: 0.28368451497167413 and parameters: {'model_name': 'VAE', 'batch_size': 764, 'iterations': 9721, 'learning_rate': 0.00019719686497935522, 'p_miss': 0.018558374744607642}. Best is trial 153 with value: 0.2778374842983272.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0.2778374842983272
{'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best root_mean_squared_error score: -0.16990379931542704
Generation:   4%|         | 1/25 [00:16<06:30, 16.29s/it]Generation:  2
Best root_mean_squared_error score: -0.16303081301604688
Generation:   8%|         | 2/25 [00:33<06:23, 16.68s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470a2c0> 

Generation:  3
Best root_mean_squared_error score: -0.16303081301604688
Generation:  12%|        | 3/25 [10:36<1:44:22, 284.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa9b40> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  4
Best root_mean_squared_error score: -0.16182998691377629
Generation:  16%|        | 4/25 [10:44<1:01:20, 175.26s/it]Generation:  5
Best root_mean_squared_error score: -0.16177163273676842
Generation:  20%|        | 5/25 [10:55<38:41, 116.09s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474717490> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f03640> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa36a0> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  6
Best root_mean_squared_error score: -0.16177163273676842
Generation:  24%|       | 6/25 [11:11<26:01, 82.18s/it] Generation:  7
Best root_mean_squared_error score: -0.16177163273676842
Generation:  28%|       | 7/25 [11:18<17:15, 57.53s/it]Generation:  8
Best root_mean_squared_error score: -0.14878354891852177
Generation:  32%|      | 8/25 [11:39<13:00, 45.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657afb50> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  9
Best root_mean_squared_error score: -0.14494710955493803
Generation:  36%|      | 9/25 [16:13<31:15, 117.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c24a90> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  10
Best root_mean_squared_error score: -0.144826978551137
Generation:  40%|      | 10/25 [21:32<44:51, 179.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a6aaa0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b08bb0> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ffca00> 

Generation:  11
Best root_mean_squared_error score: -0.14057740163401006
Generation:  44%|     | 11/25 [31:39<1:12:22, 310.19s/it]Generation:  12
Best root_mean_squared_error score: -0.1378271614056929
Generation:  48%|     | 12/25 [38:29<1:13:50, 340.77s/it]Generation:  13
Best root_mean_squared_error score: -0.1378271614056929
Generation:  52%|    | 13/25 [44:18<1:08:38, 343.24s/it]Generation:  14
Best root_mean_squared_error score: -0.1378271614056929
Generation:  56%|    | 14/25 [53:33<1:14:37, 407.00s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472d330> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  15
Best root_mean_squared_error score: -0.1378271614056929
Generation:  60%|    | 15/25 [55:44<53:59, 323.98s/it]  Generation:  16
Best root_mean_squared_error score: -0.1378271614056929
Generation:  64%|   | 16/25 [1:01:26<49:24, 329.44s/it]Generation:  17
Best root_mean_squared_error score: -0.1378271614056929
Generation:  68%|   | 17/25 [1:05:17<39:57, 299.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e102e0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  18
Best root_mean_squared_error score: -0.1378271614056929
Generation:  72%|  | 18/25 [1:08:53<32:01, 274.45s/it]Generation:  19
Best root_mean_squared_error score: -0.1378271614056929
Generation:  76%|  | 19/25 [1:12:23<25:31, 255.20s/it]Generation:  20
Best root_mean_squared_error score: -0.1378271614056929
Generation:  80%|  | 20/25 [1:16:44<21:24, 256.97s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b333d0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  21
Best root_mean_squared_error score: -0.1378271614056929
Generation:  84%| | 21/25 [1:20:25<16:24, 246.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d9c730> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  22
Best root_mean_squared_error score: -0.1378271614056929
Generation:  88%| | 22/25 [1:25:48<13:27, 269.20s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a68d00> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  23
Best root_mean_squared_error score: -0.1378271614056929
Generation:  92%|| 23/25 [1:32:34<10:20, 310.34s/it]Generation:  24
Best root_mean_squared_error score: -0.1378271614056929
Generation:  96%|| 24/25 [1:33:55<04:01, 241.43s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ed720> 

Generation:  25
Best root_mean_squared_error score: -0.1378271614056929
Generation: 100%|| 25/25 [1:44:05<00:00, 352.05s/it]Generation: 100%|| 25/25 [1:44:08<00:00, 249.92s/it]
2024-09-20 07:03:47,036 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45895' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-b9d7a3ee3b621f4718351e43420a338f', 'DataFrame-199f3c31ceebfff04409bf1345a44d8c'} (stimulus_id='handle-worker-cleanup-1726841027.036857')
2024-09-20 07:03:51,004 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,005 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,005 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,005 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,006 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,006 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,008 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,008 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,009 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,009 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,009 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,028 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,028 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,029 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,029 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 07:03:51,029 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('mlpregressor',
                 MLPRegressor(alpha=1.998406e-07, early_stopping=True,
                              hidden_layer_sizes=[431, 431, 431],
                              learning_rate_init=0.0004011392037,
                              n_iter_no_change=32))])
score start
train score: {'explained_var': 0.8159443615846637, 'r2': 0.8159353988358367, 'rmse': 0.11355731062162074}
original test score: {'explained_var': 0.8766396490952852, 'r2': 0.8759423463725894, 'rmse': 0.09127544491131535}
imputed test score: {'explained_var': 0.7098527129967789, 'r2': 0.7098198730675711, 'rmse': 0.13959697591766895}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1553b09dd870>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4be0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474700d00> 

Generation:  1
Best root_mean_squared_error score: -0.17049496603142983
Generation:   4%|         | 1/25 [10:03<4:01:12, 603.02s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f62f0> 

Generation:  2
Best root_mean_squared_error score: -0.1655511835117864
Generation:   8%|         | 2/25 [20:06<3:51:12, 603.14s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a59f0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  3
Best root_mean_squared_error score: -0.14633827141227074
Generation:  12%|        | 3/25 [21:38<2:15:33, 369.71s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a6f50> 

Generation:  4
Best root_mean_squared_error score: -0.14633827141227074
Generation:  16%|        | 4/25 [31:41<2:41:41, 461.96s/it]Generation:  5
Best root_mean_squared_error score: -0.14633827141227074
Generation:  20%|        | 5/25 [33:45<1:53:19, 339.97s/it]Generation:  6
Best root_mean_squared_error score: -0.1420086832390489
Generation:  24%|       | 6/25 [36:59<1:31:55, 290.30s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553620dd120> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467866830> 

Generation:  7
Best root_mean_squared_error score: -0.14063586814612894
Generation:  28%|       | 7/25 [47:03<1:57:55, 393.08s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465ffcee0> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467892a70> 

Generation:  8
Best root_mean_squared_error score: -0.13948264801265384
Generation:  32%|      | 8/25 [57:08<2:10:26, 460.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553631e7970> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554651971c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c31f00> 

Generation:  9
Best root_mean_squared_error score: -0.13948264801265384
Generation:  36%|      | 9/25 [1:07:14<2:14:56, 506.02s/it]Generation:  10
Best root_mean_squared_error score: -0.13948264801265384
Generation:  40%|      | 10/25 [1:16:43<2:11:23, 525.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554653f63b0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  11
Best root_mean_squared_error score: -0.139122532942287
Generation:  44%|     | 11/25 [1:21:23<1:45:05, 450.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451b629e0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747110f0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465cf8490> 

Generation:  12
Best root_mean_squared_error score: -0.1378115495280618
Generation:  48%|     | 12/25 [1:31:28<1:47:43, 497.21s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465250670> 

Generation:  13
Best root_mean_squared_error score: -0.13770002228707384
Generation:  52%|    | 13/25 [1:41:33<1:46:00, 530.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465c91960> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678ae9b0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  14
Best root_mean_squared_error score: -0.13770002228707384
Generation:  56%|    | 14/25 [1:47:48<1:28:34, 483.10s/it]Generation:  15
Best root_mean_squared_error score: -0.13770002228707384
Generation:  60%|    | 15/25 [1:54:48<1:17:19, 463.99s/it]Generation:  16
Best root_mean_squared_error score: -0.136941099070316
Generation:  64%|   | 16/25 [2:00:39<1:04:30, 430.03s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678ca230> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  17
Best root_mean_squared_error score: -0.136941099070316
Generation:  68%|   | 17/25 [2:06:15<53:35, 401.96s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452593310> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  18
Best root_mean_squared_error score: -0.136941099070316
Generation:  72%|  | 18/25 [2:10:32<41:47, 358.24s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a0bca0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff01f0> 

Generation:  19
Best root_mean_squared_error score: -0.136941099070316
Generation:  76%|  | 19/25 [2:20:39<43:17, 432.91s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676b88e0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451cb1240> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545267c3d0> 

Generation:  20
Best root_mean_squared_error score: -0.136941099070316
Generation:  80%|  | 20/25 [2:30:47<40:27, 485.47s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465484d00> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714490> 

Generation:  21
Best root_mean_squared_error score: -0.136941099070316
Generation:  84%| | 21/25 [2:40:52<34:45, 521.43s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652b7fd0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554526aa0b0> 

Generation:  22
Best root_mean_squared_error score: -0.136941099070316
Generation:  88%| | 22/25 [2:51:00<27:22, 547.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474732230> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451b1dcc0> 

Generation:  23
Best root_mean_squared_error score: -0.136941099070316
Generation:  92%|| 23/25 [3:01:05<18:49, 564.60s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652b27d0> 

Generation:  24
Best root_mean_squared_error score: -0.136941099070316
Generation:  96%|| 24/25 [3:11:13<09:37, 577.57s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553f2c37dc0> 

Generation:  25
Best root_mean_squared_error score: -0.136941099070316
Generation: 100%|| 25/25 [3:21:18<00:00, 585.82s/it]Generation: 100%|| 25/25 [3:21:18<00:00, 483.12s/it]
2024-09-20 10:25:46,035 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35295' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-254d1c68be387bf19dac601e29af1f82', 'DataFrame-199f3c31ceebfff04409bf1345a44d8c'} (stimulus_id='handle-worker-cleanup-1726853146.0358796')
2024-09-20 10:25:50,016 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,016 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,016 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,017 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,017 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,017 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,017 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,019 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,019 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,020 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,020 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,021 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,036 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,036 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,036 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 10:25:50,036 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('mlpregressor',
                 MLPRegressor(alpha=1.125181e-07, early_stopping=True,
                              hidden_layer_sizes=[484, 484, 484],
                              learning_rate_init=0.0009612133828,
                              n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'explained_var': 0.7969182375902619, 'r2': 0.7941962338778389, 'rmse': 0.12007611289210039}
test score: {'explained_var': 0.7153728744622266, 'r2': 0.7134954409016351, 'rmse': 0.13871005557227417}
original test score: {'explained_var': 0.8875477925196902, 'r2': 0.882900794632252, 'rmse': 0.08867866594656874}
score end
189
lvl
0.1
type
MNAR
num_run
3
reg_full
finished
all finished
full run takes
11.219989209108883
hours
DONE
