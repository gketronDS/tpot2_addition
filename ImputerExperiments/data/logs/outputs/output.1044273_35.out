Run: 35
/cm/local/apps/slurm/var/spool/job1044273/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1507/1507.pkl
working on 
../data/c/1507/class_full_MNAR_0.3_2
0.8210194110870361
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-08 17:29:35,964] A new study created in memory with name: no-name-8406ec08-d537-4dc3-a8c6-4507e9880921
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-08 17:29:36,510] Trial 8 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.43020397014948947.
running
[I 2024-11-08 17:29:36,726] Trial 5 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.43020397014948947.
running
[I 2024-11-08 17:29:36,883] Trial 16 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:39,833] Trial 9 finished with value: 0.13499955307541156 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0010476340717163275, 'p_miss': 0.14388955457233019}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:40,939] Trial 7 finished with value: 0.17446902195638359 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2978, 'weights': 'uniform'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:41,844] Trial 12 finished with value: 0.4067626950600117 and parameters: {'model_name': 'GAIN', 'batch_size': 202, 'hint_rate': 0.21156997092228708, 'alpha': 38, 'iterations': 1, 'learning_rate': 0.0006528206921494012, 'p_miss': 0.13895428841128626}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:43,583] Trial 4 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.208964187465584, 'alpha': 90, 'iterations': 16, 'learning_rate': 0.019559116009385466, 'p_miss': 0.07023818394046404}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:47,132] Trial 13 finished with value: 0.3994041751019283 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.989577984701556, 'alpha': 94, 'iterations': 9, 'learning_rate': 0.009660790131253854, 'p_miss': 0.1797110909677966}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:47,656] Trial 11 finished with value: 0.13515893063070722 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8, 'learning_rate': 0.00039247885936800864, 'p_miss': 0.23175313529571495}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:47,831] Trial 20 finished with value: 0.17893922819911356 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 387, 'weights': 'uniform'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:48,758] Trial 10 finished with value: 0.14434130499128683 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 4, 'learning_rate': 0.0068705490836813024, 'p_miss': 0.2361993500916285}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:49,657] Trial 19 finished with value: 0.17774514297737037 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1136, 'weights': 'distance'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:49,898] Trial 24 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:51,730] Trial 21 finished with value: 0.17135562675582824 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4629, 'weights': 'distance'}. Best is trial 16 with value: 0.13242410692269163.
running
[I 2024-11-08 17:29:53,402] Trial 23 finished with value: 0.1317821590565861 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 3, 'learning_rate': 0.002171006322273001, 'p_miss': 0.25716452998209044}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:30:07,186] Trial 17 finished with value: 0.3968615923737463 and parameters: {'model_name': 'GAIN', 'batch_size': 489, 'hint_rate': 0.9110282990961451, 'alpha': 42, 'iterations': 17, 'learning_rate': 0.0005414813975602468, 'p_miss': 0.18330200920888595}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:30:23,740] Trial 3 finished with value: 0.4274519976567953 and parameters: {'model_name': 'GAIN', 'batch_size': 53, 'hint_rate': 0.8318478380202623, 'alpha': 14, 'iterations': 81, 'learning_rate': 0.0212468271079916, 'p_miss': 0.024113757975397165}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:30:31,123] Trial 26 finished with value: 0.16739235030100327 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 17, 'imputation_order': 'roman'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:30:51,692] Trial 28 finished with value: 0.19159443881304222 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:30:52,319] Trial 34 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:02,629] Trial 6 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.1501198156298336, 'alpha': 57, 'iterations': 780, 'learning_rate': 0.01157269302204482, 'p_miss': 0.0784285936805749}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:03,672] Trial 36 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:04,312] Trial 37 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:09,880] Trial 33 finished with value: 0.190191706909546 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:19,794] Trial 2 finished with value: 0.1685408188710837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:24,162] Trial 22 finished with value: 0.13248025321335158 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 105, 'learning_rate': 0.0004937467881414166, 'p_miss': 0.1382046450458669}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:24,690] Trial 41 finished with value: 0.17051485955237206 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:25,549] Trial 42 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:27,347] Trial 25 finished with value: 0.16893499786872931 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:39,869] Trial 30 finished with value: 0.1685820321705407 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:41,814] Trial 27 finished with value: 0.16892938464723223 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 11, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:42,332] Trial 46 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:42,758] Trial 47 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:31:43,419] Trial 48 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:32:04,852] Trial 29 finished with value: 0.27227587527900843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:32:05,607] Trial 50 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:32:48,847] Trial 18 finished with value: 0.18065390795131728 and parameters: {'model_name': 'VAE', 'batch_size': 405, 'iterations': 59, 'learning_rate': 0.028989448562959118, 'p_miss': 0.05461951681017668}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:32:49,988] Trial 52 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:32:50,888] Trial 53 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:34:46,523] Trial 0 finished with value: 0.38306314597538876 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.6438792384645812, 'alpha': 33, 'iterations': 368, 'learning_rate': 0.0006814013706837489, 'p_miss': 0.29026226613006084}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:42:00,832] Trial 14 finished with value: 0.2604483134933589 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 407, 'learning_rate': 0.02744588847844846, 'p_miss': 0.2509661001636532}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:42:01,781] Trial 56 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:42:02,856] Trial 57 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:42:03,596] Trial 58 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 17:42:04,092] Trial 59 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 18:44:23,915] Trial 15 finished with value: 0.1766492029497646 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 18:46:53,746] Trial 1 finished with value: 0.17506542706373387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:04:08,284] Trial 31 finished with value: 0.17306612347535127 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 11, 'imputation_order': 'roman'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:04:20,198] Trial 63 finished with value: 0.1333780939841745 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.00011235231553116327, 'p_miss': 0.29903897644209865}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:04:20,840] Trial 64 finished with value: 0.17051485955237206 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:10:30,561] Trial 43 finished with value: 0.1920936775520002 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 1857, 'learning_rate': 0.0833093174668269, 'p_miss': 0.29040168141360645}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:10:31,398] Trial 66 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:10:32,096] Trial 67 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:10:32,731] Trial 68 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:10:33,508] Trial 69 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:13:55,318] Trial 51 finished with value: 0.1842831170043015 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 1939, 'learning_rate': 0.07557770348005674, 'p_miss': 0.2630708889067604}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:14:03,297] Trial 71 finished with value: 0.39370331724150887 and parameters: {'model_name': 'GAIN', 'batch_size': 49, 'hint_rate': 0.4632521218515062, 'alpha': 1, 'iterations': 2, 'learning_rate': 0.0025687569496699427, 'p_miss': 0.20884757098124584}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:14:13,276] Trial 72 finished with value: 0.17135562675582824 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5680, 'weights': 'distance'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:14:14,082] Trial 73 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:14:14,882] Trial 74 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:16:13,302] Trial 75 finished with value: 0.13198121834223553 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 42, 'learning_rate': 0.0017184556821722386, 'p_miss': 0.11946253395761204}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:42:06,146] Trial 32 finished with value: 0.17084202393712067 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 20, 'imputation_order': 'ascending'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 19:43:46,087] Trial 35 finished with value: 0.18846025872311892 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 2555, 'learning_rate': 0.0001241652199640812, 'p_miss': 0.29829973069858395}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:13:38,164] Trial 49 finished with value: 0.18734872366495864 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4220, 'learning_rate': 0.06874556098369378, 'p_miss': 0.28684163494173276}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:15:29,890] Trial 79 finished with value: 0.1429215450518374 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 36, 'learning_rate': 0.0024005844382764046, 'p_miss': 0.10611300272199964}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:27:34,855] Trial 80 finished with value: 0.18327777370589488 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 179, 'learning_rate': 0.001352787705033563, 'p_miss': 0.10970834673234786}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:34:09,148] Trial 54 finished with value: 0.19695127535750073 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4456, 'learning_rate': 0.09173236228041913, 'p_miss': 0.2858847248416332}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:26,321] Trial 82 finished with value: 0.405655028735071 and parameters: {'model_name': 'GAIN', 'batch_size': 928, 'hint_rate': 0.42886233677406305, 'alpha': 69, 'iterations': 29, 'learning_rate': 0.0015649503342808728, 'p_miss': 0.17469802217221236}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:35,805] Trial 83 finished with value: 0.17526048172393355 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2591, 'weights': 'uniform'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:36,761] Trial 84 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:37,698] Trial 85 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:38,626] Trial 86 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:39,466] Trial 87 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:40,499] Trial 88 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:35:41,214] Trial 89 finished with value: 0.17051485955237206 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:36:27,129] Trial 90 finished with value: 0.14004214375365293 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 7, 'learning_rate': 0.004573277031551328, 'p_miss': 0.2042820115383217}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:36:27,654] Trial 91 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:36:29,457] Trial 92 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:36:40,030] Trial 93 finished with value: 0.13457716594530938 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.00022325126274804516, 'p_miss': 0.10963564800204861}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:32,017] Trial 94 finished with value: 0.42887871929747134 and parameters: {'model_name': 'GAIN', 'batch_size': 125, 'hint_rate': 0.039964690903709466, 'alpha': 73, 'iterations': 177, 'learning_rate': 0.0033974125478071376, 'p_miss': 0.011952564346066036}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:32,864] Trial 95 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:33,636] Trial 96 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:34,477] Trial 97 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:36,129] Trial 98 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 21:41:37,060] Trial 99 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:04:18,874] Trial 40 finished with value: 0.1822528426693324 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 4906, 'learning_rate': 0.002333039228678169, 'p_miss': 0.29165677292382286}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:04:19,692] Trial 101 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:04:29,820] Trial 102 finished with value: 0.17349190773261358 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3435, 'weights': 'uniform'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:04:30,775] Trial 103 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:36,138] Trial 100 finished with value: 0.18278280629814386 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 519, 'learning_rate': 0.00025342093456177733, 'p_miss': 0.21079917683549615}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:36,608] Trial 105 finished with value: 0.17051485955237206 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:37,596] Trial 106 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:38,773] Trial 107 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:39,855] Trial 108 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:40,977] Trial 109 finished with value: 0.13242410692269163 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:15:41,790] Trial 110 finished with value: 0.43020397014948947 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 23 with value: 0.1317821590565861.
running
[I 2024-11-08 22:16:49,352] Trial 111 finished with value: 0.12767325952200434 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 19, 'learning_rate': 0.0009014878837783453, 'p_miss': 0.04530352925125106}. Best is trial 111 with value: 0.12767325952200434.
running
[I 2024-11-08 22:17:41,511] Trial 112 finished with value: 0.12844380285160034 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 17, 'learning_rate': 0.000994780580378998, 'p_miss': 0.04017646144069637}. Best is trial 111 with value: 0.12767325952200434.
running
[I 2024-11-08 22:19:21,877] Trial 113 finished with value: 0.13175578025240697 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 26, 'learning_rate': 0.000961332882716431, 'p_miss': 0.044937741380801824}. Best is trial 111 with value: 0.12767325952200434.
running
[I 2024-11-08 22:20:15,639] Trial 114 finished with value: 0.128358075583836 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 17, 'learning_rate': 0.0009646527905863836, 'p_miss': 0.033174152689968026}. Best is trial 111 with value: 0.12767325952200434.
running
[I 2024-11-08 22:21:27,708] Trial 115 finished with value: 0.12659446349206574 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 23, 'learning_rate': 0.0010269085839976764, 'p_miss': 0.04086040152329182}. Best is trial 115 with value: 0.12659446349206574.
running
[I 2024-11-08 22:22:36,127] Trial 116 finished with value: 0.12852053120799461 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 22, 'learning_rate': 0.0009695291434628371, 'p_miss': 0.03958168126939812}. Best is trial 115 with value: 0.12659446349206574.
running
[I 2024-11-08 22:23:57,796] Trial 117 finished with value: 0.1274795507972847 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 22, 'learning_rate': 0.0009608465643228513, 'p_miss': 0.043519569865668975}. Best is trial 115 with value: 0.12659446349206574.
running
[I 2024-11-08 22:25:06,602] Trial 118 finished with value: 0.12659720677103778 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 21, 'learning_rate': 0.001097966373331648, 'p_miss': 0.03596277843484681}. Best is trial 115 with value: 0.12659446349206574.
running
[I 2024-11-08 22:26:28,081] Trial 119 finished with value: 0.12623976623815839 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 21, 'learning_rate': 0.0009474088101179154, 'p_miss': 0.03887935613959986}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:27:46,317] Trial 120 finished with value: 0.1274785907586732 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 22, 'learning_rate': 0.0009304678728659175, 'p_miss': 0.03831625377728134}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:28:47,308] Trial 121 finished with value: 0.12926439301863066 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 19, 'learning_rate': 0.0009339108947504274, 'p_miss': 0.040373786084017434}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:29:54,052] Trial 122 finished with value: 0.12771598701273126 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 18, 'learning_rate': 0.0009255078234795527, 'p_miss': 0.04020560699454171}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:30:45,332] Trial 123 finished with value: 0.13016856390293471 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 16, 'learning_rate': 0.0009112508247043708, 'p_miss': 0.037287076658367835}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:31:47,382] Trial 124 finished with value: 0.12900966124983398 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 19, 'learning_rate': 0.0009560719806493798, 'p_miss': 0.031706837192263485}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:32:20,568] Trial 125 finished with value: 0.13352046060644454 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 11, 'learning_rate': 0.0012014280166960504, 'p_miss': 0.02698854582886491}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:33:26,522] Trial 126 finished with value: 0.13139504918872358 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 20, 'learning_rate': 0.0007608564812176985, 'p_miss': 0.0603755102492879}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:34:29,873] Trial 127 finished with value: 0.1262709801604396 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 17, 'learning_rate': 0.0008293465626497018, 'p_miss': 0.03148998410758634}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:35:07,464] Trial 128 finished with value: 0.13091629043912129 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 12, 'learning_rate': 0.000711835140929999, 'p_miss': 0.02794846359912967}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:36:36,782] Trial 129 finished with value: 0.1286298558938904 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 28, 'learning_rate': 0.0012535028513814986, 'p_miss': 0.012610959834185309}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:38:54,066] Trial 130 finished with value: 0.13203563351053543 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 43, 'learning_rate': 0.0013356926567782285, 'p_miss': 0.010285616049978978}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:40:33,681] Trial 131 finished with value: 0.12995427414517405 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 27, 'learning_rate': 0.0006214861597879831, 'p_miss': 0.05580144141102047}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:41:17,130] Trial 132 finished with value: 0.13180309387966804 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 12, 'learning_rate': 0.0011229723240948665, 'p_miss': 0.04696498398129307}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:41:45,372] Trial 133 finished with value: 0.1289738779427383 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.00047928943401689527, 'p_miss': 0.021027945697314955}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:42:55,542] Trial 134 finished with value: 0.13005832076124552 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 25, 'learning_rate': 0.0007408475780274646, 'p_miss': 0.06853783704062105}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:46:23,908] Trial 135 finished with value: 0.14438218891308296 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 57, 'learning_rate': 0.0014332545130432276, 'p_miss': 0.08245343804283564}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:46:57,827] Trial 136 finished with value: 0.1339889241056169 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 8, 'learning_rate': 0.00035018586398500245, 'p_miss': 0.01992875704413003}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:47:27,060] Trial 137 finished with value: 0.1352190987258285 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.0004601353280452682, 'p_miss': 0.037406952916356664}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:48:11,368] Trial 138 finished with value: 0.12753444207883208 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 12, 'learning_rate': 0.0007939621116730811, 'p_miss': 0.021810521456740457}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:48:59,207] Trial 139 finished with value: 0.12872815955454817 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 14, 'learning_rate': 0.0008433225620610291, 'p_miss': 0.04650601416355295}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:50:11,479] Trial 140 finished with value: 0.1277338698047843 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 20, 'learning_rate': 0.000637939423447347, 'p_miss': 0.031171382928315977}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:51:02,221] Trial 141 finished with value: 0.13350568132278967 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 15, 'learning_rate': 0.0006467958303929268, 'p_miss': 0.03420701118180404}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:52:09,806] Trial 142 finished with value: 0.12925828007573775 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 19, 'learning_rate': 0.0010271573999051182, 'p_miss': 0.05342201428954818}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:52:52,601] Trial 143 finished with value: 0.1321737316612609 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 10, 'learning_rate': 0.0006048412656553331, 'p_miss': 0.02718006982685097}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:55:20,353] Trial 144 finished with value: 0.14512125719073807 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 40, 'learning_rate': 0.001771731475722889, 'p_miss': 0.06595175422486772}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:56:19,732] Trial 145 finished with value: 0.1273465388971795 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 22, 'learning_rate': 0.0008053192802067134, 'p_miss': 0.047005375271974154}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:57:27,176] Trial 146 finished with value: 0.12786786997286642 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 22, 'learning_rate': 0.0007988234021399785, 'p_miss': 0.04823556238195846}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 22:58:17,648] Trial 147 finished with value: 0.13205271123263723 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 14, 'learning_rate': 0.0007766448937832336, 'p_miss': 0.050252805412291233}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 23:00:23,452] Trial 148 finished with value: 0.12704883135415684 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 32, 'learning_rate': 0.0006179413135261849, 'p_miss': 0.078854249953921}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 23:02:18,826] Trial 149 finished with value: 0.13334974102758515 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 35, 'learning_rate': 0.0004987905489407446, 'p_miss': 0.026156630662570686}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 23:04:54,574] Trial 70 finished with value: 0.4092039234013035 and parameters: {'model_name': 'GAIN', 'batch_size': 46, 'hint_rate': 0.4820405876718597, 'alpha': 69, 'iterations': 8733, 'learning_rate': 0.002819051346542339, 'p_miss': 0.19935262337917403}. Best is trial 119 with value: 0.12623976623815839.
running
[I 2024-11-08 23:06:54,066] Trial 150 finished with value: 0.1261575605218159 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 72, 'learning_rate': 0.0003597040099100146, 'p_miss': 0.0829863100236276}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:08:52,805] Trial 151 finished with value: 0.12714766717994797 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 85, 'learning_rate': 0.00035421287498750516, 'p_miss': 0.08692270807000108}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:12:23,157] Trial 153 finished with value: 0.1262462110125066 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 69, 'learning_rate': 0.0003520605350978536, 'p_miss': 0.09013369563595966}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:14:05,484] Trial 152 finished with value: 0.12629048870848042 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 96, 'learning_rate': 0.000323971224959263, 'p_miss': 0.07415657650142271}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:18:59,303] Trial 155 finished with value: 0.12648368933408474 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 79, 'learning_rate': 0.00029641213269882894, 'p_miss': 0.080239033311502}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:19:03,004] Trial 154 finished with value: 0.1264994827945969 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 98, 'learning_rate': 0.00027481894368014105, 'p_miss': 0.08927366070695525}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:24:22,610] Trial 157 finished with value: 0.12719374960432012 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 95, 'learning_rate': 0.0003010073779367965, 'p_miss': 0.083954636022572}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:26:56,184] Trial 156 finished with value: 0.13113567461324563 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 116, 'learning_rate': 0.00032112879451985464, 'p_miss': 0.08962632644842551}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:27:56,654] Trial 39 finished with value: 0.1848871423766822 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 6806, 'learning_rate': 0.00010750734659236052, 'p_miss': 0.2738198508817126}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:30:30,410] Trial 158 finished with value: 0.12743433864293857 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 114, 'learning_rate': 0.00031071144999235856, 'p_miss': 0.07998361523545759}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:31:30,064] Trial 160 finished with value: 0.12786010226662606 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 71, 'learning_rate': 0.0001936867880180377, 'p_miss': 0.09190735035304519}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:32:04,550] Trial 159 finished with value: 0.12759857628380047 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 85, 'learning_rate': 0.00018812454710578295, 'p_miss': 0.09308835823273166}. Best is trial 150 with value: 0.1261575605218159.
running
[I 2024-11-08 23:36:59,239] Trial 162 finished with value: 0.12443786742422425 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 109, 'learning_rate': 0.00029562055100254434, 'p_miss': 0.07866014869716208}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:37:09,350] Trial 161 finished with value: 0.1258327978192411 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 86, 'learning_rate': 0.00019642348847107683, 'p_miss': 0.08881793978159766}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:38:44,717] Trial 163 finished with value: 0.12473097725921682 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 123, 'learning_rate': 0.0003062615333622124, 'p_miss': 0.07861260044231054}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:46:18,763] Trial 164 finished with value: 0.1302712768625967 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 153, 'learning_rate': 0.0002811044927213884, 'p_miss': 0.07994608900809513}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:48:00,419] Trial 166 finished with value: 0.13082701232070754 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 161, 'learning_rate': 0.0002756333498439115, 'p_miss': 0.1007026961725866}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:49:11,189] Trial 165 finished with value: 0.1349864781219301 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 203, 'learning_rate': 0.0002575399498835613, 'p_miss': 0.07506499197886876}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:49:15,266] Trial 167 finished with value: 0.12783234748254363 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 56, 'learning_rate': 0.0004045388620777409, 'p_miss': 0.10195666375480839}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:49:24,679] Trial 170 finished with value: 0.17692877960028647 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1708, 'weights': 'distance'}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:49:58,868] Trial 169 finished with value: 0.1671453179848435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:50:09,506] Trial 168 finished with value: 0.12770091280703288 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 93, 'learning_rate': 0.00037903387263724006, 'p_miss': 0.07027073357968819}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:50:10,414] Trial 171 finished with value: 0.1672248238615824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:53:37,313] Trial 174 finished with value: 0.12902533355767304 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 69, 'learning_rate': 0.0002040100182817883, 'p_miss': 0.08739046208229019}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:55:37,585] Trial 172 finished with value: 0.12739133120937757 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 98, 'learning_rate': 0.0001679994650002017, 'p_miss': 0.07120581885387725}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:58:34,440] Trial 173 finished with value: 0.12993189611134479 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 131, 'learning_rate': 0.00014642478067364517, 'p_miss': 0.11959392085086515}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-08 23:59:54,328] Trial 175 finished with value: 0.12698939557413608 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 116, 'learning_rate': 0.00016727413593587405, 'p_miss': 0.12044338477411826}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:01:37,790] Trial 60 finished with value: 0.18891168398927388 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 7082, 'learning_rate': 0.00010651527724743874, 'p_miss': 0.2829120379457031}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:03:18,420] Trial 176 finished with value: 0.12589161445860447 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 135, 'learning_rate': 0.00017638315902003126, 'p_miss': 0.06207478713002397}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:07:57,564] Trial 180 finished with value: 0.12835780192175955 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 75, 'learning_rate': 0.00024572638020605087, 'p_miss': 0.06203376736687644}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:09:54,392] Trial 178 finished with value: 0.12784447112552497 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 215, 'learning_rate': 0.00022182850758405777, 'p_miss': 0.06290392594182728}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:10:33,306] Trial 55 finished with value: 0.18350022149486575 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6567, 'learning_rate': 0.00012394058504525845, 'p_miss': 0.2948296376666815}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:11:19,589] Trial 182 finished with value: 0.41181542092091644 and parameters: {'model_name': 'GAIN', 'batch_size': 52, 'hint_rate': 0.6925113936403321, 'alpha': 20, 'iterations': 55, 'learning_rate': 0.00015110727388204252, 'p_miss': 0.09637673533824113}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:13:47,886] Trial 179 finished with value: 0.12986995895991713 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 217, 'learning_rate': 0.00022636786037177062, 'p_miss': 0.09597932002226536}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:14:40,127] Trial 177 finished with value: 0.1270372378910538 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 263, 'learning_rate': 0.00014658694052795677, 'p_miss': 0.062957932810117}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:17:39,760] Trial 183 finished with value: 0.4167611171623219 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.693594500183118, 'alpha': 22, 'iterations': 260, 'learning_rate': 0.0004274629436806511, 'p_miss': 0.08351172700734134}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:18:22,046] Trial 181 finished with value: 0.16374676617996542 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 204, 'learning_rate': 0.0004105832135290315, 'p_miss': 0.08529077519568323}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:18:38,608] Trial 184 finished with value: 0.13619351435139904 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 130, 'learning_rate': 0.000338945446366122, 'p_miss': 0.08356498609020503}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:19:41,308] Trial 185 finished with value: 0.1279840655010155 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 124, 'learning_rate': 0.00041751747412855213, 'p_miss': 0.08696570314495808}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:23:06,027] Trial 44 finished with value: 0.197163697444916 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 7348, 'learning_rate': 0.08920282613449905, 'p_miss': 0.2929352738219434}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:23:18,038] Trial 186 finished with value: 0.14625960278892888 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 138, 'learning_rate': 0.00039663232075417133, 'p_miss': 0.08424701415121257}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:23:36,194] Trial 189 finished with value: 0.1276870689107662 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 95, 'learning_rate': 0.00013399121905064717, 'p_miss': 0.07503288316562477}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:25:00,402] Trial 190 finished with value: 0.13081507702634743 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 92, 'learning_rate': 0.00013392036288314025, 'p_miss': 0.0751574554862101}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:25:12,204] Trial 187 finished with value: 0.1300832842445474 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 133, 'learning_rate': 0.0003162672809579469, 'p_miss': 0.07749337921313736}. Best is trial 162 with value: 0.12443786742422425.
running
[I 2024-11-09 00:27:44,601] Trial 191 finished with value: 0.12396599052284388 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 89, 'learning_rate': 0.00029742448822717463, 'p_miss': 0.07534580383402216}. Best is trial 191 with value: 0.12396599052284388.
running
[I 2024-11-09 00:27:59,589] Trial 194 finished with value: 0.1285970501551639 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 50, 'learning_rate': 0.00016837975397275033, 'p_miss': 0.14780126288740694}. Best is trial 191 with value: 0.12396599052284388.
running
[I 2024-11-09 00:28:35,763] Trial 192 finished with value: 0.12731263922342845 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 88, 'learning_rate': 0.0003032625236443085, 'p_miss': 0.07579873255882655}. Best is trial 191 with value: 0.12396599052284388.
running
[I 2024-11-09 00:31:17,067] Trial 196 finished with value: 0.12631225008626984 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 65, 'learning_rate': 0.00017173090925833335, 'p_miss': 0.1517801828664276}. Best is trial 191 with value: 0.12396599052284388.
running
[I 2024-11-09 00:32:23,065] Trial 197 finished with value: 0.13253171082398935 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 70, 'learning_rate': 0.0005513506994122387, 'p_miss': 0.06977933811681661}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 00:34:35,168] Trial 199 finished with value: 0.1275883864748554 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 68, 'learning_rate': 0.00018448046200721715, 'p_miss': 0.05730451538304303}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 00:38:16,896] Trial 193 finished with value: 0.16660450722707862 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 308, 'learning_rate': 0.00029493219167060926, 'p_miss': 0.07550159467989623}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 00:40:18,084] Trial 188 finished with value: 0.18017148779156042 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 318, 'learning_rate': 0.00032548259257438207, 'p_miss': 0.07582505537609655}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 00:41:03,297] Trial 195 finished with value: 0.13819595033390594 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 312, 'learning_rate': 0.00018177113183278143, 'p_miss': 0.1136449677535781}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 00:45:03,469] Trial 198 finished with value: 0.17118051073992033 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 318, 'learning_rate': 0.00026382539684371043, 'p_miss': 0.05933368261138866}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:12:01,319] Trial 81 finished with value: 0.4171482639727018 and parameters: {'model_name': 'GAIN', 'batch_size': 135, 'hint_rate': 0.43500397627743187, 'alpha': 68, 'iterations': 8570, 'learning_rate': 0.004251459566986227, 'p_miss': 0.1762799982921813}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:12:51,985] Trial 45 finished with value: 0.2058104066414861 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 8518, 'learning_rate': 0.09327273677535368, 'p_miss': 0.2965002540112334}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:16:07,541] Trial 77 finished with value: 0.19287502123089656 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6204, 'learning_rate': 0.002586557625210043, 'p_miss': 0.11021226269041721}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:19:41,945] Trial 62 finished with value: 0.1896045586719956 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 7244, 'learning_rate': 0.0855858585319558, 'p_miss': 0.299075370247798}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:23:19,784] Trial 78 finished with value: 0.18276576033899858 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 7013, 'learning_rate': 0.001983154798423632, 'p_miss': 0.11028692241575802}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:26:50,167] Trial 38 finished with value: 0.18698292755973847 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 9145, 'learning_rate': 0.0018004062152269598, 'p_miss': 0.29665509630974096}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:27:06,608] Trial 61 finished with value: 0.1853911036314584 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 8289, 'learning_rate': 0.00013447283815308845, 'p_miss': 0.2978542349018032}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:28:19,080] Trial 65 finished with value: 0.18408636098074532 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 7114, 'learning_rate': 0.0026868640751653884, 'p_miss': 0.20220181913069935}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:30:17,881] Trial 76 finished with value: 0.18628262722640648 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 9240, 'learning_rate': 0.002624406833934351, 'p_miss': 0.11704060487029846}. Best is trial 191 with value: 0.12396599052284388.
[I 2024-11-09 01:31:40,370] Trial 104 finished with value: 0.184404701276657 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 9774, 'learning_rate': 0.00029943750744887, 'p_miss': 0.16317505939175483}. Best is trial 191 with value: 0.12396599052284388.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.12396599052284388
{'model_name': 'VAE', 'batch_size': 43, 'iterations': 89, 'learning_rate': 0.00029742448822717463, 'p_miss': 0.07534580383402216}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4cd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4af0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f86d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.6259080147539742
Generation:   4%|▍         | 1/25 [00:52<21:04, 52.68s/it]Generation:  2
Best f1_score score: 0.6426109845165314
Generation:   8%|▊         | 2/25 [01:22<15:05, 39.36s/it]Generation:  3
Best f1_score score: 0.6466025903683044
Generation:  12%|█▏        | 3/25 [01:59<14:00, 38.18s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465ba2f80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4e20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.6466025903683044
Generation:  16%|█▌        | 4/25 [02:36<13:11, 37.68s/it]Generation:  5
Best f1_score score: 0.6466025903683044
Generation:  20%|██        | 5/25 [09:40<59:02, 177.12s/it]Generation:  6
Best f1_score score: 0.6476487899175354
Generation:  24%|██▍       | 6/25 [10:12<40:28, 127.82s/it]Generation:  7
Best f1_score score: 0.6483012306089103
Generation:  28%|██▊       | 7/25 [10:48<29:17, 97.64s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a74130> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.6483012306089103
Generation:  32%|███▏      | 8/25 [11:25<22:12, 78.40s/it]Generation:  9
Best f1_score score: 0.6483012306089103
Generation:  36%|███▌      | 9/25 [11:58<17:07, 64.21s/it]Generation:  10
Best f1_score score: 0.6483012306089103
Generation:  40%|████      | 10/25 [17:27<36:27, 145.82s/it]Generation:  11
Best f1_score score: 0.6491429539953777
Generation:  44%|████▍     | 11/25 [19:54<34:06, 146.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b05e10> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  12
Best f1_score score: 0.6491429539953777
Generation:  48%|████▊     | 12/25 [20:43<25:19, 116.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fd1b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474738910> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c253c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.6491429539953777
Generation:  52%|█████▏    | 13/25 [21:16<18:17, 91.46s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659d3370> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.6491429539953777
Generation:  56%|█████▌    | 14/25 [21:51<13:37, 74.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ff4f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.6491429539953777
Generation:  60%|██████    | 15/25 [22:32<10:43, 64.33s/it]Generation:  16
Best f1_score score: 0.6491429539953777
Generation:  64%|██████▍   | 16/25 [23:15<08:41, 57.94s/it]Generation:  17
Best f1_score score: 0.6491429539953777
Generation:  68%|██████▊   | 17/25 [23:59<07:09, 53.68s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465160e80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.6491429539953777
Generation:  72%|███████▏  | 18/25 [24:32<05:30, 47.28s/it]Generation:  19
Best f1_score score: 0.6491429539953777
Generation:  76%|███████▌  | 19/25 [25:14<04:35, 45.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546578a020> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.6491429539953777
Generation:  80%|████████  | 20/25 [26:27<04:29, 53.98s/it]Generation:  21
Best f1_score score: 0.6491429539953777
Generation:  84%|████████▍ | 21/25 [27:44<04:03, 60.91s/it]Generation:  22
Best f1_score score: 0.6491429539953777
Generation:  88%|████████▊ | 22/25 [28:25<02:44, 54.98s/it]Generation:  23
Best f1_score score: 0.6491429539953777
Generation:  92%|█████████▏| 23/25 [29:26<01:53, 56.83s/it]Generation:  24
Best f1_score score: 0.6491429539953777
Generation:  96%|█████████▌| 24/25 [30:10<00:52, 52.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472f130> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.6491429539953777
Generation: 100%|██████████| 25/25 [30:55<00:00, 50.42s/it]Generation: 100%|██████████| 25/25 [30:59<00:00, 74.38s/it]
2024-11-09 02:02:56,164 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:46627' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-62a113fc7f084ef53fb4fefd025918c2', 'ndarray-d8b8a177c15b9d764d6c1db847317b9d'} (stimulus_id='handle-worker-cleanup-1731146576.1646698')
Fitted
Pipeline(steps=[('adaboostclassifier',
                 AdaBoostClassifier(algorithm='SAMME',
                                    learning_rate=0.4700003335981,
                                    n_estimators=281))])
score start
train score: {'auroc': 0.726118620397471, 'accuracy': 0.6679054054054054, 'balanced_accuracy': 0.6679180368508204, 'logloss': 0.6489948191198412, 'f1': 0.6677948422388569}
original test score: {'auroc': 0.6055927786573752, 'accuracy': 0.5378378378378378, 'balanced_accuracy': 0.537469936942909, 'logloss': 0.6821713018031299, 'f1': 0.5006274714086141}
imputed test score: {'auroc': 0.5722079477866103, 'accuracy': 0.5425675675675675, 'balanced_accuracy': 0.5425694714563029, 'logloss': 0.685016043332135, 'f1': 0.5425673587323587}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4a00> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d44100> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4c40> 

Generation:  1
Best f1_score score: 0.9461099867306894
Generation:   4%|▍         | 1/25 [10:02<4:01:04, 602.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745c6680> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.9518541001884492
Generation:   8%|▊         | 2/25 [10:39<1:43:30, 270.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d5a8c0> 

Generation:  3
Best f1_score score: 0.9518541001884492
Generation:  12%|█▏        | 3/25 [20:46<2:35:18, 423.58s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d5c040> 

Generation:  4
Best f1_score score: 0.9523599651636928
Generation:  16%|█▌        | 4/25 [30:52<2:53:28, 495.63s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f404e50> 

Generation:  5
Best f1_score score: 0.9523599651636928
Generation:  20%|██        | 5/25 [40:57<2:58:22, 535.14s/it]Generation:  6
Best f1_score score: 0.9523608247946905
Generation:  24%|██▍       | 6/25 [41:21<1:54:23, 361.22s/it]Generation:  7
Best f1_score score: 0.9528677940267292
Generation:  28%|██▊       | 7/25 [41:48<1:15:39, 252.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452a70580> 

Generation:  8
Best f1_score score: 0.9528677940267292
Generation:  32%|███▏      | 8/25 [51:53<1:43:14, 364.39s/it]Generation:  9
Best f1_score score: 0.9528677940267292
Generation:  36%|███▌      | 9/25 [52:23<1:09:20, 260.03s/it]Generation:  10
Best f1_score score: 0.9528677940267292
Generation:  40%|████      | 10/25 [53:54<51:57, 207.81s/it] WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456d32b60> 

Generation:  11
Best f1_score score: 0.9528677940267292
Generation:  44%|████▍     | 11/25 [1:04:01<1:16:59, 329.98s/it]Generation:  12
Best f1_score score: 0.9528677940267292
Generation:  48%|████▊     | 12/25 [1:04:27<51:24, 237.31s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d58580> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 589, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454a89180> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452d51990> 

Generation:  13
Best f1_score score: 0.9528677940267292
Generation:  52%|█████▏    | 13/25 [1:14:36<1:10:01, 350.15s/it]Generation:  14
Best f1_score score: 0.9528677940267292
Generation:  56%|█████▌    | 14/25 [1:14:59<46:04, 251.34s/it]  Generation:  15
Best f1_score score: 0.9528677940267292
Generation:  60%|██████    | 15/25 [1:15:25<30:32, 183.21s/it]Generation:  16
Best f1_score score: 0.9528677940267292
Generation:  64%|██████▍   | 16/25 [1:15:37<19:45, 131.68s/it]Generation:  17
Best f1_score score: 0.9528677940267292
Generation:  68%|██████▊   | 17/25 [1:18:57<20:17, 152.22s/it]Generation:  18
Best f1_score score: 0.9528677940267292
Generation:  72%|███████▏  | 18/25 [1:27:43<30:53, 264.72s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745dd480> 

Generation:  19
Best f1_score score: 0.9528677940267292
Generation:  76%|███████▌  | 19/25 [1:37:48<36:41, 366.85s/it]Generation:  20
Best f1_score score: 0.9528677940267292
Generation:  80%|████████  | 20/25 [1:42:26<28:20, 340.18s/it]Generation:  21
Best f1_score score: 0.9528677940267292
Generation:  84%|████████▍ | 21/25 [1:44:27<18:17, 274.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452d36ec0> 

Generation:  22
Best f1_score score: 0.9528677940267292
Generation:  88%|████████▊ | 22/25 [1:54:36<18:43, 374.64s/it]Generation:  23
Best f1_score score: 0.9528677940267292
Generation:  92%|█████████▏| 23/25 [1:54:59<08:58, 269.20s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456f96470> 

Generation:  24
Best f1_score score: 0.9528677940267292
Generation:  96%|█████████▌| 24/25 [2:05:07<06:10, 370.99s/it]Generation:  25
Best f1_score score: 0.9528677940267292
Generation: 100%|██████████| 25/25 [2:05:34<00:00, 267.74s/it]Generation: 100%|██████████| 25/25 [2:05:34<00:00, 301.39s/it]
2024-11-09 04:08:39,385 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36137' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-9629a5957f72f535442a82737bc87862', 'ndarray-d8b8a177c15b9d764d6c1db847317b9d'} (stimulus_id='handle-worker-cleanup-1731154119.3854723')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lineardiscriminantanalysis',
                 LinearDiscriminantAnalysis(shrinkage=0.9886350448134,
                                            solver='lsqr'))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9910671526055298, 'accuracy': 0.9521959459459459, 'balanced_accuracy': 0.952193299029081, 'logloss': 0.12070840252864268, 'f1': 0.9521949515533602}
test score: {'auroc': 0.9900273740456064, 'accuracy': 0.952027027027027, 'balanced_accuracy': 0.952035157113143, 'logloss': 0.12794109831973535, 'f1': 0.952025953831144}
original test score: {'auroc': 0.9975858246636681, 'accuracy': 0.9763513513513513, 'balanced_accuracy': 0.9763430904731382, 'logloss': 0.06343363431778841, 'f1': 0.9763500449029553}
score end
1507
lvl
0.3
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
10.656333254774411
hours
DONE
