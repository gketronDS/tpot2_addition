Run: 49
/cm/local/apps/slurm/var/spool/job1037759/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/881/881.pkl
working on 
../data/c/881/class_full_MCAR_0.01_3
2.0832784175872803
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-01 22:38:58,694] A new study created in memory with name: no-name-78063538-65a2-4e34-be3a-38dbcce166ed
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-01 22:38:59,354] Trial 1 finished with value: 0.5922511933305807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 1 with value: 0.5922511933305807.
running
[I 2024-11-01 22:38:59,784] Trial 0 finished with value: 0.3368953409269132 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.3368953409269132.
running
[I 2024-11-01 22:39:00,549] Trial 5 finished with value: 0.37566708688341377 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.3368953409269132.
running
[I 2024-11-01 22:39:00,821] Trial 7 finished with value: 0.5465568463232187 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3368953409269132.
running
[I 2024-11-01 22:39:01,020] Trial 14 finished with value: 0.5465568463232187 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3368953409269132.
running
[I 2024-11-01 22:39:35,377] Trial 3 finished with value: 0.30566421679563566 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 531, 'weights': 'uniform'}. Best is trial 3 with value: 0.30566421679563566.
running
[I 2024-11-01 22:39:46,070] Trial 11 finished with value: 0.3368953409269132 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30461, 'weights': 'uniform'}. Best is trial 3 with value: 0.30566421679563566.
running
[I 2024-11-01 22:39:52,762] Trial 16 finished with value: 0.3043498022507737 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 16 with value: 0.3043498022507737.
running
[I 2024-11-01 22:39:57,866] Trial 6 finished with value: 0.32488522950798704 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12431, 'weights': 'distance'}. Best is trial 16 with value: 0.3043498022507737.
running
[I 2024-11-01 22:40:01,096] Trial 10 finished with value: 0.3018375934902423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:01,868] Trial 9 finished with value: 0.4311004974313112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:06,661] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.2642724837069319, 'alpha': 71, 'iterations': 2, 'learning_rate': 0.02769094817109979, 'p_miss': 0.15757974017273438}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:07,497] Trial 23 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7952066429141251, 'alpha': 19, 'iterations': 5, 'learning_rate': 0.00790328046886979, 'p_miss': 0.16341072838606183}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:10,232] Trial 24 finished with value: 0.5571649539133136 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.13345045222173754, 'alpha': 43, 'iterations': 2, 'learning_rate': 0.06211293455802463, 'p_miss': 0.21805159229597362}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:15,126] Trial 4 finished with value: 0.5777561578956755 and parameters: {'model_name': 'GAIN', 'batch_size': 159, 'hint_rate': 0.18528246720418637, 'alpha': 100, 'iterations': 8, 'learning_rate': 0.04747655858584876, 'p_miss': 0.08200248845257593}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:30,320] Trial 18 finished with value: 0.5721499369545282 and parameters: {'model_name': 'GAIN', 'batch_size': 966, 'hint_rate': 0.3260440220133599, 'alpha': 26, 'iterations': 16, 'learning_rate': 0.0005423135506473578, 'p_miss': 0.15607174256292164}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:40:41,890] Trial 22 finished with value: 0.3069238950304771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:06,285] Trial 19 finished with value: 0.3185388237561409 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:07,263] Trial 15 finished with value: 0.3185388237561409 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:17,349] Trial 26 finished with value: 0.30499846400403896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:22,113] Trial 27 finished with value: 0.30499846400403896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:22,506] Trial 28 finished with value: 0.30499846400403896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:24,122] Trial 29 finished with value: 0.3039455715758087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:29,706] Trial 30 finished with value: 0.30499846400403896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:36,500] Trial 31 finished with value: 0.3039455715758087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:41:53,330] Trial 25 finished with value: 0.31779026547967787 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:43:17,886] Trial 13 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.318969474055798, 'alpha': 11, 'iterations': 763, 'learning_rate': 0.0003579853583521882, 'p_miss': 0.1423713406937712}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 22:44:06,378] Trial 2 finished with value: 0.5724244803768005 and parameters: {'model_name': 'GAIN', 'batch_size': 711, 'hint_rate': 0.2659396496809662, 'alpha': 43, 'iterations': 143, 'learning_rate': 0.0005475807931108964, 'p_miss': 0.11698195576532185}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 23:15:03,375] Trial 20 finished with value: 0.5915552030820661 and parameters: {'model_name': 'GAIN', 'batch_size': 100, 'hint_rate': 0.4198990527452931, 'alpha': 78, 'iterations': 1391, 'learning_rate': 0.0009614996275787157, 'p_miss': 0.2050688886495539}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-01 23:35:33,083] Trial 21 finished with value: 0.3380862827279895 and parameters: {'model_name': 'VAE', 'batch_size': 407, 'iterations': 994, 'learning_rate': 0.044228814511509854, 'p_miss': 0.11522029358604619}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-02 01:19:49,954] Trial 39 finished with value: 0.3413440732656738 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 2818, 'learning_rate': 0.00011176082062720626, 'p_miss': 0.016835543997160973}. Best is trial 10 with value: 0.3018375934902423.
running
[I 2024-11-02 01:45:44,790] Trial 8 finished with value: 0.28068646954411197 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 8 with value: 0.28068646954411197.
running
[I 2024-11-02 02:00:58,429] Trial 17 finished with value: 0.2794843844924745 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 03:20:25,097] Trial 41 finished with value: 0.34132350087276675 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 5025, 'learning_rate': 0.00014784068384418226, 'p_miss': 0.29575305748935565}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 03:29:38,296] Trial 46 finished with value: 0.2880923387726126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 04:07:41,243] Trial 47 finished with value: 0.28508457318761843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 04:11:35,783] Trial 40 finished with value: 0.33899217722610325 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 6552, 'learning_rate': 0.0001296823625123555, 'p_miss': 0.2882424478702376}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 04:55:02,248] Trial 48 finished with value: 0.2806431829825155 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 04:55:36,051] Trial 53 finished with value: 0.33248602649228287 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31739, 'weights': 'distance'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 05:30:18,047] Trial 44 finished with value: 0.3579432284564015 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8586, 'learning_rate': 0.00391089876370088, 'p_miss': 0.2982086820712399}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 05:31:12,105] Trial 45 finished with value: 0.3424855777454849 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6520, 'learning_rate': 0.00010275233154837948, 'p_miss': 0.024308271286213268}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 05:50:05,585] Trial 36 finished with value: 0.3402462487948522 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 7353, 'learning_rate': 0.0001046779679584676, 'p_miss': 0.2886328753351569}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:05:20,243] Trial 43 finished with value: 0.3390633101871284 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 8055, 'learning_rate': 0.003402620824476371, 'p_miss': 0.014086348969516355}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:12:16,849] Trial 49 finished with value: 0.2807597028883178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:22:52,928] Trial 50 finished with value: 0.28087551846131903 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:37:59,127] Trial 42 finished with value: 0.33932007292863015 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 9787, 'learning_rate': 0.00010034354906563402, 'p_miss': 0.29698346520650676}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:37:59,789] Trial 61 finished with value: 0.3368953409269132 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:41:58,398] Trial 37 finished with value: 0.3390009313350828 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 9621, 'learning_rate': 0.0001582840861124652, 'p_miss': 0.29229816851040913}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:49:43,985] Trial 35 finished with value: 0.3412161710860007 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 8726, 'learning_rate': 0.0001261974016912903, 'p_miss': 0.2874966719607791}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:49:46,558] Trial 34 finished with value: 0.33915946443817446 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 9411, 'learning_rate': 0.00017154747024604268, 'p_miss': 0.028964539351745783}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:50:21,151] Trial 32 finished with value: 0.3398501975924956 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 9557, 'learning_rate': 0.00014951723961236069, 'p_miss': 0.2883053155694635}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:51:06,015] Trial 33 finished with value: 0.34027522029958057 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 9238, 'learning_rate': 0.0001825987690711393, 'p_miss': 0.2966190383199774}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:51:49,226] Trial 38 finished with value: 0.33992489314301605 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 9787, 'learning_rate': 0.0001858031081743599, 'p_miss': 0.29985377338080343}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 06:57:46,229] Trial 51 finished with value: 0.2803643934946442 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 07:01:01,075] Trial 52 finished with value: 0.2810468550785387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 07:38:46,985] Trial 54 finished with value: 0.2807098139506561 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:09:27,875] Trial 55 finished with value: 0.2802692076332701 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:10:29,922] Trial 56 finished with value: 0.2800523066213505 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:10:56,377] Trial 73 finished with value: 0.3273509496715593 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16392, 'weights': 'distance'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:26:04,199] Trial 57 finished with value: 0.28048387098011 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:26:16,590] Trial 75 finished with value: 0.3070260808285088 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:40:25,494] Trial 58 finished with value: 0.2802509540831653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:46:37,790] Trial 59 finished with value: 0.2805334653134005 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 08:56:01,155] Trial 60 finished with value: 0.281072928354444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:10:25,112] Trial 62 finished with value: 0.28094260661865034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:10:25,347] Trial 80 finished with value: 0.5922511933305807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:14:08,001] Trial 63 finished with value: 0.280550529121103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:21:10,650] Trial 64 finished with value: 0.28051435195884905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:21:21,618] Trial 65 finished with value: 0.28042667417914924 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:21:55,355] Trial 66 finished with value: 0.2803332946910304 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:22:28,939] Trial 67 finished with value: 0.28051139208311493 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:23:08,177] Trial 68 finished with value: 0.2808973760194312 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:29:25,329] Trial 69 finished with value: 0.28035098931931246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:29:38,493] Trial 88 finished with value: 0.3070161613210008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 09:32:10,622] Trial 70 finished with value: 0.28057366697255953 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.2794843844924745.
running
[I 2024-11-02 10:28:49,401] Trial 71 finished with value: 0.2794622776597954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 10:29:36,619] Trial 91 finished with value: 0.43189106359772467 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 10:29:36,909] Trial 92 finished with value: 0.37566708688341377 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 10:29:39,516] Trial 93 finished with value: 0.5463872955249496 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9350921613600426, 'alpha': 100, 'iterations': 95, 'learning_rate': 0.013991518419597218, 'p_miss': 0.24232582976813927}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 10:30:02,444] Trial 94 finished with value: 0.3318974071486718 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18692, 'weights': 'uniform'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 10:59:44,659] Trial 72 finished with value: 0.2796750120079274 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:01:46,364] Trial 74 finished with value: 0.2795264044196205 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:16:30,140] Trial 76 finished with value: 0.2802936185904371 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:30:54,699] Trial 77 finished with value: 0.2798254487021262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:36:39,477] Trial 78 finished with value: 0.2796501003126123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:46:19,462] Trial 89 finished with value: 0.2823486066635736 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:46:48,119] Trial 79 finished with value: 0.2800332052389387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:47:05,077] Trial 101 finished with value: 0.3069541029379791 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 11:49:36,978] Trial 90 finished with value: 0.2817730757661025 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:01:01,484] Trial 81 finished with value: 0.2800041031379399 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:01:01,880] Trial 105 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.6203042397819086, 'alpha': 2, 'iterations': 30, 'learning_rate': 0.0017171990873991602, 'p_miss': 0.05466581351030933}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:04:24,577] Trial 82 finished with value: 0.28023218738811756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:11:29,115] Trial 84 finished with value: 0.2794720695011884 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:12:12,757] Trial 83 finished with value: 0.2798985353012774 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:12:29,993] Trial 85 finished with value: 0.27965379472623775 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:12:41,929] Trial 110 finished with value: 0.3070135644281452 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:13:30,361] Trial 86 finished with value: 0.2805506753183618 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:13:44,824] Trial 87 finished with value: 0.2803908956957435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:14:02,109] Trial 113 finished with value: 0.31467114087367565 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2091, 'weights': 'uniform'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 12:46:13,724] Trial 95 finished with value: 0.2825295121298624 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 13:15:12,349] Trial 96 finished with value: 0.283134419667166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 71 with value: 0.2794622776597954.
running
[I 2024-11-02 14:08:42,027] Trial 97 finished with value: 0.2791658925503285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 97 with value: 0.2791658925503285.
running
[I 2024-11-02 14:24:17,680] Trial 98 finished with value: 0.2793785868956403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 97 with value: 0.2791658925503285.
running
[I 2024-11-02 14:38:24,426] Trial 99 finished with value: 0.2796085839248859 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 97 with value: 0.2791658925503285.
running
[I 2024-11-02 14:44:08,249] Trial 100 finished with value: 0.2794887519388597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 97 with value: 0.2791658925503285.
running
[I 2024-11-02 14:44:50,652] Trial 120 finished with value: 0.3069541029379791 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 97 with value: 0.2791658925503285.
running
[I 2024-11-02 14:55:04,145] Trial 102 finished with value: 0.27892798042432254 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 14:55:04,385] Trial 122 finished with value: 0.3368953409269132 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 14:55:23,331] Trial 103 finished with value: 0.27900934188347515 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 14:57:45,718] Trial 104 finished with value: 0.2796846243249648 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:09:04,831] Trial 106 finished with value: 0.279225210892866 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:12:09,830] Trial 107 finished with value: 0.27931389121633404 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:19:55,636] Trial 108 finished with value: 0.2792080120843906 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:20:00,787] Trial 109 finished with value: 0.27924952276876985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:20:44,531] Trial 111 finished with value: 0.27907448776480803 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:21:18,180] Trial 112 finished with value: 0.2798920395611516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:21:57,579] Trial 131 finished with value: 0.3187727164424482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:22:05,721] Trial 132 finished with value: 0.5894586821495557 and parameters: {'model_name': 'GAIN', 'batch_size': 310, 'hint_rate': 0.5942090149189622, 'alpha': 65, 'iterations': 312, 'learning_rate': 0.007950795127358174, 'p_miss': 0.25788955288517645}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:22:06,167] Trial 114 finished with value: 0.27912391239496265 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 15:54:36,506] Trial 115 finished with value: 0.2793280783952023 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 16:22:57,713] Trial 116 finished with value: 0.27954138134058953 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 17:16:07,157] Trial 117 finished with value: 0.2797751143529237 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.27892798042432254.
running
[I 2024-11-02 17:32:14,899] Trial 118 finished with value: 0.27873670797888395 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 17:45:21,125] Trial 119 finished with value: 0.2789217348981473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 17:51:09,564] Trial 121 finished with value: 0.2792796197582956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:01:32,663] Trial 123 finished with value: 0.2790244353210356 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:02:42,970] Trial 124 finished with value: 0.2789354586023966 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:04:17,980] Trial 125 finished with value: 0.2788324901845221 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:15:34,418] Trial 126 finished with value: 0.27939582067401797 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:16:04,186] Trial 144 finished with value: 0.33191012814902743 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24045, 'weights': 'distance'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:19:13,623] Trial 127 finished with value: 0.27884787506640146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:25:58,254] Trial 128 finished with value: 0.2797511342366204 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:26:12,911] Trial 129 finished with value: 0.2800597287917459 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:26:23,410] Trial 130 finished with value: 0.2790081664785519 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:27:53,312] Trial 133 finished with value: 0.2827488590788604 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 18:28:21,965] Trial 134 finished with value: 0.2793212201859525 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:00:26,680] Trial 135 finished with value: 0.28251155209447243 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:00:37,766] Trial 152 finished with value: 0.30701358124614553 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:00:37,973] Trial 153 finished with value: 0.5922511933305807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:28:42,671] Trial 136 finished with value: 0.2827617637054464 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:29:21,797] Trial 155 finished with value: 0.31779026547967787 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 19:37:17,100] Trial 154 finished with value: 0.3295245100416074 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 20:20:22,444] Trial 137 finished with value: 0.279625145867959 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 20:36:20,006] Trial 138 finished with value: 0.27950363881717105 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 20:49:07,618] Trial 139 finished with value: 0.2795613479228757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 20:54:52,667] Trial 140 finished with value: 0.27930645472223603 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:05:34,155] Trial 141 finished with value: 0.2792657049236128 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:06:31,753] Trial 142 finished with value: 0.27944236060841077 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:08:14,355] Trial 143 finished with value: 0.28014401460441507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:19:45,863] Trial 145 finished with value: 0.27879201316585617 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:22:52,869] Trial 146 finished with value: 0.27925409123580797 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:29:20,691] Trial 147 finished with value: 0.2792471032082145 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:29:57,293] Trial 148 finished with value: 0.27892643363955016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:30:05,023] Trial 149 finished with value: 0.2795983300735609 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:31:27,592] Trial 150 finished with value: 0.27939162548843266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:32:10,796] Trial 170 finished with value: 0.4383847597759605 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:32:12,836] Trial 171 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9723421826295808, 'alpha': 31, 'iterations': 238, 'learning_rate': 0.09844191031313722, 'p_miss': 0.18212024764232126}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 21:32:18,830] Trial 151 finished with value: 0.2796559026025246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 22:35:59,055] Trial 156 finished with value: 0.27936312472809705 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 22:44:54,949] Trial 157 finished with value: 0.2796188173241509 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 23:29:02,881] Trial 158 finished with value: 0.2792290060913762 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 23:45:02,832] Trial 159 finished with value: 0.2798559611470007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-02 23:58:05,669] Trial 160 finished with value: 0.27946441622802276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:04:16,446] Trial 161 finished with value: 0.2799485449806323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:14:38,907] Trial 162 finished with value: 0.27916950961911374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:15:45,466] Trial 163 finished with value: 0.2791245558857585 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:17:06,559] Trial 164 finished with value: 0.2798349627257765 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:17:27,690] Trial 182 finished with value: 0.3209056607226802 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7422, 'weights': 'distance'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:28:40,794] Trial 165 finished with value: 0.27908656460798964 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:31:58,869] Trial 166 finished with value: 0.27894299956975954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:31:59,128] Trial 185 finished with value: 0.37566708688341377 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 118 with value: 0.27873670797888395.
running
[I 2024-11-03 00:38:43,804] Trial 167 finished with value: 0.27861771425710574 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 00:38:52,205] Trial 168 finished with value: 0.27968529333763237 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 00:39:10,686] Trial 169 finished with value: 0.27900721567231435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 00:41:20,606] Trial 173 finished with value: 0.27918059110641763 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 00:41:32,390] Trial 190 finished with value: 0.30701355439671363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 00:42:00,170] Trial 172 finished with value: 0.2796465236714103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:45:26,861] Trial 174 finished with value: 0.2794181691945007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:46:22,791] Trial 179 finished with value: 0.2871366943811982 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:47:04,509] Trial 194 finished with value: 0.3185388237561409 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:53:21,920] Trial 175 finished with value: 0.27878582775387695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:37:15,272] Trial 176 finished with value: 0.2795923058941501 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 01:52:32,324] Trial 177 finished with value: 0.279229774703287 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 02:05:09,102] Trial 193 finished with value: 0.29643062069588555 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
running
[I 2024-11-03 02:05:50,814] Trial 178 finished with value: 0.27934363012320185 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:23:06,312] Trial 180 finished with value: 0.27989187621383993 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:23:31,513] Trial 181 finished with value: 0.27894260994198583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:24:31,122] Trial 183 finished with value: 0.27914261618715486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:35:11,787] Trial 184 finished with value: 0.27934846483673254 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:38:39,350] Trial 186 finished with value: 0.27996589359108726 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:45:20,560] Trial 188 finished with value: 0.2791849212956727 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.27861771425710574.
[I 2024-11-03 02:45:48,297] Trial 187 finished with value: 0.27860117929060835 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 02:46:20,985] Trial 189 finished with value: 0.2792613443161694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 02:47:53,495] Trial 191 finished with value: 0.27946001451025393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 02:48:33,672] Trial 192 finished with value: 0.2796316175092047 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 03:51:54,407] Trial 195 finished with value: 0.279350461515761 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 03:58:34,050] Trial 196 finished with value: 0.28004798442893764 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 04:40:57,622] Trial 197 finished with value: 0.2792550240587186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 04:55:31,204] Trial 198 finished with value: 0.27940134282503837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
[I 2024-11-03 05:07:21,831] Trial 199 finished with value: 0.2791874877964352 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 187 with value: 0.27860117929060835.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.27860117929060835
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9949059131699312
Generation:   4%|▍         | 1/25 [00:54<21:45, 54.41s/it]Generation:  2
Best f1_score score: 0.9955434098403441
Generation:   8%|▊         | 2/25 [05:21<1:08:45, 179.38s/it]Generation:  3
Best f1_score score: 0.9970065591044571
Generation:  12%|█▏        | 3/25 [11:47<1:40:25, 273.89s/it]Generation:  4
Best f1_score score: 0.9970065591044571
Generation:  16%|█▌        | 4/25 [16:31<1:37:15, 277.89s/it]Generation:  5
Best f1_score score: 0.9970065591044571
Generation:  20%|██        | 5/25 [18:55<1:16:28, 229.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e2c6d0> 

Generation:  6
Best f1_score score: 0.9970065591044571
Generation:  24%|██▍       | 6/25 [29:22<1:55:31, 364.81s/it]Generation:  7
Best f1_score score: 0.9970065591044571
Generation:  28%|██▊       | 7/25 [35:38<1:50:30, 368.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469f4c0> 

Generation:  8
Best f1_score score: 0.9970065591044571
Generation:  32%|███▏      | 8/25 [46:08<2:07:57, 451.63s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f93f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fcb3a0> 

Generation:  9
Best f1_score score: 0.9970065591044571
Generation:  36%|███▌      | 9/25 [56:33<2:14:55, 506.00s/it]Generation:  10
Best f1_score score: 0.9972935157151317
Generation:  40%|████      | 10/25 [1:01:49<1:51:48, 447.22s/it]Generation:  11
Best f1_score score: 0.9972935157151317
Generation:  44%|████▍     | 11/25 [1:08:11<1:39:42, 427.30s/it]Generation:  12
Best f1_score score: 0.9972935157151317
Generation:  48%|████▊     | 12/25 [1:10:40<1:14:13, 342.55s/it]Generation:  13
Best f1_score score: 0.9972935157151317
Generation:  52%|█████▏    | 13/25 [1:11:24<50:26, 252.19s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467618580> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464d13b50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554649ea050> 

Generation:  14
Best f1_score score: 0.9972935157151317
Generation:  56%|█████▌    | 14/25 [1:22:07<1:07:52, 370.21s/it]Generation:  15
Best f1_score score: 0.9972935157151317
Generation:  60%|██████    | 15/25 [1:29:05<1:04:07, 384.71s/it]Generation:  16
Best f1_score score: 0.9972935157151317
Generation:  64%|██████▍   | 16/25 [1:30:50<45:03, 300.34s/it]  Generation:  17
Best f1_score score: 0.9972935157151317
Generation:  68%|██████▊   | 17/25 [1:35:29<39:11, 293.97s/it]Generation:  18
Best f1_score score: 0.9972935157151317
Generation:  72%|███████▏  | 18/25 [1:37:49<28:54, 247.84s/it]Generation:  19
Best f1_score score: 0.9972935157151317
Generation:  76%|███████▌  | 19/25 [1:39:26<20:15, 202.51s/it]Generation:  20
Best f1_score score: 0.9972935157151317
Generation:  80%|████████  | 20/25 [1:41:01<14:10, 170.19s/it]Generation:  21
Best f1_score score: 0.9972935157151317
Generation:  84%|████████▍ | 21/25 [1:42:28<09:41, 145.26s/it]Generation:  22
Best f1_score score: 0.9972935157151317
Generation:  88%|████████▊ | 22/25 [1:50:49<12:36, 252.08s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465030a00> 

Generation:  23
Best f1_score score: 0.9972935157151317
Generation:  92%|█████████▏| 23/25 [2:01:49<12:28, 374.22s/it]Generation:  24
Best f1_score score: 0.9972935157151317
Generation:  96%|█████████▌| 24/25 [2:03:18<04:48, 288.87s/it]Generation:  25
Best f1_score score: 0.9972935157151317
Generation: 100%|██████████| 25/25 [2:05:18<00:00, 238.21s/it]Generation: 100%|██████████| 25/25 [2:05:42<00:00, 301.72s/it]
2024-11-03 07:59:20,504 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45395' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-1fd77ef9f464d2839fb59e5ec4559c3e', 'ndarray-16205b9c29c2cbd81f55a3a14ad321d1'} (stimulus_id='handle-worker-cleanup-1730649560.5047596')
Fitted
Pipeline(steps=[('sgdclassifier',
                 SGDClassifier(alpha=0.0006689177656, class_weight='balanced',
                               eta0=0.4478860260243, l1_ratio=0.9807338589323,
                               loss='modified_huber', n_jobs=1,
                               penalty='elasticnet'))])
score start
train score: {'auroc': 0.9983489862560179, 'accuracy': 0.9970871404918134, 'balanced_accuracy': 0.9974233654169, 'logloss': 0.07159596673466274, 'f1': 0.9969769366207244}
original test score: {'auroc': 0.9997889712645976, 'accuracy': 0.9988962472406181, 'balanced_accuracy': 0.9990748355263157, 'logloss': 0.015717768836723392, 'f1': 0.998854032959646}
imputed test score: {'auroc': 0.9982021938989761, 'accuracy': 0.9970566593083149, 'balanced_accuracy': 0.997532894736842, 'logloss': 0.08218923571215343, 'f1': 0.9969463159802723}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014640>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4df0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469d060> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469cfd0> 

Generation:  1
Best f1_score score: 0.9942298931762711
Generation:   4%|▍         | 1/25 [10:03<4:01:21, 603.41s/it]Generation:  2
Best f1_score score: 0.9942298931762711
Generation:   8%|▊         | 2/25 [12:09<2:03:43, 322.77s/it]Generation:  3
Best f1_score score: 0.9942946523526267
Generation:  12%|█▏        | 3/25 [15:10<1:34:30, 257.74s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474a2c730> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fc6d0> 

Generation:  4
Best f1_score score: 0.9944218070555524
Generation:  16%|█▌        | 4/25 [25:16<2:18:22, 395.34s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546744e380> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0a0b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474735060> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d0a050> 

Generation:  5
Best f1_score score: 0.9944218070555524
Generation:  20%|██        | 5/25 [35:22<2:37:08, 471.42s/it]Generation:  6
Best f1_score score: 0.9944218070555524
Generation:  24%|██▍       | 6/25 [38:00<1:55:29, 364.70s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b3825f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554672c1990> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.9944218070555524
Generation:  28%|██▊       | 7/25 [38:48<1:18:24, 261.34s/it]Generation:  8
Best f1_score score: 0.9944218070555524
Generation:  32%|███▏      | 8/25 [39:24<53:42, 189.55s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e98d30> 

Generation:  9
Best f1_score score: 0.9956067975915583
Generation:  36%|███▌      | 9/25 [49:32<1:25:24, 320.27s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f05f60> 

Generation:  10
Best f1_score score: 0.9958940958166635
Generation:  40%|████      | 10/25 [59:40<1:42:17, 409.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466aef8e0> 

Generation:  11
Best f1_score score: 0.9958940958166635
Generation:  44%|████▍     | 11/25 [1:09:48<1:49:38, 469.90s/it]Generation:  12
Best f1_score score: 0.9959255397356976
Generation:  48%|████▊     | 12/25 [1:12:03<1:19:45, 368.13s/it]Generation:  13
Best f1_score score: 0.9959256359525327
Generation:  52%|█████▏    | 13/25 [1:12:55<54:26, 272.24s/it]  Generation:  14
Best f1_score score: 0.9959256359525327
Generation:  56%|█████▌    | 14/25 [1:17:30<50:05, 273.25s/it]Generation:  15
Best f1_score score: 0.9960210364327591
Generation:  60%|██████    | 15/25 [1:18:18<34:11, 205.18s/it]Generation:  16
Best f1_score score: 0.9960210364327591
Generation:  64%|██████▍   | 16/25 [1:22:27<32:45, 218.42s/it]Generation:  17
Best f1_score score: 0.9960211178381078
Generation:  68%|██████▊   | 17/25 [1:23:06<21:55, 164.43s/it]Generation:  18
Best f1_score score: 0.9960211178381078
Generation:  72%|███████▏  | 18/25 [1:23:46<14:50, 127.16s/it]Generation:  19
Best f1_score score: 0.9962444072615172
Generation:  76%|███████▌  | 19/25 [1:24:48<10:45, 107.63s/it]Generation:  20
Best f1_score score: 0.9963400619756617
Generation:  80%|████████  | 20/25 [1:25:36<07:28, 89.63s/it] Generation:  21
Best f1_score score: 0.9963400619756617
Generation:  84%|████████▍ | 21/25 [1:26:16<04:59, 74.86s/it]Generation:  22
Best f1_score score: 0.9963400619756617
Generation:  88%|████████▊ | 22/25 [1:28:11<04:20, 86.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747381f0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  23
Best f1_score score: 0.9963400619756617
Generation:  92%|█████████▏| 23/25 [1:28:55<02:27, 73.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554672a4670> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554672da830> 

Generation:  24
Best f1_score score: 0.9963716974812995
Generation:  96%|█████████▌| 24/25 [1:39:01<03:53, 233.66s/it]Generation:  25
Best f1_score score: 0.9963716974812995
Generation: 100%|██████████| 25/25 [1:41:22<00:00, 205.77s/it]Generation: 100%|██████████| 25/25 [1:41:22<00:00, 243.29s/it]
2024-11-03 09:41:14,932 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44513' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-16205b9c29c2cbd81f55a3a14ad321d1', 'DataFrame-18226a13a290db9848144399572abd18'} (stimulus_id='handle-worker-cleanup-1730655674.9325323')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=89)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(class_weight='balanced',
                                      criterion='entropy',
                                      max_features=0.9986847243927,
                                      min_samples_leaf=3, min_samples_split=3,
                                      n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9999960272777811, 'accuracy': 0.9982216226160544, 'balanced_accuracy': 0.9984480093847183, 'logloss': 0.006716365125721173, 'f1': 0.9981537782695834}
test score: {'auroc': 0.9989190791973284, 'accuracy': 0.9955849889624724, 'balanced_accuracy': 0.9959059050551912, 'logloss': 0.03861857032756364, 'f1': 0.9954185863580177}
original test score: {'auroc': 0.9999844399896016, 'accuracy': 0.9979151336767231, 'balanced_accuracy': 0.9978590300551912, 'logloss': 0.009572329970426233, 'f1': 0.9978345467019266}
score end
881
lvl
0.01
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
36.05024051600032
hours
DONE
