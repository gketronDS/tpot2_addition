Run: 49
/cm/local/apps/slurm/var/spool/job1044357/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1507/1507.pkl
working on 
../data/c/1507/class_full_MCAR_0.01_3
4.849290132522583
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-08 22:14:17,080] A new study created in memory with name: no-name-aaddce68-8258-4839-8048-2a446eedbf60
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-08 22:14:17,439] Trial 0 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5088229837913417.
running
[I 2024-11-08 22:14:17,848] Trial 14 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5088229837913417.
running
[I 2024-11-08 22:14:18,008] Trial 15 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5088229837913417.
running
[I 2024-11-08 22:14:18,256] Trial 11 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5088229837913417.
running
[I 2024-11-08 22:14:18,560] Trial 6 finished with value: 0.1362732615025094 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.1362732615025094.
[I 2024-11-08 22:14:18,684] Trial 12 finished with value: 0.1362732615025094 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.1362732615025094.
running
running
[I 2024-11-08 22:14:18,800] Trial 9 finished with value: 0.13634782107779944 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.1362732615025094.
running
[I 2024-11-08 22:14:19,130] Trial 18 finished with value: 0.13634782107779944 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.1362732615025094.
running
[I 2024-11-08 22:14:19,342] Trial 3 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 6 with value: 0.1362732615025094.
running
[I 2024-11-08 22:14:19,690] Trial 22 finished with value: 0.1362732615025094 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.1362732615025094.
running
[I 2024-11-08 22:14:20,063] Trial 21 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 6 with value: 0.1362732615025094.
running
[I 2024-11-08 22:14:23,967] Trial 4 finished with value: 0.12747992866934882 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 973, 'weights': 'distance'}. Best is trial 4 with value: 0.12747992866934882.
running
[I 2024-11-08 22:14:24,766] Trial 7 finished with value: 0.13060901169631398 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2590, 'weights': 'uniform'}. Best is trial 4 with value: 0.12747992866934882.
running
[I 2024-11-08 22:14:26,719] Trial 26 finished with value: 0.1285332264881892 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1745, 'weights': 'distance'}. Best is trial 4 with value: 0.12747992866934882.
running
[I 2024-11-08 22:14:29,230] Trial 20 finished with value: 0.16216681158243004 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.00028138386129663955, 'p_miss': 0.28117318999999785}. Best is trial 4 with value: 0.12747992866934882.
running
[I 2024-11-08 22:14:31,722] Trial 27 finished with value: 0.12731996379667457 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 835, 'weights': 'distance'}. Best is trial 27 with value: 0.12731996379667457.
running
[I 2024-11-08 22:14:32,111] Trial 28 finished with value: 0.12829704222678487 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1481, 'weights': 'uniform'}. Best is trial 27 with value: 0.12731996379667457.
running
[I 2024-11-08 22:14:34,633] Trial 17 finished with value: 0.3298040697809702 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.3224423104753555, 'alpha': 34, 'iterations': 4, 'learning_rate': 0.014838879685382458, 'p_miss': 0.2312467082362562}. Best is trial 27 with value: 0.12731996379667457.
running
[I 2024-11-08 22:14:35,614] Trial 29 finished with value: 0.12715467082556384 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 667, 'weights': 'distance'}. Best is trial 29 with value: 0.12715467082556384.
running
[I 2024-11-08 22:14:38,696] Trial 30 finished with value: 0.12719215178463333 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 704, 'weights': 'distance'}. Best is trial 29 with value: 0.12715467082556384.
running
[I 2024-11-08 22:14:39,475] Trial 31 finished with value: 0.12693839521594358 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 78, 'weights': 'distance'}. Best is trial 31 with value: 0.12693839521594358.
running
[I 2024-11-08 22:14:59,454] Trial 10 finished with value: 0.12981127133809572 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 31 with value: 0.12693839521594358.
running
[I 2024-11-08 22:15:01,970] Trial 34 finished with value: 0.13346421354676447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.12693839521594358.
running
[I 2024-11-08 22:15:08,082] Trial 5 finished with value: 0.1551448355149814 and parameters: {'model_name': 'VAE', 'batch_size': 230, 'iterations': 14, 'learning_rate': 0.00029295106699101225, 'p_miss': 0.2575388174859054}. Best is trial 31 with value: 0.12693839521594358.
[I 2024-11-08 22:15:08,254] Trial 38 finished with value: 0.13411085100941875 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9, 'weights': 'distance'}. Best is trial 31 with value: 0.12693839521594358.
running
running
[I 2024-11-08 22:15:09,734] Trial 37 finished with value: 0.1346460960740957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5007, 'weights': 'distance'}. Best is trial 31 with value: 0.12693839521594358.
running
[I 2024-11-08 22:15:17,935] Trial 40 finished with value: 0.12678575455652083 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 108, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:15:19,273] Trial 39 finished with value: 0.1346460960740957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4743, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:15:27,607] Trial 33 finished with value: 0.13061053697428499 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:15:51,698] Trial 25 finished with value: 0.3188232792528245 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.44461018859817353, 'alpha': 76, 'iterations': 129, 'learning_rate': 0.06941163545302051, 'p_miss': 0.2973409632101863}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:00,205] Trial 45 finished with value: 0.12807118261241685 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:09,307] Trial 46 finished with value: 0.129711872431742 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:21,716] Trial 47 finished with value: 0.127418820254588 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 910, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:30,306] Trial 16 finished with value: 0.14455125139550262 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 119, 'learning_rate': 0.0005508905405861467, 'p_miss': 0.21430962290138628}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:33,691] Trial 48 finished with value: 0.12722845525294071 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 720, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:42,137] Trial 49 finished with value: 0.12709696974717039 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 630, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:48,868] Trial 50 finished with value: 0.12951405203274854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2292, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:16:57,427] Trial 51 finished with value: 0.12886173194186284 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1941, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:02,690] Trial 52 finished with value: 0.1338568892775939 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3708, 'weights': 'uniform'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:10,417] Trial 8 finished with value: 0.1292239515784502 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:31,016] Trial 36 finished with value: 0.13054557218562235 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:41,094] Trial 56 finished with value: 0.1270404680150024 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 579, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:48,726] Trial 1 finished with value: 0.1897570156216948 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:17:50,235] Trial 57 finished with value: 0.1268812050282037 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 437, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:18:23,118] Trial 23 finished with value: 0.3205144880904224 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.30170827315562443, 'alpha': 90, 'iterations': 397, 'learning_rate': 0.0033555478281950403, 'p_miss': 0.2837464088327788}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:18:28,696] Trial 60 finished with value: 0.1268426604223198 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 397, 'weights': 'distance'}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:18:54,261] Trial 24 finished with value: 0.36862342624199707 and parameters: {'model_name': 'GAIN', 'batch_size': 494, 'hint_rate': 0.10375074180375055, 'alpha': 25, 'iterations': 143, 'learning_rate': 0.0500656305103836, 'p_miss': 0.2462312378227115}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:19:16,508] Trial 19 finished with value: 0.1394632046285325 and parameters: {'model_name': 'VAE', 'batch_size': 513, 'iterations': 82, 'learning_rate': 0.07871358607868235, 'p_miss': 0.2246686154846689}. Best is trial 40 with value: 0.12678575455652083.
running
[I 2024-11-08 22:19:22,531] Trial 63 finished with value: 0.12671145719046278 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 226, 'weights': 'distance'}. Best is trial 63 with value: 0.12671145719046278.
running
[I 2024-11-08 22:19:29,913] Trial 64 finished with value: 0.12789605611054472 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1309, 'weights': 'distance'}. Best is trial 63 with value: 0.12671145719046278.
running
[I 2024-11-08 22:19:36,142] Trial 65 finished with value: 0.12668490893095288 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 214, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 22:19:42,297] Trial 66 finished with value: 0.12672891150707075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 249, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 22:19:47,853] Trial 67 finished with value: 0.12681466655615692 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 355, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 22:19:54,028] Trial 68 finished with value: 0.12675564276960918 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 308, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 23:08:38,701] Trial 13 finished with value: 0.1419448210118797 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 1569, 'learning_rate': 0.0009242145483455583, 'p_miss': 0.08862877859188512}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 23:08:46,967] Trial 70 finished with value: 0.127800883226522 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1248, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-08 23:13:38,851] Trial 35 finished with value: 0.13748457078569962 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:02:28,465] Trial 32 finished with value: 0.35285683283552505 and parameters: {'model_name': 'GAIN', 'batch_size': 630, 'hint_rate': 0.503331892360528, 'alpha': 0, 'iterations': 4171, 'learning_rate': 0.07456284355605389, 'p_miss': 0.046409601385348845}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:16,439] Trial 73 finished with value: 0.14127936067759023 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 14, 'learning_rate': 0.003801036686876931, 'p_miss': 0.15287904118703258}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:22,915] Trial 74 finished with value: 0.13634782107779944 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5918, 'weights': 'uniform'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:29,610] Trial 75 finished with value: 0.1267853966436016 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 332, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:36,210] Trial 76 finished with value: 0.12675882579268688 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 318, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:42,363] Trial 77 finished with value: 0.12674713301685453 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 303, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:49,961] Trial 78 finished with value: 0.12757375184292447 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1037, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:03:56,410] Trial 79 finished with value: 0.1268393887241605 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 367, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:04:05,761] Trial 80 finished with value: 0.1315636590304909 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3213, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:31:59,295] Trial 2 finished with value: 0.1288007153638963 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 17, 'imputation_order': 'roman'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:11,028] Trial 55 finished with value: 0.35313233326046733 and parameters: {'model_name': 'GAIN', 'batch_size': 467, 'hint_rate': 0.9657603763941198, 'alpha': 0, 'iterations': 5615, 'learning_rate': 0.0033331456508975386, 'p_miss': 0.026056016344792737}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:14,966] Trial 83 finished with value: 0.16216717149743737 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 1, 'learning_rate': 0.00010209352710568839, 'p_miss': 0.1570786858348454}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:22,660] Trial 84 finished with value: 0.12756992459072392 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1036, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:28,286] Trial 85 finished with value: 0.12694558623190513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 452, 'weights': 'uniform'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:35,378] Trial 86 finished with value: 0.12674582752265795 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 289, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:41,814] Trial 87 finished with value: 0.1267365441380618 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 255, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:48,042] Trial 88 finished with value: 0.12678811582691057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 335, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:39:55,490] Trial 89 finished with value: 0.12732071836646042 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 831, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:40:01,533] Trial 90 finished with value: 0.12672083877277376 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 237, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:40:02,017] Trial 91 finished with value: 0.13634782107779944 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:40:09,752] Trial 92 finished with value: 0.12713140189145247 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 653, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:40:14,348] Trial 93 finished with value: 0.13802939848879597 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:40:21,685] Trial 94 finished with value: 0.12747997706440134 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 976, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:44:31,131] Trial 95 finished with value: 0.13921749204852013 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:44:37,845] Trial 96 finished with value: 0.12677011213340578 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 261, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:44:44,595] Trial 97 finished with value: 0.12672858629635161 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 232, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:44:51,462] Trial 98 finished with value: 0.12706772361613175 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 604, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:44:58,215] Trial 99 finished with value: 0.12672858629635161 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 232, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:48:18,546] Trial 100 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9409823337845791, 'alpha': 63, 'iterations': 805, 'learning_rate': 0.01623694672164164, 'p_miss': 0.1208504987952702}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:48:24,440] Trial 101 finished with value: 0.12678084919116164 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 126, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:49:37,826] Trial 102 finished with value: 0.14069353552510538 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 17, 'learning_rate': 0.01165135497552098, 'p_miss': 0.18411089638782813}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:49:43,886] Trial 103 finished with value: 0.12669726111454951 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 155, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:49:48,479] Trial 104 finished with value: 0.13205880408180465 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11, 'weights': 'uniform'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:49:49,980] Trial 105 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:49:56,792] Trial 106 finished with value: 0.127067276440958 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 598, 'weights': 'distance'}. Best is trial 65 with value: 0.12668490893095288.
running
[I 2024-11-09 00:50:02,927] Trial 107 finished with value: 0.1266776966718313 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 191, 'weights': 'distance'}. Best is trial 107 with value: 0.1266776966718313.
running
[I 2024-11-09 00:50:08,932] Trial 108 finished with value: 0.12666436150408883 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 174, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:50:13,441] Trial 109 finished with value: 0.14842375118919898 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:50:20,956] Trial 110 finished with value: 0.12727576163980087 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 782, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:50:27,336] Trial 111 finished with value: 0.12667969550796068 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 196, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:50:34,277] Trial 112 finished with value: 0.12699684153127166 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 550, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:51:43,923] Trial 113 finished with value: 0.1402042533324523 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'ascending'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:51:49,862] Trial 114 finished with value: 0.1266993535800542 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 148, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:51:55,721] Trial 115 finished with value: 0.1266873941123626 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 152, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:52:01,575] Trial 116 finished with value: 0.12669562746496416 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 153, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:52:07,258] Trial 117 finished with value: 0.12682603938542122 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 117, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:52:14,151] Trial 118 finished with value: 0.12698626142100192 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 531, 'weights': 'distance'}. Best is trial 108 with value: 0.12666436150408883.
running
[I 2024-11-09 00:52:20,638] Trial 119 finished with value: 0.12666008280686447 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 159, 'weights': 'distance'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:52:25,912] Trial 120 finished with value: 0.13079243664578774 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14, 'weights': 'distance'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:52:37,479] Trial 121 finished with value: 0.34622800741405035 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.6982613398970572, 'alpha': 99, 'iterations': 6, 'learning_rate': 0.0013964875448871305, 'p_miss': 0.07348090103351977}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:52:44,649] Trial 122 finished with value: 0.12727154285165274 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 772, 'weights': 'distance'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:52:51,257] Trial 123 finished with value: 0.12695159545611878 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 510, 'weights': 'distance'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:52:59,568] Trial 124 finished with value: 0.1285752739035785 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1772, 'weights': 'distance'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:53:05,084] Trial 125 finished with value: 0.12669072018307653 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 163, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:53:10,755] Trial 126 finished with value: 0.12669667605216112 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 149, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:53:15,895] Trial 127 finished with value: 0.12671583569267345 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 144, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:53:21,138] Trial 128 finished with value: 0.12693986461584533 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 456, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 00:53:26,459] Trial 129 finished with value: 0.12670114916216182 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 152, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:16:33,851] Trial 58 finished with value: 0.3566790700440072 and parameters: {'model_name': 'GAIN', 'batch_size': 832, 'hint_rate': 0.912255394734286, 'alpha': 0, 'iterations': 5446, 'learning_rate': 0.002942296180372186, 'p_miss': 0.07433929762852111}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:34,252] Trial 131 finished with value: 0.1609171332648285 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 30, 'learning_rate': 0.00011074755279658733, 'p_miss': 0.0116628557863806}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:39,663] Trial 132 finished with value: 0.12673735607904915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 132, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:44,796] Trial 133 finished with value: 0.12694397556722384 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 466, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:46,235] Trial 134 finished with value: 0.5088229837913417 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:50,711] Trial 135 finished with value: 0.18558158747726508 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:18:58,440] Trial 136 finished with value: 0.13566423255625926 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4295, 'weights': 'uniform'}. Best is trial 119 with value: 0.12666008280686447.
running
[I 2024-11-09 01:19:04,121] Trial 137 finished with value: 0.12665041775939398 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 167, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:19:10,655] Trial 138 finished with value: 0.1268928929916398 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 412, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:19:16,232] Trial 139 finished with value: 0.12669151771217635 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 162, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:19:24,429] Trial 140 finished with value: 0.13140722597111593 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2890, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:19:30,507] Trial 141 finished with value: 0.1268928929916398 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 412, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:19:36,553] Trial 142 finished with value: 0.12726008683685536 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 693, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:39:09,878] Trial 72 finished with value: 0.14033641641272845 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 3082, 'learning_rate': 0.004106725107880503, 'p_miss': 0.03307780731028105}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:09,023] Trial 44 finished with value: 0.35171446234983217 and parameters: {'model_name': 'GAIN', 'batch_size': 544, 'hint_rate': 0.9692959356908888, 'alpha': 98, 'iterations': 7687, 'learning_rate': 0.08129785752580976, 'p_miss': 0.015551151250023959}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:35,838] Trial 145 finished with value: 0.14833167748374768 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:41,072] Trial 146 finished with value: 0.12671087848152476 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 147, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:46,313] Trial 147 finished with value: 0.12666536859261873 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 178, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:51,607] Trial 148 finished with value: 0.1266723447876866 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 159, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:40:57,166] Trial 149 finished with value: 0.1268380365962129 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 344, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:03,017] Trial 150 finished with value: 0.1267217898694028 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 211, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:09,010] Trial 151 finished with value: 0.12693510000967323 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 439, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:14,736] Trial 152 finished with value: 0.12677673229484335 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 302, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:22,732] Trial 153 finished with value: 0.12967381783465032 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2201, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:28,077] Trial 154 finished with value: 0.12677084375414255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 128, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:34,414] Trial 155 finished with value: 0.1271665966351553 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 639, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:40,148] Trial 156 finished with value: 0.12671448566262716 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 143, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:46,549] Trial 157 finished with value: 0.12672341270155368 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 235, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:53,767] Trial 158 finished with value: 0.12681824254462593 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 358, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:41:58,133] Trial 159 finished with value: 0.15906958164588064 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:04,211] Trial 160 finished with value: 0.12669558454415036 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 146, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:10,725] Trial 161 finished with value: 0.1269119500466565 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 480, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:16,780] Trial 162 finished with value: 0.12676076625308974 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 258, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:17,136] Trial 163 finished with value: 0.13634782107779944 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:22,616] Trial 164 finished with value: 0.12681642597620282 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 101, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:29,768] Trial 165 finished with value: 0.12739362781366512 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 879, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:35,818] Trial 166 finished with value: 0.12667792778364403 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 151, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:42,326] Trial 167 finished with value: 0.12681048303473516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 352, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:49,496] Trial 168 finished with value: 0.12667828895592298 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 204, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:42:56,121] Trial 169 finished with value: 0.12672913824527 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 248, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:43:02,962] Trial 170 finished with value: 0.12703980246556595 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 572, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:43:08,711] Trial 171 finished with value: 0.12690405187744008 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 83, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:43:14,917] Trial 172 finished with value: 0.12683292259634607 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 365, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:44:44,334] Trial 173 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7262316964360664, 'alpha': 50, 'iterations': 364, 'learning_rate': 0.028003058687048634, 'p_miss': 0.11326702604317226}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:44:50,370] Trial 174 finished with value: 0.1267640618373053 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 255, 'weights': 'uniform'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:48:16,005] Trial 53 finished with value: 0.3533610055864477 and parameters: {'model_name': 'GAIN', 'batch_size': 616, 'hint_rate': 0.9608290704360141, 'alpha': 10, 'iterations': 7901, 'learning_rate': 0.003484995916321216, 'p_miss': 0.019231897063709646}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:48:21,450] Trial 176 finished with value: 0.12678575455652083 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 108, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:48:28,008] Trial 177 finished with value: 0.12666436150408883 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 174, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:48:32,591] Trial 178 finished with value: 0.18558158747726508 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 01:48:40,203] Trial 179 finished with value: 0.12691922711181047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 486, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 02:05:28,287] Trial 41 finished with value: 0.3515970602273135 and parameters: {'model_name': 'GAIN', 'batch_size': 888, 'hint_rate': 0.9657495657988746, 'alpha': 81, 'iterations': 6628, 'learning_rate': 0.08725741112278895, 'p_miss': 0.01833139148401841}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 02:23:37,951] Trial 54 finished with value: 0.355301409605293 and parameters: {'model_name': 'GAIN', 'batch_size': 867, 'hint_rate': 0.9587100822455041, 'alpha': 1, 'iterations': 7379, 'learning_rate': 0.003092489270437029, 'p_miss': 0.03108162207136013}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 02:33:23,446] Trial 62 finished with value: 0.14048425660416192 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 5669, 'learning_rate': 0.0021698351946755723, 'p_miss': 0.047232799187444344}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 02:33:33,720] Trial 183 finished with value: 0.1346460960740957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5449, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 02:38:11,784] Trial 59 finished with value: 0.35359489877859407 and parameters: {'model_name': 'GAIN', 'batch_size': 708, 'hint_rate': 0.9095124405917132, 'alpha': 2, 'iterations': 8328, 'learning_rate': 0.00268405618841463, 'p_miss': 0.014596667968779925}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:05:52,425] Trial 69 finished with value: 0.14001270817891034 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 5953, 'learning_rate': 0.002017391007418338, 'p_miss': 0.031168974311448536}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:05:58,660] Trial 186 finished with value: 0.12667425944378247 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 193, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:06:05,043] Trial 187 finished with value: 0.12672285887756907 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 228, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:06:11,787] Trial 188 finished with value: 0.12681630981058717 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 357, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:14,916] Trial 143 finished with value: 0.12917500531538417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:20,977] Trial 190 finished with value: 0.12665055968738353 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 178, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:26,809] Trial 191 finished with value: 0.12669321081124493 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 207, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:33,253] Trial 192 finished with value: 0.12677135521645316 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 269, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:40,134] Trial 193 finished with value: 0.12684610547619174 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 401, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:45,738] Trial 194 finished with value: 0.12690915997083166 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 80, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:52,563] Trial 195 finished with value: 0.12702504474197857 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 559, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:23:58,932] Trial 196 finished with value: 0.12671177091315014 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 209, 'weights': 'distance'}. Best is trial 137 with value: 0.12665041775939398.
running
[I 2024-11-09 03:24:04,966] Trial 197 finished with value: 0.1266491624524284 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 179, 'weights': 'distance'}. Best is trial 197 with value: 0.1266491624524284.
running
[I 2024-11-09 03:24:11,096] Trial 198 finished with value: 0.12677708473017393 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 330, 'weights': 'distance'}. Best is trial 197 with value: 0.1266491624524284.
running
[I 2024-11-09 03:24:16,338] Trial 199 finished with value: 0.12698742650411238 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 75, 'weights': 'distance'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 03:27:56,579] Trial 71 finished with value: 0.1403580330298339 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 5941, 'learning_rate': 0.00011541712061754764, 'p_miss': 0.012512959087222802}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 03:41:59,471] Trial 42 finished with value: 0.3537754608382451 and parameters: {'model_name': 'GAIN', 'batch_size': 950, 'hint_rate': 0.9683539697794783, 'alpha': 100, 'iterations': 9311, 'learning_rate': 0.06452556743301498, 'p_miss': 0.025490293655831137}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 03:43:52,099] Trial 180 finished with value: 0.13016502351526904 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 03:47:03,561] Trial 43 finished with value: 0.3497468210950836 and parameters: {'model_name': 'GAIN', 'batch_size': 853, 'hint_rate': 0.9893204435306292, 'alpha': 99, 'iterations': 9884, 'learning_rate': 0.04721040503893974, 'p_miss': 0.030441117394861356}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 03:51:08,961] Trial 81 finished with value: 0.14081479390850088 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 6970, 'learning_rate': 0.00010339086078295094, 'p_miss': 0.15297084507314737}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:00:20,081] Trial 82 finished with value: 0.1404726911789426 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 7869, 'learning_rate': 0.00011259636791975414, 'p_miss': 0.1557789912533932}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:05:35,726] Trial 130 finished with value: 0.14027374957498637 and parameters: {'model_name': 'VAE', 'batch_size': 178, 'iterations': 9832, 'learning_rate': 0.007447172003595839, 'p_miss': 0.11182782300522714}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:07:34,650] Trial 144 finished with value: 0.1290360904214126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 20, 'imputation_order': 'arabic'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:12:14,339] Trial 175 finished with value: 0.12855571499535584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:16:10,450] Trial 61 finished with value: 0.13959504921593108 and parameters: {'model_name': 'VAE', 'batch_size': 817, 'iterations': 9433, 'learning_rate': 0.09173297252083959, 'p_miss': 0.013287806065961028}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:24:16,794] Trial 185 finished with value: 0.1300902832800315 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:31:43,069] Trial 181 finished with value: 0.12912298976098047 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:46:02,719] Trial 182 finished with value: 0.1287856572100617 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 04:54:04,865] Trial 184 finished with value: 0.1288836867766358 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
[I 2024-11-09 05:17:59,921] Trial 189 finished with value: 0.12865971467782408 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 20, 'imputation_order': 'descending'}. Best is trial 197 with value: 0.1266491624524284.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.1266491624524284
{'model_name': 'KNNImputer', 'n_neighbors': 179, 'weights': 'distance'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9782091342257218
Generation:   4%|         | 1/25 [01:27<35:02, 87.59s/it]Generation:  2
Best f1_score score: 0.9782091342257218
Generation:   8%|         | 2/25 [04:15<51:38, 134.72s/it]Generation:  3
Best f1_score score: 0.9782091342257218
Generation:  12%|        | 3/25 [04:34<30:02, 81.94s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f40a0> 
 shrinkage not supported with 'svd' solver. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 629, in fit
    raise NotImplementedError("shrinkage not supported with 'svd' solver.")
NotImplementedError: shrinkage not supported with 'svd' solver.

Generation:  4
Best f1_score score: 0.9782091342257218
Generation:  16%|        | 4/25 [05:35<25:50, 73.81s/it]Generation:  5
Best f1_score score: 0.9782091342257218
Generation:  20%|        | 5/25 [06:15<20:29, 61.48s/it]Generation:  6
Best f1_score score: 0.9782091342257218
Generation:  24%|       | 6/25 [07:09<18:40, 58.98s/it]Generation:  7
Best f1_score score: 0.9782091342257218
Generation:  28%|       | 7/25 [07:49<15:47, 52.64s/it]Generation:  8
Best f1_score score: 0.9787159773878991
Generation:  32%|      | 8/25 [08:07<11:50, 41.79s/it]Generation:  9
Best f1_score score: 0.9787159773878991
Generation:  36%|      | 9/25 [09:22<13:52, 52.00s/it]Generation:  10
Best f1_score score: 0.9787159773878991
Generation:  40%|      | 10/25 [11:02<16:44, 66.98s/it]Generation:  11
Best f1_score score: 0.9787159773878991
Generation:  44%|     | 11/25 [11:32<12:57, 55.56s/it]Generation:  12
Best f1_score score: 0.9787159773878991
Generation:  48%|     | 12/25 [12:11<10:56, 50.51s/it]Generation:  13
Best f1_score score: 0.9787159773878991
Generation:  52%|    | 13/25 [14:44<16:18, 81.52s/it]Generation:  14
Best f1_score score: 0.9787159773878991
Generation:  56%|    | 14/25 [15:07<11:42, 63.87s/it]Generation:  15
Best f1_score score: 0.9787159773878991
Generation:  60%|    | 15/25 [17:49<15:35, 93.58s/it]Generation:  16
Best f1_score score: 0.9787159773878991
Generation:  64%|   | 16/25 [18:42<12:13, 81.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ae5f90> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  17
Best f1_score score: 0.9787159773878991
Generation:  68%|   | 17/25 [24:09<20:40, 155.04s/it]Generation:  18
Best f1_score score: 0.9787159773878991
Generation:  72%|  | 18/25 [25:06<14:38, 125.55s/it]Generation:  19
Best f1_score score: 0.9787159773878991
Generation:  76%|  | 19/25 [25:54<10:13, 102.30s/it]Generation:  20
Best f1_score score: 0.9795605226953524
Generation:  80%|  | 20/25 [26:21<06:38, 79.72s/it] Generation:  21
Best f1_score score: 0.9795605226953524
Generation:  84%| | 21/25 [26:58<04:27, 66.88s/it]Generation:  22
Best f1_score score: 0.9795605226953524
Generation:  88%| | 22/25 [28:02<03:17, 65.96s/it]Generation:  23
Best f1_score score: 0.9795605226953524
Generation:  92%|| 23/25 [28:37<01:53, 56.70s/it]Generation:  24
Best f1_score score: 0.9795605226953524
Generation:  96%|| 24/25 [29:33<00:56, 56.59s/it]Generation:  25
Best f1_score score: 0.9795605226953524
Generation: 100%|| 25/25 [30:13<00:00, 51.67s/it]Generation: 100%|| 25/25 [30:17<00:00, 72.68s/it]
2024-11-09 05:48:28,788 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42995' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-d8b8a177c15b9d764d6c1db847317b9d', 'ndarray-ce31ba54acd5fe168ac8c887a25f86e0'} (stimulus_id='handle-worker-cleanup-1731160108.7886949')
Fitted
Pipeline(steps=[('svc',
                 SVC(C=4032.3675650059977, class_weight='balanced',
                     gamma=0.0098239903595, max_iter=3000, probability=True,
                     shrinking=False))])
score start
train score: {'auroc': 0.9980315230238874, 'accuracy': 0.98125, 'balanced_accuracy': 0.9812491924987183, 'logloss': 0.05647828338403984, 'f1': 0.9812499352641688}
original test score: {'auroc': 0.9976515662008149, 'accuracy': 0.9743243243243244, 'balanced_accuracy': 0.9743279297442107, 'logloss': 0.06094317874446763, 'f1': 0.9743242774365914}
imputed test score: {'auroc': 0.9976095646631933, 'accuracy': 0.972972972972973, 'balanced_accuracy': 0.9729802282327031, 'logloss': 0.06188415680992891, 'f1': 0.9729725287669082}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9782091265138991
Generation:   4%|         | 1/25 [01:14<29:58, 74.92s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d21f00> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745a1090> 

Generation:  2
Best f1_score score: 0.9782091265138991
Generation:   8%|         | 2/25 [11:19<2:28:09, 386.49s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554550fff40> 

Generation:  3
Best f1_score score: 0.9782091265138991
Generation:  12%|        | 3/25 [21:24<2:58:14, 486.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554382e8d90> 

Generation:  4
Best f1_score score: 0.9782091342257218
Generation:  16%|        | 4/25 [31:28<3:06:28, 532.78s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454df6770> 

Generation:  5
Best f1_score score: 0.9782091342257218
Generation:  20%|        | 5/25 [41:33<3:06:15, 558.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474599330> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.9782091342257218
Generation:  24%|       | 6/25 [42:06<2:00:21, 380.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547427c2e0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.9782091342257218
Generation:  28%|       | 7/25 [43:46<1:26:33, 288.56s/it]Generation:  8
Best f1_score score: 0.9782091342257218
Generation:  32%|      | 8/25 [48:51<1:23:13, 293.75s/it]Generation:  9
Best f1_score score: 0.9782091342257218
Generation:  36%|      | 9/25 [49:54<59:03, 221.48s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b934160> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  10
Best f1_score score: 0.9782091342257218
Generation:  40%|      | 10/25 [50:13<39:44, 158.99s/it]Generation:  11
Best f1_score score: 0.9782091342257218
Generation:  44%|     | 11/25 [50:50<28:23, 121.65s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fbc3e80> 

Generation:  12
Best f1_score score: 0.9782091342257218
Generation:  48%|     | 12/25 [1:00:57<58:21, 269.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b91b130> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554552a3700> 

Generation:  13
Best f1_score score: 0.9782091342257218
Generation:  52%|    | 13/25 [1:11:04<1:14:21, 371.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452b60340> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.9782091342257218
Generation:  56%|    | 14/25 [1:11:37<49:22, 269.35s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545c7d57e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452eb4df0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d59900> 

Generation:  15
Best f1_score score: 0.9783779742168062
Generation:  60%|    | 15/25 [1:21:46<1:01:57, 371.75s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459e10040> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15532fd39120> 

Generation:  16
Best f1_score score: 0.9783780416974199
Generation:  64%|   | 16/25 [1:31:58<1:06:35, 443.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454df6bf0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545e436050> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ca1b040> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547459b4c0> 

Generation:  17
Best f1_score score: 0.9783780416974199
Generation:  68%|   | 17/25 [1:42:07<1:05:50, 493.83s/it]Generation:  18
Best f1_score score: 0.9783780416974199
Generation:  72%|  | 18/25 [1:42:58<42:04, 360.65s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc11a80> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  19
Best f1_score score: 0.9783780416974199
Generation:  76%|  | 19/25 [1:43:30<26:11, 261.95s/it]Generation:  20
Best f1_score score: 0.9783780416974199
Generation:  80%|  | 20/25 [1:44:18<16:28, 197.74s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452d10cd0> 

Generation:  21
Best f1_score score: 0.9783780416974199
Generation:  84%| | 21/25 [1:54:24<21:21, 320.34s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545a00dff0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554741a4640> 

Generation:  22
Best f1_score score: 0.9783780416974199
Generation:  88%| | 22/25 [2:04:35<20:21, 407.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745c7220> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459940940> 

Generation:  23
Best f1_score score: 0.9783780416974199
Generation:  92%|| 23/25 [2:14:40<15:33, 466.84s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554529c4970> 

Generation:  24
Best f1_score score: 0.9783780416974199
Generation:  96%|| 24/25 [2:24:46<08:28, 508.65s/it]Generation:  25
Best f1_score score: 0.9783780416974199
Generation: 100%|| 25/25 [2:25:16<00:00, 365.04s/it]Generation: 100%|| 25/25 [2:25:16<00:00, 348.68s/it]
2024-11-09 08:13:56,067 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35145' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-d8b8a177c15b9d764d6c1db847317b9d', 'DataFrame-6b0f19feecfb8916a549f0f7ff444dbd'} (stimulus_id='handle-worker-cleanup-1731168836.0673945')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=7, weights='distance')),
                ('gaussiannb', GaussianNB())])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.997803824782608, 'accuracy': 0.9787162162162162, 'balanced_accuracy': 0.9787143803480554, 'logloss': 0.05877503951928153, 'f1': 0.9787159732922445}
test score: {'auroc': 0.9976241738936703, 'accuracy': 0.977027027027027, 'balanced_accuracy': 0.977026985074845, 'logloss': 0.06247385781662391, 'f1': 0.977026985074845}
original test score: {'auroc': 0.9976625231236727, 'accuracy': 0.9777027027027027, 'balanced_accuracy': 0.9776999227536939, 'logloss': 0.061515417552005194, 'f1': 0.9777024482109228}
score end
1507
lvl
0.01
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
9.998454970518749
hours
DONE
