Run: 11
/cm/local/apps/slurm/var/spool/job1032365/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/871/871.pkl
working on 
../data/c/871/class_full_MNAR_0.3_1
3.917767286300659
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-30 07:47:49,604] A new study created in memory with name: no-name-f5e04e8f-041e-41ce-b702-c99816fc0e21
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-30 07:47:49,818] Trial 1 finished with value: 0.14357645228895372 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:49,934] Trial 12 finished with value: 0.14357645228895372 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:50,057] Trial 10 finished with value: 0.18068282262387306 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:50,253] Trial 18 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:50,842] Trial 19 finished with value: 0.23023601031360502 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 185, 'weights': 'distance'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:51,299] Trial 6 finished with value: 0.18073201648397536 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:51,637] Trial 20 finished with value: 0.23070587588235075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2547, 'weights': 'distance'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:51,786] Trial 0 finished with value: 0.18073172415408562 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:52,430] Trial 23 finished with value: 0.18068282262387306 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2475, 'weights': 'uniform'}. Best is trial 1 with value: 0.14357645228895372.
[I 2024-10-30 07:47:52,538] Trial 4 finished with value: 0.1809139596665039 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.14357645228895372.
running
running
[I 2024-10-30 07:47:53,756] Trial 8 finished with value: 0.1801507756760256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:54,678] Trial 7 finished with value: 0.2886314836572245 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:58,186] Trial 22 finished with value: 0.18605292907681545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:47:58,967] Trial 11 finished with value: 0.3977820203733241 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.11408249877765582, 'alpha': 31, 'iterations': 2, 'learning_rate': 0.00017172694830480198, 'p_miss': 0.20495909227689263}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:48:00,785] Trial 21 finished with value: 0.38867541331394806 and parameters: {'model_name': 'GAIN', 'batch_size': 97, 'hint_rate': 0.6733494440966803, 'alpha': 74, 'iterations': 3, 'learning_rate': 0.01801246172081088, 'p_miss': 0.22239422190056868}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:48:02,812] Trial 17 finished with value: 0.4092435768655732 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.1330313001816402, 'alpha': 15, 'iterations': 5, 'learning_rate': 0.00016944257273178028, 'p_miss': 0.14002307289622135}. Best is trial 1 with value: 0.14357645228895372.
running
[I 2024-10-30 07:48:03,472] Trial 15 finished with value: 0.13664200776291302 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.006709384746353296, 'p_miss': 0.05032631193780105}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:48:04,880] Trial 5 finished with value: 0.38874044044842393 and parameters: {'model_name': 'GAIN', 'batch_size': 471, 'hint_rate': 0.24134226421437435, 'alpha': 83, 'iterations': 5, 'learning_rate': 0.003377874887784127, 'p_miss': 0.2527864168335166}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:48:06,179] Trial 14 finished with value: 0.4178765053874655 and parameters: {'model_name': 'GAIN', 'batch_size': 275, 'hint_rate': 0.5322169393673897, 'alpha': 71, 'iterations': 6, 'learning_rate': 0.0008842333162763207, 'p_miss': 0.05056875915136174}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:48:09,807] Trial 27 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.024104222307079703, 'alpha': 47, 'iterations': 11, 'learning_rate': 0.00014556265906365788, 'p_miss': 0.13378723848803767}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:49:00,660] Trial 3 finished with value: 0.40086935597288836 and parameters: {'model_name': 'GAIN', 'batch_size': 326, 'hint_rate': 0.7258272873126985, 'alpha': 6, 'iterations': 44, 'learning_rate': 0.000674367937675769, 'p_miss': 0.18941286939882748}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:49:17,483] Trial 13 finished with value: 0.14085287662038054 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 26, 'learning_rate': 0.0030653356474299558, 'p_miss': 0.2328886319697706}. Best is trial 15 with value: 0.13664200776291302.
running
[I 2024-10-30 07:50:16,351] Trial 9 finished with value: 0.13630088930477707 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 43, 'learning_rate': 0.00010400032815491765, 'p_miss': 0.22799844921346407}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 07:50:30,853] Trial 2 finished with value: 0.13864336773265587 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 54, 'learning_rate': 0.0006341000049757344, 'p_miss': 0.17472431767299018}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 07:52:59,793] Trial 26 finished with value: 0.3861284748437368 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.5583376107714803, 'alpha': 78, 'iterations': 202, 'learning_rate': 0.0009042837696867212, 'p_miss': 0.2576476198507833}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 07:53:48,608] Trial 28 finished with value: 0.4053893536507319 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.9371735673177221, 'alpha': 81, 'iterations': 235, 'learning_rate': 0.0016235292490728607, 'p_miss': 0.17337035802515494}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 07:54:57,275] Trial 25 finished with value: 0.14069043341057674 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 138, 'learning_rate': 0.00025239169523318247, 'p_miss': 0.28720506253436107}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 08:03:12,439] Trial 16 finished with value: 0.4095744549649816 and parameters: {'model_name': 'GAIN', 'batch_size': 68, 'hint_rate': 0.14645217699010962, 'alpha': 53, 'iterations': 600, 'learning_rate': 0.0024288383530683853, 'p_miss': 0.17980786034031015}. Best is trial 9 with value: 0.13630088930477707.
running
[I 2024-10-30 08:03:16,953] Trial 43 finished with value: 0.13070481733174683 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.010655205584380656, 'p_miss': 0.08488785108768157}. Best is trial 43 with value: 0.13070481733174683.
running
[I 2024-10-30 08:03:21,755] Trial 44 finished with value: 0.1386279331375934 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.012094946985307114, 'p_miss': 0.05248677396231142}. Best is trial 43 with value: 0.13070481733174683.
running
[I 2024-10-30 08:19:36,628] Trial 38 finished with value: 0.24054959827739966 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 628, 'learning_rate': 0.014513678645288106, 'p_miss': 0.011459575572012146}. Best is trial 43 with value: 0.13070481733174683.
running
[I 2024-10-30 08:19:40,079] Trial 46 finished with value: 0.12619248448096057 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.008108466572533207, 'p_miss': 0.0882429526862299}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:27:19,850] Trial 35 finished with value: 0.2348737022205513 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 802, 'learning_rate': 0.05773898632429114, 'p_miss': 0.024092737672932713}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:27:24,412] Trial 48 finished with value: 0.13055499714174107 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.006796483793439413, 'p_miss': 0.0972180447627505}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:27:54,022] Trial 42 finished with value: 0.24104726611280136 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 697, 'learning_rate': 0.01360020382272787, 'p_miss': 0.012169433005077043}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:39:25,685] Trial 41 finished with value: 0.24362819534538502 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 874, 'learning_rate': 0.01407775168630695, 'p_miss': 0.07553936774752605}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:39:29,085] Trial 51 finished with value: 0.13989319194738437 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.039235298894843826, 'p_miss': 0.10217125340698732}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:39:33,573] Trial 52 finished with value: 0.13201138856062267 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.005706090666333108, 'p_miss': 0.10696008527037945}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:51:30,180] Trial 33 finished with value: 0.2410661865886346 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1296, 'learning_rate': 0.09231917909932655, 'p_miss': 0.016554046343495138}. Best is trial 46 with value: 0.12619248448096057.
running
[I 2024-10-30 08:51:34,464] Trial 54 finished with value: 0.12464018909769345 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.006149167563823061, 'p_miss': 0.0980947046930513}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 08:51:39,586] Trial 55 finished with value: 0.13366155850403036 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.00724356605637899, 'p_miss': 0.10025325541743488}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:08:10,901] Trial 32 finished with value: 0.23784407152534404 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1997, 'learning_rate': 0.0871985155143479, 'p_miss': 0.01651598327724186}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:08:16,056] Trial 57 finished with value: 0.13284446278763049 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.006024559922824386, 'p_miss': 0.10596510108743999}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:08:19,814] Trial 58 finished with value: 0.13878084562941534 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.02693472679863305, 'p_miss': 0.07788249357621504}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:34:09,336] Trial 34 finished with value: 0.25044003746684307 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2386, 'learning_rate': 0.0857715269645551, 'p_miss': 0.03461874180355004}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:34:16,351] Trial 60 finished with value: 0.13285251525290268 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.00538731858141243, 'p_miss': 0.12465579381088666}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:34:55,225] Trial 61 finished with value: 0.1582200561039656 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 12, 'learning_rate': 0.008500431854677226, 'p_miss': 0.07585885369893643}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:34:55,661] Trial 62 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:34:59,821] Trial 63 finished with value: 0.12585657611649165 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.0038259472346425473, 'p_miss': 0.11584637629846894}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:37:15,732] Trial 37 finished with value: 0.24111730157537994 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2306, 'learning_rate': 0.012262340876757918, 'p_miss': 0.016483474080427572}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:38:49,420] Trial 36 finished with value: 0.24171837094311574 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2567, 'learning_rate': 0.05803830561588351, 'p_miss': 0.01039038471747919}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:33,082] Trial 64 finished with value: 0.17964357001690984 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:37,110] Trial 67 finished with value: 0.12837325987104467 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.003942326031338444, 'p_miss': 0.11826062320557515}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:45,315] Trial 68 finished with value: 0.13207168111383957 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2, 'learning_rate': 0.0038746664997403833, 'p_miss': 0.08711994275788115}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:56,488] Trial 69 finished with value: 0.1259630856742256 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.001848750528553141, 'p_miss': 0.15350112128410395}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:57,815] Trial 70 finished with value: 0.17350083395919494 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 499, 'weights': 'uniform'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:45:58,100] Trial 71 finished with value: 0.18068282262387306 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:47:50,820] Trial 40 finished with value: 0.23885838073282706 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2329, 'learning_rate': 0.014920257566899738, 'p_miss': 0.027400385456645134}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:48:01,152] Trial 73 finished with value: 0.18101466939906305 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:48:14,220] Trial 74 finished with value: 0.12929208363164688 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.0019879173095756074, 'p_miss': 0.1537267371839136}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:48:19,897] Trial 65 finished with value: 0.1767311417990744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:48:29,698] Trial 76 finished with value: 0.1290113890059043 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.002103223881727911, 'p_miss': 0.15713414529218858}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:48:48,311] Trial 77 finished with value: 0.12827205885025314 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5, 'learning_rate': 0.001834082504804951, 'p_miss': 0.16021174467485705}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:49:11,086] Trial 78 finished with value: 0.13042237081086241 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.0014442438698784742, 'p_miss': 0.1598722576817071}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:49:19,713] Trial 79 finished with value: 0.14019029186601786 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.0039462846084573535, 'p_miss': 0.12119464585781856}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:49:20,784] Trial 80 finished with value: 0.17616512470346107 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1331, 'weights': 'uniform'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:49:54,181] Trial 81 finished with value: 0.1453879157488145 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 9, 'learning_rate': 0.002573249075348877, 'p_miss': 0.1920065379410788}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:50:46,251] Trial 82 finished with value: 0.12888220316034996 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 15, 'learning_rate': 0.0011221106967229091, 'p_miss': 0.147419933923799}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 09:58:12,380] Trial 31 finished with value: 0.24249509249786044 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2883, 'learning_rate': 0.08244870105345133, 'p_miss': 0.03835960833366664}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 10:00:11,458] Trial 84 finished with value: 0.1382302127456215 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 27, 'learning_rate': 0.0011229440227389445, 'p_miss': 0.1411135662624274}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 10:00:11,741] Trial 85 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 10:00:59,128] Trial 86 finished with value: 0.13765318465159038 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 19, 'learning_rate': 0.0005989532812365369, 'p_miss': 0.1547165344610208}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 10:01:18,646] Trial 87 finished with value: 0.13241690777860265 and parameters: {'model_name': 'VAE', 'batch_size': 942, 'iterations': 4, 'learning_rate': 0.003120039456270497, 'p_miss': 0.11997047131934356}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:15:28,732] Trial 45 finished with value: 0.22084242167301552 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4419, 'learning_rate': 0.049586301394930636, 'p_miss': 0.09656380928091138}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:15:39,354] Trial 89 finished with value: 0.1425206532189754 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 2, 'learning_rate': 0.001978125434981793, 'p_miss': 0.16395741199480227}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:15:57,971] Trial 90 finished with value: 0.13376694479032464 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6, 'learning_rate': 0.0007192112546282753, 'p_miss': 0.14395813443193733}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:09,692] Trial 91 finished with value: 0.1280803955965104 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 3, 'learning_rate': 0.004293910349775184, 'p_miss': 0.1762807203729168}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:27,263] Trial 92 finished with value: 0.13446911484283558 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 4, 'learning_rate': 0.004652038272936748, 'p_miss': 0.18756848919890745}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:28,699] Trial 93 finished with value: 0.2301556917419799 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1510, 'weights': 'distance'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:35,287] Trial 94 finished with value: 0.1255629707508379 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2, 'learning_rate': 0.0013135848054337941, 'p_miss': 0.13070243487956315}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:43,867] Trial 95 finished with value: 0.13577589219653116 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2, 'learning_rate': 0.0004784354655137044, 'p_miss': 0.12799399100937045}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:16:55,839] Trial 96 finished with value: 0.13109042455286768 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 3, 'learning_rate': 0.0012570500595997752, 'p_miss': 0.11267465481165438}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:17:41,818] Trial 97 finished with value: 0.13886755075302556 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 12, 'learning_rate': 0.0027081779987558428, 'p_miss': 0.17482621747954674}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:21:28,071] Trial 98 finished with value: 0.14513279906845278 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 77, 'learning_rate': 0.0010013634041042693, 'p_miss': 0.13396495436650319}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:21:53,172] Trial 99 finished with value: 0.13215668370950306 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 8, 'learning_rate': 0.0038541998945161742, 'p_miss': 0.20829746700301802}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:22:09,624] Trial 100 finished with value: 0.12998970852759623 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 5, 'learning_rate': 0.001726061283757277, 'p_miss': 0.14570354383565196}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:22:19,999] Trial 101 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.3541191931258556, 'alpha': 96, 'iterations': 18, 'learning_rate': 0.003345939445899838, 'p_miss': 0.11366463525615668}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:22:29,308] Trial 102 finished with value: 0.13682439406347852 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.009169493878129506, 'p_miss': 0.06271384744850034}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:22:37,924] Trial 103 finished with value: 0.1331585416309978 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 2, 'learning_rate': 0.001310448787442678, 'p_miss': 0.13321703445285105}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:22:58,110] Trial 104 finished with value: 0.1377019910420514 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.004435768719121806, 'p_miss': 0.16560424059598286}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:25:58,642] Trial 105 finished with value: 0.17251954644894396 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 55, 'learning_rate': 0.0025092437376933547, 'p_miss': 0.18024786792384384}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:07,115] Trial 106 finished with value: 0.13524347331463793 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0016804145673849677, 'p_miss': 0.15439508110413222}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:17,716] Trial 107 finished with value: 0.1278800634389524 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.0008057631744479432, 'p_miss': 0.16947248228103226}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:21,058] Trial 108 finished with value: 0.12866782224487744 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.0007697169167586072, 'p_miss': 0.090549930197133}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:24,523] Trial 109 finished with value: 0.12998899210018372 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1, 'learning_rate': 0.00035096411335390205, 'p_miss': 0.09364576786720422}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:25,214] Trial 110 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:34,392] Trial 111 finished with value: 0.18162886162839803 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:42,533] Trial 112 finished with value: 0.13174260977654756 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.0007782932822118139, 'p_miss': 0.06569715095719847}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:46,630] Trial 113 finished with value: 0.1417445692080242 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 1, 'learning_rate': 0.0005598523764155214, 'p_miss': 0.19845259544507055}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:26:56,541] Trial 114 finished with value: 0.13190020044851897 and parameters: {'model_name': 'VAE', 'batch_size': 225, 'iterations': 2, 'learning_rate': 0.0009206325859098997, 'p_miss': 0.1149539831423787}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:54:46,204] Trial 39 finished with value: 0.2685599486631748 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4441, 'learning_rate': 0.01604264715779074, 'p_miss': 0.2997884824359197}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:54:59,688] Trial 116 finished with value: 0.12859419745653172 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 4, 'learning_rate': 0.0011203070738765876, 'p_miss': 0.1688764187120143}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:55:20,439] Trial 117 finished with value: 0.131878955831818 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.0008523103648974468, 'p_miss': 0.16886249252268926}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 11:55:33,659] Trial 118 finished with value: 0.13584674143288034 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 3, 'learning_rate': 0.008210904191285059, 'p_miss': 0.17802632132639962}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:02,867] Trial 115 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.9370072575326964, 'alpha': 23, 'iterations': 9687, 'learning_rate': 0.0004572597030297919, 'p_miss': 0.17102708225174146}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:14,615] Trial 120 finished with value: 0.12938975974655706 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0048291826166811085, 'p_miss': 0.09283585418083709}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:18,594] Trial 121 finished with value: 0.12526589218050424 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.0015840961719007247, 'p_miss': 0.1337565342629876}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:20,002] Trial 122 finished with value: 0.18068282262387306 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2908, 'weights': 'uniform'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:31,504] Trial 119 finished with value: 0.17058075922387014 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 336, 'learning_rate': 0.0004223047549734983, 'p_miss': 0.08879244843824911}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:37,425] Trial 124 finished with value: 0.13130930361288104 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.002189312235404293, 'p_miss': 0.1357913048445415}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:40,513] Trial 123 finished with value: 0.13518096528316864 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 6, 'learning_rate': 0.0016025381705487983, 'p_miss': 0.13318242165197972}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:44,538] Trial 126 finished with value: 0.1315597242486767 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.0029313784680285956, 'p_miss': 0.11012267091873836}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:48,501] Trial 127 finished with value: 0.12982562595497069 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0010894067299539905, 'p_miss': 0.1836961056856764}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:58,454] Trial 125 finished with value: 0.13098714289628968 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 4, 'learning_rate': 0.0015199928078887244, 'p_miss': 0.18441768930356717}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:14:59,990] Trial 128 finished with value: 0.136992037859638 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0013834093791786745, 'p_miss': 0.12415257833912491}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:06,469] Trial 130 finished with value: 0.1306351597169456 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.006513942634989747, 'p_miss': 0.14711077416642523}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:06,834] Trial 129 finished with value: 0.1269877921867067 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.006201793344627254, 'p_miss': 0.14806739910515465}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:12,029] Trial 131 finished with value: 0.13695526075243997 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.005362930546101301, 'p_miss': 0.08069678365736505}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:15,700] Trial 132 finished with value: 0.18605292907681545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:16,311] Trial 134 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:21,431] Trial 133 finished with value: 0.18939101660067542 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:25,543] Trial 135 finished with value: 0.12736067097351667 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.00391142095661661, 'p_miss': 0.15072915212548824}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:40,308] Trial 136 finished with value: 0.14268988795157173 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7, 'learning_rate': 0.010272405520436335, 'p_miss': 0.10355165211373865}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:46,296] Trial 137 finished with value: 0.13123523335894943 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.003547447829064906, 'p_miss': 0.16166570273837472}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:50,619] Trial 138 finished with value: 0.1401140879390314 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.003378334973101409, 'p_miss': 0.1605874379812806}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:15:57,455] Trial 139 finished with value: 0.13636473545873246 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.007015680103935826, 'p_miss': 0.15251481727060853}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:18,746] Trial 140 finished with value: 0.1433324196312082 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9, 'learning_rate': 0.00516059857368133, 'p_miss': 0.15204947080093537}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:26,704] Trial 141 finished with value: 0.13714159241292903 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9, 'learning_rate': 0.004316124711075986, 'p_miss': 0.1284936176991844}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:33,827] Trial 142 finished with value: 0.13130929034621786 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.0022380146775689805, 'p_miss': 0.14071264129308092}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:40,008] Trial 143 finished with value: 0.13773867533123224 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 5, 'learning_rate': 0.002250019128915522, 'p_miss': 0.1422322681856182}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:43,466] Trial 145 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.36769264159099746, 'alpha': 44, 'iterations': 2, 'learning_rate': 0.0018714590478015479, 'p_miss': 0.11912706288159619}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:16:55,086] Trial 144 finished with value: 0.1404075127012627 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 5, 'learning_rate': 0.005928264021788312, 'p_miss': 0.1203855886482894}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:03,869] Trial 146 finished with value: 0.13121674673595113 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.0006597200658954621, 'p_miss': 0.1721434806250607}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:07,851] Trial 147 finished with value: 0.13002000891352883 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.0011810295190741507, 'p_miss': 0.16552980340457557}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:12,877] Trial 149 finished with value: 0.13296630987587052 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.002993226729079428, 'p_miss': 0.19472318153741053}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:14,593] Trial 148 finished with value: 0.1346604178413752 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.0028213748875304486, 'p_miss': 0.16490636425633062}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:15,861] Trial 151 finished with value: 0.22997012930586677 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 849, 'weights': 'distance'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:18,579] Trial 150 finished with value: 0.13259711383542666 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.007939969944915007, 'p_miss': 0.10145669138413126}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:22,919] Trial 153 finished with value: 0.13157744029586912 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.004302469322395501, 'p_miss': 0.07155529651834544}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:37,666] Trial 154 finished with value: 0.12606946543385042 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 4, 'learning_rate': 0.0007988344476041217, 'p_miss': 0.13716793093324942}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:17:54,337] Trial 155 finished with value: 0.12652751961014091 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 4, 'learning_rate': 0.0009392876516777948, 'p_miss': 0.14821187663219787}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:18:06,907] Trial 156 finished with value: 0.13252272614881652 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 4, 'learning_rate': 0.0009813728135556424, 'p_miss': 0.14732266704319658}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:18:24,975] Trial 157 finished with value: 0.1323116575574576 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 5, 'learning_rate': 0.0008526057487030284, 'p_miss': 0.13778440990726434}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:18:51,186] Trial 53 finished with value: 0.22756516205215965 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4634, 'learning_rate': 0.005813215334911686, 'p_miss': 0.09960182922135621}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:19:12,170] Trial 159 finished with value: 0.13692135289049787 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 6, 'learning_rate': 0.0017861900498886535, 'p_miss': 0.13044283876930332}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:19:25,126] Trial 160 finished with value: 0.1291301244861756 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4, 'learning_rate': 0.0013104012696646323, 'p_miss': 0.15073193375024216}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:19:35,699] Trial 161 finished with value: 0.13012695761351453 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 3, 'learning_rate': 0.0010013188006932623, 'p_miss': 0.15673925259848545}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:19:42,712] Trial 162 finished with value: 0.13008931936230944 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 2, 'learning_rate': 0.0005693191996617916, 'p_miss': 0.13844387585945728}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:20:00,766] Trial 163 finished with value: 0.12905024102099782 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 4, 'learning_rate': 0.003761331819884126, 'p_miss': 0.24966504847973783}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:20:00,947] Trial 164 finished with value: 0.45041345248092873 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:22:46,828] Trial 152 finished with value: 0.22027165503054724 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 114, 'learning_rate': 0.007858946819217949, 'p_miss': 0.06925532235658777}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:22:59,171] Trial 166 finished with value: 0.13321233049103415 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 3, 'learning_rate': 0.0008071457165665855, 'p_miss': 0.17678413321968164}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:23:06,776] Trial 167 finished with value: 0.12713278215814783 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 2, 'learning_rate': 0.0007814708994798972, 'p_miss': 0.10944422849271786}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:24:06,126] Trial 158 finished with value: 0.1693946207382503 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 116, 'learning_rate': 0.001351442420912566, 'p_miss': 0.12959307571583306}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:24:15,245] Trial 169 finished with value: 0.1317762173614657 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 2, 'learning_rate': 0.0011018056341901197, 'p_miss': 0.11094213786378287}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:24:18,048] Trial 168 finished with value: 0.13167091454693666 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 27, 'learning_rate': 0.0014290047828343943, 'p_miss': 0.1277206368564661}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:24:34,612] Trial 171 finished with value: 0.1308251583013585 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 5, 'learning_rate': 0.0007124337956563885, 'p_miss': 0.11602765737827753}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:24:51,970] Trial 172 finished with value: 0.13483125459234374 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 6, 'learning_rate': 0.0006364082276624322, 'p_miss': 0.14515484605989454}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:25:04,537] Trial 173 finished with value: 0.1277913638297736 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 3, 'learning_rate': 0.0048451599722462374, 'p_miss': 0.15882104820302123}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:25:18,038] Trial 174 finished with value: 0.13690619438927115 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 3, 'learning_rate': 0.009901743749403322, 'p_miss': 0.15808348088161928}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:25:24,427] Trial 175 finished with value: 0.4110934915119273 and parameters: {'model_name': 'GAIN', 'batch_size': 34, 'hint_rate': 0.7620942765397656, 'alpha': 100, 'iterations': 3, 'learning_rate': 0.006456288802968532, 'p_miss': 0.10539487872902328}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:25:40,664] Trial 176 finished with value: 0.13654707399763458 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 4, 'learning_rate': 0.0041173336955974285, 'p_miss': 0.1688313796750395}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:25:48,786] Trial 177 finished with value: 0.1310547057096874 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.0033250856714525235, 'p_miss': 0.14800352668547703}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:03,613] Trial 178 finished with value: 0.13009808996053662 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 4, 'learning_rate': 0.0049493423395246755, 'p_miss': 0.12419084280219055}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:10,834] Trial 170 finished with value: 0.19495974698059299 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 27, 'learning_rate': 0.010206126072816792, 'p_miss': 0.11529200477553649}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:31,536] Trial 180 finished with value: 0.14445499392769318 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.005642494075533581, 'p_miss': 0.08436077821926104}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:42,085] Trial 181 finished with value: 0.12846351713443 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.0008987526693691095, 'p_miss': 0.1597284447591265}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:50,509] Trial 182 finished with value: 0.13680192191430152 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.0009022899950578787, 'p_miss': 0.15546685224247409}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:26:51,444] Trial 183 finished with value: 0.17797624388153874 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1967, 'weights': 'uniform'}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:00,254] Trial 184 finished with value: 0.13606779896849142 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 2, 'learning_rate': 0.004862370000987312, 'p_miss': 0.16030967809520566}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:08,255] Trial 185 finished with value: 0.1287054453494783 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.0005165587471494126, 'p_miss': 0.13566630706560776}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:22,767] Trial 186 finished with value: 0.1280433039049751 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0011265251471761757, 'p_miss': 0.17198165947964553}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:41,463] Trial 187 finished with value: 0.14045167487836246 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.0007127048667688268, 'p_miss': 0.17442925889813501}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:46,994] Trial 179 finished with value: 0.18235589930547222 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 39, 'learning_rate': 0.005587877551148564, 'p_miss': 0.1393047031298448}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:53,764] Trial 188 finished with value: 0.13653204561351134 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0015626025048110655, 'p_miss': 0.14091596378294985}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:27:59,669] Trial 189 finished with value: 0.1304175444780238 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 4, 'learning_rate': 0.0009511236591624315, 'p_miss': 0.16373815344759812}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:09,799] Trial 190 finished with value: 0.13738293382505426 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0012072772487736172, 'p_miss': 0.1634339418511775}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:10,116] Trial 191 finished with value: 0.13873867949801696 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.0025745375471727112, 'p_miss': 0.09719856169112281}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:15,629] Trial 192 finished with value: 0.18064130547062504 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:25,885] Trial 194 finished with value: 0.13496301267756208 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0008290845694849023, 'p_miss': 0.18138660263187145}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:33,215] Trial 195 finished with value: 0.13359629702861825 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.0037426278824235267, 'p_miss': 0.15127531796366117}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:28:54,798] Trial 196 finished with value: 0.12896073051932438 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.0011820276698094583, 'p_miss': 0.17258061050763887}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:29:07,080] Trial 197 finished with value: 0.13993557749025676 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 4, 'learning_rate': 0.0011012692223978263, 'p_miss': 0.1680049753629493}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:29:27,585] Trial 165 finished with value: 0.18814566227374593 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 136, 'learning_rate': 0.0015001800150370166, 'p_miss': 0.1741068275512333}. Best is trial 54 with value: 0.12464018909769345.
running
[I 2024-10-30 12:29:31,748] Trial 198 finished with value: 0.1339919572131072 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.0009853094353934233, 'p_miss': 0.1893779679629258}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 12:29:38,699] Trial 199 finished with value: 0.13651856100382656 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.0010477051904607191, 'p_miss': 0.15402885404948646}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 12:37:56,943] Trial 193 finished with value: 0.18234577318292858 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 12:55:13,809] Trial 56 finished with value: 0.2148941367795354 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5118, 'learning_rate': 0.005547896401810856, 'p_miss': 0.10830362381018485}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:00:24,762] Trial 59 finished with value: 0.2383294483285326 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5597, 'learning_rate': 0.004746769501381843, 'p_miss': 0.11736907760881282}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:03:13,049] Trial 49 finished with value: 0.2235046527287364 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6482, 'learning_rate': 0.035687662372946766, 'p_miss': 0.1016076878924859}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:17:07,877] Trial 47 finished with value: 0.24670555794861398 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7331, 'learning_rate': 0.06359949106109693, 'p_miss': 0.09575738682413232}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:28:53,996] Trial 66 finished with value: 0.2132293605467604 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6746, 'learning_rate': 0.004453414365339107, 'p_miss': 0.12110995196289454}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:36:29,284] Trial 72 finished with value: 0.2480808570142825 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6416, 'learning_rate': 0.0019194227203990105, 'p_miss': 0.16109170388158073}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:38:32,170] Trial 30 finished with value: 0.2518770410978401 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8450, 'learning_rate': 0.0861865775226748, 'p_miss': 0.042791284336303206}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:44:35,296] Trial 29 finished with value: 0.19208551674870855 and parameters: {'model_name': 'VAE', 'batch_size': 889, 'iterations': 6842, 'learning_rate': 0.09965106210288475, 'p_miss': 0.045103998437408505}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:45:52,021] Trial 75 finished with value: 0.23138095272643816 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6949, 'learning_rate': 0.0017837992641598992, 'p_miss': 0.12616676895500178}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:46:13,185] Trial 50 finished with value: 0.21810556678889975 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8425, 'learning_rate': 0.03866639786744345, 'p_miss': 0.10408808849980922}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:47:05,284] Trial 24 finished with value: 0.20036082831463947 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 8413, 'learning_rate': 0.0215900571695977, 'p_miss': 0.07614975782739523}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:47:47,956] Trial 88 finished with value: 0.1970857224446269 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 7454, 'learning_rate': 0.0005402906844872029, 'p_miss': 0.1701803734762488}. Best is trial 54 with value: 0.12464018909769345.
[I 2024-10-30 13:49:02,397] Trial 83 finished with value: 0.2115286231573644 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7989, 'learning_rate': 0.0011129147440539985, 'p_miss': 0.1447227233978698}. Best is trial 54 with value: 0.12464018909769345.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.12464018909769345
{'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.006149167563823061, 'p_miss': 0.0980947046930513}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a8e80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5290868029610548
Generation:   4%|▍         | 1/25 [00:06<02:44,  6.86s/it]Generation:  2
Best f1_score score: 0.5290868029610548
Generation:   8%|▊         | 2/25 [00:17<03:24,  8.87s/it]Generation:  3
Best f1_score score: 0.5290868029610548
Generation:  12%|█▏        | 3/25 [00:27<03:35,  9.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a6140> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f09d20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.5290868029610548
Generation:  16%|█▌        | 4/25 [00:39<03:40, 10.51s/it]Generation:  5
Best f1_score score: 0.5290868029610548
Generation:  20%|██        | 5/25 [00:48<03:17,  9.86s/it]Generation:  6
Best f1_score score: 0.5290868029610548
Generation:  24%|██▍       | 6/25 [01:01<03:29, 11.00s/it]Generation:  7
Best f1_score score: 0.5290868029610548
Generation:  28%|██▊       | 7/25 [01:32<05:13, 17.44s/it]Generation:  8
Best f1_score score: 0.5330847030996405
Generation:  32%|███▏      | 8/25 [01:54<05:20, 18.85s/it]Generation:  9
Best f1_score score: 0.5330847030996405
Generation:  36%|███▌      | 9/25 [02:14<05:10, 19.42s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467bbb1f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5330847030996405
Generation:  40%|████      | 10/25 [04:13<12:29, 49.94s/it]Generation:  11
Best f1_score score: 0.5330847030996405
Generation:  44%|████▍     | 11/25 [04:26<09:04, 38.89s/it]Generation:  12
Best f1_score score: 0.5330847030996405
Generation:  48%|████▊     | 12/25 [04:38<06:38, 30.65s/it]Generation:  13
Best f1_score score: 0.5330847030996405
Generation:  52%|█████▏    | 13/25 [04:55<05:17, 26.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29240> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.5330847030996405
Generation:  56%|█████▌    | 14/25 [05:16<04:31, 24.70s/it]Generation:  15
Best f1_score score: 0.5330847030996405
Generation:  60%|██████    | 15/25 [05:30<03:37, 21.72s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c5c8e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5330847030996405
Generation:  64%|██████▍   | 16/25 [05:48<03:03, 20.41s/it]Generation:  17
Best f1_score score: 0.5330847030996405
Generation:  68%|██████▊   | 17/25 [06:08<02:43, 20.42s/it]Generation:  18
Best f1_score score: 0.5330847030996405
Generation:  72%|███████▏  | 18/25 [06:25<02:15, 19.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465808a60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659921a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.5330847030996405
Generation:  76%|███████▌  | 19/25 [06:42<01:51, 18.60s/it]Generation:  20
Best f1_score score: 0.5330847030996405
Generation:  80%|████████  | 20/25 [07:09<01:45, 21.06s/it]Generation:  21
Best f1_score score: 0.5330847030996405
Generation:  84%|████████▍ | 21/25 [11:59<06:47, 101.97s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f45e10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.5330847030996405
Generation:  88%|████████▊ | 22/25 [12:29<04:00, 80.10s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c1ee60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.5330847030996405
Generation:  92%|█████████▏| 23/25 [12:48<02:03, 61.89s/it]Generation:  24
Best f1_score score: 0.5330847030996405
Generation:  96%|█████████▌| 24/25 [13:11<00:50, 50.21s/it]Generation:  25
Best f1_score score: 0.5330847030996405
Generation: 100%|██████████| 25/25 [13:32<00:00, 41.51s/it]Generation: 100%|██████████| 25/25 [13:37<00:00, 32.70s/it]
2024-10-30 14:02:49,328 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33627' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-17f12efdf9ceab315b0ca59aef48a069', 'ndarray-2c00092ba1cd743626b416db9c976854'} (stimulus_id='handle-worker-cleanup-1730322169.3283658')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(max_features=0.2633926250966,
                                      min_samples_leaf=10, min_samples_split=14,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.6517573625059688, 'accuracy': 0.6091617933723197, 'balanced_accuracy': 0.6091617933723197, 'logloss': 0.6893062944202063, 'f1': 0.609070643352029}
original test score: {'auroc': 0.5197402597402597, 'accuracy': 0.5, 'balanced_accuracy': 0.5, 'logloss': 0.693094330389902, 'f1': 0.39640305493964034}
imputed test score: {'auroc': 0.527488615280823, 'accuracy': 0.5324675324675324, 'balanced_accuracy': 0.5324675324675324, 'logloss': 0.6927033591030797, 'f1': 0.5318484891473968}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5120981373237375
Generation:   4%|▍         | 1/25 [01:41<40:46, 101.92s/it]Generation:  2
Best f1_score score: 0.5120981373237375
Generation:   8%|▊         | 2/25 [04:52<58:58, 153.83s/it]Generation:  3
Best f1_score score: 0.5120981373237375
Generation:  12%|█▏        | 3/25 [06:34<47:52, 130.57s/it]Generation:  4
Best f1_score score: 0.5120981373237375
Generation:  16%|█▌        | 4/25 [08:10<40:52, 116.78s/it]Generation:  5
Best f1_score score: 0.5120981373237375
Generation:  20%|██        | 5/25 [08:18<25:48, 77.44s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d55ea0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.5120981373237375
Generation:  24%|██▍       | 6/25 [10:01<27:17, 86.19s/it]Generation:  7
Best f1_score score: 0.5132023468616506
Generation:  28%|██▊       | 7/25 [11:58<28:50, 96.14s/it]Generation:  8
Best f1_score score: 0.5132023468616506
Generation:  32%|███▏      | 8/25 [16:46<44:36, 157.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545e3716f0> 

Generation:  9
Best f1_score score: 0.5132023468616506
Generation:  36%|███▌      | 9/25 [26:52<1:19:23, 297.71s/it]Generation:  10
Best f1_score score: 0.5132023468616506
Generation:  40%|████      | 10/25 [30:18<1:07:20, 269.36s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545df05420> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  11
Best f1_score score: 0.5132023468616506
Generation:  44%|████▍     | 11/25 [33:10<55:54, 239.60s/it]  Generation:  12
Best f1_score score: 0.5210034895523051
Generation:  48%|████▊     | 12/25 [35:18<44:30, 205.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474580850> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  13
Best f1_score score: 0.5210034895523051
Generation:  52%|█████▏    | 13/25 [37:15<35:44, 178.73s/it]Generation:  14
Best f1_score score: 0.5210034895523051
Generation:  56%|█████▌    | 14/25 [40:41<34:15, 186.85s/it]Generation:  15
Best f1_score score: 0.5210034895523051
Generation:  60%|██████    | 15/25 [44:48<34:10, 205.08s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554550a9060> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5210034895523051
Generation:  64%|██████▍   | 16/25 [47:59<30:07, 200.84s/it]Generation:  17
Best f1_score score: 0.5210034895523051
Generation:  68%|██████▊   | 17/25 [51:19<26:45, 200.74s/it]Generation:  18
Best f1_score score: 0.5210034895523051
Generation:  72%|███████▏  | 18/25 [54:47<23:40, 202.87s/it]Generation:  19
Best f1_score score: 0.5210034895523051
Generation:  76%|███████▌  | 19/25 [58:29<20:51, 208.55s/it]Generation:  20
Best f1_score score: 0.5210034895523051
Generation:  80%|████████  | 20/25 [59:10<13:10, 158.17s/it]Generation:  21
Best f1_score score: 0.5210034895523051
Generation:  84%|████████▍ | 21/25 [1:00:53<09:26, 141.63s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554740ec430> 

Generation:  22
Best f1_score score: 0.5210034895523051
Generation:  88%|████████▊ | 22/25 [1:10:59<14:02, 280.95s/it]Generation:  23
Best f1_score score: 0.5210034895523051
Generation:  92%|█████████▏| 23/25 [1:13:04<07:48, 234.23s/it]Generation:  24
Best f1_score score: 0.5210034895523051
Generation:  96%|█████████▌| 24/25 [1:15:28<03:27, 207.14s/it]Generation:  25
Best f1_score score: 0.5210034895523051
Generation: 100%|██████████| 25/25 [1:15:46<00:00, 150.54s/it]Generation: 100%|██████████| 25/25 [1:15:46<00:00, 181.88s/it]
2024-10-30 15:18:44,803 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37025' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-d97cbabe6af6a06f568662ff25c0ac98', 'ndarray-2c00092ba1cd743626b416db9c976854'} (stimulus_id='handle-worker-cleanup-1730326724.8037317')
Fitted
Pipeline(steps=[('vaeimputer',
                 VAEImputer(batch_size=1, code_size=1,
                            decoder_hidden_sizes=[1, 2],
                            encoder_hidden_sizes=[2, 1], iterations=135,
                            learning_rate=0.0015403653029,
                            p_miss=0.1179834447429, split_size=1)),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, devic...
                               feature_types=None, gamma=0.0097560915886,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.23959077788, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=18,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100, n_jobs=1,
                               nthread=1, num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.49806102626913584, 'accuracy': 0.5188434048083171, 'balanced_accuracy': 0.5142949967511371, 'logloss': 0.7536649923361882, 'f1': 0.5116954425629943}
test score: {'auroc': 0.4795007589812784, 'accuracy': 0.5194805194805194, 'balanced_accuracy': 0.49350649350649345, 'logloss': 0.7617516105897361, 'f1': 0.489299438517971}
failed on 
../data/c/871/class_full_MNAR_0.3_1
'numpy.ndarray' object has no attribute 'to_numpy'
Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/ImputerExperiments/Locally_run_code/utils.py", line 33, in score
    this_auroc_score = sklearn.metrics.get_scorer("roc_auc_ovr")(est, X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 940, in predict_proba
    return self.fitted_pipeline_.predict_proba(X,**predict_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 720, in predict_proba
    Xt = transform.transform(Xt)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 688, in transform
    features = torch.from_numpy(X.to_numpy()) #X features
AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/ImputerExperiments/Locally_run_code/utils.py", line 686, in loop_through_tasks
    ori_test_score = score(tpot_space, X_test, y_test, r_or_c=r_or_c)
  File "/common/ketrong/tpotexp/tpot2/ImputerExperiments/Locally_run_code/utils.py", line 35, in score
    y_preds = est.predict(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 930, in predict
    preds = self.fitted_pipeline_.predict(X,**predict_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 600, in predict
    Xt = transform.transform(Xt)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 688, in transform
    features = torch.from_numpy(X.to_numpy()) #X features
AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'

full run takes
7.5182320017947095
hours
DONE
