Run: 36
/cm/local/apps/slurm/var/spool/job1033174/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/871/871.pkl
working on 
../data/c/871/class_full_MNAR_0.5_2
2.3451247215270996
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-30 17:13:35,331] A new study created in memory with name: no-name-e1445e72-441a-472c-ab33-f9857393dfe3
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-30 17:13:35,467] Trial 1 finished with value: 0.20033360046627807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 1 with value: 0.20033360046627807.
running
running
running
[I 2024-10-30 17:13:35,727] Trial 3 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 1 with value: 0.20033360046627807.
running
running
running
running
[I 2024-10-30 17:13:36,019] Trial 8 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:36,183] Trial 6 finished with value: 0.29642954850876635 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:36,374] Trial 9 finished with value: 0.29642954850876635 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:36,583] Trial 13 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:36,722] Trial 12 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:36,979] Trial 20 finished with value: 0.29642954850876635 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.20033360046627807.
running
[I 2024-10-30 17:13:37,520] Trial 7 finished with value: 0.19964222157783645 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1358, 'weights': 'uniform'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:37,845] Trial 2 finished with value: 0.2416434106794894 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2402, 'weights': 'distance'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:38,726] Trial 17 finished with value: 0.2027193511288244 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:39,077] Trial 24 finished with value: 0.24094054415274094 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1587, 'weights': 'distance'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:39,499] Trial 21 finished with value: 0.20272110188328235 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:40,878] Trial 18 finished with value: 0.20107723897975988 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:44,971] Trial 10 finished with value: 0.22084565696260033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:45,268] Trial 14 finished with value: 0.2217937876634592 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:45,592] Trial 28 finished with value: 0.3577901425637232 and parameters: {'model_name': 'GAIN', 'batch_size': 167, 'hint_rate': 0.4191117221944429, 'alpha': 53, 'iterations': 1, 'learning_rate': 0.003919530279666076, 'p_miss': 0.011480575762948364}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:46,219] Trial 15 finished with value: 0.3266275623853156 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.4667918906893233, 'alpha': 69, 'iterations': 1, 'learning_rate': 0.0014675314096932687, 'p_miss': 0.2471942445150607}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:49,256] Trial 25 finished with value: 0.3358484360431493 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.5335342231049622, 'alpha': 5, 'iterations': 3, 'learning_rate': 0.00047549331701710236, 'p_miss': 0.1738747306562619}. Best is trial 7 with value: 0.19964222157783645.
running
[I 2024-10-30 17:13:56,708] Trial 22 finished with value: 0.11540229634923227 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.005769394083194204, 'p_miss': 0.14833493452264057}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:13:57,956] Trial 31 finished with value: 0.33520843024092745 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.8148438719775026, 'alpha': 85, 'iterations': 6, 'learning_rate': 0.0001297826339518735, 'p_miss': 0.20956555907177873}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:14:00,885] Trial 4 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.29785138369734265, 'alpha': 86, 'iterations': 54, 'learning_rate': 0.08203703472197117, 'p_miss': 0.2771223319826838}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:14:11,276] Trial 16 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.02087478070565539, 'alpha': 91, 'iterations': 84, 'learning_rate': 0.0002704936791581006, 'p_miss': 0.27905592776105864}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:14:55,163] Trial 26 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.2671251530958399, 'alpha': 8, 'iterations': 196, 'learning_rate': 0.00040008097891803136, 'p_miss': 0.031429513030102704}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:16:41,719] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.6532448568392498, 'alpha': 60, 'iterations': 121, 'learning_rate': 0.0012708393583562884, 'p_miss': 0.23090159599097768}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:21:52,986] Trial 5 finished with value: 0.2187747402713664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 17:24:42,705] Trial 11 finished with value: 0.21601506826651468 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 18:08:41,799] Trial 27 finished with value: 0.335943148723195 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.6114813166599274, 'alpha': 46, 'iterations': 1753, 'learning_rate': 0.0021248141053372724, 'p_miss': 0.27709837583754476}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 18:10:19,504] Trial 43 finished with value: 0.2117810671583109 and parameters: {'model_name': 'VAE', 'batch_size': 219, 'iterations': 15, 'learning_rate': 0.01630525243500226, 'p_miss': 0.0959843241345979}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 18:36:11,313] Trial 35 finished with value: 0.22281774509943753 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 1181, 'learning_rate': 0.06209895847458644, 'p_miss': 0.0817446548957118}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 18:36:12,396] Trial 45 finished with value: 0.20239845092429448 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 56, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:31,369] Trial 36 finished with value: 0.2068589775837379 and parameters: {'model_name': 'VAE', 'batch_size': 737, 'iterations': 2250, 'learning_rate': 0.08073391015774065, 'p_miss': 0.07648494445149541}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:32,500] Trial 47 finished with value: 0.19974993594710386 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 587, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:33,765] Trial 48 finished with value: 0.19917304436596706 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 640, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:34,951] Trial 49 finished with value: 0.20020876867718726 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 523, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:35,868] Trial 50 finished with value: 0.19901403289041172 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 979, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:37,325] Trial 51 finished with value: 0.19924141818082325 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1189, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:38,824] Trial 52 finished with value: 0.19924141818082325 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1189, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:16:39,978] Trial 53 finished with value: 0.19895583592024133 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 812, 'weights': 'uniform'}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:17:40,446] Trial 54 finished with value: 0.14986225993929117 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 15, 'learning_rate': 0.00954897706998403, 'p_miss': 0.13815507830816567}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:18:47,612] Trial 55 finished with value: 0.16266908738660574 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 18, 'learning_rate': 0.0109640907493275, 'p_miss': 0.142107464257127}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:19:42,585] Trial 56 finished with value: 0.1320841919154751 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 14, 'learning_rate': 0.008360282284163313, 'p_miss': 0.1379257871212974}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:20:41,443] Trial 57 finished with value: 0.12535186530987213 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 15, 'learning_rate': 0.0081233529930758, 'p_miss': 0.14284078840692307}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:21:42,674] Trial 58 finished with value: 0.1394233735516513 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 17, 'learning_rate': 0.008831348874097244, 'p_miss': 0.14008916379157058}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:22:40,656] Trial 59 finished with value: 0.12496628104940859 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 14, 'learning_rate': 0.008856569960869469, 'p_miss': 0.14809447741155818}. Best is trial 22 with value: 0.11540229634923227.
running
[I 2024-10-30 20:23:08,015] Trial 60 finished with value: 0.11205056648292185 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 6, 'learning_rate': 0.005942734126083355, 'p_miss': 0.17287883493563888}. Best is trial 60 with value: 0.11205056648292185.
running
[I 2024-10-30 20:23:23,661] Trial 61 finished with value: 0.12138677573440179 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.005732472878347, 'p_miss': 0.1785765505446481}. Best is trial 60 with value: 0.11205056648292185.
running
[I 2024-10-30 20:23:36,358] Trial 62 finished with value: 0.11450788080394406 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 3, 'learning_rate': 0.0038843973712411007, 'p_miss': 0.18046265765641004}. Best is trial 60 with value: 0.11205056648292185.
running
[I 2024-10-30 20:23:49,987] Trial 63 finished with value: 0.11597193134647774 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 3, 'learning_rate': 0.0040112843523032755, 'p_miss': 0.1837844866753113}. Best is trial 60 with value: 0.11205056648292185.
running
[I 2024-10-30 20:24:05,164] Trial 64 finished with value: 0.10991626389069334 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.003733780482593223, 'p_miss': 0.18416677369533124}. Best is trial 64 with value: 0.10991626389069334.
running
[I 2024-10-30 20:24:18,604] Trial 65 finished with value: 0.11186956368686196 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.0030397893489328203, 'p_miss': 0.1904207559475257}. Best is trial 64 with value: 0.10991626389069334.
running
[I 2024-10-30 20:24:34,091] Trial 66 finished with value: 0.10663802094563764 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 3, 'learning_rate': 0.0033952289906797736, 'p_miss': 0.19010146889116553}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:24:43,122] Trial 67 finished with value: 0.11173974130866471 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 2, 'learning_rate': 0.0024206986535727673, 'p_miss': 0.2025979364135012}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:24:48,110] Trial 68 finished with value: 0.11541729098831284 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.002431123127520393, 'p_miss': 0.20693480750098917}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:24:58,381] Trial 69 finished with value: 0.11483135139149118 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 2, 'learning_rate': 0.0011442651575563855, 'p_miss': 0.19769485157658548}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:25:07,347] Trial 70 finished with value: 0.108949791425203 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 2, 'learning_rate': 0.0025171902592281987, 'p_miss': 0.22494660407111544}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:25:18,034] Trial 71 finished with value: 0.1081683984532047 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 2, 'learning_rate': 0.002229674212162893, 'p_miss': 0.2234609101326155}. Best is trial 66 with value: 0.10663802094563764.
running
[I 2024-10-30 20:25:26,084] Trial 72 finished with value: 0.10560556684781057 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 2, 'learning_rate': 0.0018207347305265265, 'p_miss': 0.2279945936207257}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:25:31,267] Trial 73 finished with value: 0.11101636243598874 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 1, 'learning_rate': 0.0009127754760263608, 'p_miss': 0.24767449682314585}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:25:36,628] Trial 74 finished with value: 0.10973470776682055 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 1, 'learning_rate': 0.0007640805467759249, 'p_miss': 0.23667207364494722}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:25:41,485] Trial 75 finished with value: 0.10795279967023916 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 1, 'learning_rate': 0.0007095145785567349, 'p_miss': 0.2337507935393982}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:25:46,052] Trial 76 finished with value: 0.12243150073475681 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 1, 'learning_rate': 0.0007165106502226319, 'p_miss': 0.2331880140484245}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:25:58,867] Trial 77 finished with value: 0.10950802587366441 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 2, 'learning_rate': 0.0015234833855638865, 'p_miss': 0.22806275628935185}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:26:04,470] Trial 78 finished with value: 0.11007916607930739 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 1, 'learning_rate': 0.0015484969480658547, 'p_miss': 0.25242836537704666}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:26:18,658] Trial 79 finished with value: 0.1197528445432714 and parameters: {'model_name': 'VAE', 'batch_size': 127, 'iterations': 2, 'learning_rate': 0.0016653366783411715, 'p_miss': 0.2222737082102561}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:26:19,053] Trial 80 finished with value: 0.20033360046627807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 72 with value: 0.10560556684781057.
running
[I 2024-10-30 20:26:49,680] Trial 81 finished with value: 0.10485009438164132 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 7, 'learning_rate': 0.0008369267893527308, 'p_miss': 0.2657143173681843}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:27:17,913] Trial 82 finished with value: 0.11261956686681521 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 6, 'learning_rate': 0.000488960455881073, 'p_miss': 0.26335310589284744}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:27:25,413] Trial 83 finished with value: 0.28100241216957755 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:27:48,076] Trial 84 finished with value: 0.13164972260041524 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6, 'learning_rate': 0.0016776672062761532, 'p_miss': 0.224148793822974}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:27:48,578] Trial 85 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:28:00,203] Trial 86 finished with value: 0.11680743268791918 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 2, 'learning_rate': 0.0007805090148300855, 'p_miss': 0.23705121922490527}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:28:06,334] Trial 87 finished with value: 0.11854704176207162 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 1, 'learning_rate': 0.0010612115360259169, 'p_miss': 0.2675782838957313}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:28:16,921] Trial 88 finished with value: 0.11049958316756822 and parameters: {'model_name': 'VAE', 'batch_size': 137, 'iterations': 2, 'learning_rate': 0.0005807378003162836, 'p_miss': 0.2848507520007276}. Best is trial 81 with value: 0.10485009438164132.
running
[I 2024-10-30 20:28:39,812] Trial 89 finished with value: 0.10478131578293944 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 4, 'learning_rate': 0.0002747011633474894, 'p_miss': 0.29468999868766055}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:30:52,273] Trial 90 finished with value: 0.10888013041262101 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 37, 'learning_rate': 0.0002822141739433052, 'p_miss': 0.2947010195793662}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:33:28,966] Trial 91 finished with value: 0.11118551098690196 and parameters: {'model_name': 'VAE', 'batch_size': 248, 'iterations': 42, 'learning_rate': 0.0002796578658166294, 'p_miss': 0.27197217985349215}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:42:52,324] Trial 23 finished with value: 0.20763314202988017 and parameters: {'model_name': 'VAE', 'batch_size': 995, 'iterations': 2318, 'learning_rate': 0.0521314705248884, 'p_miss': 0.17679028647845427}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:45:09,693] Trial 93 finished with value: 0.10511868877729687 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 36, 'learning_rate': 0.00016078120193608334, 'p_miss': 0.2991582807072421}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:45:19,815] Trial 94 finished with value: 0.20251066190038744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:45:39,346] Trial 29 finished with value: 0.3397254361530298 and parameters: {'model_name': 'GAIN', 'batch_size': 130, 'hint_rate': 0.3283237746351144, 'alpha': 34, 'iterations': 6693, 'learning_rate': 0.0017254478601795237, 'p_miss': 0.2875165528828413}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:47:48,920] Trial 96 finished with value: 0.11828383173808635 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 32, 'learning_rate': 0.00011447850751302767, 'p_miss': 0.298151405345608}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:48:56,089] Trial 95 finished with value: 0.10796109678540308 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 41, 'learning_rate': 0.00011371620168152349, 'p_miss': 0.29983020221515755}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:50:53,597] Trial 30 finished with value: 0.20777250649834295 and parameters: {'model_name': 'VAE', 'batch_size': 599, 'iterations': 2862, 'learning_rate': 0.00033339883710040277, 'p_miss': 0.19347669693908098}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:53:14,483] Trial 97 finished with value: 0.1096806640537115 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 90, 'learning_rate': 0.00016788681996659957, 'p_miss': 0.29769142450224784}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:54:26,790] Trial 99 finished with value: 0.11303725060794012 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 64, 'learning_rate': 0.00017545980237022532, 'p_miss': 0.29994683804892946}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:54:36,217] Trial 98 finished with value: 0.11222805063344028 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 97, 'learning_rate': 0.00017580223781442746, 'p_miss': 0.2984154902858183}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:59:02,184] Trial 92 finished with value: 0.1239736589210236 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 312, 'learning_rate': 0.00013827799085201965, 'p_miss': 0.29768623018703805}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:59:02,607] Trial 103 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 20:59:40,365] Trial 104 finished with value: 0.11631500740308895 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 10, 'learning_rate': 0.0002571920410291824, 'p_miss': 0.25705223648673114}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:01:54,214] Trial 105 finished with value: 0.10913915898819784 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 28, 'learning_rate': 0.00021755493128226865, 'p_miss': 0.27865657096047747}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:02:14,695] Trial 106 finished with value: 0.11363103949894382 and parameters: {'model_name': 'VAE', 'batch_size': 314, 'iterations': 4, 'learning_rate': 0.0003574920480107356, 'p_miss': 0.21358813426729867}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:04:26,815] Trial 101 finished with value: 0.11184263353703368 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 132, 'learning_rate': 0.00020040319294897322, 'p_miss': 0.2846132959538213}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:05:36,041] Trial 100 finished with value: 0.11244287348194419 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 187, 'learning_rate': 0.0001903234876142074, 'p_miss': 0.2876685096453765}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:05:55,817] Trial 108 finished with value: 0.11080144951025468 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 25, 'learning_rate': 0.0001056720196105461, 'p_miss': 0.26103478240849115}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:08:23,952] Trial 109 finished with value: 0.10504134532233411 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 44, 'learning_rate': 0.00010587911222360084, 'p_miss': 0.2424484910453755}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:08:42,133] Trial 110 finished with value: 0.13598288345066836 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 43, 'learning_rate': 0.0031500405103699765, 'p_miss': 0.2446696929680114}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:09:26,082] Trial 112 finished with value: 0.1074212381402061 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 9, 'learning_rate': 0.0002880235490034583, 'p_miss': 0.2735466995098117}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:09:46,725] Trial 113 finished with value: 0.3276312280745789 and parameters: {'model_name': 'GAIN', 'batch_size': 80, 'hint_rate': 0.9766674872168291, 'alpha': 29, 'iterations': 10, 'learning_rate': 0.0001372335363935, 'p_miss': 0.2748530859976745}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:09:55,419] Trial 114 finished with value: 0.20631797257220605 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:10:27,498] Trial 115 finished with value: 0.11097862493044246 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 8, 'learning_rate': 0.00010002807797563373, 'p_miss': 0.16155953510011445}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:11:28,528] Trial 111 finished with value: 0.1103404552323477 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 53, 'learning_rate': 0.0001372391535292696, 'p_miss': 0.24729801644344623}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:11:56,277] Trial 107 finished with value: 0.12043960042026344 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 146, 'learning_rate': 0.0004347253442288439, 'p_miss': 0.2855378379392187}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:12:12,486] Trial 118 finished with value: 0.1123708970183371 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 4, 'learning_rate': 0.00029476415823616407, 'p_miss': 0.2680108316634329}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:12:52,099] Trial 117 finished with value: 0.11700418540456754 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 23, 'learning_rate': 0.00044233083609913605, 'p_miss': 0.28953199624766607}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:13:14,992] Trial 116 finished with value: 0.1065111011710738 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 44, 'learning_rate': 0.0002798754458141097, 'p_miss': 0.28945438867538364}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:13:29,670] Trial 121 finished with value: 0.11976752398096127 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0005726942860168353, 'p_miss': 0.27822475845032846}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:14:47,679] Trial 119 finished with value: 0.10519060760379433 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 37, 'learning_rate': 0.0002664041522834153, 'p_miss': 0.29184229181640053}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:15:59,464] Trial 120 finished with value: 0.1146950240003298 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 40, 'learning_rate': 0.0005629328238297654, 'p_miss': 0.27813929071596216}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:17:04,520] Trial 122 finished with value: 0.11378591489847137 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 60, 'learning_rate': 0.00021761850325719746, 'p_miss': 0.212923868564052}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:18:24,451] Trial 125 finished with value: 0.10882593648394065 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 22, 'learning_rate': 0.0003324075283168874, 'p_miss': 0.2900882945528695}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:18:32,559] Trial 123 finished with value: 0.11212514574434636 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 65, 'learning_rate': 0.00036363466334350756, 'p_miss': 0.27382024864217264}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:19:25,331] Trial 127 finished with value: 0.11290113160187991 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 11, 'learning_rate': 0.0020544288783883435, 'p_miss': 0.12550503374430755}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:02,293] Trial 128 finished with value: 0.1155643651212503 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 8, 'learning_rate': 0.004822520476017162, 'p_miss': 0.2536063903037548}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:04,619] Trial 124 finished with value: 0.10981031068561245 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 71, 'learning_rate': 0.000248108609789708, 'p_miss': 0.26018341278658885}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:04,913] Trial 130 finished with value: 0.20033360046627807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:28,748] Trial 129 finished with value: 0.10888487843211048 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 5, 'learning_rate': 0.0012864264610900479, 'p_miss': 0.241928553863964}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:30,722] Trial 131 finished with value: 0.10739080228242068 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 5, 'learning_rate': 0.00016240591362880883, 'p_miss': 0.24031251186156574}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:40,295] Trial 133 finished with value: 0.32325364472495355 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.05534468495837919, 'alpha': 23, 'iterations': 5, 'learning_rate': 0.00014816066725542465, 'p_miss': 0.28163544667763957}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:20:40,867] Trial 132 finished with value: 0.12744012351392037 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 3, 'learning_rate': 0.0001183747005420168, 'p_miss': 0.2672697347871823}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:22:00,766] Trial 135 finished with value: 0.21338730903985015 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 18, 'learning_rate': 0.03167654311722166, 'p_miss': 0.29120506328039997}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:22:21,281] Trial 102 finished with value: 0.14257007955905385 and parameters: {'model_name': 'VAE', 'batch_size': 295, 'iterations': 302, 'learning_rate': 0.0002501872497860889, 'p_miss': 0.28142183475015337}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:22:37,622] Trial 126 finished with value: 0.1305947029490468 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 74, 'learning_rate': 0.0012625207601680208, 'p_miss': 0.24154576677241163}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:23:18,960] Trial 138 finished with value: 0.11151610383222606 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 8, 'learning_rate': 0.0019657061502726977, 'p_miss': 0.2259106440072367}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:24:29,383] Trial 41 finished with value: 0.20649588374094816 and parameters: {'model_name': 'VAE', 'batch_size': 739, 'iterations': 3165, 'learning_rate': 0.013850478089494805, 'p_miss': 0.0960017817214704}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:25:25,429] Trial 136 finished with value: 0.11186843154384807 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 48, 'learning_rate': 0.00022926122612367453, 'p_miss': 0.21857142718021078}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:25:28,319] Trial 137 finished with value: 0.114001736422777 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 51, 'learning_rate': 0.00015295405393335118, 'p_miss': 0.2208526738718013}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:25:43,221] Trial 142 finished with value: 0.26613091312654286 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:26:00,247] Trial 139 finished with value: 0.10828244039874499 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 47, 'learning_rate': 0.0001594094623906428, 'p_miss': 0.2204411794005142}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:26:58,838] Trial 140 finished with value: 0.10921322469667114 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 51, 'learning_rate': 0.00021599670168899983, 'p_miss': 0.21775726872863665}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:27:00,109] Trial 145 finished with value: 0.2416434106794894 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2967, 'weights': 'distance'}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:27:38,322] Trial 141 finished with value: 0.10651757095887875 and parameters: {'model_name': 'VAE', 'batch_size': 165, 'iterations': 35, 'learning_rate': 0.00015567153148726131, 'p_miss': 0.23171649786614829}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:27:51,973] Trial 143 finished with value: 0.13594801929093217 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 31, 'learning_rate': 0.002724693000904268, 'p_miss': 0.2357533787617167}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:28:04,654] Trial 144 finished with value: 0.13090795714355202 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 32, 'learning_rate': 0.002729517032748634, 'p_miss': 0.20257383484238545}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:29:19,079] Trial 146 finished with value: 0.14531789207764154 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 32, 'learning_rate': 0.0027847148616386153, 'p_miss': 0.23173182836713943}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:29:19,388] Trial 147 finished with value: 0.1283764557321778 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 29, 'learning_rate': 0.0028189580748117058, 'p_miss': 0.23317209779808631}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:29:40,690] Trial 149 finished with value: 0.11345806473969278 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 19, 'learning_rate': 0.00011968321654096616, 'p_miss': 0.231010017784283}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:02,995] Trial 152 finished with value: 0.10767789776946195 and parameters: {'model_name': 'VAE', 'batch_size': 138, 'iterations': 5, 'learning_rate': 0.00018777015691172734, 'p_miss': 0.25027555801313317}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:14,823] Trial 151 finished with value: 0.10670616681642738 and parameters: {'model_name': 'VAE', 'batch_size': 148, 'iterations': 12, 'learning_rate': 0.00012584238856616018, 'p_miss': 0.2920550774703878}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:20,097] Trial 148 finished with value: 0.11161846340048123 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 33, 'learning_rate': 0.0001260193773551001, 'p_miss': 0.23052311258449074}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:34,762] Trial 154 finished with value: 0.11581410560784806 and parameters: {'model_name': 'VAE', 'batch_size': 170, 'iterations': 5, 'learning_rate': 0.0003136774444138726, 'p_miss': 0.25328533040149726}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:38,856] Trial 150 finished with value: 0.1093874865911834 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 20, 'learning_rate': 0.00011894781007754726, 'p_miss': 0.2524245802903654}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:40,859] Trial 155 finished with value: 0.10895494333230385 and parameters: {'model_name': 'VAE', 'batch_size': 159, 'iterations': 5, 'learning_rate': 0.0003057540154194668, 'p_miss': 0.2514691898286749}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:30:50,308] Trial 153 finished with value: 0.10873420069264132 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 12, 'learning_rate': 0.0001733893478182171, 'p_miss': 0.2519566591522337}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:07,532] Trial 159 finished with value: 0.11725316302658648 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 4, 'learning_rate': 0.00018049176352544119, 'p_miss': 0.2933562512606795}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:08,074] Trial 160 finished with value: 0.36537692257230087 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:14,235] Trial 157 finished with value: 0.11207720135203476 and parameters: {'model_name': 'VAE', 'batch_size': 183, 'iterations': 7, 'learning_rate': 0.00016931529841768028, 'p_miss': 0.2683806487380133}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:39,720] Trial 161 finished with value: 0.10951562842349945 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 7, 'learning_rate': 0.00019729575974066388, 'p_miss': 0.2684332811237182}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:45,350] Trial 156 finished with value: 0.12184633551697999 and parameters: {'model_name': 'VAE', 'batch_size': 196, 'iterations': 13, 'learning_rate': 0.00018622786538485489, 'p_miss': 0.28926305633829363}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:31:45,869] Trial 158 finished with value: 0.10927957617496191 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 13, 'learning_rate': 0.00016365688088119487, 'p_miss': 0.29048841265363445}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:00,157] Trial 164 finished with value: 0.12159054641649296 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 3, 'learning_rate': 0.0009079207217517776, 'p_miss': 0.2828763394857497}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:16,137] Trial 165 finished with value: 0.11421144677435917 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 9, 'learning_rate': 0.0001455508728610388, 'p_miss': 0.28426536421761994}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:20,903] Trial 166 finished with value: 0.10633037446584322 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 4, 'learning_rate': 0.003529222378110605, 'p_miss': 0.2412521832829889}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:28,291] Trial 162 finished with value: 0.1049536623776954 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 14, 'learning_rate': 0.00020244615642685563, 'p_miss': 0.2920164176550113}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:29,885] Trial 168 finished with value: 0.32881645110875446 and parameters: {'model_name': 'GAIN', 'batch_size': 92, 'hint_rate': 0.7883156554793562, 'alpha': 99, 'iterations': 4, 'learning_rate': 0.005045673097357465, 'p_miss': 0.2419278886794977}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:34,044] Trial 163 finished with value: 0.10722753560606306 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 14, 'learning_rate': 0.00039351050184357133, 'p_miss': 0.04354026542811165}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:52,902] Trial 169 finished with value: 0.10956652817019281 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 4, 'learning_rate': 0.005227232970748307, 'p_miss': 0.2384265294709024}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:32:57,236] Trial 170 finished with value: 0.11583176678489929 and parameters: {'model_name': 'VAE', 'batch_size': 128, 'iterations': 6, 'learning_rate': 0.0004022865482773226, 'p_miss': 0.2395688953255013}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:33:03,515] Trial 171 finished with value: 0.10931758807972417 and parameters: {'model_name': 'VAE', 'batch_size': 250, 'iterations': 6, 'learning_rate': 0.0003954557740806023, 'p_miss': 0.026356749654277062}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:33:58,387] Trial 172 finished with value: 0.10871891742186779 and parameters: {'model_name': 'VAE', 'batch_size': 242, 'iterations': 16, 'learning_rate': 0.000259721093964955, 'p_miss': 0.0705259771481053}. Best is trial 89 with value: 0.10478131578293944.
running
[I 2024-10-30 21:34:13,208] Trial 173 finished with value: 0.10377253621104095 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 16, 'learning_rate': 0.0002612763459827826, 'p_miss': 0.1285267092910324}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:35:50,699] Trial 176 finished with value: 0.12290060098251884 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 25, 'learning_rate': 0.003731940656598889, 'p_miss': 0.05572758049322951}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:36:30,814] Trial 177 finished with value: 0.10817542568565788 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 10, 'learning_rate': 0.0002366958779065686, 'p_miss': 0.11750216311933151}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:37:32,200] Trial 178 finished with value: 0.11804465720952051 and parameters: {'model_name': 'VAE', 'batch_size': 198, 'iterations': 15, 'learning_rate': 0.0002794396442588495, 'p_miss': 0.16775026538378382}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:39:02,140] Trial 167 finished with value: 0.11082901236654474 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 96, 'learning_rate': 0.000107165919110003, 'p_miss': 0.23891390353534156}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:43:28,397] Trial 174 finished with value: 0.22522358723037866 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:43:31,711] Trial 181 finished with value: 0.24126512203289435 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1926, 'weights': 'distance'}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:43:57,926] Trial 175 finished with value: 0.2262276684303904 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:44:13,575] Trial 182 finished with value: 0.11769050212594667 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 9, 'learning_rate': 0.0002066164578352083, 'p_miss': 0.09570788493626263}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:44:22,118] Trial 183 finished with value: 0.1089384505724434 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 7, 'learning_rate': 0.00020761192851341995, 'p_miss': 0.10072671236199833}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:44:27,946] Trial 184 finished with value: 0.10560832052274712 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 3, 'learning_rate': 0.0003352869234295779, 'p_miss': 0.2585893407608789}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:44:42,135] Trial 186 finished with value: 0.11152998082977679 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 3, 'learning_rate': 0.0003446985838709523, 'p_miss': 0.2603621257447673}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:45:06,069] Trial 187 finished with value: 0.11482233190140378 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 5, 'learning_rate': 0.0005100362169572246, 'p_miss': 0.24644838701342614}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:45:49,940] Trial 185 finished with value: 0.13224934311628117 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 21, 'learning_rate': 0.004057277156868633, 'p_miss': 0.1890484070621332}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:46:00,643] Trial 188 finished with value: 0.10487035883077485 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 12, 'learning_rate': 0.00025844219308981476, 'p_miss': 0.18835350684775057}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:46:05,656] Trial 189 finished with value: 0.1119812949042696 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 3, 'learning_rate': 0.000252398817072373, 'p_miss': 0.2730276335357169}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:46:45,279] Trial 190 finished with value: 0.11643315997469046 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 12, 'learning_rate': 0.0002559673048220192, 'p_miss': 0.29999035285963266}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:46:46,613] Trial 134 finished with value: 0.11611897658825501 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 371, 'learning_rate': 0.00012267689811235697, 'p_miss': 0.26512451666746323}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:47:16,511] Trial 191 finished with value: 0.1190407925557438 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 16, 'learning_rate': 0.0003129518427881297, 'p_miss': 0.27825045958592015}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:47:54,239] Trial 179 finished with value: 0.2246053998494122 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:47:58,071] Trial 193 finished with value: 0.11347587064334567 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 17, 'learning_rate': 0.00030004304667086227, 'p_miss': 0.14827570190476153}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:48:36,402] Trial 196 finished with value: 0.1078907768271103 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 11, 'learning_rate': 0.0035137856274009053, 'p_miss': 0.15562890829467518}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:48:51,636] Trial 194 finished with value: 0.1288103055152637 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 24, 'learning_rate': 0.0035286806789837813, 'p_miss': 0.15926615418926968}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:49:29,180] Trial 195 finished with value: 0.11413083319799744 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 26, 'learning_rate': 0.0003694158032344619, 'p_miss': 0.2936070067351386}. Best is trial 173 with value: 0.10377253621104095.
running
[I 2024-10-30 21:49:29,409] Trial 180 finished with value: 0.22647022846303438 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 21:49:30,544] Trial 198 finished with value: 0.10660063181636885 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 8, 'learning_rate': 0.00014354632285479762, 'p_miss': 0.29201334125660044}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 21:49:55,231] Trial 199 finished with value: 0.11209607954276257 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 8, 'learning_rate': 0.00022546909319977234, 'p_miss': 0.2592472417112957}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 21:51:10,351] Trial 197 finished with value: 0.11060811484168986 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 40, 'learning_rate': 0.00037608322815842454, 'p_miss': 0.29225116519382976}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 22:10:28,550] Trial 40 finished with value: 0.20733236747789405 and parameters: {'model_name': 'VAE', 'batch_size': 451, 'iterations': 4252, 'learning_rate': 0.014588584504902639, 'p_miss': 0.10341212337437336}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 22:14:49,408] Trial 32 finished with value: 0.19573425854406984 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5123, 'learning_rate': 0.0001508660910043241, 'p_miss': 0.29839345493143976}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 22:57:00,402] Trial 33 finished with value: 0.20820484076977436 and parameters: {'model_name': 'VAE', 'batch_size': 965, 'iterations': 4465, 'learning_rate': 0.07075575086177853, 'p_miss': 0.08019536712332906}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 23:24:44,961] Trial 38 finished with value: 0.20739674738183905 and parameters: {'model_name': 'VAE', 'batch_size': 787, 'iterations': 5522, 'learning_rate': 0.019350321537710838, 'p_miss': 0.0878199073430314}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 23:31:48,794] Trial 46 finished with value: 0.20916742876532898 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5663, 'learning_rate': 0.008681993340553166, 'p_miss': 0.13513947999019624}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-30 23:49:30,655] Trial 0 finished with value: 0.21859090382690063 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 6760, 'learning_rate': 0.007493108899752867, 'p_miss': 0.026586873109296083}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:13:13,626] Trial 44 finished with value: 0.20837604935197987 and parameters: {'model_name': 'VAE', 'batch_size': 972, 'iterations': 6194, 'learning_rate': 0.01083158701763387, 'p_miss': 0.10875832973551036}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:15:14,418] Trial 39 finished with value: 0.20752612694308076 and parameters: {'model_name': 'VAE', 'batch_size': 921, 'iterations': 7353, 'learning_rate': 0.01333090659333759, 'p_miss': 0.0975033081465487}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:18:02,597] Trial 37 finished with value: 0.20760244907552922 and parameters: {'model_name': 'VAE', 'batch_size': 542, 'iterations': 9200, 'learning_rate': 0.018429138676615237, 'p_miss': 0.08494844672275641}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:18:13,497] Trial 42 finished with value: 0.2082090224598848 and parameters: {'model_name': 'VAE', 'batch_size': 428, 'iterations': 9670, 'learning_rate': 0.01817100227042625, 'p_miss': 0.09684206566474765}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:24:40,436] Trial 34 finished with value: 0.2070818247356792 and parameters: {'model_name': 'VAE', 'batch_size': 751, 'iterations': 9866, 'learning_rate': 0.07375566267833898, 'p_miss': 0.015894088407025553}. Best is trial 173 with value: 0.10377253621104095.
[I 2024-10-31 00:25:36,186] Trial 192 finished with value: 0.21323543169682974 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 9793, 'learning_rate': 0.00030984523869724475, 'p_miss': 0.15335523604788312}. Best is trial 173 with value: 0.10377253621104095.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.10377253621104095
{'model_name': 'VAE', 'batch_size': 111, 'iterations': 16, 'learning_rate': 0.0002612763459827826, 'p_miss': 0.1285267092910324}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5109207098573789
Generation:   4%|         | 1/25 [03:19<1:19:52, 199.68s/it]Generation:  2
Best f1_score score: 0.5109207098573789
Generation:   8%|         | 2/25 [04:09<42:42, 111.40s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e29f00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  3
Best f1_score score: 0.5129748897360752
Generation:  12%|        | 3/25 [04:23<24:35, 67.07s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e2a860> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2e4d0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  4
Best f1_score score: 0.5136948173694111
Generation:  16%|        | 4/25 [04:33<15:34, 44.48s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c3d540> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b15f00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  5
Best f1_score score: 0.5136948173694111
Generation:  20%|        | 5/25 [06:47<25:32, 76.63s/it]Generation:  6
Best f1_score score: 0.5136948173694111
Generation:  24%|       | 6/25 [06:54<16:50, 53.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659a3ac0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.5181819929918999
Generation:  28%|       | 7/25 [07:03<11:33, 38.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fb640> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5181819929918999
Generation:  32%|      | 8/25 [07:12<08:17, 29.29s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0a200> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5181819929918999
Generation:  36%|      | 9/25 [07:20<06:00, 22.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465c0ea70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5181819929918999
Generation:  40%|      | 10/25 [07:28<04:33, 18.25s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e12890> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5181819929918999
Generation:  44%|     | 11/25 [07:40<03:44, 16.05s/it]Generation:  12
Best f1_score score: 0.5185286033749507
Generation:  48%|     | 12/25 [07:49<03:03, 14.12s/it]Generation:  13
Best f1_score score: 0.5215873904197366
Generation:  52%|    | 13/25 [07:59<02:33, 12.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658a2ef0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.5215873904197366
Generation:  56%|    | 14/25 [08:13<02:24, 13.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e0cd00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  15
Best f1_score score: 0.5215873904197366
Generation:  60%|    | 15/25 [08:24<02:05, 12.53s/it]Generation:  16
Best f1_score score: 0.5215873904197366
Generation:  64%|   | 16/25 [08:35<01:48, 12.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554653fa8c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.5215873904197366
Generation:  68%|   | 17/25 [08:52<01:48, 13.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658eaef0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.5215873904197366
Generation:  72%|  | 18/25 [09:08<01:40, 14.41s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546574fb80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655c8d00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  19
Best f1_score score: 0.5215873904197366
Generation:  76%|  | 19/25 [09:26<01:32, 15.42s/it]Generation:  20
Best f1_score score: 0.5215873904197366
Generation:  80%|  | 20/25 [09:55<01:37, 19.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471aad0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  21
Best f1_score score: 0.5215873904197366
Generation:  84%| | 21/25 [10:13<01:16, 19.06s/it]Generation:  22
Best f1_score score: 0.5215873904197366
Generation:  88%| | 22/25 [10:36<01:00, 20.21s/it]Generation:  23
Best f1_score score: 0.5215873904197366
Generation:  92%|| 23/25 [10:53<00:38, 19.32s/it]Generation:  24
Best f1_score score: 0.5215873904197366
Generation:  96%|| 24/25 [11:23<00:22, 22.36s/it]Generation:  25
Best f1_score score: 0.5215873904197366
Generation: 100%|| 25/25 [11:43<00:00, 21.85s/it]Generation: 100%|| 25/25 [11:47<00:00, 28.29s/it]
2024-10-31 00:37:34,210 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:40423' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-2c00092ba1cd743626b416db9c976854', 'ndarray-57e1a86eacd807ff02efa5ec974536d8'} (stimulus_id='handle-worker-cleanup-1730360254.2104127')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(criterion='entropy',
                                      max_features=0.9282073101504,
                                      min_samples_leaf=7, min_samples_split=9,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.8759717562141099, 'accuracy': 0.7936972059779077, 'balanced_accuracy': 0.7936972059779077, 'logloss': 0.6060406526387923, 'f1': 0.7936856861019965}
original test score: {'auroc': 0.4992005397200202, 'accuracy': 0.4857142857142857, 'balanced_accuracy': 0.4857142857142857, 'logloss': 0.6959797233094348, 'f1': 0.45803947218746444}
imputed test score: {'auroc': 0.5106088716478326, 'accuracy': 0.5077922077922078, 'balanced_accuracy': 0.5077922077922077, 'logloss': 0.6998340176194194, 'f1': 0.5077714526670883}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4c40> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4910> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4af0> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 727, in predict
    pred = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 788, in decision_function
    X = self._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.5142576064043645
Generation:   4%|         | 1/25 [00:54<21:50, 54.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d2ba90> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.5158423879518873
Generation:   8%|         | 2/25 [02:22<28:28, 74.29s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745996c0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 904, in predict
    proba = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 946, in predict_proba
    X = self._validate_X_predict(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547404ceb0> 
 Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 732, in fit
    X, y = self._check_X_y(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 1184, in _check_X_y
    X, y = super()._check_X_y(X, y, reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 578, in _check_X_y
    return self._validate_data(X, y, accept_sparse="csr", reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  3
Best f1_score score: 0.5158423879518873
Generation:  12%|        | 3/25 [05:48<49:18, 134.49s/it]Generation:  4
Best f1_score score: 0.5226411063226708
Generation:  16%|        | 4/25 [08:50<53:36, 153.17s/it]Generation:  5
Best f1_score score: 0.5226411063226708
Generation:  20%|        | 5/25 [09:40<38:40, 116.04s/it]Generation:  6
Best f1_score score: 0.5316394106726807
Generation:  24%|       | 6/25 [11:26<35:40, 112.65s/it]Generation:  7
Best f1_score score: 0.5316394106726807
Generation:  28%|       | 7/25 [13:11<32:57, 109.88s/it]Generation:  8
Best f1_score score: 0.5316394106726807
Generation:  32%|      | 8/25 [13:29<22:51, 80.65s/it] Generation:  9
Best f1_score score: 0.5316394106726807
Generation:  36%|      | 9/25 [19:38<45:34, 170.90s/it]Generation:  10
Best f1_score score: 0.5316394106726807
Generation:  40%|      | 10/25 [21:56<40:09, 160.66s/it]Generation:  11
Best f1_score score: 0.5365110499469796
Generation:  44%|     | 11/25 [22:22<27:54, 119.62s/it]Generation:  12
Best f1_score score: 0.5365110499469796
Generation:  48%|     | 12/25 [22:36<18:57, 87.52s/it] Generation:  13
Best f1_score score: 0.5365110499469796
Generation:  52%|    | 13/25 [24:32<19:11, 95.97s/it]Generation:  14
Best f1_score score: 0.5365110499469796
Generation:  56%|    | 14/25 [24:57<13:40, 74.58s/it]Generation:  15
Best f1_score score: 0.5365110499469796
Generation:  60%|    | 15/25 [27:05<15:06, 90.65s/it]Generation:  16
Best f1_score score: 0.5365110499469796
Generation:  64%|   | 16/25 [27:26<10:28, 69.85s/it]Generation:  17
Best f1_score score: 0.5365110499469796
Generation:  68%|   | 17/25 [28:55<10:02, 75.36s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545752e740> 
 Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 101, in predict
    X = self._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 1178, in _check_X
    X = super()._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 574, in _check_X
    return self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  18
Best f1_score score: 0.5365110499469796
Generation:  72%|  | 18/25 [29:46<07:57, 68.16s/it]Generation:  19
Best f1_score score: 0.5365110499469796
Generation:  76%|  | 19/25 [30:01<05:13, 52.24s/it]Generation:  20
Best f1_score score: 0.5365110499469796
Generation:  80%|  | 20/25 [31:51<05:48, 69.67s/it]Generation:  21
Best f1_score score: 0.5365110499469796
Generation:  84%| | 21/25 [32:25<03:54, 58.70s/it]Generation:  22
Best f1_score score: 0.5365110499469796
Generation:  88%| | 22/25 [35:27<04:47, 95.99s/it]Generation:  23
Best f1_score score: 0.5365110499469796
Generation:  92%|| 23/25 [35:43<02:23, 71.76s/it]Generation:  24
Best f1_score score: 0.5365110499469796
Generation:  96%|| 24/25 [36:03<00:56, 56.32s/it]Generation:  25
Best f1_score score: 0.5365110499469796
Generation: 100%|| 25/25 [36:19<00:00, 44.25s/it]Generation: 100%|| 25/25 [36:19<00:00, 87.18s/it]
2024-10-31 01:14:02,625 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41093' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-2c00092ba1cd743626b416db9c976854', 'DataFrame-4ac3425fa56c19a8f2109f40a8716b13'} (stimulus_id='handle-worker-cleanup-1730362442.6255202')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='most_frequent')),
                ('randomforestclassifier',
                 RandomForestClassifier(bootstrap=False, criterion='entropy',
                                        max_features=0.5976552888462,
                                        min_samples_leaf=17,
                                        min_samples_split=8,
                                        n_estimators=128))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8283688428348324, 'accuracy': 0.7394411955815464, 'balanced_accuracy': 0.7394411955815464, 'logloss': 0.591571623030392, 'f1': 0.7392280437846095}
test score: {'auroc': 0.4793590824759656, 'accuracy': 0.4792207792207792, 'balanced_accuracy': 0.4792207792207792, 'logloss': 0.7211232585656917, 'f1': 0.4791144760526267}
original test score: {'auroc': 0.47549333783100023, 'accuracy': 0.4701298701298701, 'balanced_accuracy': 0.4701298701298701, 'logloss': 0.7230184239753729, 'f1': 0.46806277048947165}
score end
871
lvl
0.5
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
8.01158717446857
hours
DONE
