Run: 36
/cm/local/apps/slurm/var/spool/job1069603/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40922/40922.pkl
working on 
../data/c/40922/class_full_MNAR_0.5_2
2.6031298637390137
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-24 02:35:17,688] A new study created in memory with name: no-name-d65687cf-8a1d-4329-ada1-7baea2b3487a
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-24 02:35:18,218] Trial 3 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.36825608645803265.
running
[I 2024-11-24 02:35:18,363] Trial 7 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.36825608645803265.
running
[I 2024-11-24 02:35:18,736] Trial 5 finished with value: 0.1933475769513514 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 5 with value: 0.1933475769513514.
running
[I 2024-11-24 02:35:24,563] Trial 13 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7230300267077953, 'alpha': 78, 'iterations': 1, 'learning_rate': 0.045069711717845684, 'p_miss': 0.27699294555167264}. Best is trial 5 with value: 0.1933475769513514.
running
[I 2024-11-24 02:35:28,198] Trial 6 finished with value: 0.32709737444051035 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.47653808059309377, 'alpha': 48, 'iterations': 1, 'learning_rate': 0.00011122294477058727, 'p_miss': 0.2321632971458039}. Best is trial 5 with value: 0.1933475769513514.
running
[I 2024-11-24 02:35:29,379] Trial 20 finished with value: 0.1933475769513514 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 5 with value: 0.1933475769513514.
running
[I 2024-11-24 02:35:30,551] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.47453697158144353, 'alpha': 62, 'iterations': 17, 'learning_rate': 0.0021097274159098153, 'p_miss': 0.04232456362285988}. Best is trial 5 with value: 0.1933475769513514.
running
[I 2024-11-24 02:35:37,897] Trial 17 finished with value: 0.10094503268180752 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 2, 'learning_rate': 0.01417863231567491, 'p_miss': 0.1880804116763376}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:35:38,257] Trial 11 finished with value: 0.10730094892652393 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.010080074736868066, 'p_miss': 0.05350065054442422}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:35:39,061] Trial 23 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:35:39,979] Trial 24 finished with value: 0.286277927056752 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:21,142] Trial 10 finished with value: 0.20598004816536872 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:22,351] Trial 15 finished with value: 0.18751359459171207 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 540, 'weights': 'uniform'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:35,419] Trial 22 finished with value: 0.20306863958726332 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:37,028] Trial 18 finished with value: 0.19173910802322608 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12689, 'weights': 'uniform'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:40,488] Trial 2 finished with value: 0.1919149927486265 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20203, 'weights': 'uniform'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:36:47,836] Trial 0 finished with value: 0.19209104868494137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31771, 'weights': 'uniform'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:37:14,617] Trial 25 finished with value: 0.21272630576985696 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 68458, 'weights': 'distance'}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:40:49,525] Trial 28 finished with value: 0.2044056113675302 and parameters: {'model_name': 'VAE', 'batch_size': 450, 'iterations': 56, 'learning_rate': 0.013614395048806686, 'p_miss': 0.1049427139310722}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:41:11,981] Trial 31 finished with value: 0.20306536711539785 and parameters: {'model_name': 'VAE', 'batch_size': 624, 'iterations': 58, 'learning_rate': 0.015983309811931034, 'p_miss': 0.1091377502370236}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:41:22,016] Trial 27 finished with value: 0.20388817312893365 and parameters: {'model_name': 'VAE', 'batch_size': 652, 'iterations': 63, 'learning_rate': 0.015824271343553457, 'p_miss': 0.10960450955265702}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:41:27,367] Trial 12 finished with value: 0.20435738093700412 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 104, 'learning_rate': 0.02797833350494341, 'p_miss': 0.062079700342577405}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:42:21,607] Trial 30 finished with value: 0.20373687824110975 and parameters: {'model_name': 'VAE', 'batch_size': 486, 'iterations': 76, 'learning_rate': 0.014274585848622873, 'p_miss': 0.1006643453915244}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:46:58,728] Trial 4 finished with value: 0.20290940431516075 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 236, 'learning_rate': 0.033269810720741706, 'p_miss': 0.14914261585472186}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:47:17,246] Trial 39 finished with value: 0.10432344976939949 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0026203474363721913, 'p_miss': 0.1968719797729556}. Best is trial 17 with value: 0.10094503268180752.
running
[I 2024-11-24 02:47:35,640] Trial 40 finished with value: 0.09387341193472527 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5, 'learning_rate': 0.0024037112948925676, 'p_miss': 0.19430898020980844}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 02:48:36,288] Trial 1 finished with value: 0.3389577690024705 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.9730651848528344, 'alpha': 59, 'iterations': 528, 'learning_rate': 0.007808887189817121, 'p_miss': 0.19890258006065106}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 02:48:58,464] Trial 42 finished with value: 0.0990836288752446 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.0013661871706995598, 'p_miss': 0.199201026497965}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 02:49:20,203] Trial 43 finished with value: 0.1135474614578528 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7, 'learning_rate': 0.0007365805712173998, 'p_miss': 0.18214888177800959}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 02:49:29,606] Trial 44 finished with value: 0.10274052049301526 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 2, 'learning_rate': 0.0008639163006929885, 'p_miss': 0.24832701986975556}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:29:51,387] Trial 16 finished with value: 0.3539692218343227 and parameters: {'model_name': 'GAIN', 'batch_size': 366, 'hint_rate': 0.8243454894295154, 'alpha': 13, 'iterations': 2033, 'learning_rate': 0.002086525145151673, 'p_miss': 0.08935301210385226}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:30:02,372] Trial 46 finished with value: 0.09604397771296486 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 2, 'learning_rate': 0.0009019139415891315, 'p_miss': 0.24756291318463278}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:30:29,845] Trial 21 finished with value: 0.20867197622569425 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:30:56,362] Trial 47 finished with value: 0.10209461565635143 and parameters: {'model_name': 'VAE', 'batch_size': 115, 'iterations': 14, 'learning_rate': 0.0005330977223852959, 'p_miss': 0.23020042595101298}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:05,170] Trial 49 finished with value: 0.10574275076954416 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.001083289194514264, 'p_miss': 0.15084599699982748}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:25,403] Trial 48 finished with value: 0.10663580245756632 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 14, 'learning_rate': 0.0006788673175111866, 'p_miss': 0.2326767413909929}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:34,805] Trial 51 finished with value: 0.1029149017182939 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.004757101779773718, 'p_miss': 0.17402028381498152}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:41,310] Trial 52 finished with value: 0.09669770552503461 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00029384148029566775, 'p_miss': 0.2939382149815255}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:47,024] Trial 53 finished with value: 0.10093826794574907 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0002623887893937209, 'p_miss': 0.2998527877142718}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:31:55,086] Trial 50 finished with value: 0.24262630338113675 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 17, 'learning_rate': 0.09673763209850468, 'p_miss': 0.2863403351089026}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:32:01,286] Trial 54 finished with value: 0.09508222223458132 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.00027519084640338637, 'p_miss': 0.263704537313437}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:32:06,919] Trial 55 finished with value: 0.18946582153106564 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.09387341193472527.
running
[I 2024-11-24 03:32:13,281] Trial 56 finished with value: 0.09378837409608833 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 6, 'learning_rate': 0.00032039168134821553, 'p_miss': 0.260260996481348}. Best is trial 56 with value: 0.09378837409608833.
running
[I 2024-11-24 03:32:32,510] Trial 57 finished with value: 0.10370268893820116 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.00028223917298297966, 'p_miss': 0.25602675404092423}. Best is trial 56 with value: 0.09378837409608833.
running
[I 2024-11-24 03:32:32,869] Trial 58 finished with value: 0.09270266166187567 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 4, 'learning_rate': 0.00031007878120030663, 'p_miss': 0.261659904413496}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:32:44,298] Trial 59 finished with value: 0.0965962677510814 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0003186476831088327, 'p_miss': 0.2692836601457055}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:32:46,171] Trial 60 finished with value: 0.09745847949208078 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.000162117202617231, 'p_miss': 0.2621805663217724}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:34:08,007] Trial 62 finished with value: 0.21272630576985696 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 60783, 'weights': 'distance'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:34:20,274] Trial 61 finished with value: 0.10327628653880978 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 32, 'learning_rate': 0.00012945877377783108, 'p_miss': 0.21748587701581493}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:34:40,949] Trial 64 finished with value: 0.32802112845966286 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.012213949587552064, 'alpha': 4, 'iterations': 10, 'learning_rate': 0.0005187689181726255, 'p_miss': 0.24386556737972917}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:34:54,086] Trial 63 finished with value: 0.33666937148556564 and parameters: {'model_name': 'GAIN', 'batch_size': 40, 'hint_rate': 0.1094958745902147, 'alpha': 99, 'iterations': 26, 'learning_rate': 0.00043288167730498107, 'p_miss': 0.21408376969226234}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:35:07,882] Trial 66 finished with value: 0.09995874655863594 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.0002024300261050834, 'p_miss': 0.254250890697096}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:35:22,619] Trial 67 finished with value: 0.09967738914349926 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0003834453677656138, 'p_miss': 0.274629050256544}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:35:54,371] Trial 68 finished with value: 0.10199071603573755 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.004663429789150506, 'p_miss': 0.26424025063013806}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:36:05,567] Trial 69 finished with value: 0.10246823116565829 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 3, 'learning_rate': 0.0014417268401226478, 'p_miss': 0.27874626465029195}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:36:31,247] Trial 70 finished with value: 0.19181453961440825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:36:33,275] Trial 71 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:38:05,948] Trial 72 finished with value: 0.21271026994579872 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 47065, 'weights': 'distance'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 03:48:56,555] Trial 73 finished with value: 0.09910762093333678 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 185, 'learning_rate': 0.00021187793014649264, 'p_miss': 0.23732234712393382}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:07:09,709] Trial 36 finished with value: 0.20503427293459603 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 1617, 'learning_rate': 0.0016921400211637224, 'p_miss': 0.19310745496099477}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:28:40,234] Trial 74 finished with value: 0.1919653289675901 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 797, 'learning_rate': 0.00037845840745038715, 'p_miss': 0.2698980460202373}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:28:46,245] Trial 76 finished with value: 0.10083768942046112 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.00033321720440862134, 'p_miss': 0.29403625784631365}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:06,557] Trial 41 finished with value: 0.22517179450330987 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2440, 'learning_rate': 0.0019066492461232993, 'p_miss': 0.20559003834039224}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:12,586] Trial 78 finished with value: 0.09973612317721647 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00011066578839948194, 'p_miss': 0.28734742634584265}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:21,561] Trial 79 finished with value: 0.09478688984703779 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.000197332990602676, 'p_miss': 0.27167460797312054}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:31,199] Trial 80 finished with value: 0.11600567435036928 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.00017536476129248064, 'p_miss': 0.24727576627702014}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:32,512] Trial 81 finished with value: 0.286277927056752 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:34:52,148] Trial 82 finished with value: 0.09933066292012897 and parameters: {'model_name': 'VAE', 'batch_size': 973, 'iterations': 4, 'learning_rate': 0.0005920417051172853, 'p_miss': 0.2675883604380253}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:35:03,344] Trial 83 finished with value: 0.3302568956903823 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.2629232921315594, 'alpha': 29, 'iterations': 3, 'learning_rate': 0.0001465846038536584, 'p_miss': 0.22496343875161331}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:35:56,272] Trial 84 finished with value: 0.2679245166782802 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:36:14,865] Trial 85 finished with value: 0.1039511137903896 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 5, 'learning_rate': 0.0009946609896823557, 'p_miss': 0.1384916494066719}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:36:20,144] Trial 86 finished with value: 0.09625478702436471 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0002501154525186749, 'p_miss': 0.2819344571391034}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 04:36:31,626] Trial 87 finished with value: 0.09467128660645152 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.00021073761723379848, 'p_miss': 0.27820227381889495}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:03:56,155] Trial 9 finished with value: 0.20556342573211422 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 2508, 'learning_rate': 0.002749356314581285, 'p_miss': 0.14158940491530295}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:04:05,201] Trial 89 finished with value: 0.09804260700804229 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.00021863817791130215, 'p_miss': 0.28466324887647515}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:06:50,350] Trial 45 finished with value: 0.19683883104539868 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:06:55,967] Trial 91 finished with value: 0.10966737726922234 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.00010198437820034587, 'p_miss': 0.25698761653637625}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:07:22,937] Trial 37 finished with value: 0.20420182478802182 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 3105, 'learning_rate': 0.0023180867096280603, 'p_miss': 0.18750101373306655}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:07:30,209] Trial 92 finished with value: 0.10288562893509878 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 10, 'learning_rate': 0.00023420175714491934, 'p_miss': 0.2790768381489845}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:09:00,332] Trial 93 finished with value: 0.21270911404250228 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46339, 'weights': 'distance'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:09:09,282] Trial 94 finished with value: 0.21270882362452187 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46108, 'weights': 'distance'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:09:15,624] Trial 95 finished with value: 0.10082657628627359 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.0004236211170647384, 'p_miss': 0.016162259322211936}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:18:06,705] Trial 38 finished with value: 0.22604016983952752 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2720, 'learning_rate': 0.0028495668678491562, 'p_miss': 0.19063152487318755}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:18:19,571] Trial 98 finished with value: 0.09765669690286696 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.00032658967624250195, 'p_miss': 0.27037396743705017}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:18:29,540] Trial 99 finished with value: 0.09632645297021919 and parameters: {'model_name': 'VAE', 'batch_size': 293, 'iterations': 2, 'learning_rate': 0.0001734612654126473, 'p_miss': 0.24124581869761985}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:39:04,849] Trial 35 finished with value: 0.20188067281433336 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 3397, 'learning_rate': 0.002821367127727138, 'p_miss': 0.18639539183110151}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:39:14,854] Trial 101 finished with value: 0.10806056242160067 and parameters: {'model_name': 'VAE', 'batch_size': 214, 'iterations': 2, 'learning_rate': 0.00016620160354027298, 'p_miss': 0.23954394392690082}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:39:35,247] Trial 102 finished with value: 0.09566443761429103 and parameters: {'model_name': 'VAE', 'batch_size': 242, 'iterations': 4, 'learning_rate': 0.00019153189836213728, 'p_miss': 0.25459285079572064}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:40:01,563] Trial 103 finished with value: 0.09609205589784456 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7, 'learning_rate': 0.003882754587649779, 'p_miss': 0.25541197804251253}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:40:03,586] Trial 104 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:40:34,361] Trial 105 finished with value: 0.09868862980917087 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8, 'learning_rate': 0.004043575770077354, 'p_miss': 0.24797246179409219}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:40:51,686] Trial 106 finished with value: 0.10008279020931987 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.0035462783152127235, 'p_miss': 0.2569099713213746}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:41:08,429] Trial 107 finished with value: 0.10258519724139345 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 4, 'learning_rate': 0.00769817878819999, 'p_miss': 0.2780386711059234}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:42:18,798] Trial 108 finished with value: 0.0928488109081243 and parameters: {'model_name': 'VAE', 'batch_size': 246, 'iterations': 13, 'learning_rate': 0.0002446172616672664, 'p_miss': 0.26259096583234587}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:43:13,988] Trial 109 finished with value: 0.10485263838286332 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 13, 'learning_rate': 0.0001315478791609334, 'p_miss': 0.259510022226277}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:44:31,414] Trial 110 finished with value: 0.09569840092154658 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 20, 'learning_rate': 0.00020449522686838892, 'p_miss': 0.16860034193341872}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:45:20,088] Trial 111 finished with value: 0.0927452788942757 and parameters: {'model_name': 'VAE', 'batch_size': 303, 'iterations': 12, 'learning_rate': 0.0001996485016634127, 'p_miss': 0.17123675497856852}. Best is trial 58 with value: 0.09270266166187567.
running
[I 2024-11-24 05:46:35,733] Trial 112 finished with value: 0.09189118076615407 and parameters: {'model_name': 'VAE', 'batch_size': 401, 'iterations': 22, 'learning_rate': 0.0001917715001307907, 'p_miss': 0.16479500971934785}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 05:47:27,575] Trial 113 finished with value: 0.34203143030785366 and parameters: {'model_name': 'GAIN', 'batch_size': 334, 'hint_rate': 0.29845194946404574, 'alpha': 99, 'iterations': 31, 'learning_rate': 0.00013130032064974525, 'p_miss': 0.1346194225988512}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:43:15,228] Trial 14 finished with value: 0.3545417670289338 and parameters: {'model_name': 'GAIN', 'batch_size': 981, 'hint_rate': 0.21974034979072868, 'alpha': 55, 'iterations': 8528, 'learning_rate': 0.005621246211866489, 'p_miss': 0.08590659274109419}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:43:59,481] Trial 115 finished with value: 0.09416244526991265 and parameters: {'model_name': 'VAE', 'batch_size': 216, 'iterations': 11, 'learning_rate': 0.0002687329051207901, 'p_miss': 0.15605446913584303}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:45:00,827] Trial 116 finished with value: 0.10558804804200125 and parameters: {'model_name': 'VAE', 'batch_size': 241, 'iterations': 12, 'learning_rate': 0.0002679719188673202, 'p_miss': 0.16137335590659752}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:46:36,120] Trial 117 finished with value: 0.09537502898167749 and parameters: {'model_name': 'VAE', 'batch_size': 445, 'iterations': 23, 'learning_rate': 0.0001833488252065604, 'p_miss': 0.15793264255658934}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:48:09,455] Trial 118 finished with value: 0.09616434899532098 and parameters: {'model_name': 'VAE', 'batch_size': 451, 'iterations': 20, 'learning_rate': 0.000478294244340233, 'p_miss': 0.12048862934720447}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:51:14,966] Trial 119 finished with value: 0.10343871966220068 and parameters: {'model_name': 'VAE', 'batch_size': 377, 'iterations': 43, 'learning_rate': 0.00024158872199253617, 'p_miss': 0.15620710582539143}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:52:50,201] Trial 120 finished with value: 0.09225455690102366 and parameters: {'model_name': 'VAE', 'batch_size': 621, 'iterations': 19, 'learning_rate': 0.00033408397164653736, 'p_miss': 0.1752740506602267}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:53:36,541] Trial 121 finished with value: 0.0972660220619472 and parameters: {'model_name': 'VAE', 'batch_size': 628, 'iterations': 11, 'learning_rate': 0.00034974184687671614, 'p_miss': 0.16999778680447597}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:54:55,339] Trial 122 finished with value: 0.09416763003698012 and parameters: {'model_name': 'VAE', 'batch_size': 193, 'iterations': 16, 'learning_rate': 0.00029191312029512204, 'p_miss': 0.17915964726898054}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:56:11,527] Trial 123 finished with value: 0.20786857138948314 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 17, 'learning_rate': 0.03371138597976298, 'p_miss': 0.17955723712503036}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:57:17,840] Trial 124 finished with value: 0.09661660497067126 and parameters: {'model_name': 'VAE', 'batch_size': 794, 'iterations': 15, 'learning_rate': 0.00014213886157809973, 'p_miss': 0.143640608476842}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:57:44,052] Trial 125 finished with value: 0.19002845572759758 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 06:58:19,303] Trial 126 finished with value: 0.10021074003750945 and parameters: {'model_name': 'VAE', 'batch_size': 290, 'iterations': 7, 'learning_rate': 0.00030215648273256127, 'p_miss': 0.20512024482932625}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:01:40,743] Trial 127 finished with value: 0.09410659790205769 and parameters: {'model_name': 'VAE', 'batch_size': 509, 'iterations': 45, 'learning_rate': 0.00028048484694390575, 'p_miss': 0.1649551773709887}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:04:38,282] Trial 128 finished with value: 0.10354282777336969 and parameters: {'model_name': 'VAE', 'batch_size': 528, 'iterations': 43, 'learning_rate': 0.0003877811359329004, 'p_miss': 0.17874639114853527}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:13:15,181] Trial 129 finished with value: 0.09712581344329851 and parameters: {'model_name': 'VAE', 'batch_size': 186, 'iterations': 122, 'learning_rate': 0.0002401895915632722, 'p_miss': 0.16399890293006578}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:19:02,618] Trial 130 finished with value: 0.09651534670994046 and parameters: {'model_name': 'VAE', 'batch_size': 550, 'iterations': 80, 'learning_rate': 0.0004623948657600957, 'p_miss': 0.1497817058385028}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:22:26,480] Trial 131 finished with value: 0.09485173749705006 and parameters: {'model_name': 'VAE', 'batch_size': 318, 'iterations': 40, 'learning_rate': 0.0002965106157263808, 'p_miss': 0.18735793955578964}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:22:27,581] Trial 132 finished with value: 0.1933475769513514 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:25:23,948] Trial 133 finished with value: 0.09563991978552026 and parameters: {'model_name': 'VAE', 'batch_size': 388, 'iterations': 28, 'learning_rate': 0.00015480448487180794, 'p_miss': 0.17370641703831532}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:26:59,751] Trial 134 finished with value: 0.09616757750888494 and parameters: {'model_name': 'VAE', 'batch_size': 748, 'iterations': 20, 'learning_rate': 0.000624384754609967, 'p_miss': 0.19850280130053563}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:27:52,682] Trial 135 finished with value: 0.10462192335651288 and parameters: {'model_name': 'VAE', 'batch_size': 241, 'iterations': 9, 'learning_rate': 0.00021281825133639685, 'p_miss': 0.1256791592881998}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:28:56,091] Trial 136 finished with value: 0.10498861366183891 and parameters: {'model_name': 'VAE', 'batch_size': 318, 'iterations': 16, 'learning_rate': 0.00029076353110614456, 'p_miss': 0.18377657101069528}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:31:30,841] Trial 137 finished with value: 0.09391308508885117 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 42, 'learning_rate': 0.00034012331116984614, 'p_miss': 0.19139538820817137}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:34:23,728] Trial 138 finished with value: 0.09552865918588413 and parameters: {'model_name': 'VAE', 'batch_size': 96, 'iterations': 39, 'learning_rate': 0.00036222753273565373, 'p_miss': 0.1654343925282127}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:36:03,815] Trial 139 finished with value: 0.09450237903540606 and parameters: {'model_name': 'VAE', 'batch_size': 178, 'iterations': 23, 'learning_rate': 0.000787883377876637, 'p_miss': 0.1724802306693943}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:39:44,461] Trial 140 finished with value: 0.10622122793290104 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 53, 'learning_rate': 0.0007845635645073229, 'p_miss': 0.1923577015588851}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:41:41,552] Trial 141 finished with value: 0.10161345310271261 and parameters: {'model_name': 'VAE', 'batch_size': 140, 'iterations': 27, 'learning_rate': 0.00025645405104848524, 'p_miss': 0.1542379113397135}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:42:50,444] Trial 142 finished with value: 0.19196129638480586 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27039, 'weights': 'uniform'}. Best is trial 112 with value: 0.09189118076615407.
running
[I 2024-11-24 07:44:35,957] Trial 143 finished with value: 0.09097111341122086 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 23, 'learning_rate': 0.0005238522985864762, 'p_miss': 0.14445062163479164}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:45:01,394] Trial 144 finished with value: 0.33995321391406275 and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.6664625590773661, 'alpha': 33, 'iterations': 12, 'learning_rate': 0.0005606717855157876, 'p_miss': 0.14764748717299964}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:46:31,609] Trial 145 finished with value: 0.09799729904232977 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 22, 'learning_rate': 0.00042951113761033615, 'p_miss': 0.1740939750094551}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:48:25,222] Trial 146 finished with value: 0.10462738570042722 and parameters: {'model_name': 'VAE', 'batch_size': 197, 'iterations': 34, 'learning_rate': 0.0003195367345817171, 'p_miss': 0.17603603991135283}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:53:20,451] Trial 147 finished with value: 0.0953838912040286 and parameters: {'model_name': 'VAE', 'batch_size': 268, 'iterations': 64, 'learning_rate': 0.00047201923750396334, 'p_miss': 0.2058432824275558}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:53:45,709] Trial 148 finished with value: 0.09986857672250445 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 6, 'learning_rate': 0.00037967770395183875, 'p_miss': 0.1612568074474535}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:54:43,129] Trial 149 finished with value: 0.10622384495737658 and parameters: {'model_name': 'VAE', 'batch_size': 118, 'iterations': 15, 'learning_rate': 0.00023518921798754876, 'p_miss': 0.18566632172262326}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:56:26,009] Trial 150 finished with value: 0.0961731346888213 and parameters: {'model_name': 'VAE', 'batch_size': 395, 'iterations': 25, 'learning_rate': 0.0011568925385481842, 'p_miss': 0.1354231404085034}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 07:57:44,388] Trial 151 finished with value: 0.09610446129939643 and parameters: {'model_name': 'VAE', 'batch_size': 216, 'iterations': 18, 'learning_rate': 0.0006902205178361252, 'p_miss': 0.16884782294820902}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 08:51:33,899] Trial 8 finished with value: 0.20403460898019313 and parameters: {'model_name': 'VAE', 'batch_size': 107, 'iterations': 7487, 'learning_rate': 0.00022276413022238547, 'p_miss': 0.23876463979137696}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 08:52:09,118] Trial 153 finished with value: 0.09560094235018202 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 9, 'learning_rate': 0.00026680813068385577, 'p_miss': 0.14504578398209408}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 08:52:33,239] Trial 154 finished with value: 0.18996317794845666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 08:55:26,339] Trial 75 finished with value: 0.2087313410363571 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 6589, 'learning_rate': 0.0003783483452971686, 'p_miss': 0.2715925157604649}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 08:57:07,662] Trial 156 finished with value: 0.09601466187495708 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 34, 'learning_rate': 0.0001969533850301186, 'p_miss': 0.1932896007384534}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:00:18,987] Trial 155 finished with value: 0.11476633147711576 and parameters: {'model_name': 'VAE', 'batch_size': 558, 'iterations': 87, 'learning_rate': 0.0005105558332067946, 'p_miss': 0.19395471635435177}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:01:01,287] Trial 157 finished with value: 0.09271771097815654 and parameters: {'model_name': 'VAE', 'batch_size': 564, 'iterations': 54, 'learning_rate': 0.0003321276853314828, 'p_miss': 0.15850247609045692}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:01:08,880] Trial 158 finished with value: 0.10148931295853277 and parameters: {'model_name': 'VAE', 'batch_size': 163, 'iterations': 12, 'learning_rate': 0.00032736317718143733, 'p_miss': 0.29154471024391554}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:05:13,906] Trial 160 finished with value: 0.09780864480685988 and parameters: {'model_name': 'VAE', 'batch_size': 750, 'iterations': 55, 'learning_rate': 0.00040544608774563694, 'p_miss': 0.15736811433470324}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:07:08,105] Trial 161 finished with value: 0.09706999324969286 and parameters: {'model_name': 'VAE', 'batch_size': 423, 'iterations': 24, 'learning_rate': 0.00022806843171254456, 'p_miss': 0.15129618309496648}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:07:16,960] Trial 88 finished with value: 0.22220452973411725 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5098, 'learning_rate': 0.00022169291043280936, 'p_miss': 0.2775620026447008}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:07:35,983] Trial 163 finished with value: 0.10303872457618832 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 6, 'learning_rate': 0.0002911320958061969, 'p_miss': 0.07076970252535812}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:07:37,921] Trial 164 finished with value: 0.36825608645803265 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:10:24,666] Trial 159 finished with value: 0.09878552084292087 and parameters: {'model_name': 'VAE', 'batch_size': 903, 'iterations': 123, 'learning_rate': 0.000314178475974278, 'p_miss': 0.1552574211104265}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:10:38,591] Trial 162 finished with value: 0.09705360310622836 and parameters: {'model_name': 'VAE', 'batch_size': 505, 'iterations': 47, 'learning_rate': 0.00028453334164622813, 'p_miss': 0.18125681877381408}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:11:38,944] Trial 167 finished with value: 0.10277831904439653 and parameters: {'model_name': 'VAE', 'batch_size': 632, 'iterations': 14, 'learning_rate': 0.0001756755337326498, 'p_miss': 0.16779463789687904}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:12:21,141] Trial 168 finished with value: 0.09567147965512743 and parameters: {'model_name': 'VAE', 'batch_size': 349, 'iterations': 10, 'learning_rate': 0.0001964046848898193, 'p_miss': 0.12743241192675808}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:14:34,872] Trial 169 finished with value: 0.09925864660676546 and parameters: {'model_name': 'VAE', 'batch_size': 224, 'iterations': 32, 'learning_rate': 0.00011988376074842511, 'p_miss': 0.26400531877351624}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:14:41,850] Trial 166 finished with value: 0.10194645563058624 and parameters: {'model_name': 'VAE', 'batch_size': 475, 'iterations': 53, 'learning_rate': 0.000156216798278837, 'p_miss': 0.1676345815957796}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:15:18,653] Trial 171 finished with value: 0.09915999350717744 and parameters: {'model_name': 'VAE', 'batch_size': 280, 'iterations': 8, 'learning_rate': 0.0003422336573628472, 'p_miss': 0.17415289120681943}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:15:31,334] Trial 165 finished with value: 0.10380984905088057 and parameters: {'model_name': 'VAE', 'batch_size': 496, 'iterations': 102, 'learning_rate': 0.00033989989675215816, 'p_miss': 0.1729104321562761}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:15:37,152] Trial 170 finished with value: 0.09635009794497221 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 18, 'learning_rate': 0.00035829947304926325, 'p_miss': 0.1621351847756799}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:16:24,957] Trial 173 finished with value: 0.10137648228483773 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 18, 'learning_rate': 0.0022706342971103525, 'p_miss': 0.1629471049316865}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:16:31,635] Trial 172 finished with value: 0.10371512257852142 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 21, 'learning_rate': 0.002400203100002567, 'p_miss': 0.1395321669742896}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:16:32,147] Trial 174 finished with value: 0.18991225193659228 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2496, 'weights': 'uniform'}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:17:19,956] Trial 175 finished with value: 0.1905598617584777 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3500, 'weights': 'uniform'}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:17:48,912] Trial 33 finished with value: 0.2035614673112344 and parameters: {'model_name': 'VAE', 'batch_size': 636, 'iterations': 5580, 'learning_rate': 0.01465112044387361, 'p_miss': 0.11131567326396244}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:18:51,083] Trial 176 finished with value: 0.09763802048742296 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 37, 'learning_rate': 0.0002567509324767057, 'p_miss': 0.18767257330180911}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:19:10,811] Trial 177 finished with value: 0.09581144938981372 and parameters: {'model_name': 'VAE', 'batch_size': 316, 'iterations': 37, 'learning_rate': 0.00026329062000862133, 'p_miss': 0.18554401641357732}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:20:50,641] Trial 178 finished with value: 0.09567136198435768 and parameters: {'model_name': 'VAE', 'batch_size': 254, 'iterations': 65, 'learning_rate': 0.00024727922351423554, 'p_miss': 0.1867099722063706}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:21:42,183] Trial 179 finished with value: 0.097761175936411 and parameters: {'model_name': 'VAE', 'batch_size': 346, 'iterations': 40, 'learning_rate': 0.00025920294817041755, 'p_miss': 0.1866488567782515}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:21:56,326] Trial 181 finished with value: 0.10796101317060677 and parameters: {'model_name': 'VAE', 'batch_size': 138, 'iterations': 45, 'learning_rate': 0.00022168995302671276, 'p_miss': 0.2160507977208441}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:22:39,673] Trial 184 finished with value: 0.33433325770020356 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.5675081515378931, 'alpha': 79, 'iterations': 27, 'learning_rate': 0.0004137386486330236, 'p_miss': 0.1774522989821024}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:22:46,002] Trial 180 finished with value: 0.1003465946883807 and parameters: {'model_name': 'VAE', 'batch_size': 264, 'iterations': 62, 'learning_rate': 0.0002207698086401902, 'p_miss': 0.17879163287838104}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:06,846] Trial 186 finished with value: 0.11074114187163855 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 5, 'learning_rate': 0.0002942926917222151, 'p_miss': 0.27201513660037513}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:08,976] Trial 183 finished with value: 0.09710860692539397 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 27, 'learning_rate': 0.0002069743727987351, 'p_miss': 0.20106720566897232}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:18,514] Trial 182 finished with value: 0.09554750362996714 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 46, 'learning_rate': 0.0002096019002483985, 'p_miss': 0.2046235078491414}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:31,291] Trial 187 finished with value: 0.1045160192181569 and parameters: {'model_name': 'VAE', 'batch_size': 197, 'iterations': 6, 'learning_rate': 0.00018592062283276668, 'p_miss': 0.25087732958377423}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:31,758] Trial 189 finished with value: 0.1059937898701632 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 4, 'learning_rate': 0.00017727994733395832, 'p_miss': 0.2745242277232865}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:31,939] Trial 188 finished with value: 0.09858220211971623 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 8, 'learning_rate': 0.0018409692546078355, 'p_miss': 0.26932067886337346}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:23:46,412] Trial 190 finished with value: 0.102395410933115 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4, 'learning_rate': 0.0003089870828404835, 'p_miss': 0.2649996857684332}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:24:09,718] Trial 185 finished with value: 0.20235147383700172 and parameters: {'model_name': 'VAE', 'batch_size': 186, 'iterations': 29, 'learning_rate': 0.006828045436945598, 'p_miss': 0.20438153174683088}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:24:17,083] Trial 193 finished with value: 0.19158440474360888 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:24:36,700] Trial 192 finished with value: 0.20706816422070182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:24:40,228] Trial 194 finished with value: 0.10203855172676908 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 13, 'learning_rate': 0.000446160033640638, 'p_miss': 0.2882080979673301}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:25:04,018] Trial 195 finished with value: 0.22678367265458563 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 13, 'learning_rate': 0.02006620781362539, 'p_miss': 0.287308807648795}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:25:20,971] Trial 196 finished with value: 0.11450100142639481 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 13, 'learning_rate': 0.00015213151283989155, 'p_miss': 0.15524195480980296}. Best is trial 143 with value: 0.09097111341122086.
running
[I 2024-11-24 09:25:58,314] Trial 197 finished with value: 0.09223060583622579 and parameters: {'model_name': 'VAE', 'batch_size': 408, 'iterations': 22, 'learning_rate': 0.00015445460566719006, 'p_miss': 0.1552610579650337}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:26:40,622] Trial 198 finished with value: 0.09484633509899465 and parameters: {'model_name': 'VAE', 'batch_size': 399, 'iterations': 21, 'learning_rate': 0.0001393371023445487, 'p_miss': 0.16000371261888907}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:27:16,010] Trial 199 finished with value: 0.1014766071306857 and parameters: {'model_name': 'VAE', 'batch_size': 385, 'iterations': 22, 'learning_rate': 0.0002841177570386295, 'p_miss': 0.160785733855311}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:52:38,920] Trial 26 finished with value: 0.203697978836774 and parameters: {'model_name': 'VAE', 'batch_size': 601, 'iterations': 6750, 'learning_rate': 0.011852492529794128, 'p_miss': 0.11792423188933651}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:55:38,530] Trial 152 finished with value: 0.19999884340242655 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:57:11,207] Trial 97 finished with value: 0.21092198916601804 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5796, 'learning_rate': 0.0003014908886828303, 'p_miss': 0.2649327773782562}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 09:58:32,691] Trial 96 finished with value: 0.21461488450397184 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5242, 'learning_rate': 0.0004289848423527202, 'p_miss': 0.26934715348234556}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:08:07,764] Trial 77 finished with value: 0.2281764162913297 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6088, 'learning_rate': 0.00012102524727396404, 'p_miss': 0.28735798817539626}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:08:52,768] Trial 100 finished with value: 0.2028508250387387 and parameters: {'model_name': 'VAE', 'batch_size': 221, 'iterations': 5618, 'learning_rate': 0.00016094798534447037, 'p_miss': 0.24254675888296262}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:30:45,015] Trial 191 finished with value: 0.2108257729478281 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:32:18,737] Trial 34 finished with value: 0.2024134313498877 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 9926, 'learning_rate': 0.004846686940854351, 'p_miss': 0.16423794298537467}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:33:30,866] Trial 29 finished with value: 0.2029373249087746 and parameters: {'model_name': 'VAE', 'batch_size': 498, 'iterations': 9177, 'learning_rate': 0.023118834193744796, 'p_miss': 0.09535064585118563}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:34:05,942] Trial 114 finished with value: 0.2030596911846189 and parameters: {'model_name': 'VAE', 'batch_size': 250, 'iterations': 6820, 'learning_rate': 0.00026647351793265177, 'p_miss': 0.16671756410222616}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:35:08,939] Trial 90 finished with value: 0.2173495491752533 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8343, 'learning_rate': 0.00010107189733085945, 'p_miss': 0.2562691255030134}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:36:31,571] Trial 65 finished with value: 0.20515204553889185 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 9970, 'learning_rate': 0.0044111376569838795, 'p_miss': 0.21281611186411556}. Best is trial 143 with value: 0.09097111341122086.
[I 2024-11-24 10:37:31,323] Trial 32 finished with value: 0.2029244039115276 and parameters: {'model_name': 'VAE', 'batch_size': 843, 'iterations': 9167, 'learning_rate': 0.015662829775695716, 'p_miss': 0.10483369181145585}. Best is trial 143 with value: 0.09097111341122086.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.09097111341122086
{'model_name': 'VAE', 'batch_size': 109, 'iterations': 23, 'learning_rate': 0.0005238522985864762, 'p_miss': 0.14445062163479164}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5955516090535244
Generation:   4%|▍         | 1/25 [05:28<2:11:14, 328.12s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f7610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747115d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.5955516090535244
Generation:   8%|▊         | 2/25 [11:09<2:08:43, 335.82s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f1720> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  3
Best f1_score score: 0.5983869146752407
Generation:  12%|█▏        | 3/25 [20:18<2:38:53, 433.36s/it]Generation:  4
Best f1_score score: 0.5984842442058748
Generation:  16%|█▌        | 4/25 [27:44<2:33:26, 438.42s/it]Generation:  5
Best f1_score score: 0.5996005315852804
Generation:  20%|██        | 5/25 [34:14<2:20:13, 420.70s/it]Generation:  6
Best f1_score score: 0.5996005315852804
Generation:  24%|██▍       | 6/25 [36:32<1:42:49, 324.69s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f06350> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  7
Best f1_score score: 0.6008697077587548
Generation:  28%|██▊       | 7/25 [42:13<1:38:59, 329.97s/it]Generation:  8
Best f1_score score: 0.6008697077587548
Generation:  32%|███▏      | 8/25 [43:48<1:12:19, 255.28s/it]Generation:  9
Best f1_score score: 0.6008697077587548
Generation:  36%|███▌      | 9/25 [49:52<1:17:06, 289.14s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b902110> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465354280> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467435db0> 

Generation:  10
Best f1_score score: 0.6014348546598507
Generation:  40%|████      | 10/25 [59:59<1:36:51, 387.41s/it]Generation:  11
Best f1_score score: 0.6017798650209896
Generation:  44%|████▍     | 11/25 [1:02:17<1:12:32, 310.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b4f880> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.6017798650209896
Generation:  48%|████▊     | 12/25 [1:10:36<1:19:47, 368.23s/it]Generation:  13
Best f1_score score: 0.6017798650209896
Generation:  52%|█████▏    | 13/25 [1:15:24<1:08:46, 343.88s/it]Generation:  14
Best f1_score score: 0.6017798650209896
Generation:  56%|█████▌    | 14/25 [1:17:30<50:58, 278.07s/it]  Generation:  15
Best f1_score score: 0.6017798650209896
Generation:  60%|██████    | 15/25 [1:20:29<41:21, 248.11s/it]Generation:  16
Best f1_score score: 0.6017798650209896
Generation:  64%|██████▍   | 16/25 [1:22:11<30:38, 204.24s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d11090> 

Generation:  17
Best f1_score score: 0.6017798650209896
Generation:  68%|██████▊   | 17/25 [1:32:21<43:31, 326.39s/it]Generation:  18
Best f1_score score: 0.6017798650209896
Generation:  72%|███████▏  | 18/25 [1:34:43<31:35, 270.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546776ac20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.6017798650209896
Generation:  76%|███████▌  | 19/25 [1:42:55<33:43, 337.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b8c370> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.6018650272774426
Generation:  80%|████████  | 20/25 [1:47:42<26:50, 322.18s/it]Generation:  21
Best f1_score score: 0.6018650272774426
Generation:  84%|████████▍ | 21/25 [1:50:02<17:49, 267.50s/it]Generation:  22
Best f1_score score: 0.6018650272774426
Generation:  88%|████████▊ | 22/25 [1:52:15<11:21, 227.18s/it]Generation:  23
Best f1_score score: 0.6018650272774426
Generation:  92%|█████████▏| 23/25 [2:01:36<10:54, 327.21s/it]Generation:  24
Best f1_score score: 0.6018650272774426
Generation:  96%|█████████▌| 24/25 [2:05:12<04:54, 294.08s/it]Generation:  25
Best f1_score score: 0.6018650272774426
Generation: 100%|██████████| 25/25 [2:07:42<00:00, 250.67s/it]Generation: 100%|██████████| 25/25 [2:07:46<00:00, 306.65s/it]
2024-11-24 12:45:42,416 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44923' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-2392fb8d75ddc9b083bdc53d72cbf4f6', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732481142.4161224')
Fitted
Pipeline(steps=[('adaboostclassifier',
                 AdaBoostClassifier(algorithm='SAMME',
                                    learning_rate=0.6836990313865,
                                    n_estimators=285))])
score start
train score: {'auroc': 0.6464745822160164, 'accuracy': 0.603866233949485, 'balanced_accuracy': 0.603802245627916, 'logloss': 0.6593805404828834, 'f1': 0.6032073132186959}
original test score: {'auroc': 0.6435915462314551, 'accuracy': 0.5475222937126086, 'balanced_accuracy': 0.5477064171086541, 'logloss': 0.672141511244717, 'f1': 0.5413889251867349}
imputed test score: {'auroc': 0.5174890358177198, 'accuracy': 0.5136584264589683, 'balanced_accuracy': 0.5135877306915619, 'logloss': 0.7118948405068364, 'f1': 0.512647403637572}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0370> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0ee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0ee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a03d0> 

Generation:  1
Best f1_score score: 0.8685810831309506
Generation:   4%|▍         | 1/25 [10:03<4:01:13, 603.07s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474718ca0> 

Generation:  2
Best f1_score score: 0.8687150579201836
Generation:   8%|▊         | 2/25 [20:07<3:51:28, 603.85s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466a5e7d0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e97df0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546787d240> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f11b70> 

Generation:  3
Best f1_score score: 0.8742964913301519
Generation:  12%|█▏        | 3/25 [30:11<3:41:30, 604.11s/it]Generation:  4
Best f1_score score: 0.8744631305368422
Generation:  16%|█▌        | 4/25 [37:30<3:08:30, 538.61s/it]Generation:  5
Best f1_score score: 0.8839662780569819
Generation:  20%|██        | 5/25 [37:52<1:57:26, 352.32s/it]Generation:  6
Best f1_score score: 0.8839662780569819
Generation:  24%|██▍       | 6/25 [38:36<1:18:25, 247.67s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554671a8b50> 

Generation:  7
Best f1_score score: 0.8839662780569819
Generation:  28%|██▊       | 7/25 [48:40<1:49:15, 364.20s/it]Generation:  8
Best f1_score score: 0.8839662780569819
Generation:  32%|███▏      | 8/25 [55:08<1:45:19, 371.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d0d780> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  9
Best f1_score score: 0.8848379607575183
Generation:  36%|███▌      | 9/25 [55:33<1:10:13, 263.35s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467feace0> 

Generation:  10
Best f1_score score: 0.8858650215395987
Generation:  40%|████      | 10/25 [1:05:39<1:32:17, 369.14s/it]Generation:  11
Best f1_score score: 0.8858650215395987
Generation:  44%|████▍     | 11/25 [1:13:19<1:32:36, 396.91s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e97430> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554585fbf10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659e8ac0> 

Generation:  12
Best f1_score score: 0.8858650215395987
Generation:  48%|████▊     | 12/25 [1:23:26<1:39:49, 460.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459938160> 

Generation:  13
Best f1_score score: 0.8858650215395987
Generation:  52%|█████▏    | 13/25 [1:33:31<1:40:53, 504.46s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466b592d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ff760> 

Generation:  14
Best f1_score score: 0.8868107677229187
Generation:  56%|█████▌    | 14/25 [1:43:37<1:38:06, 535.16s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546667de10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474719360> 

Generation:  15
Best f1_score score: 0.8868107677229187
Generation:  60%|██████    | 15/25 [1:53:45<1:32:50, 557.02s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450d3a170> 

Generation:  16
Best f1_score score: 0.8868107677229187
Generation:  64%|██████▍   | 16/25 [2:03:53<1:25:51, 572.36s/it]Generation:  17
Best f1_score score: 0.8868107677229187
Generation:  68%|██████▊   | 17/25 [2:06:29<59:38, 447.30s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474705990> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466993af0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b81a980> 

Generation:  18
Best f1_score score: 0.8868107677229187
Generation:  72%|███████▏  | 18/25 [2:16:36<57:46, 495.20s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466076890> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554649f93f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464225d50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474740850> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3970> 

Generation:  19
Best f1_score score: 0.8868107677229187
Generation:  76%|███████▌  | 19/25 [2:26:44<52:54, 529.13s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467167580> 

Generation:  20
Best f1_score score: 0.8868107677229187
Generation:  80%|████████  | 20/25 [2:36:51<46:02, 552.60s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453281ff0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b66c20> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466a55150> 

Generation:  21
Best f1_score score: 0.8868107677229187
Generation:  84%|████████▍ | 21/25 [2:46:58<37:55, 568.94s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546578ace0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474741780> 

Generation:  22
Best f1_score score: 0.8868107677229187
Generation:  88%|████████▊ | 22/25 [2:57:06<29:01, 580.61s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464990940> 

Generation:  23
Best f1_score score: 0.8868107677229187
Generation:  92%|█████████▏| 23/25 [3:07:13<19:36, 588.42s/it]Generation:  24
Best f1_score score: 0.8868107677229187
Generation:  96%|█████████▌| 24/25 [3:08:40<07:18, 438.01s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546499db70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554643cf6d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f03010> 

Generation:  25
Best f1_score score: 0.8868107677229187
Generation: 100%|██████████| 25/25 [3:18:47<00:00, 488.69s/it]Generation: 100%|██████████| 25/25 [3:18:47<00:00, 477.09s/it]
2024-11-24 16:04:45,763 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38933' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-b08d92deab1c9130d0738094953bde10', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732493085.7637908')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='most_frequent')),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.1938992777153,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0839127054531, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=13,
                               max_leaves=None, min_child_weight=4, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9675231040051053, 'accuracy': 0.9000987724001693, 'balanced_accuracy': 0.9001916651040588, 'logloss': 0.22390164199536214, 'f1': 0.8997811065504093}
test score: {'auroc': 0.9502322293411514, 'accuracy': 0.8709222259848741, 'balanced_accuracy': 0.8710104720610929, 'logloss': 0.2731288212089472, 'f1': 0.8705381944468296}
original test score: {'auroc': 0.9988925569067484, 'accuracy': 0.9873010497798849, 'balanced_accuracy': 0.9873011072583369, 'logloss': 0.03947961693707312, 'f1': 0.9873010202904151}
score end
40922
lvl
0.5
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
13.494313093092707
hours
DONE
