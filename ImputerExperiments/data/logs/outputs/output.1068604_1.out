Run: 1
/cm/local/apps/slurm/var/spool/job1068604/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40983/40983.pkl
        GLCM_Pan      Mean_G      Mean_R    Mean_NIR    SD_Plan
0     120.362774  205.500000  119.395349  416.581395  20.676318
1     124.739583  202.800000  115.333333  354.333333  16.707151
2     134.691964  199.285714  116.857143  477.857143  22.496712
3     127.946309  178.368421   92.368421  278.473684  14.977453
4     135.431548  197.000000  112.690476  532.952381  17.604193
...          ...         ...         ...         ...        ...
4834  123.554348  202.826087  106.391304  364.565217  17.314068
4835  121.549028  276.220000  175.593333  402.620000  13.394574
4836  119.076687  247.951220  113.365854  808.024390  24.830059
4837  107.944444  197.000000   90.000000  451.000000   8.214887
4838  119.731928  182.238095   74.285714  301.690476  22.944278

[4839 rows x 5 columns]
<class 'pandas.core.frame.DataFrame'>
        GLCM_Pan      Mean_G      Mean_R    Mean_NIR    SD_Plan
1438   87.312500  227.000000   99.000000  576.000000  10.222524
3578  141.405556  213.632353   99.970588  451.235294  22.176588
3477  132.656294  204.977778   90.496296  521.266667  34.915976
1336  134.055556  208.555556   91.444444  492.888889  22.103014
2421  122.093114  229.192308  109.984615  557.030769  20.231806
...          ...         ...         ...         ...        ...
4043  100.773109  326.533333  250.600000  399.200000  12.861657
4223  142.786164  236.625000  106.850000  606.100000  29.526672
753   136.076503  296.782609  188.782609  438.695652  11.882061
2498  132.276405  212.169643   95.080357  620.857143  30.852171
4355  116.948953  214.562500  127.750000  390.208333  23.070506

[3871 rows x 5 columns]
<class 'pandas.core.frame.DataFrame'>
             0         1         2         3         4
0     0.476385  0.063400  0.031361  0.323993  0.065316
1     0.771522  0.055680  0.031989  0.241413  0.141696
2     0.723785  0.050683  0.025853  0.287766  0.223093
3     0.731420  0.052749  0.026467  0.268983  0.141226
4     0.666152  0.064666  0.038475  0.311438  0.129270
...        ...       ...       ...       ...       ...
3866  0.549828  0.120877  0.129547  0.206972  0.082179
3867  0.779055  0.068958  0.036445  0.343916  0.188659
3868  0.742446  0.103697  0.089510  0.233114  0.075920
3869  0.721713  0.054836  0.028822  0.353684  0.197128
3870  0.638085  0.056217  0.049981  0.201020  0.147407

[3871 rows x 5 columns]
<class 'numpy.ndarray'>
            0         1         2         3         4
0    0.767580  0.046402  0.026292  0.257344  0.110109
1    0.697698  0.174678  0.162423  0.167999  0.127417
2    0.677217  0.050654  0.024815  0.230770  0.163252
3    0.624774  0.051836  0.025451  0.238544  0.208663
4    0.614000  0.064041  0.035175  0.282000  0.201670
..        ...       ...       ...       ...       ...
963  0.727218  0.093043  0.049495  0.465858  0.105077
964  0.636621  0.069495  0.040560  0.409892  0.179726
965  0.669974  0.084333  0.048200  0.513458  0.159739
966  0.721660  0.044786  0.021970  0.153359  0.122040
967  0.842049  0.052872  0.028023  0.314269  0.076174

[968 rows x 5 columns]
<class 'numpy.ndarray'>
working on 
../data/c/40983/class_full_MCAR_0.01_1
1.6994552612304688
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-21 08:11:38,251] A new study created in memory with name: no-name-ffc36f92-5811-4d00-b223-2dc8a490c40b
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-21 08:11:38,372] Trial 3 finished with value: 0.34800673458449155 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.34800673458449155.
running
[I 2024-11-21 08:11:38,530] Trial 14 finished with value: 0.34800673458449155 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.34800673458449155.
running
[I 2024-11-21 08:11:39,285] Trial 5 finished with value: 0.06351047615168012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3098, 'weights': 'uniform'}. Best is trial 5 with value: 0.06351047615168012.
running
[I 2024-11-21 08:11:39,458] Trial 4 finished with value: 0.05610863649674773 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 117, 'weights': 'uniform'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:39,648] Trial 0 finished with value: 0.061208422769365854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3399, 'weights': 'distance'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:39,810] Trial 9 finished with value: 0.06351047615168012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3055, 'weights': 'uniform'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:39,945] Trial 7 finished with value: 0.061208422769365854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3313, 'weights': 'distance'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:40,057] Trial 10 finished with value: 0.06331178789665297 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2427, 'weights': 'uniform'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:40,265] Trial 22 finished with value: 0.34800673458449155 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:41,070] Trial 23 finished with value: 0.061957466050870234 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1327, 'weights': 'uniform'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:41,290] Trial 24 finished with value: 0.06343520324042748 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2757, 'weights': 'uniform'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:41,689] Trial 8 finished with value: 0.059210631717578247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:43,200] Trial 25 finished with value: 0.0588967400852447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:44,002] Trial 27 finished with value: 0.059210631717578247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:44,577] Trial 21 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.35997853464449225, 'alpha': 36, 'iterations': 8, 'learning_rate': 0.05880425588363508, 'p_miss': 0.13487274239504402}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:45,001] Trial 2 finished with value: 0.360055369128594 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.0002077267154080751, 'p_miss': 0.07375168974654359}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:45,591] Trial 29 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.4340579382180423, 'alpha': 17, 'iterations': 3, 'learning_rate': 0.031038775863001664, 'p_miss': 0.15460703590830632}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:46,153] Trial 19 finished with value: 0.09070327309572501 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:46,522] Trial 20 finished with value: 0.05775102161284521 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 4 with value: 0.05610863649674773.
running
[I 2024-11-21 08:11:53,401] Trial 31 finished with value: 0.05493351179659843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:13:11,140] Trial 26 finished with value: 0.3584888441880153 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 25, 'learning_rate': 0.00011399465208807804, 'p_miss': 0.10474582115296835}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:13:19,150] Trial 36 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:13:30,284] Trial 37 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:13:40,091] Trial 38 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:13:51,505] Trial 39 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:14:02,436] Trial 40 finished with value: 0.05625013168951422 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:14:29,693] Trial 28 finished with value: 0.3373350215613355 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 54, 'learning_rate': 0.0005586475369732054, 'p_miss': 0.21828631668099752}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:14:55,829] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 86, 'hint_rate': 0.37141237591753135, 'alpha': 92, 'iterations': 595, 'learning_rate': 0.0007917309457411838, 'p_miss': 0.013510944699990503}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:14:59,398] Trial 13 finished with value: 0.31967259807423626 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 53, 'learning_rate': 0.0007749241930588861, 'p_miss': 0.11276677340935785}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:15:14,608] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9500058115837037, 'alpha': 62, 'iterations': 352, 'learning_rate': 0.00024224382190668266, 'p_miss': 0.26539489996563204}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:21:00,373] Trial 17 finished with value: 0.2837517421443235 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.19345681033206813, 'alpha': 82, 'iterations': 359, 'learning_rate': 0.0011424489387320737, 'p_miss': 0.2678500745764668}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:21:09,875] Trial 46 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:21:19,377] Trial 47 finished with value: 0.05613691713368533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:21:29,929] Trial 48 finished with value: 0.05575344079129198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.05493351179659843.
running
[I 2024-11-21 08:27:09,875] Trial 16 finished with value: 0.04990551405582794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:27:29,253] Trial 32 finished with value: 0.05024143225896479 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:29:59,425] Trial 41 finished with value: 0.050990064662684645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:30:27,308] Trial 42 finished with value: 0.05012068787767106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:30:27,920] Trial 53 finished with value: 0.34800673458449155 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:30:41,933] Trial 45 finished with value: 0.050060397922127006 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:30:56,509] Trial 44 finished with value: 0.0506185879120206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:31:02,189] Trial 43 finished with value: 0.049966216468277994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:31:16,180] Trial 11 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.6235258688181775, 'alpha': 29, 'iterations': 3703, 'learning_rate': 0.06238902870827892, 'p_miss': 0.06903259433160369}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:37:22,489] Trial 49 finished with value: 0.050589972408495665 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:42:54,074] Trial 50 finished with value: 0.049951684555694965 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:43:39,455] Trial 51 finished with value: 0.050128287475312304 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:03,483] Trial 58 finished with value: 0.05426218464629541 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:10,513] Trial 52 finished with value: 0.04999924444858004 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:16,369] Trial 57 finished with value: 0.05270260332311013 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:24,634] Trial 55 finished with value: 0.05054714313314329 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:39,820] Trial 54 finished with value: 0.05023249443699266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:46:58,656] Trial 56 finished with value: 0.050209262315989676 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:52:53,878] Trial 59 finished with value: 0.05341045025010449 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:52:54,246] Trial 68 finished with value: 0.06351047615168012 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 08:58:54,920] Trial 60 finished with value: 0.05073078593718612 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 09:00:00,967] Trial 61 finished with value: 0.05190028329385861 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 09:31:18,775] Trial 6 finished with value: 0.06935118343806938 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1249, 'learning_rate': 0.004164582905543055, 'p_miss': 0.04321601517991135}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 12:17:43,946] Trial 65 finished with value: 0.0667677714059865 and parameters: {'model_name': 'VAE', 'batch_size': 460, 'iterations': 3162, 'learning_rate': 0.009692942951378248, 'p_miss': 0.20944376364942618}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 12:17:46,333] Trial 73 finished with value: 0.05958446165179036 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1080, 'weights': 'distance'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 12:17:46,936] Trial 74 finished with value: 0.06372743180151116 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 12:34:32,025] Trial 75 finished with value: 0.05048624293861513 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 12:50:41,833] Trial 76 finished with value: 0.0501800804436785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 16 with value: 0.04990551405582794.
running
[I 2024-11-21 13:06:07,485] Trial 77 finished with value: 0.04989071156390045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 13:21:20,953] Trial 78 finished with value: 0.050214642543819146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 13:21:25,663] Trial 79 finished with value: 0.3254036907828842 and parameters: {'model_name': 'GAIN', 'batch_size': 961, 'hint_rate': 0.019924818026726132, 'alpha': 1, 'iterations': 1, 'learning_rate': 0.012836035780931553, 'p_miss': 0.19630591426223648}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 13:45:14,019] Trial 63 finished with value: 0.06679936307972043 and parameters: {'model_name': 'VAE', 'batch_size': 873, 'iterations': 3620, 'learning_rate': 0.009061231803966468, 'p_miss': 0.2081972642171085}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 13:45:40,594] Trial 81 finished with value: 0.09170961617897407 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 13:45:43,061] Trial 82 finished with value: 0.06072500884504907 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2002, 'weights': 'distance'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:00:51,599] Trial 83 finished with value: 0.05016494382715371 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:01:02,942] Trial 84 finished with value: 0.05874684722834359 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:01:26,727] Trial 85 finished with value: 0.05775243999769379 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:17:13,956] Trial 86 finished with value: 0.0501800804436785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:17:39,484] Trial 64 finished with value: 0.06657468185202456 and parameters: {'model_name': 'VAE', 'batch_size': 821, 'iterations': 3814, 'learning_rate': 0.009052301360034322, 'p_miss': 0.20593780472962814}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:30:20,842] Trial 88 finished with value: 0.07362264430004194 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:30:28,310] Trial 87 finished with value: 0.06060506585917754 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:32:33,095] Trial 33 finished with value: 0.06750915448424656 and parameters: {'model_name': 'VAE', 'batch_size': 981, 'iterations': 3720, 'learning_rate': 0.00014956892836437023, 'p_miss': 0.28660117739450897}. Best is trial 77 with value: 0.04989071156390045.
running
[I 2024-11-21 14:46:06,126] Trial 90 finished with value: 0.04970737165729271 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 14:47:01,866] Trial 92 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 79, 'hint_rate': 0.9586371396295075, 'alpha': 63, 'iterations': 139, 'learning_rate': 0.002168194710313315, 'p_miss': 0.013091844852144013}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 14:47:29,568] Trial 89 finished with value: 0.04982505865453855 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 14:47:38,312] Trial 94 finished with value: 0.05874717976689905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 14:49:02,444] Trial 91 finished with value: 0.05087562875696089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:02:55,189] Trial 93 finished with value: 0.05006920180619316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:03:09,533] Trial 95 finished with value: 0.050015215263110556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:04:23,712] Trial 96 finished with value: 0.050362508020480555 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:18:11,666] Trial 98 finished with value: 0.050702836585213275 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:18:55,915] Trial 97 finished with value: 0.0500067439433292 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:19:24,875] Trial 99 finished with value: 0.05117553799952472 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:19:26,410] Trial 102 finished with value: 0.05488873550088336 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 73, 'weights': 'distance'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:23:32,216] Trial 18 finished with value: 0.06696088970490394 and parameters: {'model_name': 'VAE', 'batch_size': 657, 'iterations': 5914, 'learning_rate': 0.027645049489237315, 'p_miss': 0.04266490202008038}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:32:02,828] Trial 100 finished with value: 0.06072199149150537 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:32:23,277] Trial 105 finished with value: 0.05775191204950216 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:33:37,424] Trial 101 finished with value: 0.051207149765568304 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:33:56,646] Trial 103 finished with value: 0.051767301354852746 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:38:00,553] Trial 104 finished with value: 0.05306454231888221 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:38:01,148] Trial 109 finished with value: 0.34800673458449155 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:48:33,746] Trial 106 finished with value: 0.050280620425165054 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:49:31,186] Trial 108 finished with value: 0.049829968387379756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:49:48,602] Trial 107 finished with value: 0.0500373985475623 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:49:58,300] Trial 113 finished with value: 0.058747138212001435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:54:18,008] Trial 110 finished with value: 0.050609911019958376 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 15:54:45,421] Trial 115 finished with value: 0.31508145119009495 and parameters: {'model_name': 'GAIN', 'batch_size': 52, 'hint_rate': 0.6599766578906416, 'alpha': 100, 'iterations': 12, 'learning_rate': 0.003119882191393799, 'p_miss': 0.17361000786600378}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:04:41,050] Trial 34 finished with value: 0.0683490947128811 and parameters: {'model_name': 'VAE', 'batch_size': 639, 'iterations': 5883, 'learning_rate': 0.00010606856738338274, 'p_miss': 0.26765807520974744}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:05:02,378] Trial 112 finished with value: 0.05014964395097937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:05:16,662] Trial 111 finished with value: 0.05029822904363292 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:06:21,277] Trial 114 finished with value: 0.04982232762080073 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:11:07,611] Trial 116 finished with value: 0.05041011833165315 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:21:16,161] Trial 118 finished with value: 0.05044263911265703 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 90 with value: 0.04970737165729271.
running
[I 2024-11-21 16:21:54,927] Trial 117 finished with value: 0.049598895801655586 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:21:56,379] Trial 120 finished with value: 0.05023827649274816 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:22:07,692] Trial 119 finished with value: 0.05040377020737842 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:22:08,193] Trial 125 finished with value: 0.06351047615168012 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:27:14,685] Trial 121 finished with value: 0.05025522725241162 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:37:12,078] Trial 122 finished with value: 0.050200552616726034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:37:43,212] Trial 126 finished with value: 0.05047416597594452 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:38:16,156] Trial 124 finished with value: 0.05070097608515363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:38:43,299] Trial 123 finished with value: 0.049985168777603686 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:39:18,818] Trial 67 finished with value: 0.06672931790764419 and parameters: {'model_name': 'VAE', 'batch_size': 816, 'iterations': 6126, 'learning_rate': 0.007249741908835841, 'p_miss': 0.2021222706391624}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:39:21,478] Trial 132 finished with value: 0.0592125191195052 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 898, 'weights': 'distance'}. Best is trial 117 with value: 0.049598895801655586.
running
[I 2024-11-21 16:43:08,353] Trial 127 finished with value: 0.04956531511533378 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:43:18,897] Trial 134 finished with value: 0.05505103708433974 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:52:49,749] Trial 128 finished with value: 0.0502792447942347 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:53:05,999] Trial 129 finished with value: 0.05022781289609437 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:53:43,228] Trial 130 finished with value: 0.050993738867581406 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:54:47,633] Trial 133 finished with value: 0.050352684247227816 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:55:09,426] Trial 131 finished with value: 0.0505995142223399 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:55:51,636] Trial 140 finished with value: 0.09491098180989806 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:58:56,029] Trial 135 finished with value: 0.05034270381119381 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 16:59:05,513] Trial 142 finished with value: 0.3092867879335225 and parameters: {'model_name': 'GAIN', 'batch_size': 234, 'hint_rate': 0.7597505749689104, 'alpha': 53, 'iterations': 4, 'learning_rate': 0.0003628006466844525, 'p_miss': 0.24069975728069687}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:03:35,565] Trial 35 finished with value: 0.06721833455307362 and parameters: {'model_name': 'VAE', 'batch_size': 287, 'iterations': 8727, 'learning_rate': 0.0001032899465370513, 'p_miss': 0.2875350366566026}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:08:42,763] Trial 136 finished with value: 0.05076687117613615 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:09:14,816] Trial 138 finished with value: 0.05015288460902277 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:09:15,997] Trial 137 finished with value: 0.05049448921653016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:10:55,143] Trial 139 finished with value: 0.05042863427869586 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:11:55,299] Trial 141 finished with value: 0.05049658536359861 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:14:40,959] Trial 143 finished with value: 0.04994643020671312 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:14:52,911] Trial 150 finished with value: 0.058747054028464654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:19:34,072] Trial 144 finished with value: 0.05083640800960846 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:21:14,948] Trial 70 finished with value: 0.06705779425687283 and parameters: {'model_name': 'VAE', 'batch_size': 522, 'iterations': 7326, 'learning_rate': 0.009505241530625494, 'p_miss': 0.20695344409140737}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:24:02,343] Trial 145 finished with value: 0.050494996674648185 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:24:38,952] Trial 146 finished with value: 0.05008455039897931 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:25:41,411] Trial 147 finished with value: 0.05114353847240725 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:26:53,442] Trial 148 finished with value: 0.05020162777364682 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:27:23,672] Trial 149 finished with value: 0.05010571664333243 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:30:24,521] Trial 151 finished with value: 0.050951171957244266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:35:21,836] Trial 152 finished with value: 0.05008484342510054 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:36:06,560] Trial 153 finished with value: 0.05045078668629397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:36:09,448] Trial 161 finished with value: 0.06351047615168012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3854, 'weights': 'uniform'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:36:09,858] Trial 162 finished with value: 0.06372743180151116 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:36:19,188] Trial 163 finished with value: 0.05697918181271835 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:38:35,914] Trial 155 finished with value: 0.05018314362276075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:39:10,805] Trial 154 finished with value: 0.04982313886896629 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:40:36,728] Trial 158 finished with value: 0.05235709389377041 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:40:43,271] Trial 156 finished with value: 0.052825827777159516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:41:29,844] Trial 157 finished with value: 0.052460637649405104 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:44:07,347] Trial 159 finished with value: 0.051444857248213294 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:49:36,557] Trial 164 finished with value: 0.05317767987687666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:50:08,832] Trial 160 finished with value: 0.051269532799924224 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:50:21,451] Trial 171 finished with value: 0.057749990088250415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:50:59,060] Trial 172 finished with value: 0.0917130307157379 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:51:35,567] Trial 174 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.10797069726711683, 'alpha': 76, 'iterations': 97, 'learning_rate': 0.0018356578108560885, 'p_miss': 0.1015688334198262}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:51:58,227] Trial 165 finished with value: 0.05314333403949141 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:55:17,858] Trial 166 finished with value: 0.049978578191731175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:55:42,666] Trial 167 finished with value: 0.050581936673846715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:57:06,705] Trial 168 finished with value: 0.05061804456111019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:58:07,460] Trial 169 finished with value: 0.05028686203936441 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 17:59:49,419] Trial 170 finished with value: 0.04985116902110459 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 18:04:38,345] Trial 173 finished with value: 0.05027891389062822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 127 with value: 0.04956531511533378.
running
[I 2024-11-21 18:05:53,510] Trial 176 finished with value: 0.04948450560820018 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:06:41,753] Trial 175 finished with value: 0.0507962322612476 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:09:37,186] Trial 178 finished with value: 0.04972123772346123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:09:42,624] Trial 177 finished with value: 0.05059080561477934 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:09:56,868] Trial 185 finished with value: 0.19211848844445298 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 3, 'learning_rate': 0.03215570587460491, 'p_miss': 0.16968354815438447}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:10:26,063] Trial 1 finished with value: 0.06845539611178111 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 9403, 'learning_rate': 0.00021219509897947851, 'p_miss': 0.08247760284968211}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:10:42,941] Trial 71 finished with value: 0.06682267812224277 and parameters: {'model_name': 'VAE', 'batch_size': 858, 'iterations': 6632, 'learning_rate': 0.009738342464852709, 'p_miss': 0.21013417805953577}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:12:19,581] Trial 179 finished with value: 0.050343082913355694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:12:29,251] Trial 190 finished with value: 0.058747138212001435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:13:41,534] Trial 180 finished with value: 0.05085376420961367 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:18:44,232] Trial 66 finished with value: 0.06705716072010137 and parameters: {'model_name': 'VAE', 'batch_size': 397, 'iterations': 8792, 'learning_rate': 0.009194630408993126, 'p_miss': 0.20494882584977667}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:23:08,393] Trial 187 finished with value: 0.0510856988148833 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:23:24,147] Trial 186 finished with value: 0.05022337561880238 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:23:54,675] Trial 189 finished with value: 0.04994678582387453 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:24:14,319] Trial 188 finished with value: 0.049828418566962504 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:27:24,753] Trial 191 finished with value: 0.04988543950037423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:29:09,533] Trial 192 finished with value: 0.05052657576341979 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
running
[I 2024-11-21 18:33:10,413] Trial 193 finished with value: 0.05052540004479474 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:36:49,346] Trial 194 finished with value: 0.05040776351502656 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:36:50,755] Trial 195 finished with value: 0.0498343908444082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:37:33,505] Trial 196 finished with value: 0.05006519712941757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:37:56,022] Trial 197 finished with value: 0.05009121082655517 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:41:09,875] Trial 198 finished with value: 0.049692935731021584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:42:20,005] Trial 30 finished with value: 0.06674496494667417 and parameters: {'model_name': 'VAE', 'batch_size': 991, 'iterations': 6805, 'learning_rate': 0.00013343068925887727, 'p_miss': 0.2970345845317141}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:42:36,644] Trial 199 finished with value: 0.050172923953518564 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:46:53,731] Trial 183 finished with value: 0.07105188975303427 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 1032, 'learning_rate': 0.021719826149915366, 'p_miss': 0.16605104050203098}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:47:59,088] Trial 182 finished with value: 0.06821147518151909 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 1037, 'learning_rate': 0.09761101016038537, 'p_miss': 0.175685529673566}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:55:46,429] Trial 181 finished with value: 0.06640058002494054 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 1232, 'learning_rate': 0.09548209591053222, 'p_miss': 0.17583922412261643}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 18:58:45,619] Trial 184 finished with value: 0.06791339673048213 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 1586, 'learning_rate': 0.021455797814041073, 'p_miss': 0.16137472783704607}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 19:00:12,694] Trial 62 finished with value: 0.06674464525698004 and parameters: {'model_name': 'VAE', 'batch_size': 947, 'iterations': 8463, 'learning_rate': 0.00996743166524015, 'p_miss': 0.20812028525142434}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 19:06:05,011] Trial 69 finished with value: 0.06682709968146622 and parameters: {'model_name': 'VAE', 'batch_size': 743, 'iterations': 9266, 'learning_rate': 0.009810122739741405, 'p_miss': 0.20231541197887984}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 19:06:19,398] Trial 80 finished with value: 0.06655388447366978 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 9000, 'learning_rate': 0.0018578585074102974, 'p_miss': 0.28038425534433326}. Best is trial 176 with value: 0.04948450560820018.
[I 2024-11-21 19:08:16,302] Trial 72 finished with value: 0.06667037179613121 and parameters: {'model_name': 'VAE', 'batch_size': 921, 'iterations': 8956, 'learning_rate': 0.009572704810339033, 'p_miss': 0.20113525418045003}. Best is trial 176 with value: 0.04948450560820018.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.04948450560820018
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9148544917656144
Generation:   4%|▍         | 1/25 [00:09<03:50,  9.61s/it]Generation:  2
Best f1_score score: 0.9148544917656144
Generation:   8%|▊         | 2/25 [00:18<03:25,  8.94s/it]Generation:  3
Best f1_score score: 0.9148544917656144
Generation:  12%|█▏        | 3/25 [01:13<11:06, 30.30s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472c0a0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  4
Best f1_score score: 0.9278351045409128
Generation:  16%|█▌        | 4/25 [02:20<15:41, 44.85s/it]Generation:  5
Best f1_score score: 0.9278351045409128
Generation:  20%|██        | 5/25 [02:33<11:03, 33.17s/it]Generation:  6
Best f1_score score: 0.9278351045409128
Generation:  24%|██▍       | 6/25 [03:42<14:24, 45.52s/it]Generation:  7
Best f1_score score: 0.9278351045409128
Generation:  28%|██▊       | 7/25 [03:59<10:50, 36.17s/it]Generation:  8
Best f1_score score: 0.9278351045409128
Generation:  32%|███▏      | 8/25 [05:48<16:45, 59.13s/it]Generation:  9
Best f1_score score: 0.9278351045409128
Generation:  36%|███▌      | 9/25 [06:00<11:50, 44.43s/it]Generation:  10
Best f1_score score: 0.9278351045409128
Generation:  40%|████      | 10/25 [06:17<09:00, 36.02s/it]Generation:  11
Best f1_score score: 0.9278351045409128
Generation:  44%|████▍     | 11/25 [06:44<07:45, 33.26s/it]Generation:  12
Best f1_score score: 0.9278351045409128
Generation:  48%|████▊     | 12/25 [06:54<05:40, 26.17s/it]Generation:  13
Best f1_score score: 0.9278351045409128
Generation:  52%|█████▏    | 13/25 [09:44<13:55, 69.66s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ffb80> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  14
Best f1_score score: 0.9278351045409128
Generation:  56%|█████▌    | 14/25 [10:20<10:56, 59.70s/it]Generation:  15
Best f1_score score: 0.9278351045409128
Generation:  60%|██████    | 15/25 [10:31<07:29, 44.98s/it]Generation:  16
Best f1_score score: 0.9278351045409128
Generation:  64%|██████▍   | 16/25 [11:07<06:21, 42.37s/it]Generation:  17
Best f1_score score: 0.9278351045409128
Generation:  68%|██████▊   | 17/25 [11:21<04:30, 33.84s/it]Generation:  18
Best f1_score score: 0.9278351045409128
Generation:  72%|███████▏  | 18/25 [11:35<03:14, 27.84s/it]Generation:  19
Best f1_score score: 0.9278351045409128
Generation:  76%|███████▌  | 19/25 [12:21<03:19, 33.21s/it]Generation:  20
Best f1_score score: 0.9278351045409128
Generation:  80%|████████  | 20/25 [12:44<02:30, 30.16s/it]Generation:  21
Best f1_score score: 0.9278351045409128
Generation:  84%|████████▍ | 21/25 [13:01<01:45, 26.28s/it]Generation:  22
Best f1_score score: 0.9278351045409128
Generation:  88%|████████▊ | 22/25 [14:32<02:16, 45.56s/it]Generation:  23
Best f1_score score: 0.9278351045409128
Generation:  92%|█████████▏| 23/25 [19:02<03:45, 112.83s/it]Generation:  24
Best f1_score score: 0.9399079597176929
Generation:  96%|█████████▌| 24/25 [20:28<01:44, 104.84s/it]Generation:  25
Best f1_score score: 0.9399079597176929
Generation: 100%|██████████| 25/25 [22:04<00:00, 102.18s/it]Generation: 100%|██████████| 25/25 [22:07<00:00, 53.10s/it] 
2024-11-21 19:31:54,798 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41185' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-f8669e463f79e8b50f494c45639fa7dd', 'ndarray-ebd5ec05bb0f66b412969f9be33321b3'} (stimulus_id='handle-worker-cleanup-1732246314.7985759')
Fitted
Pipeline(steps=[('mlpclassifier',
                 MLPClassifier(alpha=0.0013148327873,
                               hidden_layer_sizes=[22, 22],
                               learning_rate='adaptive',
                               learning_rate_init=0.0033648573192,
                               n_iter_no_change=32))])
score start
train score: {'auroc': 0.9963598734187138, 'accuracy': 0.9857917850684578, 'balanced_accuracy': 0.8909791234951487, 'logloss': 0.036713194518721584, 'f1': 0.924461512643086}
original test score: {'auroc': 0.9913293584145113, 'accuracy': 0.981404958677686, 'balanced_accuracy': 0.8359926100100773, 'logloss': 0.05073337284765342, 'f1': 0.8928571428571428}
imputed test score: {'auroc': 0.9907415183070205, 'accuracy': 0.9793388429752066, 'balanced_accuracy': 0.816761840779308, 'logloss': 0.05542050106094128, 'f1': 0.8783155248271528}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd5360> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.9006098395332078
Generation:   4%|▍         | 1/25 [05:11<2:04:30, 311.29s/it]Generation:  2
Best f1_score score: 0.9104934671527538
Generation:   8%|▊         | 2/25 [05:43<56:25, 147.18s/it]  Generation:  3
Best f1_score score: 0.9104934671527538
Generation:  12%|█▏        | 3/25 [06:14<34:27, 94.00s/it] Generation:  4
Best f1_score score: 0.9119346605882808
Generation:  16%|█▌        | 4/25 [06:27<21:45, 62.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545738e320> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  5
Best f1_score score: 0.9119346605882808
Generation:  20%|██        | 5/25 [08:38<28:55, 86.79s/it]Generation:  6
Best f1_score score: 0.9131383771402476
Generation:  24%|██▍       | 6/25 [13:52<51:59, 164.19s/it]Generation:  7
Best f1_score score: 0.9285566840000248
Generation:  28%|██▊       | 7/25 [15:53<45:01, 150.10s/it]Generation:  8
Best f1_score score: 0.9285566840000248
Generation:  32%|███▏      | 8/25 [17:52<39:44, 140.26s/it]Generation:  9
Best f1_score score: 0.9285566840000248
Generation:  36%|███▌      | 9/25 [19:32<34:01, 127.60s/it]Generation:  10
Best f1_score score: 0.9285566840000248
Generation:  40%|████      | 10/25 [21:50<32:39, 130.64s/it]Generation:  11
Best f1_score score: 0.9285566840000248
Generation:  44%|████▍     | 11/25 [23:48<29:35, 126.85s/it]Generation:  12
Best f1_score score: 0.9367156910056321
Generation:  48%|████▊     | 12/25 [32:33<53:42, 247.89s/it]Generation:  13
Best f1_score score: 0.9388785789794429
Generation:  52%|█████▏    | 13/25 [37:47<53:38, 268.20s/it]Generation:  14
Best f1_score score: 0.9389223820275024
Generation:  56%|█████▌    | 14/25 [43:09<52:08, 284.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455542560> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  15
Best f1_score score: 0.9389223820275024
Generation:  60%|██████    | 15/25 [50:52<56:20, 338.01s/it]Generation:  16
Best f1_score score: 0.9402356293339956
Generation:  64%|██████▍   | 16/25 [58:05<55:01, 366.81s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547427cf40> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  17
Best f1_score score: 0.9402356293339956
Generation:  68%|██████▊   | 17/25 [1:03:19<46:47, 350.99s/it]Generation:  18
Best f1_score score: 0.9402356293339956
Generation:  72%|███████▏  | 18/25 [1:08:47<40:08, 344.01s/it]Generation:  19
Best f1_score score: 0.9402356293339956
Generation:  76%|███████▌  | 19/25 [1:16:08<37:18, 373.06s/it]Generation:  20
Best f1_score score: 0.9402356293339956
Generation:  80%|████████  | 20/25 [1:22:37<31:29, 377.90s/it]Generation:  21
Best f1_score score: 0.9402356293339956
Generation:  84%|████████▍ | 21/25 [1:24:57<20:26, 306.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554575324a0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  22
Best f1_score score: 0.9402356293339956
Generation:  88%|████████▊ | 22/25 [1:27:00<12:34, 251.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545af5e1d0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  23
Best f1_score score: 0.9402356293339956
Generation:  92%|█████████▏| 23/25 [1:35:16<10:49, 324.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452c83040> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  24
Best f1_score score: 0.9402356293339956
Generation:  96%|█████████▌| 24/25 [1:44:01<06:24, 384.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455337430> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453164100> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  25
Best f1_score score: 0.9402356293339956
Generation: 100%|██████████| 25/25 [1:45:21<00:00, 293.46s/it]Generation: 100%|██████████| 25/25 [1:45:21<00:00, 252.87s/it]
2024-11-21 21:17:26,427 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45709' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-7b4208107d809dc2ce1615625f7d455a', 'ndarray-ebd5ec05bb0f66b412969f9be33321b3'} (stimulus_id='handle-worker-cleanup-1732252646.4272428')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=78)),
                ('mlpclassifier',
                 MLPClassifier(alpha=0.0010478331418,
                               hidden_layer_sizes=[39, 39, 39],
                               learning_rate_init=0.0038951947836,
                               n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9933469043245122, 'accuracy': 0.9901834151382072, 'balanced_accuracy': 0.9632302791634764, 'logloss': 0.0337085187574635, 'f1': 0.9530097189106029}
test score: {'auroc': 0.9843802485723884, 'accuracy': 0.9855371900826446, 'balanced_accuracy': 0.9288713469936177, 'logloss': 0.046677792149034114, 'f1': 0.9288713469936177}
original test score: {'auroc': 0.985136042996305, 'accuracy': 0.9865702479338843, 'balanced_accuracy': 0.9294171985220021, 'logloss': 0.04318643752100792, 'f1': 0.933347104592715}
score end
40983
lvl
0.01
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
13.100453389088313
hours
DONE
