Run: 57
/cm/local/apps/slurm/var/spool/job1069384/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/23395/23395.pkl
working on 
../data/c/23395/class_full_MNAR_0.01_3
3.5629212856292725
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-23 04:30:40,668] A new study created in memory with name: no-name-5f93dc2d-5320-49a7-b49c-f42dba7f8f5f
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-23 04:30:40,780] Trial 4 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.04526416487526203, 'p_miss': 0.11974774152440111}. Best is trial 4 with value: inf.
running
[I 2024-11-23 04:30:41,402] Trial 7 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.4200694025872111.
[I 2024-11-23 04:30:41,602] Trial 13 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.4200694025872111.
running
running
[I 2024-11-23 04:30:43,155] Trial 16 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 7 with value: 0.4200694025872111.
running
[I 2024-11-23 04:30:43,685] Trial 0 finished with value: 0.2329948412567951 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.2329948412567951.
[I 2024-11-23 04:30:43,897] Trial 17 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 31, 'learning_rate': 0.07345106094249959, 'p_miss': 0.2237974152486424}. Best is trial 0 with value: 0.2329948412567951.
running
running
[I 2024-11-23 04:30:44,569] Trial 21 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:30:44,777] Trial 20 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:30:55,112] Trial 23 finished with value: 0.38745462085958604 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.8744228553230022, 'alpha': 95, 'iterations': 18, 'learning_rate': 0.0452162696790291, 'p_miss': 0.2550173874939701}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:30:55,501] Trial 24 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.022756793470970035, 'p_miss': 0.16700951589709698}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:30:56,117] Trial 15 finished with value: 0.40414502095338883 and parameters: {'model_name': 'GAIN', 'batch_size': 46, 'hint_rate': 0.06167956620991732, 'alpha': 26, 'iterations': 18, 'learning_rate': 0.005688844272509416, 'p_miss': 0.15408210615375698}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:30:57,929] Trial 11 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.7147466884884979, 'alpha': 74, 'iterations': 143, 'learning_rate': 0.001274408593610731, 'p_miss': 0.027442592984698894}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:31:23,510] Trial 2 finished with value: 0.3207195524928359 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:31:24,821] Trial 14 finished with value: 0.32695625468315886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:31:50,221] Trial 10 finished with value: 0.23643401336919476 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 427, 'weights': 'distance'}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:32:05,342] Trial 3 finished with value: 0.2364068981757616 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7306, 'weights': 'distance'}. Best is trial 0 with value: 0.2329948412567951.
running
[I 2024-11-23 04:32:14,773] Trial 18 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 68619, 'weights': 'uniform'}. Best is trial 18 with value: 0.23009573497304614.
running
[I 2024-11-23 04:32:15,037] Trial 28 finished with value: 0.3207195524928359 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 18 with value: 0.23009573497304614.
running
[I 2024-11-23 04:32:18,330] Trial 12 finished with value: 0.22993680535839003 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25234, 'weights': 'uniform'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:32:26,363] Trial 27 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 63830, 'weights': 'uniform'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:32:26,823] Trial 26 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 64628, 'weights': 'uniform'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:32:40,105] Trial 9 finished with value: 0.23639383339834125 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38368, 'weights': 'distance'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:32:42,558] Trial 8 finished with value: 0.23639287292867892 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 40664, 'weights': 'distance'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:33:00,460] Trial 30 finished with value: 0.2364130507438038 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4055, 'weights': 'distance'}. Best is trial 12 with value: 0.22993680535839003.
running
[I 2024-11-23 04:33:21,300] Trial 31 finished with value: 0.22990262841938555 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17523, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:29,462] Trial 32 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 68806, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:31,919] Trial 33 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 70214, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:34,754] Trial 34 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 64447, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:40,570] Trial 36 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 66995, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:49,225] Trial 35 finished with value: 0.23000097667475763 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 41256, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:52,101] Trial 37 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 71525, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:33:56,794] Trial 38 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 64100, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:34:14,259] Trial 39 finished with value: 0.23009573497304614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 71352, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:34:31,952] Trial 1 finished with value: 0.4362845319848496 and parameters: {'model_name': 'GAIN', 'batch_size': 938, 'hint_rate': 0.8723300031965625, 'alpha': 19, 'iterations': 455, 'learning_rate': 0.005153907415390207, 'p_miss': 0.161141889860466}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:34:37,185] Trial 40 finished with value: 0.22996532467861072 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21719, 'weights': 'uniform'}. Best is trial 31 with value: 0.22990262841938555.
running
[I 2024-11-23 04:34:44,017] Trial 50 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:46,100] Trial 41 finished with value: 0.2299687662773653 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24309, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:46,809] Trial 52 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 989, 'iterations': 7926, 'learning_rate': 0.0001503679621505483, 'p_miss': 0.29791901167240875}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:48,506] Trial 42 finished with value: 0.22996334329724638 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21363, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:51,179] Trial 43 finished with value: 0.22995712845857028 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21914, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:53,733] Trial 51 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:57,451] Trial 53 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:57,812] Trial 54 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:34:59,094] Trial 44 finished with value: 0.22995394286932988 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20183, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:01,364] Trial 55 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:03,095] Trial 56 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:06,650] Trial 57 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:08,383] Trial 58 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:09,650] Trial 59 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:10,445] Trial 60 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:10,623] Trial 46 finished with value: 0.2299611741339629 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21235, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:11,135] Trial 45 finished with value: 0.2299572364696522 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23691, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:12,756] Trial 61 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:15,264] Trial 62 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:16,762] Trial 63 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:17,906] Trial 47 finished with value: 0.2299261263797915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22572, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:18,531] Trial 64 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:18,926] Trial 66 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:19,314] Trial 65 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:20,866] Trial 67 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:23,837] Trial 68 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:27,327] Trial 69 finished with value: 0.22849668298193163 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:29,862] Trial 48 finished with value: 0.22995794662584249 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21106, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:35:41,297] Trial 49 finished with value: 0.22996121880473624 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21220, 'weights': 'uniform'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:36:00,923] Trial 73 finished with value: 0.24494699186335991 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:36:01,462] Trial 71 finished with value: 0.2472407444544408 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:36:01,672] Trial 72 finished with value: 0.24494699186335991 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:36:06,795] Trial 77 finished with value: 0.246717361479397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:36:09,634] Trial 80 finished with value: 0.22849668347570548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:37:43,038] Trial 5 finished with value: 0.4218004163978574 and parameters: {'model_name': 'GAIN', 'batch_size': 920, 'hint_rate': 0.38566742542861016, 'alpha': 24, 'iterations': 647, 'learning_rate': 0.059043655874354936, 'p_miss': 0.23858073616963796}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:51:11,387] Trial 81 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 167, 'hint_rate': 0.2942533201114968, 'alpha': 54, 'iterations': 5658, 'learning_rate': 0.000155332536976625, 'p_miss': 0.011535454578341292}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:53:57,283] Trial 29 finished with value: 0.23293368674023437 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:02,253] Trial 87 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:07,621] Trial 88 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:13,342] Trial 89 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:13,995] Trial 90 finished with value: 0.23009573497304614 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:20,287] Trial 91 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 04:54:20,647] Trial 92 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0008934188714299528, 'p_miss': 0.07055773827023906}. Best is trial 50 with value: 0.2284966717233372.
running
[I 2024-11-23 05:01:17,893] Trial 19 finished with value: 0.22787203210708254 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:07:57,839] Trial 25 finished with value: 0.2323883036809858 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:08:30,880] Trial 22 finished with value: 0.2294400193350586 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:08:43,653] Trial 96 finished with value: 0.22850746055618076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:38,489] Trial 75 finished with value: 0.2328625763869822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:39,267] Trial 79 finished with value: 0.23373515675644926 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:44,828] Trial 98 finished with value: 0.2284967445080393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:47,507] Trial 76 finished with value: 0.23277116449749427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:51,201] Trial 99 finished with value: 0.22863557359767187 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:56,235] Trial 74 finished with value: 0.2337234130093388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:10:58,494] Trial 70 finished with value: 0.23282254727924792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:11:04,836] Trial 78 finished with value: 0.23349236605662482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.22787203210708254.
running
[I 2024-11-23 05:11:16,129] Trial 84 finished with value: 0.2258266098779662 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:24,879] Trial 102 finished with value: 0.4227890272923416 and parameters: {'model_name': 'GAIN', 'batch_size': 170, 'hint_rate': 0.04931996964586449, 'alpha': 1, 'iterations': 646, 'learning_rate': 0.0005696871670006497, 'p_miss': 0.08652206318152184}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:26,401] Trial 107 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:46,499] Trial 83 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 164, 'hint_rate': 0.26106879732649285, 'alpha': 54, 'iterations': 9100, 'learning_rate': 0.00010076947493219486, 'p_miss': 0.016891261624262188}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:48,177] Trial 108 finished with value: 0.22854382391190037 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:48,459] Trial 110 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5, 'learning_rate': 0.013672786606419853, 'p_miss': 0.20176851327525885}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:25:53,212] Trial 111 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:02,479] Trial 112 finished with value: 0.22852282759501388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:06,447] Trial 109 finished with value: 0.22854382391190037 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:07,308] Trial 113 finished with value: 0.2284966775809032 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:11,958] Trial 114 finished with value: 0.2284966775809032 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:13,681] Trial 115 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:17,380] Trial 116 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:19,520] Trial 117 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:23,170] Trial 118 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:25,756] Trial 119 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:27,904] Trial 120 finished with value: 0.2284966717233372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:30,371] Trial 121 finished with value: 0.22849667991568542 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:26:31,215] Trial 123 finished with value: 0.23009573497304614 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 84 with value: 0.2258266098779662.
running
[I 2024-11-23 05:28:19,628] Trial 86 finished with value: 0.22580718372729783 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:31:47,487] Trial 97 finished with value: 0.23051290009319403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:32:43,093] Trial 93 finished with value: 0.22974573442802576 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:33:12,229] Trial 94 finished with value: 0.22827175346775683 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:35:45,596] Trial 101 finished with value: 0.4215769694347872 and parameters: {'model_name': 'GAIN', 'batch_size': 139, 'hint_rate': 0.582570132906697, 'alpha': 2, 'iterations': 1202, 'learning_rate': 0.0005109103517421284, 'p_miss': 0.07410179178291124}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:37:33,066] Trial 104 finished with value: 0.42290096941644456 and parameters: {'model_name': 'GAIN', 'batch_size': 141, 'hint_rate': 0.6073213502305248, 'alpha': 0, 'iterations': 1256, 'learning_rate': 0.0004502239090649919, 'p_miss': 0.08268192985414312}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:38:43,068] Trial 105 finished with value: 0.4129431862888332 and parameters: {'model_name': 'GAIN', 'batch_size': 133, 'hint_rate': 0.02140365725151777, 'alpha': 52, 'iterations': 1310, 'learning_rate': 0.0005500990805025289, 'p_miss': 0.0788275280252339}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:39:56,842] Trial 100 finished with value: 0.42013656929622256 and parameters: {'model_name': 'GAIN', 'batch_size': 144, 'hint_rate': 0.014612814672561314, 'alpha': 2, 'iterations': 1465, 'learning_rate': 0.0003591997574967849, 'p_miss': 0.08540604583738755}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:42:26,868] Trial 106 finished with value: 0.4201548925460824 and parameters: {'model_name': 'GAIN', 'batch_size': 148, 'hint_rate': 0.5881299471488469, 'alpha': 5, 'iterations': 1582, 'learning_rate': 0.0005836406569755155, 'p_miss': 0.08736018900669375}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:42:49,457] Trial 95 finished with value: 0.4240143584433905 and parameters: {'model_name': 'GAIN', 'batch_size': 122, 'hint_rate': 0.010947321927971598, 'alpha': 0, 'iterations': 1852, 'learning_rate': 0.0005138913913761561, 'p_miss': 0.08126734990827325}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:45:48,461] Trial 103 finished with value: 0.4280236968993282 and parameters: {'model_name': 'GAIN', 'batch_size': 117, 'hint_rate': 0.02251830320861825, 'alpha': 2, 'iterations': 1798, 'learning_rate': 0.0005475482876329621, 'p_miss': 0.09194226469315978}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:48:29,384] Trial 6 finished with value: 0.41903384610659666 and parameters: {'model_name': 'GAIN', 'batch_size': 471, 'hint_rate': 0.8708556067000202, 'alpha': 97, 'iterations': 5488, 'learning_rate': 0.0001868309187741242, 'p_miss': 0.1911571790851605}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:52:52,926] Trial 82 finished with value: 0.41621747399249076 and parameters: {'model_name': 'GAIN', 'batch_size': 246, 'hint_rate': 0.2872341945825576, 'alpha': 53, 'iterations': 5931, 'learning_rate': 0.00010679954357538557, 'p_miss': 0.033569334833207926}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:54:03,551] Trial 85 finished with value: 0.4172132110495558 and parameters: {'model_name': 'GAIN', 'batch_size': 127, 'hint_rate': 0.06279013273308554, 'alpha': 58, 'iterations': 7186, 'learning_rate': 0.00011472699382128846, 'p_miss': 0.037766793179826716}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:58:31,354] Trial 128 finished with value: 0.22932202647999103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:59:44,262] Trial 122 finished with value: 0.22979037947117834 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 86 with value: 0.22580718372729783.
running
[I 2024-11-23 05:59:51,290] Trial 124 finished with value: 0.22551223870684703 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 05:59:57,323] Trial 129 finished with value: 0.22929495871662925 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:00:59,614] Trial 125 finished with value: 0.23261412551896102 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:01:08,492] Trial 130 finished with value: 0.22901217257598722 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:01:46,798] Trial 131 finished with value: 0.22860068446244902 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:02:23,485] Trial 132 finished with value: 0.2288285315384031 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:02:27,346] Trial 146 finished with value: 0.22849668347570548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:02:32,544] Trial 147 finished with value: 0.22849668347570548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:03:41,186] Trial 126 finished with value: 0.22563459642604916 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:04:18,246] Trial 133 finished with value: 0.22799459157502508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:04:18,437] Trial 150 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 171, 'learning_rate': 0.0016568498414317365, 'p_miss': 0.28642744233576556}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:04:24,223] Trial 127 finished with value: 0.2255149164428861 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:04:36,200] Trial 134 finished with value: 0.22825814503262482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:06:36,805] Trial 135 finished with value: 0.22989296163700845 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:07:45,523] Trial 136 finished with value: 0.22799047607190878 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:11:21,082] Trial 137 finished with value: 0.22754115883987303 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:12:26,408] Trial 138 finished with value: 0.22668983266829637 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:16:54,197] Trial 139 finished with value: 0.22744167226690554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:18:01,938] Trial 140 finished with value: 0.22702884850638072 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:18:14,956] Trial 141 finished with value: 0.2273006102450573 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:22:51,977] Trial 153 finished with value: 0.22740593376473922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:24:51,124] Trial 154 finished with value: 0.2273504118606581 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:25:54,297] Trial 155 finished with value: 0.2277400407593499 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:26:21,761] Trial 142 finished with value: 0.22557453301787694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:27:25,488] Trial 143 finished with value: 0.22708540103209587 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:27:36,352] Trial 144 finished with value: 0.2256631274548236 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:28:13,767] Trial 145 finished with value: 0.22666338165363387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:28:41,850] Trial 148 finished with value: 0.22587998136410653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:29:34,486] Trial 156 finished with value: 0.22924094165394715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:29:58,793] Trial 149 finished with value: 0.2256066938117962 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:30:37,482] Trial 151 finished with value: 0.22573479746552244 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:30:39,395] Trial 157 finished with value: 0.22796556801207876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:30:45,546] Trial 152 finished with value: 0.22555231394261463 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:35:20,906] Trial 158 finished with value: 0.22822215279751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:36:24,003] Trial 159 finished with value: 0.22758463553185315 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:36:24,259] Trial 175 finished with value: 0.4200694025872111 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:36:38,774] Trial 160 finished with value: 0.22732232924077794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:41:18,817] Trial 161 finished with value: 0.22816938245271853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:43:16,905] Trial 162 finished with value: 0.22844790487875793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:44:22,853] Trial 163 finished with value: 0.22957893182881112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:44:46,333] Trial 164 finished with value: 0.22810212001658395 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:45:52,305] Trial 165 finished with value: 0.22883329979829775 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:45:52,516] Trial 182 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 3, 'learning_rate': 0.0024983467583565024, 'p_miss': 0.12915394494025484}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:46:02,629] Trial 166 finished with value: 0.22743528179636666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 124 with value: 0.22551223870684703.
running
[I 2024-11-23 06:47:16,096] Trial 167 finished with value: 0.22455468496950695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 167 with value: 0.22455468496950695.
running
[I 2024-11-23 06:47:41,960] Trial 168 finished with value: 0.22438450975969762 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 168 with value: 0.22438450975969762.
running
[I 2024-11-23 06:48:32,852] Trial 169 finished with value: 0.2242261638166508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 06:56:19,596] Trial 170 finished with value: 0.22659909220234026 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 06:56:57,256] Trial 171 finished with value: 0.22629142407663383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 06:56:59,368] Trial 172 finished with value: 0.2259865224031823 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 06:57:06,653] Trial 173 finished with value: 0.22692357948466907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:01:38,213] Trial 174 finished with value: 0.2258399831545887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:02:30,600] Trial 176 finished with value: 0.22675728120006017 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:02:43,598] Trial 177 finished with value: 0.22688344838964306 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:02:59,509] Trial 194 finished with value: 0.246717361479397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:07:28,983] Trial 178 finished with value: 0.22627279969386996 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:09:19,354] Trial 179 finished with value: 0.22587153687908015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:10:22,965] Trial 180 finished with value: 0.22650609349084178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:10:45,859] Trial 181 finished with value: 0.22754775119819728 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
running
[I 2024-11-23 07:11:52,122] Trial 183 finished with value: 0.22698901611131306 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:11:57,420] Trial 184 finished with value: 0.22562227662972761 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:13:12,439] Trial 185 finished with value: 0.22626098295412037 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:13:34,273] Trial 186 finished with value: 0.22596685693682245 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:14:19,902] Trial 187 finished with value: 0.22661538901057843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:21:53,373] Trial 188 finished with value: 0.22587335989908533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:22:17,369] Trial 189 finished with value: 0.22592103115822765 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:22:21,604] Trial 190 finished with value: 0.22656813691811198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:22:33,493] Trial 191 finished with value: 0.22581641033730132 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:26:48,974] Trial 192 finished with value: 0.23415598474335714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:27:40,250] Trial 193 finished with value: 0.23192066457948454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:28:02,973] Trial 195 finished with value: 0.2278083427197713 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:32:05,918] Trial 196 finished with value: 0.22745328034400894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:33:46,344] Trial 197 finished with value: 0.22596989463039785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:34:44,787] Trial 198 finished with value: 0.2263117888126059 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
[I 2024-11-23 07:35:04,282] Trial 199 finished with value: 0.22633747263504098 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.2242261638166508.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
dtype: int64
0    0
1    0
2    0
3    0
dtype: int64
0.2242261638166508
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9221742922729298
Generation:   4%|▍         | 1/25 [09:57<3:58:48, 597.03s/it]Generation:  2
Best f1_score score: 0.9221742922729298
Generation:   8%|▊         | 2/25 [13:41<2:24:56, 378.09s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eefe50> 

Generation:  3
Best f1_score score: 0.9221742922729298
Generation:  12%|█▏        | 3/25 [23:46<2:56:33, 481.53s/it]Generation:  4
Best f1_score score: 0.9236089922835362
Generation:  16%|█▌        | 4/25 [25:45<1:58:27, 338.43s/it]Generation:  5
Best f1_score score: 0.9291063202295898
Generation:  20%|██        | 5/25 [27:17<1:23:08, 249.45s/it]Generation:  6
Best f1_score score: 0.932667119572168
Generation:  24%|██▍       | 6/25 [29:06<1:03:54, 201.82s/it]Generation:  7
Best f1_score score: 0.932667119572168
Generation:  28%|██▊       | 7/25 [36:07<1:22:02, 273.48s/it]Generation:  8
Best f1_score score: 0.9329799794974697
Generation:  32%|███▏      | 8/25 [38:36<1:06:16, 233.90s/it]Generation:  9
Best f1_score score: 0.9329799794974697
Generation:  36%|███▌      | 9/25 [39:21<46:35, 174.70s/it]  Generation:  10
Best f1_score score: 0.9342733760497601
Generation:  40%|████      | 10/25 [40:08<33:50, 135.38s/it]Generation:  11
Best f1_score score: 0.9342733760497601
Generation:  44%|████▍     | 11/25 [40:55<25:15, 108.28s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747125c0> 

Generation:  12
Best f1_score score: 0.9342733760497601
Generation:  48%|████▊     | 12/25 [51:04<56:27, 260.56s/it]Generation:  13
Best f1_score score: 0.9342733760497601
Generation:  52%|█████▏    | 13/25 [52:05<40:03, 200.27s/it]Generation:  14
Best f1_score score: 0.9342733760497601
Generation:  56%|█████▌    | 14/25 [53:16<29:31, 161.00s/it]Generation:  15
Best f1_score score: 0.9342733760497601
Generation:  60%|██████    | 15/25 [54:06<21:17, 127.73s/it]Generation:  16
Best f1_score score: 0.9342733760497601
Generation:  64%|██████▍   | 16/25 [58:35<25:31, 170.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747301c0> 

Generation:  17
Best f1_score score: 0.9342733760497601
Generation:  68%|██████▊   | 17/25 [1:08:46<40:22, 302.78s/it]Generation:  18
Best f1_score score: 0.9342733760497601
Generation:  72%|███████▏  | 18/25 [1:09:10<25:32, 218.86s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464fd40a0> 

Generation:  19
Best f1_score score: 0.9342733760497601
Generation:  76%|███████▌  | 19/25 [1:19:20<33:39, 336.54s/it]Generation:  20
Best f1_score score: 0.9342733760497601
Generation:  80%|████████  | 20/25 [1:19:43<20:11, 242.36s/it]Generation:  21
Best f1_score score: 0.9342733760497601
Generation:  84%|████████▍ | 21/25 [1:20:32<12:16, 184.23s/it]Generation:  22
Best f1_score score: 0.9351083564018197
Generation:  88%|████████▊ | 22/25 [1:23:13<08:52, 177.34s/it]Generation:  23
Best f1_score score: 0.9351083564018197
Generation:  92%|█████████▏| 23/25 [1:31:17<08:58, 269.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554674c08b0> 

Generation:  24
Best f1_score score: 0.9351083564018197
Generation:  96%|█████████▌| 24/25 [1:41:30<06:12, 372.49s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464538460> 

Generation:  25
Best f1_score score: 0.9351083564018197
Generation: 100%|██████████| 25/25 [1:51:44<00:00, 444.96s/it]Generation: 100%|██████████| 25/25 [1:51:48<00:00, 268.32s/it]
2024-11-23 09:29:51,135 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38035' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-06f6063e93d8a71aef1aecaa767b3534', 'ndarray-8f8c22aea6c70fbd60fa1f9e6d8850d2'} (stimulus_id='handle-worker-cleanup-1732382991.135612')
Fitted
Pipeline(steps=[('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=True,
                                                l2_regularization=0.0008870092475,
                                                learning_rate=0.1469327824433,
                                                max_features=0.9826417256609,
                                                max_leaf_nodes=1146,
                                                min_samples_leaf=145,
                                                n_iter_no_change=4, tol=0.0001,
                                                validation_fraction=None))])
score start
train score: {'auroc': 0.9999776167365052, 'accuracy': 0.9992748772869254, 'balanced_accuracy': 0.9975145048973425, 'logloss': 0.004210716931748475, 'f1': 0.9918682768593121}
original test score: {'auroc': 0.9987248040028838, 'accuracy': 0.9945894689870594, 'balanced_accuracy': 0.9524959828783609, 'logloss': 0.013438182340837077, 'f1': 0.940251857234518}
imputed test score: {'auroc': 0.9985711250878568, 'accuracy': 0.9943663543061133, 'balanced_accuracy': 0.9511727622202988, 'logloss': 0.014175868875298514, 'f1': 0.9379338406978587}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0040> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1030> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f70> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0d30> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f8910> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1480> 

Generation:  1
Best f1_score score: 0.8951415947456324
Generation:   4%|▍         | 1/25 [10:01<4:00:47, 601.98s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f9cf0> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.8970960134445782
Generation:   8%|▊         | 2/25 [11:39<1:56:58, 305.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d993c0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474717b50> 

Generation:  3
Best f1_score score: 0.904124077717077
Generation:  12%|█▏        | 3/25 [21:44<2:42:10, 442.29s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467db79a0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f01810> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fc2920> 

Generation:  4
Best f1_score score: 0.904124077717077
Generation:  16%|█▌        | 4/25 [31:48<2:57:04, 505.95s/it]Generation:  5
Best f1_score score: 0.9055787460412489
Generation:  20%|██        | 5/25 [33:30<2:00:08, 360.41s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464e62b90> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ddd390> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  6
Best f1_score score: 0.9055787460412489
Generation:  24%|██▍       | 6/25 [35:16<1:26:42, 273.82s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d9a5f0> 

Generation:  7
Best f1_score score: 0.9120140823448176
Generation:  28%|██▊       | 7/25 [45:22<1:54:45, 382.53s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459c01ab0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

malloc(): invalid next size (unsorted)
2024-11-23 10:19:33,363 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41835' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-a552df79ceef2d63efd46c5de9881fe3', 'ndarray-8f8c22aea6c70fbd60fa1f9e6d8850d2'} (stimulus_id='handle-worker-cleanup-1732385973.3636544')
Cancelled future (likely memory related)
Generation:  8
Best f1_score score: 0.9189484450031074
Generation:  32%|███▏      | 8/25 [49:33<1:36:30, 340.61s/it]2024-11-23 10:19:33,438 - distributed.nanny - WARNING - Restarting worker
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  9
Best f1_score score: 0.9189484450031074
Generation:  36%|███▌      | 9/25 [49:39<1:02:56, 236.03s/it]Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  10
Best f1_score score: 0.9189484450031074
Generation:  40%|████      | 10/25 [49:46<41:16, 165.10s/it] Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  11
Best f1_score score: 0.9189484450031074
Generation:  44%|████▍     | 11/25 [49:52<27:11, 116.57s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  12
Best f1_score score: 0.9189484450031074
Generation:  48%|████▊     | 12/25 [49:57<17:53, 82.56s/it] Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  13
Best f1_score score: 0.9189484450031074
Generation:  52%|█████▏    | 13/25 [50:04<11:55, 59.64s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  14
Best f1_score score: 0.9189484450031074
Generation:  56%|█████▌    | 14/25 [50:10<07:57, 43.42s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  15
Best f1_score score: 0.9189484450031074
Generation:  60%|██████    | 15/25 [50:16<05:21, 32.15s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  16
Best f1_score score: 0.9189484450031074
Generation:  64%|██████▍   | 16/25 [50:22<03:39, 24.34s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  17
Best f1_score score: 0.9189484450031074
Generation:  68%|██████▊   | 17/25 [50:27<02:28, 18.61s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  18
Best f1_score score: 0.9189484450031074
Generation:  72%|███████▏  | 18/25 [50:34<01:44, 14.98s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  19
Best f1_score score: 0.9189484450031074
Generation:  76%|███████▌  | 19/25 [50:40<01:14, 12.39s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  20
Best f1_score score: 0.9189484450031074
Generation:  80%|████████  | 20/25 [50:47<00:53, 10.63s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  21
Best f1_score score: 0.9189484450031074
Generation:  84%|████████▍ | 21/25 [50:52<00:36,  9.03s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  22
Best f1_score score: 0.9189484450031074
Generation:  88%|████████▊ | 22/25 [50:58<00:24,  8.29s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  23
Best f1_score score: 0.9189484450031074
Generation:  92%|█████████▏| 23/25 [51:05<00:15,  7.78s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  24
Best f1_score score: 0.9189484450031074
Generation:  96%|█████████▌| 24/25 [51:10<00:06,  6.94s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  25
Best f1_score score: 0.9189484450031074
Generation: 100%|██████████| 25/25 [51:16<00:00,  6.74s/it]Generation: 100%|██████████| 25/25 [51:16<00:00, 123.07s/it]
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),
                ('randomforestclassifier',
                 RandomForestClassifier(criterion='entropy',
                                        max_features=0.1803623391387,
                                        min_samples_leaf=2,
                                        min_samples_split=16,
                                        n_estimators=128))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9995812115221488, 'accuracy': 0.9964162204373048, 'balanced_accuracy': 0.9622190848597868, 'logloss': 0.012539226740437753, 'f1': 0.9595812644308637}
test score: {'auroc': 0.9982033126846125, 'accuracy': 0.9932507809013833, 'balanced_accuracy': 0.931256652828031, 'logloss': 0.017597614699936256, 'f1': 0.9245825342223464}
original test score: {'auroc': 0.9982778921580814, 'accuracy': 0.9932507809013833, 'balanced_accuracy': 0.9324657442918454, 'logloss': 0.017198536078303704, 'f1': 0.9247615136972573}
score end
23395
lvl
0.01
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
5.848202597432667
hours
DONE
