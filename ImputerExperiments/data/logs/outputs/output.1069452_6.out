Run: 6
/cm/local/apps/slurm/var/spool/job1069452/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40922/40922.pkl
working on 
../data/c/40922/class_full_MAR_0.1_1
3.138195753097534
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-23 10:52:37,780] A new study created in memory with name: no-name-7acef09d-3d3d-44c2-8b4f-7c4c818a100f
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-23 10:52:39,049] Trial 3 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:41,210] Trial 16 finished with value: 0.535992871242666 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:49,727] Trial 17 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.19820974858082632, 'alpha': 86, 'iterations': 5, 'learning_rate': 0.004127612352098724, 'p_miss': 0.05258480963385768}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:50,416] Trial 18 finished with value: 0.535992871242666 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:56,137] Trial 1 finished with value: 0.14266681682927135 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.009550070285466405, 'p_miss': 0.2716204116154531}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:58,266] Trial 6 finished with value: 0.3201860649518685 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.7716658946291538, 'alpha': 34, 'iterations': 2, 'learning_rate': 0.0005828046758923056, 'p_miss': 0.06235184533185686}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:52:58,488] Trial 20 finished with value: 0.3839386956838902 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:00,141] Trial 8 finished with value: 0.32518940880877223 and parameters: {'model_name': 'GAIN', 'batch_size': 160, 'hint_rate': 0.18499040982028683, 'alpha': 77, 'iterations': 2, 'learning_rate': 0.00027682802250134303, 'p_miss': 0.22057459430663381}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:01,915] Trial 11 finished with value: 0.30935235137966766 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.6153097106937341, 'alpha': 59, 'iterations': 4, 'learning_rate': 0.0014027558573988363, 'p_miss': 0.2960903259759825}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:02,644] Trial 2 finished with value: 0.09486526229119874 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:03,986] Trial 23 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.37460175121782, 'alpha': 17, 'iterations': 9, 'learning_rate': 0.0013456730490369957, 'p_miss': 0.09350692990544615}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:14,266] Trial 7 finished with value: 0.09247997733970403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:25,844] Trial 5 finished with value: 0.10965138002096428 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:39,144] Trial 15 finished with value: 0.0976429812457513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 69983, 'weights': 'uniform'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:41,427] Trial 12 finished with value: 0.0976429812457513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 65627, 'weights': 'uniform'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:41,920] Trial 21 finished with value: 0.09408511273420224 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.09061846041012386.
running
[I 2024-11-23 10:53:49,774] Trial 4 finished with value: 0.08950714860594411 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21951, 'weights': 'distance'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:53:54,523] Trial 19 finished with value: 0.1110055949692744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:53:54,795] Trial 26 finished with value: 0.09486526229119874 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:53:55,665] Trial 22 finished with value: 0.0926874696178818 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:02,543] Trial 10 finished with value: 0.09275747784881197 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 70374, 'weights': 'distance'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:04,217] Trial 27 finished with value: 0.09247997733970403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:04,809] Trial 36 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:06,001] Trial 38 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:07,663] Trial 14 finished with value: 0.0920752296480492 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44338, 'weights': 'distance'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:08,225] Trial 39 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:09,411] Trial 40 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:10,978] Trial 25 finished with value: 0.09336054908712996 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23772, 'weights': 'uniform'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:22,342] Trial 29 finished with value: 0.09247997733970403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:22,590] Trial 28 finished with value: 0.09096975756214908 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8982, 'weights': 'uniform'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:23,768] Trial 30 finished with value: 0.09247997733970403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:24,087] Trial 24 finished with value: 0.09035581341211714 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30580, 'weights': 'distance'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:25,322] Trial 46 finished with value: 0.09061846041012386 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.08950714860594411.
running
[I 2024-11-23 10:54:40,551] Trial 32 finished with value: 0.08762475575720417 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9015, 'weights': 'distance'}. Best is trial 32 with value: 0.08762475575720417.
running
[I 2024-11-23 10:54:41,470] Trial 34 finished with value: 0.08666934487025461 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6169, 'weights': 'distance'}. Best is trial 34 with value: 0.08666934487025461.
running
[I 2024-11-23 10:54:43,202] Trial 35 finished with value: 0.08729916694734506 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7813, 'weights': 'distance'}. Best is trial 34 with value: 0.08666934487025461.
running
[I 2024-11-23 10:54:43,482] Trial 33 finished with value: 0.08705146287546442 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7097, 'weights': 'distance'}. Best is trial 34 with value: 0.08666934487025461.
running
[I 2024-11-23 11:19:48,680] Trial 9 finished with value: 0.11594259854680974 and parameters: {'model_name': 'VAE', 'batch_size': 937, 'iterations': 269, 'learning_rate': 0.00027894833421249676, 'p_miss': 0.04245031837502792}. Best is trial 34 with value: 0.08666934487025461.
running
[I 2024-11-23 11:20:16,473] Trial 53 finished with value: 0.08076415658848964 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 260, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:32:56,266] Trial 0 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.0892970539413097, 'alpha': 96, 'iterations': 6313, 'learning_rate': 0.008274443255761894, 'p_miss': 0.053065662771622946}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:46:54,073] Trial 55 finished with value: 0.10777944932950803 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 183, 'learning_rate': 0.07107384141199756, 'p_miss': 0.15296831384106488}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:47:21,407] Trial 56 finished with value: 0.08154863853946351 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 518, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:47:49,927] Trial 57 finished with value: 0.0824814367939837 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 990, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:48:19,433] Trial 58 finished with value: 0.08443256316299057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2341, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:48:49,195] Trial 59 finished with value: 0.08387521669344533 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1859, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:49:17,626] Trial 60 finished with value: 0.08213795169321572 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 797, 'weights': 'distance'}. Best is trial 53 with value: 0.08076415658848964.
running
[I 2024-11-23 11:49:45,718] Trial 61 finished with value: 0.08028001828328074 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 76, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 11:50:14,114] Trial 62 finished with value: 0.08247043081574743 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 984, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:06:20,469] Trial 13 finished with value: 0.34830266588186803 and parameters: {'model_name': 'GAIN', 'batch_size': 263, 'hint_rate': 0.8616316371685525, 'alpha': 27, 'iterations': 3891, 'learning_rate': 0.0006122684400466352, 'p_miss': 0.20129210852454058}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:10:13,641] Trial 64 finished with value: 0.11146816369480272 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 41, 'learning_rate': 0.07681327803563046, 'p_miss': 0.14762742272070856}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:10:50,598] Trial 65 finished with value: 0.08890836852362871 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17418, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:11:18,175] Trial 66 finished with value: 0.08058432741631945 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 211, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:11:46,524] Trial 67 finished with value: 0.08134217842119894 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 441, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:12:22,856] Trial 68 finished with value: 0.08847317082058627 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14888, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:12:49,840] Trial 69 finished with value: 0.08089847427712263 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 294, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:13:24,378] Trial 70 finished with value: 0.08801096628270358 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11708, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:13:50,837] Trial 71 finished with value: 0.08032641369550828 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 68, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:14:22,120] Trial 72 finished with value: 0.08645618803936912 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5655, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 13:15:09,409] Trial 73 finished with value: 0.09217451618547912 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46191, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:09:07,531] Trial 74 finished with value: 0.10640730524244138 and parameters: {'model_name': 'VAE', 'batch_size': 944, 'iterations': 998, 'learning_rate': 0.00010264686047405723, 'p_miss': 0.10992954562909231}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:09:41,210] Trial 75 finished with value: 0.0881303340924621 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12668, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:10:08,307] Trial 76 finished with value: 0.08082150204765168 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 272, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:10:39,011] Trial 77 finished with value: 0.08614477397093481 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4928, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:11:05,933] Trial 78 finished with value: 0.08102551637958728 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 327, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:11:36,270] Trial 79 finished with value: 0.0860678816822105 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4774, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:12:06,282] Trial 80 finished with value: 0.08620094656688426 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5051, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:13:08,227] Trial 81 finished with value: 0.3310698472089111 and parameters: {'model_name': 'GAIN', 'batch_size': 46, 'hint_rate': 0.4977230232887546, 'alpha': 0, 'iterations': 28, 'learning_rate': 0.026268847187877045, 'p_miss': 0.21271730066000055}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:13:35,204] Trial 82 finished with value: 0.08029961174024343 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 86, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:14:08,523] Trial 83 finished with value: 0.08780042891451806 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9919, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:14:38,420] Trial 84 finished with value: 0.08579779741787845 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4229, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:15:10,939] Trial 85 finished with value: 0.09285853853290285 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18775, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:15:38,657] Trial 86 finished with value: 0.0814882748493939 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 498, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:16:05,550] Trial 87 finished with value: 0.08031146607611064 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 85, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:16:36,300] Trial 88 finished with value: 0.08609090766120438 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4821, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:17:06,073] Trial 89 finished with value: 0.08591046599816395 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4453, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:23:29,304] Trial 90 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9837315272695228, 'alpha': 54, 'iterations': 1004, 'learning_rate': 0.023963002898578528, 'p_miss': 0.018570879829489934}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:24:16,680] Trial 91 finished with value: 0.09208621436524729 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44573, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:24:58,201] Trial 92 finished with value: 0.09736174849019037 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 52850, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:26:15,291] Trial 93 finished with value: 0.12661420565867634 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 17, 'learning_rate': 0.0027909722331425427, 'p_miss': 0.24971787196021364}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:26:56,036] Trial 94 finished with value: 0.08984431339558738 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25898, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:27:28,229] Trial 95 finished with value: 0.08736951347496617 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8051, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:27:54,960] Trial 96 finished with value: 0.08148029389325259 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 496, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:28:24,162] Trial 97 finished with value: 0.08552684138616166 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3700, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:28:56,730] Trial 98 finished with value: 0.08742787255228424 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8248, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:29:24,515] Trial 99 finished with value: 0.08059957495608702 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 215, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:29:54,252] Trial 100 finished with value: 0.08543442756117572 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3538, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:30:23,588] Trial 101 finished with value: 0.09030295577208944 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7389, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:31:07,644] Trial 102 finished with value: 0.09073585442474581 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 33266, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:37:33,482] Trial 103 finished with value: 0.309859661370835 and parameters: {'model_name': 'GAIN', 'batch_size': 349, 'hint_rate': 0.35209057391892995, 'alpha': 68, 'iterations': 180, 'learning_rate': 0.0001202549434358343, 'p_miss': 0.18393000912627136}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 15:38:02,575] Trial 104 finished with value: 0.08516739846112066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3121, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 16:00:53,686] Trial 63 finished with value: 0.10781021614268167 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 3699, 'learning_rate': 0.09969269861699091, 'p_miss': 0.16562244822019975}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 16:01:21,504] Trial 106 finished with value: 0.08212047275392129 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 787, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 16:01:48,352] Trial 107 finished with value: 0.08051919347002931 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 184, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 16:02:15,210] Trial 108 finished with value: 0.08032619944855617 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 82, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 17:39:02,174] Trial 43 finished with value: 0.10750369880476693 and parameters: {'model_name': 'VAE', 'batch_size': 830, 'iterations': 5045, 'learning_rate': 0.07479767764089955, 'p_miss': 0.16697674216439343}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 17:42:58,100] Trial 44 finished with value: 0.1078157060957898 and parameters: {'model_name': 'VAE', 'batch_size': 603, 'iterations': 4742, 'learning_rate': 0.0951711464046421, 'p_miss': 0.16479203213458038}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 17:43:27,230] Trial 111 finished with value: 0.08500759864965549 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2923, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:38:01,701] Trial 105 finished with value: 0.09145841827040417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:38:30,442] Trial 113 finished with value: 0.08470977515558564 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2595, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:39:03,102] Trial 114 finished with value: 0.08785764552240513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10353, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:39:33,745] Trial 115 finished with value: 0.08689692764310512 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6719, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:40:00,292] Trial 116 finished with value: 0.09587888083154378 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:40:28,839] Trial 117 finished with value: 0.08472663561958435 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2612, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:40:57,911] Trial 118 finished with value: 0.08454179207291349 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2437, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:41:24,987] Trial 119 finished with value: 0.08079604861409936 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 267, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:41:52,030] Trial 120 finished with value: 0.0803274484016487 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 83, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:42:23,063] Trial 121 finished with value: 0.08662690403991943 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6069, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:42:24,080] Trial 122 finished with value: 0.0976429812457513 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:43:06,398] Trial 123 finished with value: 0.09275747784881197 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 62756, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 18:43:35,796] Trial 124 finished with value: 0.08488763420420961 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2786, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:02:32,575] Trial 109 finished with value: 0.09133796729345907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:02:58,912] Trial 126 finished with value: 0.08080927338462238 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 39, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:03:27,157] Trial 127 finished with value: 0.08462294671776142 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2514, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:03:27,802] Trial 49 finished with value: 0.10956755989561924 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 8241, 'learning_rate': 0.08240441049903637, 'p_miss': 0.16036624257818427}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:03:58,774] Trial 128 finished with value: 0.08649107009491264 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5745, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:04:01,205] Trial 129 finished with value: 0.08661635744541185 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6044, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:04:28,034] Trial 130 finished with value: 0.08077604989918648 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 261, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:04:30,790] Trial 131 finished with value: 0.0804356038822672 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 152, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:04:58,461] Trial 132 finished with value: 0.08667688729761196 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2309, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:05:00,053] Trial 133 finished with value: 0.08682489451462234 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2408, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:05:27,944] Trial 134 finished with value: 0.08550877049378136 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3670, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:05:54,009] Trial 136 finished with value: 0.08031146607611064 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 85, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:06:21,929] Trial 137 finished with value: 0.08346026594508092 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1559, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:06:51,792] Trial 138 finished with value: 0.08599978721296438 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4639, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:12:27,454] Trial 139 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.6584250313409835, 'alpha': 1, 'iterations': 1093, 'learning_rate': 0.028623639280862725, 'p_miss': 0.1219730990586234}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:12:56,260] Trial 140 finished with value: 0.08381052947650355 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1808, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:13:26,191] Trial 141 finished with value: 0.08577841692528158 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4194, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:13:53,634] Trial 142 finished with value: 0.0806130590077713 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 219, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:14:24,835] Trial 143 finished with value: 0.08697807929034924 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6909, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:14:26,559] Trial 144 finished with value: 0.3839386956838902 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:14:52,355] Trial 145 finished with value: 0.08082279908765916 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:15:20,683] Trial 146 finished with value: 0.08380508040369088 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1802, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:15:47,432] Trial 147 finished with value: 0.08046004637569933 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:16:15,840] Trial 148 finished with value: 0.08407669424176226 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2024, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:16:45,734] Trial 149 finished with value: 0.0859792381971361 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4598, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:17:31,239] Trial 150 finished with value: 0.09179105977871589 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 40974, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:17:57,184] Trial 151 finished with value: 0.08082279908765916 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:18:26,939] Trial 152 finished with value: 0.08564297347223335 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3923, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:19:52,781] Trial 54 finished with value: 0.10781819399916866 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 7480, 'learning_rate': 0.056066333216857236, 'p_miss': 0.15316501097437085}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:22:54,552] Trial 135 finished with value: 0.32826419427783116 and parameters: {'model_name': 'GAIN', 'batch_size': 45, 'hint_rate': 0.6587824740718387, 'alpha': 38, 'iterations': 733, 'learning_rate': 0.018027054694155012, 'p_miss': 0.11255296777568996}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:23:23,678] Trial 155 finished with value: 0.08425887196000373 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2178, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:23:52,130] Trial 156 finished with value: 0.08331175411724476 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1456, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:24:18,859] Trial 157 finished with value: 0.08038575684498214 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 117, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:24:47,269] Trial 158 finished with value: 0.08360081015226137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1655, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:25:17,096] Trial 159 finished with value: 0.08568854935112886 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4012, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:29:38,651] Trial 31 finished with value: 0.10729429330339721 and parameters: {'model_name': 'VAE', 'batch_size': 524, 'iterations': 5720, 'learning_rate': 0.08955716305507176, 'p_miss': 0.1601147669882288}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:40:58,243] Trial 50 finished with value: 0.10820298057585806 and parameters: {'model_name': 'VAE', 'batch_size': 802, 'iterations': 6445, 'learning_rate': 0.07446510804973719, 'p_miss': 0.1575694229821349}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 19:46:47,505] Trial 47 finished with value: 0.10782852914211791 and parameters: {'model_name': 'VAE', 'batch_size': 730, 'iterations': 6835, 'learning_rate': 0.05177356171626, 'p_miss': 0.15788589159826535}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:10:07,722] Trial 51 finished with value: 0.107512612192084 and parameters: {'model_name': 'VAE', 'batch_size': 480, 'iterations': 8136, 'learning_rate': 0.08134794983108307, 'p_miss': 0.15505827677884504}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:14:43,626] Trial 37 finished with value: 0.10786089692967686 and parameters: {'model_name': 'VAE', 'batch_size': 931, 'iterations': 6962, 'learning_rate': 0.05212469624520275, 'p_miss': 0.15126784671289534}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:23:32,493] Trial 42 finished with value: 0.10801053252425323 and parameters: {'model_name': 'VAE', 'batch_size': 888, 'iterations': 7563, 'learning_rate': 0.07007324953097986, 'p_miss': 0.1670273975052288}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:23:58,705] Trial 166 finished with value: 0.0825574315284722 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:37:34,191] Trial 110 finished with value: 0.09176072684121024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:38:01,356] Trial 168 finished with value: 0.08042148650113981 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 47, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:38:28,392] Trial 169 finished with value: 0.08338939001033378 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1511, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:38:58,904] Trial 170 finished with value: 0.08540941514096423 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3496, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:39:30,643] Trial 171 finished with value: 0.08342777218659957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1538, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:40:04,483] Trial 172 finished with value: 0.08649985795163155 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5766, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:40:33,348] Trial 173 finished with value: 0.0806301909295779 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:41:04,409] Trial 174 finished with value: 0.08537790223192897 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3441, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:41:35,473] Trial 175 finished with value: 0.08322084289703477 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1404, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:42:05,471] Trial 176 finished with value: 0.08352655123518248 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:42:37,979] Trial 177 finished with value: 0.08370967523404053 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1736, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:42:49,506] Trial 112 finished with value: 0.09100867112031207 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:43:10,961] Trial 178 finished with value: 0.08518029072616452 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3138, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:43:20,974] Trial 179 finished with value: 0.08510782243374379 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3043, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:43:41,024] Trial 180 finished with value: 0.08040151684422717 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 51, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:43:50,040] Trial 181 finished with value: 0.08273350496827114 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1143, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:44:11,318] Trial 182 finished with value: 0.08294476210069324 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1251, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:44:32,996] Trial 183 finished with value: 0.08975662428029328 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24814, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:44:43,958] Trial 184 finished with value: 0.08621296163257193 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5078, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:03,870] Trial 185 finished with value: 0.08604534285671442 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4726, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:11,698] Trial 186 finished with value: 0.08877924559388403 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:31,428] Trial 187 finished with value: 0.08314601105621656 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:34,599] Trial 52 finished with value: 0.10717790053185752 and parameters: {'model_name': 'VAE', 'batch_size': 636, 'iterations': 8943, 'learning_rate': 0.07308791100311143, 'p_miss': 0.15608222772621677}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:35,023] Trial 190 finished with value: 0.0976429812457513 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:45:42,647] Trial 188 finished with value: 0.08294199913389551 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:46:04,883] Trial 189 finished with value: 0.08748553706352521 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2932, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:46:10,169] Trial 191 finished with value: 0.08734847289103838 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2805, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:46:17,201] Trial 192 finished with value: 0.08705511656375672 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2569, 'weights': 'uniform'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:46:42,554] Trial 194 finished with value: 0.08349890801877405 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1586, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:46:53,168] Trial 193 finished with value: 0.09013815164992203 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28844, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:47:05,793] Trial 195 finished with value: 0.08943936881747538 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21287, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:47:14,228] Trial 196 finished with value: 0.08276335239488039 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1159, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
running
[I 2024-11-23 20:47:16,549] Trial 41 finished with value: 0.10781928198687765 and parameters: {'model_name': 'VAE', 'batch_size': 932, 'iterations': 8703, 'learning_rate': 0.09342418871700528, 'p_miss': 0.15536411811183024}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 20:47:24,237] Trial 197 finished with value: 0.0829087585434192 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1234, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 20:47:36,999] Trial 198 finished with value: 0.08269934862362258 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1124, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 20:47:43,152] Trial 199 finished with value: 0.08278417074895088 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1171, 'weights': 'distance'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 20:52:46,023] Trial 48 finished with value: 0.10731024738467113 and parameters: {'model_name': 'VAE', 'batch_size': 646, 'iterations': 9709, 'learning_rate': 0.07249171968577987, 'p_miss': 0.15433134463344672}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 20:55:17,270] Trial 45 finished with value: 0.10753511438708001 and parameters: {'model_name': 'VAE', 'batch_size': 955, 'iterations': 9915, 'learning_rate': 0.09063759049936598, 'p_miss': 0.1478330744263514}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 22:13:29,685] Trial 125 finished with value: 0.08495161793693999 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 22:47:00,209] Trial 153 finished with value: 0.08414580794029312 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 22:47:45,546] Trial 154 finished with value: 0.08425538126248373 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 22:54:03,202] Trial 160 finished with value: 0.0840572614243719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 22:57:28,241] Trial 161 finished with value: 0.08432580414086824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 23:08:01,997] Trial 162 finished with value: 0.08408993540574279 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 23:14:05,639] Trial 163 finished with value: 0.08406216130195489 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 23:35:17,163] Trial 164 finished with value: 0.08429838009187321 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 23:40:13,576] Trial 165 finished with value: 0.08451178981531024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 61 with value: 0.08028001828328074.
[I 2024-11-23 23:48:01,242] Trial 167 finished with value: 0.08450332652434414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 61 with value: 0.08028001828328074.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.08028001828328074
{'model_name': 'KNNImputer', 'n_neighbors': 76, 'weights': 'distance'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4dc0> 

Generation:  1
Best f1_score score: 0.9870890304869704
Generation:   4%|         | 1/25 [10:02<4:01:05, 602.73s/it]Generation:  2
Best f1_score score: 0.9870890304869704
Generation:   8%|         | 2/25 [14:05<2:29:58, 391.23s/it]Generation:  3
Best f1_score score: 0.9870890304869704
Generation:  12%|        | 3/25 [16:24<1:41:04, 275.65s/it]Generation:  4
Best f1_score score: 0.9870890304869704
Generation:  16%|        | 4/25 [20:33<1:32:48, 265.17s/it]Generation:  5
Best f1_score score: 0.9870890304869704
Generation:  20%|        | 5/25 [28:35<1:54:30, 343.52s/it]Generation:  6
Best f1_score score: 0.9873853398823309
Generation:  24%|       | 6/25 [32:42<1:38:22, 310.64s/it]Generation:  7
Best f1_score score: 0.9873853398823309
Generation:  28%|       | 7/25 [37:06<1:28:35, 295.32s/it]Generation:  8
Best f1_score score: 0.9873853398823309
Generation:  32%|      | 8/25 [39:01<1:07:23, 237.87s/it]Generation:  9
Best f1_score score: 0.9873853398823309
Generation:  36%|      | 9/25 [40:15<49:50, 186.92s/it]  Generation:  10
Best f1_score score: 0.9873853398823309
Generation:  40%|      | 10/25 [46:49<1:02:40, 250.69s/it]Generation:  11
Best f1_score score: 0.9873853398823309
Generation:  44%|     | 11/25 [47:46<44:41, 191.56s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546742ae00> 

Generation:  12
Best f1_score score: 0.9875970045948591
Generation:  48%|     | 12/25 [57:54<1:08:55, 318.15s/it]Generation:  13
Best f1_score score: 0.9875970045948591
Generation:  52%|    | 13/25 [1:05:49<1:13:07, 365.63s/it]Generation:  14
Best f1_score score: 0.9875970045948591
Generation:  56%|    | 14/25 [1:10:26<1:02:07, 338.85s/it]Generation:  15
Best f1_score score: 0.9875970045948591
Generation:  60%|    | 15/25 [1:11:21<42:14, 253.41s/it]  Generation:  16
Best f1_score score: 0.9875970045948591
Generation:  64%|   | 16/25 [1:15:44<38:24, 256.07s/it]Generation:  17
Best f1_score score: 0.9875970045948591
Generation:  68%|   | 17/25 [1:17:04<27:06, 203.28s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467031870> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464e481f0> 

Generation:  18
Best f1_score score: 0.9875970045948591
Generation:  72%|  | 18/25 [1:27:15<37:59, 325.66s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554672b9090> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554670407c0> 

Generation:  19
Best f1_score score: 0.9875970045948591
Generation:  76%|  | 19/25 [1:37:25<41:06, 411.14s/it]Generation:  20
Best f1_score score: 0.9875970045948591
Generation:  80%|  | 20/25 [1:38:59<26:19, 315.88s/it]Generation:  21
Best f1_score score: 0.9875970045948591
Generation:  84%| | 21/25 [1:43:23<20:01, 300.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2ba00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  22
Best f1_score score: 0.9875970045948591
Generation:  88%| | 22/25 [1:43:47<10:51, 217.28s/it]Generation:  23
Best f1_score score: 0.9875970045948591
Generation:  92%|| 23/25 [1:46:38<06:47, 203.50s/it]Generation:  24
Best f1_score score: 0.9875970045948591
Generation:  96%|| 24/25 [1:47:35<02:39, 159.46s/it]Generation:  25
Best f1_score score: 0.9875970045948591
Generation: 100%|| 25/25 [1:51:19<00:00, 178.89s/it]Generation: 100%|| 25/25 [1:51:23<00:00, 267.36s/it]
2024-11-24 01:40:35,695 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45117' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-f69bc84046193dfb342d0ab51397dc9d', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732441235.6959283')
Fitted
Pipeline(steps=[('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=5.78917442e-05,
                                                learning_rate=0.1499953684331,
                                                max_features=0.1839151968162,
                                                max_leaf_nodes=92,
                                                min_samples_leaf=138,
                                                tol=0.0001,
                                                validation_fraction=None))])
score start
train score: {'auroc': 0.9999892707757205, 'accuracy': 0.9983490898828842, 'balanced_accuracy': 0.9983502431918214, 'logloss': 0.009335563407426152, 'f1': 0.9983490885782762}
original test score: {'auroc': 0.9995008771791789, 'accuracy': 0.9923241900891748, 'balanced_accuracy': 0.9923263115464456, 'logloss': 0.02369628302976655, 'f1': 0.9923241896979604}
imputed test score: {'auroc': 0.9989922107304398, 'accuracy': 0.9890506829213229, 'balanced_accuracy': 0.9890561855291461, 'logloss': 0.03464715453184405, 'f1': 0.9890506426016434}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ee0> 
 Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 732, in fit
    X, y = self._check_X_y(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 1184, in _check_X_y
    X, y = super()._check_X_y(X, y, reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 578, in _check_X_y
    return self._validate_data(X, y, accept_sparse="csr", reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e82d40> 

Generation:  1
Best f1_score score: 0.9856497729184553
Generation:   4%|         | 1/25 [10:02<4:00:59, 602.49s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5480> 

Generation:  2
Best f1_score score: 0.9856497729184553
Generation:   8%|         | 2/25 [20:08<3:51:39, 604.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467cea260> 

Generation:  3
Best f1_score score: 0.9856497729184553
Generation:  12%|        | 3/25 [30:12<3:41:39, 604.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2a6e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464cee0b0> 

Generation:  4
Best f1_score score: 0.9858332036219151
Generation:  16%|        | 4/25 [40:17<3:31:35, 604.55s/it]Generation:  5
Best f1_score score: 0.9860871862529393
Generation:  20%|        | 5/25 [45:36<2:47:10, 501.52s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467dbfa00> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.9860871862529393
Generation:  24%|       | 6/25 [50:22<2:15:37, 428.31s/it]Generation:  7
Best f1_score score: 0.9862000799391822
Generation:  28%|       | 7/25 [54:37<1:51:32, 371.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554648ff610> 

Generation:  8
Best f1_score score: 0.9869620305297364
Generation:  32%|      | 8/25 [1:04:44<2:06:29, 446.43s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f8b610> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459d4f6a0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c14880> 

Generation:  9
Best f1_score score: 0.9869620305297364
Generation:  36%|      | 9/25 [1:14:50<2:12:23, 496.47s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554660ca410> 

Generation:  10
Best f1_score score: 0.9870890187331156
Generation:  40%|      | 10/25 [1:24:56<2:12:31, 530.13s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d86200> 

Generation:  11
Best f1_score score: 0.9870890187331156
Generation:  44%|     | 11/25 [1:35:03<2:09:13, 553.80s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554512a39d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554648cbbb0> 

Generation:  12
Best f1_score score: 0.9878650863795494
Generation:  48%|     | 12/25 [1:45:10<2:03:30, 570.04s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459e227a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464215b10> 

Generation:  13
Best f1_score score: 0.9879074202898794
Generation:  52%|    | 13/25 [1:55:17<1:56:12, 581.06s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466b7f070> 

Generation:  14
Best f1_score score: 0.9879074202898794
Generation:  56%|    | 14/25 [2:05:21<1:47:48, 588.01s/it]Generation:  15
Best f1_score score: 0.9880344103112352
Generation:  60%|    | 15/25 [2:11:38<1:27:25, 524.57s/it]Generation:  16
Best f1_score score: 0.9884153997963198
Generation:  64%|   | 16/25 [2:15:52<1:06:26, 442.92s/it]Generation:  17
Best f1_score score: 0.9884153997963198
Generation:  68%|   | 17/25 [2:17:03<44:08, 331.04s/it]  Generation:  18
Best f1_score score: 0.9884153997963198
Generation:  72%|  | 18/25 [2:21:15<35:51, 307.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b949a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467dd95a0> 

Generation:  19
Best f1_score score: 0.9884153997963198
Generation:  76%|  | 19/25 [2:31:20<39:41, 396.94s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554644e2a40> 

Generation:  20
Best f1_score score: 0.9884153997963198
Generation:  80%|  | 20/25 [2:41:24<38:14, 458.88s/it]Generation:  21
Best f1_score score: 0.9885565036702781
Generation:  84%| | 21/25 [2:45:30<26:20, 395.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466dbafe0> 

Generation:  22
Best f1_score score: 0.9885565036702781
Generation:  88%| | 22/25 [2:55:34<22:53, 457.73s/it]Generation:  23
Best f1_score score: 0.9885565036702781
Generation:  92%|| 23/25 [2:56:35<11:17, 338.71s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471a590> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e26ce0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451b57f70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676a12a0> 

Generation:  24
Best f1_score score: 0.9885565036702781
Generation:  96%|| 24/25 [3:06:42<06:59, 419.33s/it]Generation:  25
Best f1_score score: 0.9885565036702781
Generation: 100%|| 25/25 [3:10:41<00:00, 365.28s/it]Generation: 100%|| 25/25 [3:10:41<00:00, 457.68s/it]
2024-11-24 04:51:30,437 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33067' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-cc16fe6840f759985163f22af1b4c0c1', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732452690.4373245')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='constant')),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=0.8622708986406,
                                                learning_rate=0.1801607478489,
                                                max_features=0.8860025919996,
                                                max_leaf_nodes=1213,
                                                min_samples_leaf=166,
                                                tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9999999936287266, 'accuracy': 0.999957668971356, 'balanced_accuracy': 0.9999577369548067, 'logloss': 0.003995753865885495, 'f1': 0.999957668867512}
test score: {'auroc': 0.9983477164130714, 'accuracy': 0.9775369680550853, 'balanced_accuracy': 0.9775187166279623, 'logloss': 0.0726917890481483, 'f1': 0.9775331160272428}
original test score: {'auroc': 0.9995266666356615, 'accuracy': 0.9919291116378823, 'balanced_accuracy': 0.9919313213012693, 'logloss': 0.02440545831823275, 'f1': 0.9919291114064978}
score end
40922
lvl
0.1
type
MAR
num_run
1
class_full
finished
all finished
full run takes
17.985962568852635
hours
DONE
