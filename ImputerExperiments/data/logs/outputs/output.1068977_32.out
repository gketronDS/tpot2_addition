Run: 32
/cm/local/apps/slurm/var/spool/job1068977/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MAR_0.5_2
4.121297121047974
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 03:29:47,404] A new study created in memory with name: no-name-03e84247-c35a-4de1-b535-f60075c5e88f
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 03:29:48,211] Trial 6 finished with value: 0.33202178787532277 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.33202178787532277.
running
[I 2024-11-22 03:29:48,413] Trial 0 finished with value: 0.5308726402982651 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.33202178787532277.
running
[I 2024-11-22 03:29:48,780] Trial 2 finished with value: 0.467121632630085 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 6 with value: 0.33202178787532277.
running
[I 2024-11-22 03:29:49,321] Trial 15 finished with value: 0.43397142321070464 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.33202178787532277.
running
[I 2024-11-22 03:29:57,688] Trial 19 finished with value: 0.3209141518698335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:01,658] Trial 3 finished with value: 0.34580643598225347 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1851, 'weights': 'distance'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:02,597] Trial 17 finished with value: 0.3237280676322235 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3928, 'weights': 'uniform'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:02,903] Trial 11 finished with value: 0.33202178787532277 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31968, 'weights': 'uniform'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:03,786] Trial 22 finished with value: 0.467121632630085 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:04,554] Trial 5 finished with value: 0.3282497492220166 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15385, 'weights': 'uniform'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:07,727] Trial 1 finished with value: 0.3458841673105617 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30948, 'weights': 'distance'}. Best is trial 19 with value: 0.3209141518698335.
running
[I 2024-11-22 03:30:11,287] Trial 14 finished with value: 0.29663231338143337 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0005235100750875776, 'p_miss': 0.14454819696596916}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:13,526] Trial 25 finished with value: 0.3209141518698335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:17,341] Trial 26 finished with value: 0.3209141518698335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:18,860] Trial 28 finished with value: 0.3018688640210062 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.00032713105036826515, 'p_miss': 0.1394511781607946}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:19,875] Trial 16 finished with value: 0.5256011507474121 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.08913392664519842, 'alpha': 91, 'iterations': 14, 'learning_rate': 0.04153815735952952, 'p_miss': 0.21052199713082317}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:22,160] Trial 27 finished with value: 0.3209141518698335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:24,248] Trial 30 finished with value: 0.2971491360532078 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.0003348024431488854, 'p_miss': 0.1471272449489241}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:25,272] Trial 12 finished with value: 0.34607405116514406 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 14 with value: 0.29663231338143337.
running
[I 2024-11-22 03:30:25,560] Trial 31 finished with value: 0.29443473035083434 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0001712135979601991, 'p_miss': 0.10088718497882124}. Best is trial 31 with value: 0.29443473035083434.
running
[I 2024-11-22 03:30:25,958] Trial 7 finished with value: 0.5249714812885372 and parameters: {'model_name': 'GAIN', 'batch_size': 31, 'hint_rate': 0.41948487088918024, 'alpha': 47, 'iterations': 20, 'learning_rate': 0.0013827272265494097, 'p_miss': 0.12753203595913304}. Best is trial 31 with value: 0.29443473035083434.
running
[I 2024-11-22 03:30:26,480] Trial 4 finished with value: 0.3494109041598653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 31 with value: 0.29443473035083434.
running
[I 2024-11-22 03:30:26,928] Trial 29 finished with value: 0.29349194454028893 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0003858490329832438, 'p_miss': 0.14490180161927035}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:28,331] Trial 13 finished with value: 0.34569650277226727 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:29,290] Trial 32 finished with value: 0.2972911634996499 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.00017684712935741643, 'p_miss': 0.10629942660815764}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:30,346] Trial 33 finished with value: 0.2936316262696682 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0003101554921922504, 'p_miss': 0.07624545485282255}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:30,836] Trial 34 finished with value: 0.29571141418913205 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0002898667684556214, 'p_miss': 0.082545820628217}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:31,685] Trial 36 finished with value: 0.2960903971192491 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.00011541274746401366, 'p_miss': 0.04627185902863027}. Best is trial 29 with value: 0.29349194454028893.
running
[I 2024-11-22 03:30:32,484] Trial 37 finished with value: 0.29239075449806806 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0002467544381229506, 'p_miss': 0.036486426614080344}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:30:33,202] Trial 38 finished with value: 0.29770327206772174 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00016961090376212639, 'p_miss': 0.01913244301388889}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:30:34,151] Trial 39 finished with value: 0.2956217831918273 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00010988715454045327, 'p_miss': 0.04031806213789692}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:31:04,498] Trial 23 finished with value: 0.3460924869639486 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 20, 'learning_rate': 0.05746182808296571, 'p_miss': 0.20755814195305727}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:33:40,022] Trial 24 finished with value: 0.5253488923137296 and parameters: {'model_name': 'GAIN', 'batch_size': 64, 'hint_rate': 0.506753450596297, 'alpha': 61, 'iterations': 133, 'learning_rate': 0.0003970593149613735, 'p_miss': 0.1899040625852599}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:34:05,724] Trial 21 finished with value: 0.5268765602672778 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.12937250061009714, 'alpha': 73, 'iterations': 154, 'learning_rate': 0.006793111361590717, 'p_miss': 0.17636598748786794}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:34:23,311] Trial 48 finished with value: 0.29550076935970965 and parameters: {'model_name': 'VAE', 'batch_size': 389, 'iterations': 6, 'learning_rate': 0.0012288781142348764, 'p_miss': 0.29671842872311505}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:35:16,492] Trial 8 finished with value: 0.2937589534147533 and parameters: {'model_name': 'VAE', 'batch_size': 677, 'iterations': 71, 'learning_rate': 0.00031071390919976236, 'p_miss': 0.06192269676945963}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:41:07,813] Trial 20 finished with value: 0.32127389481715085 and parameters: {'model_name': 'VAE', 'batch_size': 383, 'iterations': 139, 'learning_rate': 0.0007844911152295878, 'p_miss': 0.2849826619242039}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:41:18,305] Trial 10 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.24423656093062343, 'alpha': 86, 'iterations': 2147, 'learning_rate': 0.007003749044635403, 'p_miss': 0.046869649488670846}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:46:03,456] Trial 53 finished with value: 0.31891025849410604 and parameters: {'model_name': 'VAE', 'batch_size': 942, 'iterations': 56, 'learning_rate': 0.0018852342567399647, 'p_miss': 0.0628033747064949}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:46:20,263] Trial 18 finished with value: 0.3092236785704303 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 315, 'learning_rate': 0.0002752860898420422, 'p_miss': 0.014940744453926017}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:46:45,050] Trial 55 finished with value: 0.2974627449186625 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.0007088570926683409, 'p_miss': 0.06963974878036029}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:46:56,485] Trial 56 finished with value: 0.2930225795438191 and parameters: {'model_name': 'VAE', 'batch_size': 118, 'iterations': 3, 'learning_rate': 0.00019493317615602835, 'p_miss': 0.10095579690635609}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:47:12,701] Trial 57 finished with value: 0.2935357300620175 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 3, 'learning_rate': 0.0006365593294091787, 'p_miss': 0.09490336221681195}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:47:27,086] Trial 58 finished with value: 0.2974656976384834 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 3, 'learning_rate': 0.0007820893813000228, 'p_miss': 0.10699876695003875}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:48:04,072] Trial 59 finished with value: 0.3038254309005931 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 8, 'learning_rate': 0.00019870669246229268, 'p_miss': 0.11890184139695276}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:48:18,812] Trial 60 finished with value: 0.3458618120929292 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19066, 'weights': 'distance'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:48:20,246] Trial 61 finished with value: 0.43397142321070464 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:48:33,766] Trial 62 finished with value: 0.29512888907577733 and parameters: {'model_name': 'VAE', 'batch_size': 176, 'iterations': 2, 'learning_rate': 0.0005317888090048611, 'p_miss': 0.08998628865533122}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:48:54,634] Trial 63 finished with value: 0.2933830195142786 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.00011432650474280975, 'p_miss': 0.08118233718893894}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:49:11,274] Trial 64 finished with value: 0.29600861881995943 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.0001299296836690324, 'p_miss': 0.1219511781216163}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:49:25,313] Trial 65 finished with value: 0.3458613013007849 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18667, 'weights': 'distance'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:49:33,303] Trial 66 finished with value: 0.29402924377177236 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.00021737957942185841, 'p_miss': 0.07992454600586339}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:49:56,136] Trial 67 finished with value: 0.29699491703852193 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 4, 'learning_rate': 0.00045843624552887837, 'p_miss': 0.09333893544437548}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:49:58,839] Trial 40 finished with value: 0.2951564239529989 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 365, 'learning_rate': 0.0001054969416834243, 'p_miss': 0.03914533977676172}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:50:41,894] Trial 68 finished with value: 0.2955150504463678 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 13, 'learning_rate': 0.0014755261161950412, 'p_miss': 0.033914940830049894}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:50:42,636] Trial 70 finished with value: 0.5308726402982651 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:50:49,335] Trial 71 finished with value: 0.29386358078646874 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 2, 'learning_rate': 0.0002618293591860134, 'p_miss': 0.06711004244427557}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:50:51,448] Trial 69 finished with value: 0.29803837997411575 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 14, 'learning_rate': 0.0014935367218249418, 'p_miss': 0.06856657659108432}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:50:54,730] Trial 73 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.8892805970987259, 'alpha': 7, 'iterations': 2, 'learning_rate': 0.0005797923479806622, 'p_miss': 0.1652000924837313}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:52:57,399] Trial 44 finished with value: 0.3406914420410468 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 364, 'learning_rate': 0.002114298465632896, 'p_miss': 0.01545657158841077}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:53:27,174] Trial 75 finished with value: 0.3344406339933296 and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 4, 'learning_rate': 0.024482276418068664, 'p_miss': 0.12677551989592925}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:55:57,110] Trial 76 finished with value: 0.29301563327973995 and parameters: {'model_name': 'VAE', 'batch_size': 978, 'iterations': 27, 'learning_rate': 0.0002551302071077159, 'p_miss': 0.055280772507779685}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 03:58:12,240] Trial 77 finished with value: 0.3001466971473161 and parameters: {'model_name': 'VAE', 'batch_size': 487, 'iterations': 31, 'learning_rate': 0.0002380780284208076, 'p_miss': 0.05743656048407079}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:06:23,438] Trial 42 finished with value: 0.3002963741119433 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 657, 'learning_rate': 0.00011274539682089154, 'p_miss': 0.01454023585646863}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:06:34,668] Trial 79 finished with value: 0.3275068326847518 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12787, 'weights': 'uniform'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:14:41,232] Trial 72 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9581091310322627, 'alpha': 10, 'iterations': 4760, 'learning_rate': 0.000562652343155002, 'p_miss': 0.16541484340768536}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:15:13,510] Trial 81 finished with value: 0.29317380180028796 and parameters: {'model_name': 'VAE', 'batch_size': 282, 'iterations': 8, 'learning_rate': 0.00040195285710649083, 'p_miss': 0.08018177760661761}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:16:05,575] Trial 82 finished with value: 0.2946902125653208 and parameters: {'model_name': 'VAE', 'batch_size': 250, 'iterations': 10, 'learning_rate': 0.0009692109664963107, 'p_miss': 0.05573184526999113}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:16:06,364] Trial 83 finished with value: 0.33202178787532277 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:19:12,758] Trial 84 finished with value: 0.30033078095362686 and parameters: {'model_name': 'VAE', 'batch_size': 586, 'iterations': 35, 'learning_rate': 0.0004368239413493955, 'p_miss': 0.09012622651847613}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:19:34,717] Trial 85 finished with value: 0.44582891629439614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:19:49,838] Trial 86 finished with value: 0.2930157303058462 and parameters: {'model_name': 'VAE', 'batch_size': 257, 'iterations': 3, 'learning_rate': 0.0003562853824936856, 'p_miss': 0.07770185099830797}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:20:08,002] Trial 87 finished with value: 0.30035509259908055 and parameters: {'model_name': 'VAE', 'batch_size': 290, 'iterations': 3, 'learning_rate': 0.00036451668726913744, 'p_miss': 0.11194515436980959}. Best is trial 37 with value: 0.29239075449806806.
running
[I 2024-11-22 04:20:26,879] Trial 88 finished with value: 0.2918460005277739 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 5, 'learning_rate': 0.0001534197669994708, 'p_miss': 0.027575935170927546}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:20:59,600] Trial 89 finished with value: 0.299355964699801 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 9, 'learning_rate': 0.00014250061914509735, 'p_miss': 0.030113482412820598}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:22:26,149] Trial 90 finished with value: 0.29648674628329263 and parameters: {'model_name': 'VAE', 'batch_size': 102, 'iterations': 22, 'learning_rate': 0.0001648420104417214, 'p_miss': 0.05254314451570405}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:22:55,670] Trial 91 finished with value: 0.293139562546776 and parameters: {'model_name': 'VAE', 'batch_size': 981, 'iterations': 5, 'learning_rate': 0.00022928016906802336, 'p_miss': 0.2432636049577076}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:24:28,348] Trial 92 finished with value: 0.31350110437173306 and parameters: {'model_name': 'VAE', 'batch_size': 841, 'iterations': 6, 'learning_rate': 0.005704318176762187, 'p_miss': 0.25563130702324954}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:25:02,977] Trial 54 finished with value: 0.3482035436595169 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 700, 'learning_rate': 0.0007261111575326559, 'p_miss': 0.0193028568608414}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:25:37,244] Trial 93 finished with value: 0.29620567866395764 and parameters: {'model_name': 'VAE', 'batch_size': 651, 'iterations': 11, 'learning_rate': 0.0002289998953058514, 'p_miss': 0.04698129128322692}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:26:33,834] Trial 94 finished with value: 0.29349757843208907 and parameters: {'model_name': 'VAE', 'batch_size': 703, 'iterations': 13, 'learning_rate': 0.00021437406188855608, 'p_miss': 0.24022702572293184}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:26:50,631] Trial 96 finished with value: 0.29438453035065415 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 4, 'learning_rate': 0.0003378891972903817, 'p_miss': 0.028419912265871122}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:27:26,778] Trial 95 finished with value: 0.2944763420675559 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 23, 'learning_rate': 0.0001483473577119651, 'p_miss': 0.24734424113371611}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:27:27,094] Trial 97 finished with value: 0.2941097625626514 and parameters: {'model_name': 'VAE', 'batch_size': 253, 'iterations': 5, 'learning_rate': 0.0001471874828870812, 'p_miss': 0.1930543065135271}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:27:36,840] Trial 99 finished with value: 0.294601747529474 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 2, 'learning_rate': 0.0002793430406060941, 'p_miss': 0.07812318625564796}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:27:49,057] Trial 98 finished with value: 0.2964931154869678 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 5, 'learning_rate': 0.0002873058375339618, 'p_miss': 0.19351939562383724}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:33:40,766] Trial 100 finished with value: 0.3000761610314581 and parameters: {'model_name': 'VAE', 'batch_size': 429, 'iterations': 74, 'learning_rate': 0.0004082881621439367, 'p_miss': 0.14242054498824044}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:33:41,875] Trial 45 finished with value: 0.34154412268635354 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1080, 'learning_rate': 0.0015412776546990927, 'p_miss': 0.21663058617260073}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:38:48,238] Trial 50 finished with value: 0.3525487980290447 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1000, 'learning_rate': 0.0009237248991620109, 'p_miss': 0.07948828264520506}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:39:06,658] Trial 52 finished with value: 0.35664145792366403 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1031, 'learning_rate': 0.003459689828040926, 'p_miss': 0.06313561982090012}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:42:57,232] Trial 51 finished with value: 0.3367013615713911 and parameters: {'model_name': 'VAE', 'batch_size': 724, 'iterations': 870, 'learning_rate': 0.0011592538300110884, 'p_miss': 0.051256531660609866}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:43:11,041] Trial 101 finished with value: 0.32775434850408836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:43:48,134] Trial 107 finished with value: 0.5273596155580819 and parameters: {'model_name': 'GAIN', 'batch_size': 572, 'hint_rate': 0.6800524576495919, 'alpha': 36, 'iterations': 17, 'learning_rate': 0.00018326785317045034, 'p_miss': 0.2405296204836735}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:44:04,814] Trial 108 finished with value: 0.29653875406994473 and parameters: {'model_name': 'VAE', 'batch_size': 334, 'iterations': 3, 'learning_rate': 0.00010289647225928944, 'p_miss': 0.21925558651449398}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:44:55,368] Trial 109 finished with value: 0.29472159826047106 and parameters: {'model_name': 'VAE', 'batch_size': 976, 'iterations': 8, 'learning_rate': 0.00020518664268110462, 'p_miss': 0.04024866552095069}. Best is trial 88 with value: 0.2918460005277739.
running
[I 2024-11-22 04:45:18,209] Trial 110 finished with value: 0.2918224239126794 and parameters: {'model_name': 'VAE', 'batch_size': 758, 'iterations': 4, 'learning_rate': 0.0002409314756650499, 'p_miss': 0.26781068637962285}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:45:30,926] Trial 111 finished with value: 0.3314268328506017 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25893, 'weights': 'uniform'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:45:50,067] Trial 112 finished with value: 0.2943633724492186 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 3, 'learning_rate': 0.00035713296902223373, 'p_miss': 0.2671283131989735}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:45:51,095] Trial 113 finished with value: 0.33202178787532277 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:46:14,693] Trial 114 finished with value: 0.2949273344288731 and parameters: {'model_name': 'VAE', 'batch_size': 800, 'iterations': 4, 'learning_rate': 0.00012637483347715557, 'p_miss': 0.27167153196894384}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:46:35,991] Trial 115 finished with value: 0.2933270462728356 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.0002511109023762409, 'p_miss': 0.07183507499839752}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:47:06,518] Trial 116 finished with value: 0.2940225222886328 and parameters: {'model_name': 'VAE', 'batch_size': 499, 'iterations': 6, 'learning_rate': 0.0002655454619120721, 'p_miss': 0.07207191003265101}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:47:15,873] Trial 117 finished with value: 0.29563687411969514 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.00018220441178627608, 'p_miss': 0.10022551302881155}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:47:42,625] Trial 118 finished with value: 0.2948366299426709 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.0004376590672147098, 'p_miss': 0.08517504314539526}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:47:57,889] Trial 119 finished with value: 0.2921226401702391 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 4, 'learning_rate': 0.00032258965363680654, 'p_miss': 0.2989658677264515}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:48:12,308] Trial 120 finished with value: 0.2964836457902552 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.00030940356191544633, 'p_miss': 0.2979775440521638}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:48:35,187] Trial 121 finished with value: 0.2934411907425513 and parameters: {'model_name': 'VAE', 'batch_size': 227, 'iterations': 5, 'learning_rate': 0.00023949275550419263, 'p_miss': 0.0607672162048052}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:48:55,596] Trial 103 finished with value: 0.3276438345050655 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:49:06,462] Trial 122 finished with value: 0.2921105230082987 and parameters: {'model_name': 'VAE', 'batch_size': 127, 'iterations': 9, 'learning_rate': 0.00016137974540479113, 'p_miss': 0.28409777960777166}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:49:22,688] Trial 102 finished with value: 0.3277464817290653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:49:32,903] Trial 123 finished with value: 0.29266943430803627 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 9, 'learning_rate': 0.0001694977649578825, 'p_miss': 0.28653229414885417}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:49:41,208] Trial 124 finished with value: 0.30215833890215044 and parameters: {'model_name': 'VAE', 'batch_size': 129, 'iterations': 10, 'learning_rate': 0.00018075591646025718, 'p_miss': 0.2833212053491641}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:50:02,909] Trial 125 finished with value: 0.2950788663419449 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 10, 'learning_rate': 0.00019689795664543593, 'p_miss': 0.2863609053472332}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:50:11,477] Trial 126 finished with value: 0.29343718510093564 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 10, 'learning_rate': 0.0001645476455873415, 'p_miss': 0.2852605258651761}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:50:14,714] Trial 127 finished with value: 0.2965058190679926 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 8, 'learning_rate': 0.00024661247142829777, 'p_miss': 0.2817760747162176}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:50:28,930] Trial 128 finished with value: 0.3000784986973869 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 7, 'learning_rate': 0.0001580239467091434, 'p_miss': 0.2833508415591209}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:51:26,333] Trial 129 finished with value: 0.2939301181155257 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 16, 'learning_rate': 0.0003140418444151955, 'p_miss': 0.28978526918789915}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:51:28,239] Trial 130 finished with value: 0.29242629385531016 and parameters: {'model_name': 'VAE', 'batch_size': 200, 'iterations': 15, 'learning_rate': 0.00013528296074394528, 'p_miss': 0.2705316570775818}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:51:28,959] Trial 131 finished with value: 0.5251562354319825 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.7107036074028898, 'alpha': 27, 'iterations': 31, 'learning_rate': 0.0003164616436915321, 'p_miss': 0.2738592045709184}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:51:42,200] Trial 134 finished with value: 0.34586976642385814 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9312, 'weights': 'distance'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:52:22,286] Trial 133 finished with value: 0.5263967791334738 and parameters: {'model_name': 'GAIN', 'batch_size': 210, 'hint_rate': 0.7001939671306202, 'alpha': 31, 'iterations': 28, 'learning_rate': 0.00013163939322479202, 'p_miss': 0.2737766983534747}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:52:47,622] Trial 136 finished with value: 0.2956181993686461 and parameters: {'model_name': 'VAE', 'batch_size': 338, 'iterations': 6, 'learning_rate': 0.00020326951726421972, 'p_miss': 0.2590051334611293}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:53:18,695] Trial 135 finished with value: 0.3023284375706147 and parameters: {'model_name': 'VAE', 'batch_size': 207, 'iterations': 20, 'learning_rate': 0.00013652543292007175, 'p_miss': 0.25919188821710726}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:53:35,903] Trial 132 finished with value: 0.2940032941556341 and parameters: {'model_name': 'VAE', 'batch_size': 202, 'iterations': 32, 'learning_rate': 0.0005054408877260325, 'p_miss': 0.2714419845784853}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:53:43,585] Trial 104 finished with value: 0.32779700388048527 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:53:47,409] Trial 137 finished with value: 0.3346627008238755 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 13, 'learning_rate': 0.027696556616134536, 'p_miss': 0.2979991056713208}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:54:26,095] Trial 139 finished with value: 0.29542192829106756 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 12, 'learning_rate': 0.0002507030924995588, 'p_miss': 0.0252233141968931}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:54:30,859] Trial 140 finished with value: 0.3446952077946738 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 12, 'learning_rate': 0.026471871657718422, 'p_miss': 0.29580512034198525}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:54:45,111] Trial 143 finished with value: 0.2986163911757652 and parameters: {'model_name': 'VAE', 'batch_size': 291, 'iterations': 3, 'learning_rate': 0.000365492340342862, 'p_miss': 0.29048702000461174}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:54:46,365] Trial 144 finished with value: 0.43397142321070464 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:55:11,632] Trial 145 finished with value: 0.29366489921446315 and parameters: {'model_name': 'VAE', 'batch_size': 864, 'iterations': 4, 'learning_rate': 0.00011794889551925932, 'p_miss': 0.011114100669144467}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:55:20,132] Trial 105 finished with value: 0.32546705285523636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:55:37,039] Trial 146 finished with value: 0.303506069448328 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 5, 'learning_rate': 0.00010586677324039148, 'p_miss': 0.0733028460889171}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:55:58,569] Trial 148 finished with value: 0.2977680065024989 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.00015647031925755586, 'p_miss': 0.08581173835313112}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:56:19,713] Trial 138 finished with value: 0.29567504964427943 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 52, 'learning_rate': 0.00049496418837091, 'p_miss': 0.2999599893749889}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:56:37,571] Trial 149 finished with value: 0.29298355263393716 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 8, 'learning_rate': 0.00021888783418906631, 'p_miss': 0.04512675080691604}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:56:51,189] Trial 150 finished with value: 0.2946069365177539 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8, 'learning_rate': 0.00022203088886093336, 'p_miss': 0.05031369116043105}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:13,287] Trial 141 finished with value: 0.2942296077532093 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 55, 'learning_rate': 0.0002499668050144382, 'p_miss': 0.2905526462528197}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:14,213] Trial 151 finished with value: 0.29624140993970033 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 8, 'learning_rate': 0.000221654092836488, 'p_miss': 0.0467277686628584}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:29,832] Trial 153 finished with value: 0.2989297489029538 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.00018423415402629158, 'p_miss': 0.037486511422861885}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:36,368] Trial 106 finished with value: 0.327567914577019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:41,071] Trial 142 finished with value: 0.2940266853126749 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 56, 'learning_rate': 0.0003758829615896137, 'p_miss': 0.2786237231589568}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:44,950] Trial 152 finished with value: 0.29527144487785373 and parameters: {'model_name': 'VAE', 'batch_size': 157, 'iterations': 16, 'learning_rate': 0.0002733181127153009, 'p_miss': 0.04393286671320187}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:57:59,050] Trial 147 finished with value: 0.2959067604628961 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 47, 'learning_rate': 0.00011256370856508506, 'p_miss': 0.07334239899217544}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:07,867] Trial 158 finished with value: 0.2995652306079105 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 6, 'learning_rate': 0.0001247310308482615, 'p_miss': 0.06763888588155019}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:09,925] Trial 156 finished with value: 0.33466820022744137 and parameters: {'model_name': 'VAE', 'batch_size': 145, 'iterations': 6, 'learning_rate': 0.08551906661727325, 'p_miss': 0.060371096222964896}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:13,584] Trial 154 finished with value: 0.2970099297445096 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 17, 'learning_rate': 0.00018451047902395929, 'p_miss': 0.0398826837065096}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:16,887] Trial 159 finished with value: 0.29521366825198475 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.00014264292173898183, 'p_miss': 0.06583835504629063}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:26,598] Trial 160 finished with value: 0.29749098503883153 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 5, 'learning_rate': 0.00015003575362696874, 'p_miss': 0.023939001041763767}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:35,313] Trial 157 finished with value: 0.29517847354860066 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 16, 'learning_rate': 0.00012132835963173448, 'p_miss': 0.06558143919021044}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:37,191] Trial 163 finished with value: 0.29697985322926357 and parameters: {'model_name': 'VAE', 'batch_size': 996, 'iterations': 3, 'learning_rate': 0.00016129872318068663, 'p_miss': 0.10269103716546091}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:38,501] Trial 161 finished with value: 0.2939588525391505 and parameters: {'model_name': 'VAE', 'batch_size': 994, 'iterations': 5, 'learning_rate': 0.00015748022914325788, 'p_miss': 0.09882364954237183}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:39,767] Trial 155 finished with value: 0.293744246036988 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 16, 'learning_rate': 0.00027903265108297656, 'p_miss': 0.2632540818078946}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:48,187] Trial 165 finished with value: 0.33124286610725107 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25406, 'weights': 'uniform'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:58:59,999] Trial 162 finished with value: 0.2928336752138013 and parameters: {'model_name': 'VAE', 'batch_size': 731, 'iterations': 9, 'learning_rate': 0.0001488615499287431, 'p_miss': 0.2669408367377498}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:03,178] Trial 166 finished with value: 0.3069435825476432 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 9, 'learning_rate': 0.0001712707738894022, 'p_miss': 0.2665985010014815}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:03,882] Trial 168 finished with value: 0.2927109093653953 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 9, 'learning_rate': 0.00021071732835793903, 'p_miss': 0.13530619878805175}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:08,762] Trial 167 finished with value: 0.2952245780019133 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 9, 'learning_rate': 0.0002972701511972218, 'p_miss': 0.26584692763344087}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:11,117] Trial 164 finished with value: 0.29504396896774926 and parameters: {'model_name': 'VAE', 'batch_size': 632, 'iterations': 9, 'learning_rate': 0.0003034634507685294, 'p_miss': 0.26489716467974955}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:12,527] Trial 174 finished with value: 0.467121632630085 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:37,223] Trial 169 finished with value: 0.2941158448058062 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 9, 'learning_rate': 0.00020627832948425046, 'p_miss': 0.24701529973156025}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:41,168] Trial 171 finished with value: 0.2927809135499831 and parameters: {'model_name': 'VAE', 'batch_size': 780, 'iterations': 7, 'learning_rate': 0.00020225127712788902, 'p_miss': 0.2510979095513481}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:45,205] Trial 170 finished with value: 0.2983340835436442 and parameters: {'model_name': 'VAE', 'batch_size': 620, 'iterations': 9, 'learning_rate': 0.00020527662561868008, 'p_miss': 0.08066843204968689}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:45,835] Trial 172 finished with value: 0.2924465805522668 and parameters: {'model_name': 'VAE', 'batch_size': 717, 'iterations': 9, 'learning_rate': 0.00021419284953371173, 'p_miss': 0.25135977717911995}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:49,913] Trial 173 finished with value: 0.2943151367252246 and parameters: {'model_name': 'VAE', 'batch_size': 650, 'iterations': 7, 'learning_rate': 0.00020993858498663488, 'p_miss': 0.11215031208426898}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 04:59:50,940] Trial 175 finished with value: 0.292222278217081 and parameters: {'model_name': 'VAE', 'batch_size': 769, 'iterations': 7, 'learning_rate': 0.000204179131483024, 'p_miss': 0.13288596491031274}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:00:12,361] Trial 177 finished with value: 0.29887705977815465 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7, 'learning_rate': 0.0002223170126764598, 'p_miss': 0.15499914983665472}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:00:14,686] Trial 176 finished with value: 0.2934518106554817 and parameters: {'model_name': 'VAE', 'batch_size': 555, 'iterations': 7, 'learning_rate': 0.00021346858336306575, 'p_miss': 0.2796869062083076}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:00:23,142] Trial 178 finished with value: 0.2995904658264254 and parameters: {'model_name': 'VAE', 'batch_size': 781, 'iterations': 7, 'learning_rate': 0.0002368385694825501, 'p_miss': 0.03216518377350216}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:00:29,868] Trial 179 finished with value: 0.2950192849702737 and parameters: {'model_name': 'VAE', 'batch_size': 792, 'iterations': 7, 'learning_rate': 0.0002275386135959176, 'p_miss': 0.24874990057062657}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:15,653] Trial 182 finished with value: 0.297695364244818 and parameters: {'model_name': 'VAE', 'batch_size': 769, 'iterations': 11, 'learning_rate': 0.00018308653926587425, 'p_miss': 0.24935023782101082}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:18,118] Trial 180 finished with value: 0.30250530293667816 and parameters: {'model_name': 'VAE', 'batch_size': 787, 'iterations': 11, 'learning_rate': 0.0035417529916042887, 'p_miss': 0.22724600443060747}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:01:18,244] Trial 183 finished with value: 0.2954375991026953 and parameters: {'model_name': 'VAE', 'batch_size': 772, 'iterations': 12, 'learning_rate': 0.00017164813038704471, 'p_miss': 0.13127069706050237}. Best is trial 110 with value: 0.2918224239126794.
running
running
[I 2024-11-22 05:01:19,060] Trial 185 finished with value: 0.29571702717923215 and parameters: {'model_name': 'VAE', 'batch_size': 455, 'iterations': 11, 'learning_rate': 0.00019049775845006786, 'p_miss': 0.2542624043306562}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:19,747] Trial 181 finished with value: 0.33567028327731996 and parameters: {'model_name': 'VAE', 'batch_size': 750, 'iterations': 11, 'learning_rate': 0.011743022634370406, 'p_miss': 0.15306573448296265}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:34,166] Trial 184 finished with value: 0.2967705248521433 and parameters: {'model_name': 'VAE', 'batch_size': 484, 'iterations': 11, 'learning_rate': 0.0030301155782499873, 'p_miss': 0.23189219237127223}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:38,175] Trial 187 finished with value: 0.29462491655320483 and parameters: {'model_name': 'VAE', 'batch_size': 479, 'iterations': 4, 'learning_rate': 0.00026433028408209933, 'p_miss': 0.2308542604149338}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:40,511] Trial 189 finished with value: 0.30062283085633734 and parameters: {'model_name': 'VAE', 'batch_size': 390, 'iterations': 4, 'learning_rate': 0.0003462505478798695, 'p_miss': 0.2352945410174324}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:40,911] Trial 190 finished with value: 0.29470599332101344 and parameters: {'model_name': 'VAE', 'batch_size': 424, 'iterations': 4, 'learning_rate': 0.0003367179749626158, 'p_miss': 0.13498803913200283}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:46,795] Trial 188 finished with value: 0.29422307550860977 and parameters: {'model_name': 'VAE', 'batch_size': 360, 'iterations': 4, 'learning_rate': 0.0002653910573305896, 'p_miss': 0.23250047836407065}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:01:52,076] Trial 194 finished with value: 0.5296225320286625 and parameters: {'model_name': 'GAIN', 'batch_size': 882, 'hint_rate': 0.32328442266550494, 'alpha': 69, 'iterations': 3, 'learning_rate': 0.0001398085090984448, 'p_miss': 0.12366446195184419}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:02:13,757] Trial 196 finished with value: 0.29256977758544245 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 6, 'learning_rate': 0.00023687692269229693, 'p_miss': 0.05387515214150872}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:02:14,843] Trial 186 finished with value: 0.29837855415581144 and parameters: {'model_name': 'VAE', 'batch_size': 418, 'iterations': 12, 'learning_rate': 0.00013958003402370742, 'p_miss': 0.13429149451675224}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:02:24,651] Trial 193 finished with value: 0.5280272046147987 and parameters: {'model_name': 'GAIN', 'batch_size': 275, 'hint_rate': 0.3458566142947589, 'alpha': 99, 'iterations': 25, 'learning_rate': 0.0001370017248676377, 'p_miss': 0.13377110376605342}. Best is trial 110 with value: 0.2918224239126794.
running
[I 2024-11-22 05:02:49,363] Trial 198 finished with value: 0.29256967182139093 and parameters: {'model_name': 'VAE', 'batch_size': 268, 'iterations': 6, 'learning_rate': 0.00041126466458116305, 'p_miss': 0.053953292257732814}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:02:59,624] Trial 191 finished with value: 0.2992741487065009 and parameters: {'model_name': 'VAE', 'batch_size': 918, 'iterations': 14, 'learning_rate': 0.00035053570588273775, 'p_miss': 0.27575295669075617}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:03:12,955] Trial 192 finished with value: 0.29274134800432783 and parameters: {'model_name': 'VAE', 'batch_size': 331, 'iterations': 25, 'learning_rate': 0.0003370116826706357, 'p_miss': 0.13388039256230524}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:03:14,385] Trial 197 finished with value: 0.2963656412530071 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 14, 'learning_rate': 0.00018486709085315854, 'p_miss': 0.05620893186672379}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:03:48,631] Trial 195 finished with value: 0.526922144618376 and parameters: {'model_name': 'GAIN', 'batch_size': 276, 'hint_rate': 0.33885528584035246, 'alpha': 68, 'iterations': 87, 'learning_rate': 0.00012920601638858736, 'p_miss': 0.1239824120953161}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:11:59,121] Trial 9 finished with value: 0.336745085608859 and parameters: {'model_name': 'VAE', 'batch_size': 878, 'iterations': 1467, 'learning_rate': 0.005273636428427092, 'p_miss': 0.0664064747326884}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:29:09,681] Trial 74 finished with value: 0.3364884741969118 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 2286, 'learning_rate': 0.0045404474821128535, 'p_miss': 0.13556791154191464}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:31:30,269] Trial 47 finished with value: 0.3379678528510669 and parameters: {'model_name': 'VAE', 'batch_size': 575, 'iterations': 1977, 'learning_rate': 0.0011186041204910443, 'p_miss': 0.07664923428587643}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:50:51,089] Trial 46 finished with value: 0.3367535149159619 and parameters: {'model_name': 'VAE', 'batch_size': 977, 'iterations': 2269, 'learning_rate': 0.0012530298164527944, 'p_miss': 0.07736392786996837}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:52:10,986] Trial 43 finished with value: 0.3445859945733655 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2888, 'learning_rate': 0.0020879808517534704, 'p_miss': 0.017563053621484692}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 05:55:45,710] Trial 49 finished with value: 0.3386316746211647 and parameters: {'model_name': 'VAE', 'batch_size': 302, 'iterations': 2931, 'learning_rate': 0.0009833272012741182, 'p_miss': 0.2719707395909514}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 06:09:46,160] Trial 35 finished with value: 0.3436795149201755 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4924, 'learning_rate': 0.00010297860559650205, 'p_miss': 0.012206723423860436}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 06:10:12,046] Trial 41 finished with value: 0.3429257359799358 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4731, 'learning_rate': 0.00011056172428200538, 'p_miss': 0.01863269612081117}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 06:13:12,587] Trial 80 finished with value: 0.3403103818303451 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 5718, 'learning_rate': 0.0004342946454982499, 'p_miss': 0.08118929510994896}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 06:18:32,146] Trial 78 finished with value: 0.33758463795966887 and parameters: {'model_name': 'VAE', 'batch_size': 282, 'iterations': 7847, 'learning_rate': 0.0001570513535683707, 'p_miss': 0.0794398041593122}. Best is trial 110 with value: 0.2918224239126794.
[I 2024-11-22 06:19:38,180] Trial 199 finished with value: 0.33763817186337414 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 8983, 'learning_rate': 0.00018700087498167394, 'p_miss': 0.17326850152583392}. Best is trial 110 with value: 0.2918224239126794.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.2918224239126794
{'model_name': 'VAE', 'batch_size': 758, 'iterations': 4, 'learning_rate': 0.0002409314756650499, 'p_miss': 0.26781068637962285}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4d60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.3774830435497164
Generation:   4%|         | 1/25 [04:08<1:39:30, 248.79s/it]Generation:  2
Best f1_score score: 0.3774830435497164
Generation:   8%|         | 2/25 [11:15<2:15:27, 353.35s/it]Generation:  3
Best f1_score score: 0.3774830435497164
Generation:  12%|        | 3/25 [11:59<1:17:50, 212.28s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fcee0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eac0d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.3774830435497164
Generation:  16%|        | 4/25 [14:49<1:08:27, 195.60s/it]Generation:  5
Best f1_score score: 0.38215119496449057
Generation:  20%|        | 5/25 [15:51<49:06, 147.31s/it]  Generation:  6
Best f1_score score: 0.3823674169552458
Generation:  24%|       | 6/25 [17:42<42:41, 134.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa5f60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.3883347867584118
Generation:  28%|       | 7/25 [17:57<28:42, 95.68s/it] Generation:  8
Best f1_score score: 0.3883347867584118
Generation:  32%|      | 8/25 [22:42<44:14, 156.14s/it]Generation:  9
Best f1_score score: 0.3883347867584118
Generation:  36%|      | 9/25 [23:58<34:58, 131.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fc76a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.38903264783671004
Generation:  40%|      | 10/25 [26:27<34:06, 136.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650fb0d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b3c610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e90640> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.38903264783671004
Generation:  44%|     | 11/25 [33:35<52:42, 225.89s/it]Generation:  12
Best f1_score score: 0.39096927174844043
Generation:  48%|     | 12/25 [35:16<40:40, 187.77s/it]Generation:  13
Best f1_score score: 0.39096927174844043
Generation:  52%|    | 13/25 [36:32<30:45, 153.80s/it]Generation:  14
Best f1_score score: 0.3913045201806735
Generation:  56%|    | 14/25 [37:51<24:04, 131.28s/it]Generation:  15
Best f1_score score: 0.39164890795695995
Generation:  60%|    | 15/25 [45:54<39:31, 237.18s/it]Generation:  16
Best f1_score score: 0.39164890795695995
Generation:  64%|   | 16/25 [51:07<39:01, 260.15s/it]Generation:  17
Best f1_score score: 0.39164890795695995
Generation:  68%|   | 17/25 [54:35<32:35, 244.44s/it]Generation:  18
Best f1_score score: 0.39164890795695995
Generation:  72%|  | 18/25 [55:08<21:06, 180.92s/it]Generation:  19
Best f1_score score: 0.39164890795695995
Generation:  76%|  | 19/25 [58:03<17:55, 179.29s/it]Generation:  20
Best f1_score score: 0.39164890795695995
Generation:  80%|  | 20/25 [58:56<11:45, 141.18s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa3bb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.39164890795695995
Generation:  84%| | 21/25 [1:00:01<07:53, 118.31s/it]Generation:  22
Best f1_score score: 0.3953808165117777
Generation:  88%| | 22/25 [1:02:49<06:39, 133.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465014670> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.3953808165117777
Generation:  92%|| 23/25 [1:05:48<04:53, 146.96s/it]Generation:  24
Best f1_score score: 0.3953808165117777
Generation:  96%|| 24/25 [1:10:47<03:12, 192.74s/it]Generation:  25
Best f1_score score: 0.3955035942595775
Generation: 100%|| 25/25 [1:12:34<00:00, 166.98s/it]Generation: 100%|| 25/25 [1:12:38<00:00, 174.33s/it]
2024-11-22 07:32:51,512 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44895' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-90503b44350437bcc7fb41114bb14183', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732289571.5119743')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.6612586544813,
                                        min_samples_leaf=15,
                                        min_samples_split=13,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.8631235452360677, 'accuracy': 0.6943522521266211, 'balanced_accuracy': 0.7456958891200323, 'logloss': 0.8343053523328765, 'f1': 0.693102627800676}
original test score: {'auroc': 0.6183945471920509, 'accuracy': 0.4107541276215975, 'balanced_accuracy': 0.3444327454757097, 'logloss': 0.9705968581452378, 'f1': 0.23051285572808763}
imputed test score: {'auroc': 0.5285966717820442, 'accuracy': 0.41253904506916556, 'balanced_accuracy': 0.34148318629011637, 'logloss': 1.0136218173961018, 'f1': 0.28741154003103125}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.6032485077396615
Generation:   4%|         | 1/25 [08:10<3:16:17, 490.75s/it]Generation:  2
Best f1_score score: 0.6221839111264238
Generation:   8%|         | 2/25 [14:47<2:46:49, 435.18s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f09f00> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2560> 

Generation:  3
Best f1_score score: 0.6221839111264238
Generation:  12%|        | 3/25 [24:50<3:07:46, 512.13s/it]Generation:  4
Best f1_score score: 0.6352094544173474
Generation:  16%|        | 4/25 [28:56<2:22:23, 406.83s/it]Generation:  5
Best f1_score score: 0.6405778439392267
Generation:  20%|        | 5/25 [36:54<2:24:15, 432.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474735000> 

Generation:  6
Best f1_score score: 0.6405778439392267
Generation:  24%|       | 6/25 [47:00<2:35:36, 491.40s/it]Generation:  7
Best f1_score score: 0.6405778439392267
Generation:  28%|       | 7/25 [55:17<2:28:02, 493.50s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679c62f0> 

Generation:  8
Best f1_score score: 0.6405778439392267
Generation:  32%|      | 8/25 [1:05:24<2:29:59, 529.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f00640> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467094d30> 

Generation:  9
Best f1_score score: 0.6405778439392267
Generation:  36%|      | 9/25 [1:15:29<2:27:32, 553.28s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554674cded0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a831c0> 

Generation:  10
Best f1_score score: 0.645576062311276
Generation:  40%|      | 10/25 [1:25:36<2:22:27, 569.86s/it]Generation:  11
Best f1_score score: 0.645576062311276
Generation:  44%|     | 11/25 [1:26:13<1:34:53, 406.70s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467acecb0> 

Generation:  12
Best f1_score score: 0.645576062311276
Generation:  48%|     | 12/25 [1:36:20<1:41:17, 467.48s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452d05c30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554541db670> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3dc0> 

Generation:  13
Best f1_score score: 0.645576062311276
Generation:  52%|    | 13/25 [1:46:26<1:41:54, 509.52s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650eb1f0> 

Generation:  14
Best f1_score score: 0.645576062311276
Generation:  56%|    | 14/25 [1:56:33<1:38:47, 538.85s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155444c0fa90> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464cb4c10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451039630> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546731aad0> 

Generation:  15
Best f1_score score: 0.645576062311276
Generation:  60%|    | 15/25 [2:06:41<1:33:17, 559.77s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453dbd330> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464c68400> 

Generation:  16
Best f1_score score: 0.6461976824196675
Generation:  64%|   | 16/25 [2:16:49<1:26:07, 574.20s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f032e0> 

Generation:  17
Best f1_score score: 0.6472729836933643
Generation:  68%|   | 17/25 [2:26:56<1:17:52, 584.09s/it]Generation:  18
Best f1_score score: 0.6475214302192047
Generation:  72%|  | 18/25 [2:29:38<53:21, 457.33s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464aa8be0> 

Generation:  19
Best f1_score score: 0.6475214302192047
Generation:  76%|  | 19/25 [2:39:45<50:13, 502.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546504b280> 

Generation:  20
Best f1_score score: 0.6505969306814928
Generation:  80%|  | 20/25 [2:49:53<44:30, 534.08s/it]Generation:  21
Best f1_score score: 0.6505969306814928
Generation:  84%| | 21/25 [2:53:14<28:56, 434.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546751d720> 

Generation:  22
Best f1_score score: 0.6505969306814928
Generation:  88%| | 22/25 [3:03:22<24:18, 486.31s/it]Generation:  23
Best f1_score score: 0.6521104150376944
Generation:  92%|| 23/25 [3:12:05<16:34, 497.28s/it]Generation:  24
Best f1_score score: 0.6521104150376944
Generation:  96%|| 24/25 [3:15:52<06:56, 416.17s/it]Generation:  25
Best f1_score score: 0.6521104150376944
Generation: 100%|| 25/25 [3:25:50<00:00, 470.78s/it]Generation: 100%|| 25/25 [3:25:50<00:00, 494.03s/it]
2024-11-22 10:59:05,316 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37867' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-d5a32ac8699d2d0d43f20df4f565191d', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732301945.3159149')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=BayesianRidge(),
                                  initial_strategy='median',
                                  n_nearest_features=67,
                                  sample_posterior=True)),
                ('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.8271922592159,
                                        min_samples_leaf=5,
                                        min_samples_split=19,
                                        n_estimators=128))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8997351891443891, 'accuracy': 0.7345140147817598, 'balanced_accuracy': 0.7254433775220946, 'logloss': 0.5618930676973193, 'f1': 0.6735417647524526}
test score: {'auroc': 0.833079582593861, 'accuracy': 0.6918786256135654, 'balanced_accuracy': 0.6741303133684626, 'logloss': 1.0486118028080158, 'f1': 0.6351570675151818}
original test score: {'auroc': 0.9458795253107454, 'accuracy': 0.8107987505577867, 'balanced_accuracy': 0.8286572866588434, 'logloss': 0.4518241281436876, 'f1': 0.7705245872161616}
score end
41027
lvl
0.5
type
MAR
num_run
2
class_full
finished
all finished
full run takes
7.492989640898175
hours
DONE
