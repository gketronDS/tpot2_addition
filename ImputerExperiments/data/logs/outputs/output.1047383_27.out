Run: 27
/cm/local/apps/slurm/var/spool/job1047383/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1481/1481.pkl
working on 
../data/c/1481/class_full_MCAR_0.3_2
3.9994735717773438
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-13 05:35:45,303] A new study created in memory with name: no-name-3775b42d-ef62-4fac-b59d-94bbef8647ad
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-13 05:35:45,645] Trial 12 finished with value: 0.5112537346435311 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 12 with value: 0.5112537346435311.
running
[I 2024-11-13 05:35:46,008] Trial 8 finished with value: 0.318947962797109 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 8 with value: 0.318947962797109.
running
[I 2024-11-13 05:35:48,636] Trial 1 finished with value: 0.2939265165330772 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:49,569] Trial 9 finished with value: 0.2939265295601439 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:49,918] Trial 17 finished with value: 0.293926519191885 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:50,313] Trial 20 finished with value: 0.5112537346435311 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:51,004] Trial 2 finished with value: 0.29397226010266675 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:52,024] Trial 13 finished with value: 0.2939722559012882 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 1 with value: 0.2939265165330772.
running
[I 2024-11-13 05:35:55,793] Trial 10 finished with value: 0.29357225441662604 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0002267592191493195, 'p_miss': 0.29430185248250185}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:35:55,960] Trial 7 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.15931510937270457, 'alpha': 99, 'iterations': 1, 'learning_rate': 0.00012770978694593454, 'p_miss': 0.23355384868400128}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:35:56,570] Trial 14 finished with value: 0.5088303009483268 and parameters: {'model_name': 'GAIN', 'batch_size': 41, 'hint_rate': 0.6414294292055821, 'alpha': 21, 'iterations': 1, 'learning_rate': 0.00018444924690035592, 'p_miss': 0.21167175204817773}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:35:58,800] Trial 4 finished with value: 0.29813136409241137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20322, 'weights': 'uniform'}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:36:00,192] Trial 3 finished with value: 0.29817315900675345 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15682, 'weights': 'uniform'}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:36:05,417] Trial 16 finished with value: 0.3272056072226216 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9051, 'weights': 'distance'}. Best is trial 10 with value: 0.29357225441662604.
running
[I 2024-11-13 05:36:06,046] Trial 15 finished with value: 0.2929642806093887 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 10, 'learning_rate': 0.0001879111210171364, 'p_miss': 0.15671582918295102}. Best is trial 15 with value: 0.2929642806093887.
running
[I 2024-11-13 05:36:08,419] Trial 11 finished with value: 0.292636518431764 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 12, 'learning_rate': 0.00010998924195182262, 'p_miss': 0.16462046915158765}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:36:12,827] Trial 6 finished with value: 0.3064690852391358 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 16, 'learning_rate': 0.03436319539534242, 'p_miss': 0.0984828235307979}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:36:17,436] Trial 22 finished with value: 0.42489840961350805 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:36:23,422] Trial 0 finished with value: 0.3205378622922209 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:36:33,303] Trial 24 finished with value: 0.32368699792372996 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:37:05,769] Trial 5 finished with value: 0.29692001303437604 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 48, 'learning_rate': 0.004800136639306332, 'p_miss': 0.12247656238064418}. Best is trial 11 with value: 0.292636518431764.
running
[I 2024-11-13 05:38:04,097] Trial 36 finished with value: 0.29127852373773966 and parameters: {'model_name': 'VAE', 'batch_size': 941, 'iterations': 12, 'learning_rate': 0.00012368942497830492, 'p_miss': 0.2904773480313547}. Best is trial 36 with value: 0.29127852373773966.
running
[I 2024-11-13 05:38:56,111] Trial 30 finished with value: 0.28727304431028505 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 61, 'learning_rate': 0.0016414360880938916, 'p_miss': 0.019168203337948386}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:39:20,569] Trial 37 finished with value: 0.29332078913171744 and parameters: {'model_name': 'VAE', 'batch_size': 965, 'iterations': 15, 'learning_rate': 0.00011765093308158079, 'p_miss': 0.044667739927888625}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:45:58,913] Trial 35 finished with value: 0.3050888279048947 and parameters: {'model_name': 'VAE', 'batch_size': 295, 'iterations': 119, 'learning_rate': 0.0016177680509224827, 'p_miss': 0.12485085425797367}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:46:10,240] Trial 21 finished with value: 0.30192504297572464 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 192, 'learning_rate': 0.000877890702890239, 'p_miss': 0.23950778316139593}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:47:11,178] Trial 33 finished with value: 0.29969826917548287 and parameters: {'model_name': 'VAE', 'batch_size': 772, 'iterations': 143, 'learning_rate': 0.0013433282204448457, 'p_miss': 0.12621167551500842}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:48:35,793] Trial 25 finished with value: 0.2998259393269625 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 250, 'learning_rate': 0.0006545889814912378, 'p_miss': 0.294032401860742}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:49:13,071] Trial 31 finished with value: 0.3048329008613923 and parameters: {'model_name': 'VAE', 'batch_size': 796, 'iterations': 124, 'learning_rate': 0.015351501702640396, 'p_miss': 0.08752572039476196}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:49:24,004] Trial 34 finished with value: 0.30547711723307663 and parameters: {'model_name': 'VAE', 'batch_size': 765, 'iterations': 142, 'learning_rate': 0.00196393547870478, 'p_miss': 0.12879187833417796}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:51:25,562] Trial 23 finished with value: 0.2973227173377673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:51:48,988] Trial 46 finished with value: 0.2889102807101214 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 7, 'learning_rate': 0.00039408502810171265, 'p_miss': 0.18975351915064145}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 05:55:54,894] Trial 32 finished with value: 0.3049699540929066 and parameters: {'model_name': 'VAE', 'batch_size': 800, 'iterations': 230, 'learning_rate': 0.0018209920868423014, 'p_miss': 0.1248014278093334}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:14:14,731] Trial 39 finished with value: 0.30544705463834065 and parameters: {'model_name': 'VAE', 'batch_size': 592, 'iterations': 510, 'learning_rate': 0.0008868115800588946, 'p_miss': 0.01645273620116595}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:14:24,582] Trial 49 finished with value: 0.5162840138465048 and parameters: {'model_name': 'GAIN', 'batch_size': 109, 'hint_rate': 0.9803223662801478, 'alpha': 0, 'iterations': 4, 'learning_rate': 0.00032055319763570013, 'p_miss': 0.186683602487177}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:15:25,501] Trial 19 finished with value: 0.304839102277663 and parameters: {'model_name': 'VAE', 'batch_size': 267, 'iterations': 728, 'learning_rate': 0.0002619503749423393, 'p_miss': 0.18782431172887754}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:15:33,661] Trial 51 finished with value: 0.3271027435839012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 502, 'weights': 'distance'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:16:46,981] Trial 50 finished with value: 0.29145905327408195 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 38, 'learning_rate': 0.0003418659070568979, 'p_miss': 0.17038377437072139}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:34:03,480] Trial 45 finished with value: 0.5110830877814595 and parameters: {'model_name': 'GAIN', 'batch_size': 119, 'hint_rate': 0.9642933070772676, 'alpha': 77, 'iterations': 1869, 'learning_rate': 0.0004988429298616121, 'p_miss': 0.018686089844826063}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:35:43,603] Trial 54 finished with value: 0.2893249188417758 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 32, 'learning_rate': 0.00042610115457520205, 'p_miss': 0.2552253999735513}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:35:55,387] Trial 55 finished with value: 0.29135534256275125 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.005086033264696911, 'p_miss': 0.2652321274542087}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:36:10,524] Trial 56 finished with value: 0.2873510072398768 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.007755970557401224, 'p_miss': 0.267550696590933}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:36:28,404] Trial 57 finished with value: 0.28928667956437104 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.009958080736821478, 'p_miss': 0.26308045342028297}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:36:42,405] Trial 58 finished with value: 0.2926108581074222 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.009861502694408194, 'p_miss': 0.2532196215193544}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:36:42,993] Trial 59 finished with value: 0.29813136409241137 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:38:46,976] Trial 60 finished with value: 0.3162499509637702 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 34, 'learning_rate': 0.01511463718274386, 'p_miss': 0.2649349546762926}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:38:56,439] Trial 61 finished with value: 0.32712215510837994 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 976, 'weights': 'distance'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:39:07,418] Trial 62 finished with value: 0.28749136884484683 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.00687749157469007, 'p_miss': 0.22002392970502022}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:39:18,096] Trial 63 finished with value: 0.29075548988437483 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.007256165278976327, 'p_miss': 0.2069346633932378}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:39:25,479] Trial 64 finished with value: 0.29178418335370604 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0032447018041738256, 'p_miss': 0.21736519106137991}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:39:26,085] Trial 65 finished with value: 0.29813136409241137 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:39:54,902] Trial 66 finished with value: 0.2897677848116288 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 8, 'learning_rate': 0.004717904514893421, 'p_miss': 0.2660181377700443}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:42:23,715] Trial 67 finished with value: 0.3223292339593905 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 53, 'learning_rate': 0.010706537863694007, 'p_miss': 0.23684099188451013}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:44:07,047] Trial 68 finished with value: 0.3124249315057253 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 27, 'learning_rate': 0.03254437754812541, 'p_miss': 0.27473431871952764}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:44:29,008] Trial 69 finished with value: 0.304017549733108 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 7, 'learning_rate': 0.025331381894909286, 'p_miss': 0.2455875826829417}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:44:34,773] Trial 70 finished with value: 0.5112671854725976 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.07499582873930788, 'alpha': 47, 'iterations': 2, 'learning_rate': 0.0030818007647687587, 'p_miss': 0.2216022305372769}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:44:50,413] Trial 71 finished with value: 0.2890979049181904 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 5, 'learning_rate': 0.007047626423090532, 'p_miss': 0.19119732511045665}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:45:00,626] Trial 72 finished with value: 0.2974314296942924 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8536, 'weights': 'uniform'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:45:09,109] Trial 73 finished with value: 0.3044343041131034 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 2, 'learning_rate': 0.07663326689576072, 'p_miss': 0.19378064806331347}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:46:36,787] Trial 38 finished with value: 0.3046658206675854 and parameters: {'model_name': 'VAE', 'batch_size': 502, 'iterations': 1103, 'learning_rate': 0.0012525983185400595, 'p_miss': 0.05616112533982971}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:46:41,062] Trial 75 finished with value: 0.2896612328482638 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.006041925103138497, 'p_miss': 0.1979486269170422}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:47:01,483] Trial 76 finished with value: 0.29520380651799444 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 6, 'learning_rate': 0.0033222883029358683, 'p_miss': 0.17386259345726326}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:50:35,881] Trial 44 finished with value: 0.5107671935085835 and parameters: {'model_name': 'GAIN', 'batch_size': 86, 'hint_rate': 0.9711462181068735, 'alpha': 1, 'iterations': 2748, 'learning_rate': 0.0004338345960801497, 'p_miss': 0.02507328424338312}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 06:51:35,924] Trial 78 finished with value: 0.3070186732038872 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 22, 'learning_rate': 0.008166497902211729, 'p_miss': 0.2273447338002341}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:16:05,713] Trial 40 finished with value: 0.30534446927319736 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 1426, 'learning_rate': 0.0010206057025990058, 'p_miss': 0.03053671265298323}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:19:24,446] Trial 80 finished with value: 0.3068203924634549 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 67, 'learning_rate': 0.01567185103872102, 'p_miss': 0.250092841572585}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:19:44,991] Trial 81 finished with value: 0.2876769433012392 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 6, 'learning_rate': 0.012638026047247602, 'p_miss': 0.2780189665334938}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:19:45,966] Trial 82 finished with value: 0.5112537346435311 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:20:04,425] Trial 83 finished with value: 0.29064411698577064 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.012047267875678523, 'p_miss': 0.14435422336618234}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:37:17,492] Trial 84 finished with value: 0.299076850555678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:37:25,197] Trial 85 finished with value: 0.28937395829714097 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 1, 'learning_rate': 0.01738556736581608, 'p_miss': 0.2981199703167754}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:38:03,950] Trial 86 finished with value: 0.290432257964917 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 10, 'learning_rate': 0.004333923825151235, 'p_miss': 0.28495609506294817}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:38:17,693] Trial 87 finished with value: 0.28912276785715557 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.007264765668963059, 'p_miss': 0.2746958565194932}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:38:30,611] Trial 88 finished with value: 0.2903243875852531 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.007113083382038862, 'p_miss': 0.2785369533115724}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:38:40,674] Trial 89 finished with value: 0.2891864298099654 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2, 'learning_rate': 0.010616631176919224, 'p_miss': 0.15228702804890468}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:38:51,274] Trial 90 finished with value: 0.2911156577102413 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 2, 'learning_rate': 0.018898807151593373, 'p_miss': 0.1540245913454922}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:39:46,850] Trial 91 finished with value: 0.28948360389427735 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 17, 'learning_rate': 0.002462840174998977, 'p_miss': 0.0777255599964503}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:40:03,974] Trial 92 finished with value: 0.290369694031458 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.005819804537346202, 'p_miss': 0.11123954656843382}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:40:12,542] Trial 93 finished with value: 0.29813136409241137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21500, 'weights': 'uniform'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:40:17,072] Trial 94 finished with value: 0.29108366725221935 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.008516317240656624, 'p_miss': 0.17565510041613405}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:40:40,998] Trial 95 finished with value: 0.32040755235680035 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:40:57,667] Trial 96 finished with value: 0.2887838703217639 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4, 'learning_rate': 0.011818311528701263, 'p_miss': 0.276362657112018}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:41:14,512] Trial 97 finished with value: 0.2951743650377515 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 3, 'learning_rate': 0.02178492194369135, 'p_miss': 0.2794725718680353}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:41:30,694] Trial 98 finished with value: 0.29077699674027546 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 5, 'learning_rate': 0.013546273113003719, 'p_miss': 0.20775884233295988}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:42:21,470] Trial 99 finished with value: 0.29589591779793434 and parameters: {'model_name': 'VAE', 'batch_size': 193, 'iterations': 11, 'learning_rate': 0.006531465666827388, 'p_miss': 0.2883824624541993}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 07:42:30,321] Trial 100 finished with value: 0.2933042576142747 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.0039104795247632525, 'p_miss': 0.14233686634891532}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 08:01:43,719] Trial 101 finished with value: 0.3095022721599944 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 420, 'learning_rate': 0.009114502968938383, 'p_miss': 0.18052865925151862}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 08:01:52,546] Trial 102 finished with value: 0.5061460607917784 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.4595810057112329, 'alpha': 51, 'iterations': 4, 'learning_rate': 0.012333900179658708, 'p_miss': 0.23056085577492497}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 08:02:26,545] Trial 103 finished with value: 0.2922279014121235 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 9, 'learning_rate': 0.005364107658444081, 'p_miss': 0.1620757275168048}. Best is trial 30 with value: 0.28727304431028505.
running
[I 2024-11-13 08:02:45,899] Trial 104 finished with value: 0.28610114344312565 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 5, 'learning_rate': 0.011385381186790824, 'p_miss': 0.27036808498627496}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:02:46,398] Trial 105 finished with value: 0.5112537346435311 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:03:07,189] Trial 106 finished with value: 0.29159929648391003 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 5, 'learning_rate': 0.011400546673664854, 'p_miss': 0.2597915185887144}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:03:18,635] Trial 107 finished with value: 0.2936922321702905 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 3, 'learning_rate': 0.008306308179377149, 'p_miss': 0.2721500575062926}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:04:08,022] Trial 108 finished with value: 0.29314554401295734 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 15, 'learning_rate': 0.0001490549559954303, 'p_miss': 0.24202786610780547}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:04:25,636] Trial 42 finished with value: 0.30620765790110865 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 2487, 'learning_rate': 0.0005213469936040289, 'p_miss': 0.020815007781316543}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:04:29,381] Trial 109 finished with value: 0.2889396298417508 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 6, 'learning_rate': 0.0006156725455251044, 'p_miss': 0.2967290874474302}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:04:52,607] Trial 111 finished with value: 0.29311209896934465 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 6, 'learning_rate': 0.00024548650135203205, 'p_miss': 0.29025390467030726}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:05:07,340] Trial 112 finished with value: 0.2919424273438913 and parameters: {'model_name': 'VAE', 'batch_size': 358, 'iterations': 4, 'learning_rate': 0.0007886366777024756, 'p_miss': 0.2963974904712368}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:33:01,745] Trial 43 finished with value: 0.30648390425176225 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 3117, 'learning_rate': 0.006261558225662908, 'p_miss': 0.026967999804231785}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:33:38,686] Trial 114 finished with value: 0.2938484104776123 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 14, 'learning_rate': 0.001199202380251174, 'p_miss': 0.283415170756301}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:37:17,097] Trial 47 finished with value: 0.3061363332049812 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 2975, 'learning_rate': 0.0004252503252322567, 'p_miss': 0.18016101586374067}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:37:29,503] Trial 116 finished with value: 0.29341170940781836 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.000541643521074613, 'p_miss': 0.27481898176208847}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:37:57,842] Trial 117 finished with value: 0.28843622578733424 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8, 'learning_rate': 0.013964267733823173, 'p_miss': 0.2704131386031542}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:46:01,169] Trial 115 finished with value: 0.29692258605007066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:46:27,604] Trial 119 finished with value: 0.30420691791613397 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9, 'learning_rate': 0.02429008369087125, 'p_miss': 0.2993478213644421}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:46:47,538] Trial 120 finished with value: 0.2918679839066434 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 6, 'learning_rate': 0.0015761119548798092, 'p_miss': 0.2687059862038751}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:47:14,038] Trial 121 finished with value: 0.29392902779715646 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 8, 'learning_rate': 0.013504738861888424, 'p_miss': 0.2608837885190982}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:47:27,243] Trial 122 finished with value: 0.32722306155975317 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14520, 'weights': 'distance'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:52:32,828] Trial 18 finished with value: 0.30613612496019665 and parameters: {'model_name': 'VAE', 'batch_size': 119, 'iterations': 3854, 'learning_rate': 0.00026958543950225016, 'p_miss': 0.028416983447855065}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:53:36,797] Trial 124 finished with value: 0.2938445968114092 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 19, 'learning_rate': 0.0007054662396654263, 'p_miss': 0.2520463897429174}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:53:45,529] Trial 125 finished with value: 0.5149692719744983 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.41258186974807687, 'alpha': 50, 'iterations': 4, 'learning_rate': 0.0003535489569510112, 'p_miss': 0.28201950539808185}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:54:04,370] Trial 126 finished with value: 0.29038881412020984 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.00977414403336866, 'p_miss': 0.06431358359066167}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:54:12,616] Trial 127 finished with value: 0.2896637477930694 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.007496781302548612, 'p_miss': 0.20126154035555613}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 08:54:39,700] Trial 128 finished with value: 0.307968876226021 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7, 'learning_rate': 0.018982318985724885, 'p_miss': 0.21729598651086807}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:30:09,932] Trial 48 finished with value: 0.305150369130145 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 3456, 'learning_rate': 0.0004077942165000938, 'p_miss': 0.18513627851569592}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:30:48,015] Trial 130 finished with value: 0.2983757552046929 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 12, 'learning_rate': 0.011022487176676931, 'p_miss': 0.2720602971678322}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:35:23,735] Trial 131 finished with value: 0.3171946085807234 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 104, 'learning_rate': 0.01489894937440882, 'p_miss': 0.28861688890039877}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:35:35,713] Trial 132 finished with value: 0.2896711121532275 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.03258481348904283, 'p_miss': 0.2580263977682561}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:35:49,096] Trial 133 finished with value: 0.29292192538829537 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.0025081350007415213, 'p_miss': 0.09817341271994282}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:35:49,871] Trial 134 finished with value: 0.318947962797109 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:36:06,923] Trial 135 finished with value: 0.2999542411437628 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.00020199603736828807, 'p_miss': 0.24643415271439037}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:36:23,345] Trial 136 finished with value: 0.2885260549617207 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.008882466637848231, 'p_miss': 0.26618768331671316}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 09:36:36,616] Trial 137 finished with value: 0.2882101238514191 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 3, 'learning_rate': 0.009508273823992814, 'p_miss': 0.27427746137986087}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:33:43,587] Trial 26 finished with value: 0.34357961028078743 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5187, 'learning_rate': 0.07871545628578171, 'p_miss': 0.015351466639426048}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:33:59,801] Trial 139 finished with value: 0.2884544289338994 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 4, 'learning_rate': 0.0067277714316201515, 'p_miss': 0.2761876626221695}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:34:13,508] Trial 140 finished with value: 0.2867742550442002 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4, 'learning_rate': 0.009000705032172828, 'p_miss': 0.26746660915771153}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:34:36,725] Trial 141 finished with value: 0.28817971460139546 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7, 'learning_rate': 0.009297499850806966, 'p_miss': 0.2651058023828995}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:34:49,916] Trial 142 finished with value: 0.28865624034854276 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4, 'learning_rate': 0.008913016384315919, 'p_miss': 0.2693431400826146}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:35:04,524] Trial 143 finished with value: 0.29033806049878913 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 4, 'learning_rate': 0.00915298466644444, 'p_miss': 0.26353726102342495}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:35:19,348] Trial 144 finished with value: 0.2913474917571304 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.013166563090097701, 'p_miss': 0.2678371211845119}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:35:42,676] Trial 145 finished with value: 0.2914503638031829 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 8, 'learning_rate': 0.006207235924467214, 'p_miss': 0.255403241427197}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:35:56,877] Trial 146 finished with value: 0.2898715217472244 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.008198057571150273, 'p_miss': 0.2779764585030001}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:36:20,941] Trial 147 finished with value: 0.2943530522538206 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 7, 'learning_rate': 0.01642992019923898, 'p_miss': 0.26901740856149836}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:36:54,208] Trial 148 finished with value: 0.28886301554787597 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 11, 'learning_rate': 0.004938267182749886, 'p_miss': 0.23867353028015129}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:37:31,276] Trial 149 finished with value: 0.29066905760176326 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 11, 'learning_rate': 0.004023800111491321, 'p_miss': 0.24740647439534233}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:37:49,872] Trial 150 finished with value: 0.29031838203490834 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 5, 'learning_rate': 0.005157501512102923, 'p_miss': 0.23933102255312913}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:37:58,938] Trial 151 finished with value: 0.29664116024957704 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4079, 'weights': 'uniform'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:38:12,623] Trial 152 finished with value: 0.29191098208754634 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.011007975383845535, 'p_miss': 0.28370145015449544}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:51:27,556] Trial 29 finished with value: 0.34462975152860187 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5442, 'learning_rate': 0.08169528009906427, 'p_miss': 0.04488216191985872}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:59:18,680] Trial 153 finished with value: 0.3063690498212388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 10:59:46,791] Trial 155 finished with value: 0.2892484837784448 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9, 'learning_rate': 0.009829809879443928, 'p_miss': 0.2601529151519878}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:00:08,959] Trial 156 finished with value: 0.28735009783499277 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 6, 'learning_rate': 0.00755522481698977, 'p_miss': 0.276638556980096}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:00:30,349] Trial 157 finished with value: 0.2882568720964694 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.007676850703465219, 'p_miss': 0.27421291660378294}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:00:48,788] Trial 158 finished with value: 0.2891497933136199 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 6, 'learning_rate': 0.007729249589401973, 'p_miss': 0.2766531837985341}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:01:03,474] Trial 159 finished with value: 0.2883961896393306 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 3, 'learning_rate': 0.006574539992820992, 'p_miss': 0.2901861781381109}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:01:15,143] Trial 160 finished with value: 0.2912410266947318 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.006746816541023263, 'p_miss': 0.2875905499599173}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:12:54,017] Trial 154 finished with value: 0.30734686128714855 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:13:03,143] Trial 162 finished with value: 0.29004997909035984 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.005565585130104771, 'p_miss': 0.29140564831681387}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:13:20,541] Trial 163 finished with value: 0.28925949997819206 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.008878659586629612, 'p_miss': 0.2682437442244509}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:13:29,862] Trial 164 finished with value: 0.5084587558391107 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.6959099817740568, 'alpha': 96, 'iterations': 4, 'learning_rate': 0.006350569303305502, 'p_miss': 0.2827079605183349}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:20:33,688] Trial 161 finished with value: 0.3063459523316903 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 316, 'learning_rate': 0.005628712657740329, 'p_miss': 0.2684178533941928}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:20:37,855] Trial 52 finished with value: 0.30451670449159457 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 6264, 'learning_rate': 0.0004640174555990857, 'p_miss': 0.2638564364536747}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 11:20:47,108] Trial 166 finished with value: 0.28972312166270087 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 4, 'learning_rate': 0.013197680985315796, 'p_miss': 0.2747988385190445}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:01:39,865] Trial 113 finished with value: 0.30877398477028994 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 5225, 'learning_rate': 0.0013419186702738875, 'p_miss': 0.2820288896558128}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:02:01,497] Trial 169 finished with value: 0.2864718103565689 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 7, 'learning_rate': 0.0119954100254854, 'p_miss': 0.25325483200769994}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:02:28,083] Trial 170 finished with value: 0.2945480921118379 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 8, 'learning_rate': 0.009877782962149863, 'p_miss': 0.25487971227220285}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:05:51,397] Trial 167 finished with value: 0.3159143710744798 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 822, 'learning_rate': 0.012495489329642189, 'p_miss': 0.27436264440286634}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:05:52,025] Trial 172 finished with value: 0.29813136409241137 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:06:01,550] Trial 173 finished with value: 0.2911516007535238 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3, 'learning_rate': 0.007693959309375931, 'p_miss': 0.26330625561349674}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:06:24,362] Trial 174 finished with value: 0.28892538889550445 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.008594498281435176, 'p_miss': 0.2917126946437214}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:06:39,514] Trial 175 finished with value: 0.2934767492893404 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.014460425875334972, 'p_miss': 0.2567679249418109}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:07:05,646] Trial 176 finished with value: 0.28803104070882035 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7, 'learning_rate': 0.011285858886045268, 'p_miss': 0.27998020475232227}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:07:32,017] Trial 177 finished with value: 0.2942758623640187 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 7, 'learning_rate': 0.011520903997488823, 'p_miss': 0.27045125968936795}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:07:50,731] Trial 178 finished with value: 0.28899103563993506 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.009741151358855499, 'p_miss': 0.2805121525024765}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:08:00,173] Trial 168 finished with value: 0.31556449679277015 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 856, 'learning_rate': 0.011938052086794557, 'p_miss': 0.280048070641648}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:08:28,073] Trial 179 finished with value: 0.30712557037871147 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 13, 'learning_rate': 0.01752994555997463, 'p_miss': 0.2661906135047089}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:08:46,826] Trial 180 finished with value: 0.2895553108962747 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 14, 'learning_rate': 0.00692861794744755, 'p_miss': 0.26375998443006243}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:08:56,632] Trial 181 finished with value: 0.29001614506493534 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7, 'learning_rate': 0.007545549206438387, 'p_miss': 0.2865544002988568}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:08:59,717] Trial 182 finished with value: 0.28933886741277315 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.008714868451217214, 'p_miss': 0.28596550569941925}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:09:24,852] Trial 183 finished with value: 0.28979154044504707 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 9, 'learning_rate': 0.009222696388319383, 'p_miss': 0.27301031771910117}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:09:32,721] Trial 184 finished with value: 0.2921345336558988 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 9, 'learning_rate': 0.010151620696429395, 'p_miss': 0.27062835628451054}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:09:46,229] Trial 185 finished with value: 0.28870075791733646 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 5, 'learning_rate': 0.010531308741832092, 'p_miss': 0.2936393678616541}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:09:47,223] Trial 186 finished with value: 0.28945490185029954 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4, 'learning_rate': 0.0113532648696925, 'p_miss': 0.034592624887478704}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:10:05,555] Trial 188 finished with value: 0.29326134471639353 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.00667278448145885, 'p_miss': 0.29336485240861127}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:10:27,754] Trial 189 finished with value: 0.2893582951507385 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 6, 'learning_rate': 0.01481806762080105, 'p_miss': 0.25018825030968633}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:10:37,102] Trial 190 finished with value: 0.29121369785065776 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 3, 'learning_rate': 0.02006997109073039, 'p_miss': 0.2999467204985744}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:10:47,497] Trial 191 finished with value: 0.28930346127534035 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2, 'learning_rate': 0.007920841614632175, 'p_miss': 0.2773736826271741}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:11:00,713] Trial 192 finished with value: 0.32722375649230057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15314, 'weights': 'distance'}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:11:13,951] Trial 193 finished with value: 0.29202978631196147 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 4, 'learning_rate': 0.010948806723720287, 'p_miss': 0.2602419645239217}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:11:31,919] Trial 194 finished with value: 0.2889828969530922 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.004363193103844428, 'p_miss': 0.280037000004113}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:11:57,667] Trial 195 finished with value: 0.28978795599012797 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 7, 'learning_rate': 0.0062799951143766115, 'p_miss': 0.2944112423026694}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:12:14,184] Trial 196 finished with value: 0.2868607967812732 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4, 'learning_rate': 0.013458457554872953, 'p_miss': 0.2738680449831821}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:12:29,774] Trial 197 finished with value: 0.287805989850473 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5, 'learning_rate': 0.013833497324778288, 'p_miss': 0.27118531206093044}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:12:46,014] Trial 198 finished with value: 0.2908004969911401 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 4, 'learning_rate': 0.016352888125658945, 'p_miss': 0.27242286554090384}. Best is trial 104 with value: 0.28610114344312565.
running
[I 2024-11-13 12:12:56,750] Trial 199 finished with value: 0.28807115250838455 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.012968799421751272, 'p_miss': 0.26402030350211214}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:13:44,454] Trial 53 finished with value: 0.3075094761253406 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 6133, 'learning_rate': 0.0004308142799740504, 'p_miss': 0.26162822649498896}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:16:48,863] Trial 41 finished with value: 0.3065060008707544 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 5890, 'learning_rate': 0.000576491757043744, 'p_miss': 0.011829596306303099}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:26:26,967] Trial 79 finished with value: 0.30614785282834744 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 8118, 'learning_rate': 0.011678162284198525, 'p_miss': 0.2528294040955234}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:33:34,039] Trial 28 finished with value: 0.343987584654886 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7299, 'learning_rate': 0.06429344299300417, 'p_miss': 0.024303112200459775}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:36:04,995] Trial 77 finished with value: 0.3112014645545397 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 7518, 'learning_rate': 0.008441534393198058, 'p_miss': 0.22426482875924464}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 12:54:53,628] Trial 110 finished with value: 0.3107007189984373 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 6172, 'learning_rate': 0.020422824359523657, 'p_miss': 0.2985967151293751}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:00:17,256] Trial 27 finished with value: 0.3527203204317749 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8862, 'learning_rate': 0.05184700716845569, 'p_miss': 0.07121690986498493}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:01:41,465] Trial 74 finished with value: 0.30937316161076034 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 7906, 'learning_rate': 0.006916371905801212, 'p_miss': 0.17499392874133785}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:05:05,049] Trial 138 finished with value: 0.3141171503995329 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4899, 'learning_rate': 0.007721390745461383, 'p_miss': 0.2671221537457902}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:23:55,949] Trial 123 finished with value: 0.32182047688209925 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8377, 'learning_rate': 0.0003190657134087985, 'p_miss': 0.281612038700211}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:27:17,630] Trial 118 finished with value: 0.32931163198820007 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8728, 'learning_rate': 0.022835108157288384, 'p_miss': 0.26817283930619157}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:27:18,934] Trial 129 finished with value: 0.31515646951352977 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7115, 'learning_rate': 0.010789946721345983, 'p_miss': 0.26998564452082296}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:31:33,948] Trial 171 finished with value: 0.33198765033805633 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9286, 'learning_rate': 0.007743693956919013, 'p_miss': 0.2618647784511379}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:33:17,581] Trial 165 finished with value: 0.3079531666486775 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7789, 'learning_rate': 0.01372458348560012, 'p_miss': 0.2558484081332168}. Best is trial 104 with value: 0.28610114344312565.
[I 2024-11-13 13:34:57,668] Trial 187 finished with value: 0.31099568025963764 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 9148, 'learning_rate': 0.021122873694480734, 'p_miss': 0.29363755546352216}. Best is trial 104 with value: 0.28610114344312565.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.28610114344312565
{'model_name': 'VAE', 'batch_size': 14, 'iterations': 5, 'learning_rate': 0.011385381186790824, 'p_miss': 0.27036808498627496}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.05475624913183068
Generation:   4%|         | 1/25 [04:33<1:49:31, 273.82s/it]Generation:  2
Best f1_score score: 0.05571979192964101
Generation:   8%|         | 2/25 [12:39<2:32:41, 398.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714b50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.05571979192964101
Generation:  12%|        | 3/25 [18:11<2:14:56, 368.02s/it]Generation:  4
Best f1_score score: 0.05571979192964101
Generation:  16%|        | 4/25 [27:24<2:34:22, 441.07s/it]Generation:  5
Best f1_score score: 0.057785930165023945
Generation:  20%|        | 5/25 [35:26<2:31:55, 455.76s/it]Generation:  6
Best f1_score score: 0.057785930165023945
Generation:  24%|       | 6/25 [39:01<1:58:23, 373.87s/it]Generation:  7
Best f1_score score: 0.057785930165023945
Generation:  28%|       | 7/25 [42:15<1:34:36, 315.34s/it]Generation:  8
Best f1_score score: 0.057785930165023945
Generation:  32%|      | 8/25 [50:39<1:46:19, 375.28s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b430> 

Generation:  9
Best f1_score score: 0.05788520193998727
Generation:  36%|      | 9/25 [1:00:49<1:59:40, 448.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a0e5c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.058573047801954034
Generation:  40%|      | 10/25 [1:06:39<1:44:31, 418.13s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655aac50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.058573047801954034
Generation:  44%|     | 11/25 [1:11:05<1:26:44, 371.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676b44c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.058573047801954034
Generation:  48%|     | 12/25 [1:15:47<1:14:37, 344.46s/it]Generation:  13
Best f1_score score: 0.05915039178404263
Generation:  52%|    | 13/25 [1:19:00<59:41, 298.42s/it]  Generation:  14
Best f1_score score: 0.05915039178404263
Generation:  56%|    | 14/25 [1:27:05<1:05:04, 354.91s/it]Generation:  15
Best f1_score score: 0.05915039178404263
Generation:  60%|    | 15/25 [1:31:17<53:57, 323.74s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650b38b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2aa0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.05915039178404263
Generation:  64%|   | 16/25 [1:34:34<42:51, 285.67s/it]Generation:  17
Best f1_score score: 0.05940745096933
Generation:  68%|   | 17/25 [1:42:15<45:05, 338.22s/it]Generation:  18
Best f1_score score: 0.05940745096933
Generation:  72%|  | 18/25 [1:45:43<34:55, 299.36s/it]Generation:  19
Best f1_score score: 0.05940745096933
Generation:  76%|  | 19/25 [1:54:13<36:14, 362.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466db42e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.05994528655224821
Generation:  80%|  | 20/25 [2:01:54<32:40, 392.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f76e60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fccbb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.05994528655224821
Generation:  84%| | 21/25 [2:06:46<24:07, 361.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747359c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.05994528655224821
Generation:  88%| | 22/25 [2:10:38<16:08, 322.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474734cd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474735930> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.06137869439777897
Generation:  92%|| 23/25 [2:15:43<10:35, 317.70s/it]Generation:  24
Best f1_score score: 0.06137869439777897
Generation:  96%|| 24/25 [2:21:00<05:17, 317.63s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466db7850> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.06137869439777897
Generation: 100%|| 25/25 [2:24:46<00:00, 289.90s/it]Generation: 100%|| 25/25 [2:24:52<00:00, 347.72s/it]
2024-11-13 16:00:07,831 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:40789' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-72325f7fcf600e0f25d6094837f710e5', 'ndarray-04ef1e3a7246aa787bf6714e77e9803f'} (stimulus_id='handle-worker-cleanup-1731542407.8314908')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        max_features=0.465719915396,
                                        min_samples_leaf=3,
                                        min_samples_split=14,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9977355387961021, 'accuracy': 0.9453306006059526, 'balanced_accuracy': 0.9774759348603816, 'logloss': 1.6264464515903587, 'f1': 0.901692352581849}
original test score: {'auroc': 0.5465326482965057, 'accuracy': 0.14237348538845332, 'balanced_accuracy': 0.06874372556681672, 'logloss': 2.62469144557764, 'f1': 0.06168785632598496}
imputed test score: {'auroc': 0.4981271943095264, 'accuracy': 0.09194583036350677, 'balanced_accuracy': 0.05346798751600071, 'logloss': 2.752145402998463, 'f1': 0.05310324012017351}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0b20> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1060> 

Generation:  1
Best f1_score score: 0.24808338152405013
Generation:   4%|         | 1/25 [10:02<4:00:50, 602.11s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474705de0> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.27133085493424597
Generation:   8%|         | 2/25 [18:05<3:23:59, 532.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3940> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471f760> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  3
Best f1_score score: 0.2851182544753893
Generation:  12%|        | 3/25 [25:31<3:00:41, 492.80s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a31f0> 

Generation:  4
Best f1_score score: 0.28705631646738006
Generation:  16%|        | 4/25 [35:36<3:07:57, 537.00s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b0b280> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f109d0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471eb90> 

Generation:  5
Best f1_score score: 0.28705631646738006
Generation:  20%|        | 5/25 [45:41<3:07:17, 561.87s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454768fd0> 

Generation:  6
Best f1_score score: 0.2876706624811573
Generation:  24%|       | 6/25 [55:46<3:02:32, 576.45s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471d8d0> 

Generation:  7
Best f1_score score: 0.28883379760305544
Generation:  28%|       | 7/25 [1:05:52<2:55:48, 586.05s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465af9ab0> 

Generation:  8
Best f1_score score: 0.29184827892949017
Generation:  32%|      | 8/25 [1:15:57<2:47:47, 592.20s/it]Generation:  9
Best f1_score score: 0.298619559892111
Generation:  36%|      | 9/25 [1:18:45<2:02:31, 459.47s/it]Generation:  10
Best f1_score score: 0.298619559892111
Generation:  40%|      | 10/25 [1:22:36<1:37:13, 388.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465ca5b40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.298619559892111
Generation:  44%|     | 11/25 [1:25:34<1:15:42, 324.44s/it]Generation:  12
Best f1_score score: 0.298619559892111
Generation:  48%|     | 12/25 [1:28:43<1:01:19, 283.04s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e28a60> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546797f580> 

Generation:  13
Best f1_score score: 0.298619559892111
Generation:  52%|    | 13/25 [1:38:49<1:16:10, 380.90s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f63250> 

Generation:  14
Best f1_score score: 0.298619559892111
Generation:  56%|    | 14/25 [1:48:57<1:22:24, 449.47s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2d510> 

Generation:  15
Best f1_score score: 0.298619559892111
Generation:  60%|    | 15/25 [1:59:04<1:22:49, 496.98s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466bde7a0> 

Generation:  16
Best f1_score score: 0.29902303561973315
Generation:  64%|   | 16/25 [2:09:10<1:19:29, 529.97s/it]Generation:  17
Best f1_score score: 0.30871910440770123
Generation:  68%|   | 17/25 [2:13:08<58:56, 442.12s/it]  Generation:  18
Best f1_score score: 0.3116213001216674
Generation:  72%|  | 18/25 [2:15:55<41:55, 359.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546583a740> 

Generation:  19
Best f1_score score: 0.3116213001216674
Generation:  76%|  | 19/25 [2:26:01<43:20, 433.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f65f00> 

Generation:  20
Best f1_score score: 0.3143007987066933
Generation:  80%|  | 20/25 [2:36:09<40:29, 485.97s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465c89b70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2800> 

Generation:  21
Best f1_score score: 0.3143007987066933
Generation:  84%| | 21/25 [2:46:18<34:51, 522.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652f01f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467965cf0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467abcfd0> 

Generation:  22
Best f1_score score: 0.31711667206919386
Generation:  88%| | 22/25 [2:56:25<27:24, 548.18s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450b63460> 

Generation:  23
Best f1_score score: 0.31711667206919386
Generation:  92%|| 23/25 [3:06:34<18:52, 566.43s/it]Generation:  24
Best f1_score score: 0.3177996979716324
Generation:  96%|| 24/25 [3:09:57<07:37, 457.29s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465f520> 

Generation:  25
Best f1_score score: 0.31919748179543384
Generation: 100%|| 25/25 [3:20:04<00:00, 502.19s/it]Generation: 100%|| 25/25 [3:20:04<00:00, 480.18s/it]
2024-11-13 19:21:47,657 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:46077' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-0a1c80706ffa755971be419a411ee496', 'ndarray-04ef1e3a7246aa787bf6714e77e9803f'} (stimulus_id='handle-worker-cleanup-1731554507.657221')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=RandomForestRegressor(),
                                  initial_strategy='most_frequent',
                                  n_nearest_features=1)),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=3.178921e-07,
                                                learning_rate=0.020659406687,
                                                max_features=0.4871344144777,
                                                max_leaf_nodes=1438,
                                                min_samples_leaf=28, tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9755059300414786, 'accuracy': 0.6481910532881839, 'balanced_accuracy': 0.6557193028985386, 'logloss': 1.1306664253531697, 'f1': 0.6721164523824777}
test score: {'auroc': 0.8866201011891603, 'accuracy': 0.3907697790449038, 'balanced_accuracy': 0.30530408689283, 'logloss': 1.7307316810554627, 'f1': 0.3178061217430963}
original test score: {'auroc': 0.9708620747810612, 'accuracy': 0.6646471846044191, 'balanced_accuracy': 0.5762716693712798, 'logloss': 1.0749756829195996, 'f1': 0.592350207920045}
score end
1481
lvl
0.3
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
13.775824113620653
hours
DONE
