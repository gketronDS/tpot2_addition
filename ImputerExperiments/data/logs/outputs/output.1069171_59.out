Run: 59
/cm/local/apps/slurm/var/spool/job1069171/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MNAR_0.3_3
2.6770453453063965
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 16:22:35,395] A new study created in memory with name: no-name-060b385c-c428-4e27-aa04-4f14b4af06d6
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 16:22:35,737] Trial 0 finished with value: 0.5471410788198927 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5471410788198927.
running
[I 2024-11-22 16:22:36,489] Trial 16 finished with value: 0.5471410788198927 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5471410788198927.
running
[I 2024-11-22 16:22:36,779] Trial 15 finished with value: 0.3804360336110601 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 15 with value: 0.3804360336110601.
running
[I 2024-11-22 16:22:41,621] Trial 6 finished with value: 0.3291418131296372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:22:45,539] Trial 2 finished with value: 0.33192645248547736 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:22:56,467] Trial 1 finished with value: 0.5444754397804676 and parameters: {'model_name': 'GAIN', 'batch_size': 28, 'hint_rate': 0.735619892014253, 'alpha': 28, 'iterations': 11, 'learning_rate': 0.0022314611857548318, 'p_miss': 0.05856886678251436}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:22:56,804] Trial 19 finished with value: 0.3291672370726393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:22:59,522] Trial 10 finished with value: 0.547163984418769 and parameters: {'model_name': 'GAIN', 'batch_size': 130, 'hint_rate': 0.6148740016308706, 'alpha': 4, 'iterations': 14, 'learning_rate': 0.010926708958994906, 'p_miss': 0.02853386951554311}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:23:00,329] Trial 7 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5118105768028526, 'alpha': 5, 'iterations': 98, 'learning_rate': 0.006576490571552537, 'p_miss': 0.08176111175210432}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:23:01,615] Trial 17 finished with value: 0.3529432759776284 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 610, 'weights': 'distance'}. Best is trial 6 with value: 0.3291418131296372.
running
[I 2024-11-22 16:23:13,188] Trial 24 finished with value: 0.32914180881461486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:14,860] Trial 13 finished with value: 0.3528924431926309 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32044, 'weights': 'distance'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:16,756] Trial 8 finished with value: 0.4645207164437354 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:17,811] Trial 9 finished with value: 0.3528958728884858 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21516, 'weights': 'distance'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:22,591] Trial 14 finished with value: 0.36906632264933925 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:26,159] Trial 23 finished with value: 0.33461640604225235 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21764, 'weights': 'uniform'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:23:35,213] Trial 22 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9132961247203828, 'alpha': 97, 'iterations': 189, 'learning_rate': 0.0003642278863336023, 'p_miss': 0.09953739661430094}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:25:19,125] Trial 20 finished with value: 0.3806462334669565 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 69, 'learning_rate': 0.032276094396965216, 'p_miss': 0.12511536812081486}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:25:28,151] Trial 33 finished with value: 0.3291419142417744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:25:56,242] Trial 11 finished with value: 0.3426228483680407 and parameters: {'model_name': 'VAE', 'batch_size': 279, 'iterations': 47, 'learning_rate': 0.007608544423557244, 'p_miss': 0.0834286958078009}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:26:16,749] Trial 35 finished with value: 0.32932953652439034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:26:26,982] Trial 36 finished with value: 0.3291419142417744 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:28:34,182] Trial 3 finished with value: 0.33365905385729555 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 143, 'learning_rate': 0.001870319853996889, 'p_miss': 0.07094537000543731}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:38:05,471] Trial 5 finished with value: 0.3319974725688386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.32914180881461486.
running
[I 2024-11-22 16:38:16,856] Trial 39 finished with value: 0.32914180703314144 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:38:37,867] Trial 40 finished with value: 0.329644464959657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:38:49,117] Trial 41 finished with value: 0.32914180703314144 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:38:59,952] Trial 42 finished with value: 0.32914180881461486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:41:06,058] Trial 21 finished with value: 0.5442002276016009 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.737562839913674, 'alpha': 48, 'iterations': 743, 'learning_rate': 0.03844046533290007, 'p_miss': 0.19539517119136987}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:41:07,248] Trial 44 finished with value: 0.5471410788198927 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:41:45,878] Trial 45 finished with value: 0.35858384896709045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:41:57,978] Trial 46 finished with value: 0.32914180881461486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:42:10,929] Trial 47 finished with value: 0.32914180881461486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:42:23,517] Trial 48 finished with value: 0.32914180881461486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:59:24,328] Trial 18 finished with value: 0.3538731396028848 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:59:48,190] Trial 50 finished with value: 0.32915293670878737 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 39 with value: 0.32914180703314144.
running
[I 2024-11-22 16:59:54,793] Trial 51 finished with value: 0.3198250036920103 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 1, 'learning_rate': 0.0001148393143082886, 'p_miss': 0.2833223988539687}. Best is trial 51 with value: 0.3198250036920103.
running
[I 2024-11-22 17:00:02,583] Trial 52 finished with value: 0.31685463259628105 and parameters: {'model_name': 'VAE', 'batch_size': 888, 'iterations': 1, 'learning_rate': 0.00011127400739503621, 'p_miss': 0.29763559430651565}. Best is trial 52 with value: 0.31685463259628105.
running
[I 2024-11-22 17:00:09,513] Trial 53 finished with value: 0.3133870865347809 and parameters: {'model_name': 'VAE', 'batch_size': 900, 'iterations': 1, 'learning_rate': 0.00010004323755785791, 'p_miss': 0.29331879880154244}. Best is trial 53 with value: 0.3133870865347809.
running
[I 2024-11-22 17:00:17,693] Trial 54 finished with value: 0.31302828179689857 and parameters: {'model_name': 'VAE', 'batch_size': 911, 'iterations': 1, 'learning_rate': 0.0001277587224652667, 'p_miss': 0.2990522028805065}. Best is trial 54 with value: 0.31302828179689857.
running
[I 2024-11-22 17:00:24,171] Trial 55 finished with value: 0.3156869021746579 and parameters: {'model_name': 'VAE', 'batch_size': 937, 'iterations': 1, 'learning_rate': 0.00010871447004194092, 'p_miss': 0.29709118234632353}. Best is trial 54 with value: 0.31302828179689857.
running
[I 2024-11-22 17:00:31,709] Trial 56 finished with value: 0.314466785180601 and parameters: {'model_name': 'VAE', 'batch_size': 701, 'iterations': 1, 'learning_rate': 0.0001172166159033269, 'p_miss': 0.29948724723303755}. Best is trial 54 with value: 0.31302828179689857.
running
[I 2024-11-22 17:00:39,265] Trial 57 finished with value: 0.31318875925654843 and parameters: {'model_name': 'VAE', 'batch_size': 927, 'iterations': 1, 'learning_rate': 0.00010286603057469623, 'p_miss': 0.2977028983633632}. Best is trial 54 with value: 0.31302828179689857.
running
[I 2024-11-22 17:00:47,098] Trial 58 finished with value: 0.31191509219645297 and parameters: {'model_name': 'VAE', 'batch_size': 986, 'iterations': 1, 'learning_rate': 0.0002644470300838604, 'p_miss': 0.24910545901240724}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:01:01,630] Trial 59 finished with value: 0.31429739640346277 and parameters: {'model_name': 'VAE', 'batch_size': 470, 'iterations': 3, 'learning_rate': 0.0003557942293047221, 'p_miss': 0.24794308921420757}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:01:21,052] Trial 60 finished with value: 0.31958347203898757 and parameters: {'model_name': 'VAE', 'batch_size': 289, 'iterations': 4, 'learning_rate': 0.0003786087577456064, 'p_miss': 0.2400696159692676}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:01:41,547] Trial 61 finished with value: 0.32446065674733143 and parameters: {'model_name': 'VAE', 'batch_size': 309, 'iterations': 3, 'learning_rate': 0.00033558687970613896, 'p_miss': 0.24420333383215231}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:02:07,864] Trial 62 finished with value: 0.31537335874276096 and parameters: {'model_name': 'VAE', 'batch_size': 966, 'iterations': 4, 'learning_rate': 0.0002703980846952546, 'p_miss': 0.25496853137934805}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:02:18,106] Trial 63 finished with value: 0.31425598543188554 and parameters: {'model_name': 'VAE', 'batch_size': 363, 'iterations': 2, 'learning_rate': 0.0007936887286290138, 'p_miss': 0.26192031825805084}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:02:24,523] Trial 64 finished with value: 0.3120203071202948 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 1, 'learning_rate': 0.000883326890280974, 'p_miss': 0.2695752702196802}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:02:58,998] Trial 37 finished with value: 0.35215095222027554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:03:05,496] Trial 66 finished with value: 0.31679654195514834 and parameters: {'model_name': 'VAE', 'batch_size': 127, 'iterations': 1, 'learning_rate': 0.0009260927315929682, 'p_miss': 0.27228318461738066}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:03:19,222] Trial 67 finished with value: 0.31221758906738906 and parameters: {'model_name': 'VAE', 'batch_size': 468, 'iterations': 2, 'learning_rate': 0.0008057738872923599, 'p_miss': 0.21495920724488465}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:03:27,246] Trial 68 finished with value: 0.3159072227782144 and parameters: {'model_name': 'VAE', 'batch_size': 521, 'iterations': 1, 'learning_rate': 0.00018882227257556976, 'p_miss': 0.22276602201606102}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:03:36,799] Trial 69 finished with value: 0.3160941398427074 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 2, 'learning_rate': 0.0009483270509953938, 'p_miss': 0.20450243686945696}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:05:22,571] Trial 38 finished with value: 0.3515178177923447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:06:19,960] Trial 71 finished with value: 0.3142355095643724 and parameters: {'model_name': 'VAE', 'batch_size': 525, 'iterations': 11, 'learning_rate': 0.00020237321328403447, 'p_miss': 0.2703880495132836}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:06:43,750] Trial 72 finished with value: 0.31505541333255854 and parameters: {'model_name': 'VAE', 'batch_size': 966, 'iterations': 2, 'learning_rate': 0.0002156671727322944, 'p_miss': 0.1675227820910711}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:12:54,581] Trial 49 finished with value: 0.33556647656743566 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:15:31,704] Trial 43 finished with value: 0.352169044111682 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:16:09,408] Trial 75 finished with value: 0.31538885172287 and parameters: {'model_name': 'VAE', 'batch_size': 195, 'iterations': 6, 'learning_rate': 0.0006917054619126076, 'p_miss': 0.27738959709851757}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:16:18,234] Trial 76 finished with value: 0.3193315036426184 and parameters: {'model_name': 'VAE', 'batch_size': 534, 'iterations': 1, 'learning_rate': 0.0001794002386048726, 'p_miss': 0.27126406672764364}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:16:33,965] Trial 77 finished with value: 0.32003058596225337 and parameters: {'model_name': 'VAE', 'batch_size': 592, 'iterations': 2, 'learning_rate': 0.0001736993193123717, 'p_miss': 0.2804668668944554}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:17:49,253] Trial 78 finished with value: 0.3130149501522782 and parameters: {'model_name': 'VAE', 'batch_size': 509, 'iterations': 17, 'learning_rate': 0.0005246778347610696, 'p_miss': 0.22695859197419094}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:18:07,041] Trial 79 finished with value: 0.329390993862952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2437, 'weights': 'uniform'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:19:01,282] Trial 80 finished with value: 0.5426999096521341 and parameters: {'model_name': 'GAIN', 'batch_size': 613, 'hint_rate': 0.11584161678134292, 'alpha': 93, 'iterations': 24, 'learning_rate': 0.0005551363545164632, 'p_miss': 0.22722281005683612}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:48:52,188] Trial 12 finished with value: 0.3417712207846197 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 1402, 'learning_rate': 0.0003566117171766545, 'p_miss': 0.24397486388967654}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:48:53,114] Trial 82 finished with value: 0.336569395056512 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 17:49:07,942] Trial 83 finished with value: 0.3126251425788317 and parameters: {'model_name': 'VAE', 'batch_size': 364, 'iterations': 2, 'learning_rate': 0.0013358861582321649, 'p_miss': 0.21455583741365022}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:57:06,202] Trial 4 finished with value: 0.3410673967054512 and parameters: {'model_name': 'VAE', 'batch_size': 145, 'iterations': 4541, 'learning_rate': 0.00021693266682705598, 'p_miss': 0.14121478596484194}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:57:43,025] Trial 85 finished with value: 0.31704055744955834 and parameters: {'model_name': 'VAE', 'batch_size': 363, 'iterations': 6, 'learning_rate': 0.0015141401923620362, 'p_miss': 0.20246401367075234}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:57:54,163] Trial 86 finished with value: 0.31952387972224455 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 2, 'learning_rate': 0.001532838867958997, 'p_miss': 0.2239114678979822}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:58:13,451] Trial 87 finished with value: 0.3140701253306956 and parameters: {'model_name': 'VAE', 'batch_size': 679, 'iterations': 2, 'learning_rate': 0.0030455533866632946, 'p_miss': 0.18344926558874297}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:58:21,553] Trial 88 finished with value: 0.3121766000940216 and parameters: {'model_name': 'VAE', 'batch_size': 218, 'iterations': 1, 'learning_rate': 0.0005370746580664345, 'p_miss': 0.2848311047765859}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:58:31,569] Trial 89 finished with value: 0.31458761712000083 and parameters: {'model_name': 'VAE', 'batch_size': 216, 'iterations': 2, 'learning_rate': 0.0005636733344195236, 'p_miss': 0.2610188718121693}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 20:59:07,429] Trial 90 finished with value: 0.31454598355689856 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 7, 'learning_rate': 0.0005175233191216522, 'p_miss': 0.21284545548633216}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:01:11,405] Trial 91 finished with value: 0.3248739221196054 and parameters: {'model_name': 'VAE', 'batch_size': 407, 'iterations': 27, 'learning_rate': 0.002215229425677332, 'p_miss': 0.22775046964513063}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:01:23,030] Trial 92 finished with value: 0.5419011349985959 and parameters: {'model_name': 'GAIN', 'batch_size': 104, 'hint_rate': 0.13192686342964843, 'alpha': 65, 'iterations': 3, 'learning_rate': 0.0013046425677458377, 'p_miss': 0.28259048311113194}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:01:42,029] Trial 93 finished with value: 0.336569395056512 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 34456, 'weights': 'uniform'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:16:23,142] Trial 94 finished with value: 0.34292068682049287 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 203, 'learning_rate': 0.001275586506571212, 'p_miss': 0.2605901030007185}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:16:24,557] Trial 95 finished with value: 0.5471410788198927 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:16:33,576] Trial 96 finished with value: 0.3168794920767365 and parameters: {'model_name': 'VAE', 'batch_size': 743, 'iterations': 1, 'learning_rate': 0.00014237970097811934, 'p_miss': 0.28899036065394756}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:16:40,953] Trial 97 finished with value: 0.3166080983529892 and parameters: {'model_name': 'VAE', 'batch_size': 230, 'iterations': 1, 'learning_rate': 0.0004820303846258667, 'p_miss': 0.2873003915202242}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:16:47,915] Trial 98 finished with value: 0.31415922241836064 and parameters: {'model_name': 'VAE', 'batch_size': 459, 'iterations': 1, 'learning_rate': 0.00026265131749846716, 'p_miss': 0.299428152719212}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:17:02,471] Trial 99 finished with value: 0.3129318660841817 and parameters: {'model_name': 'VAE', 'batch_size': 744, 'iterations': 2, 'learning_rate': 0.000751796947107611, 'p_miss': 0.2355070838241803}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:17:22,115] Trial 100 finished with value: 0.3173463701077553 and parameters: {'model_name': 'VAE', 'batch_size': 719, 'iterations': 3, 'learning_rate': 0.0010415121530768527, 'p_miss': 0.2379402841793117}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:17:37,077] Trial 101 finished with value: 0.3172890343497089 and parameters: {'model_name': 'VAE', 'batch_size': 420, 'iterations': 2, 'learning_rate': 0.0008587905120353718, 'p_miss': 0.18700845450626308}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:47:36,741] Trial 102 finished with value: 0.3391074254754058 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 456, 'learning_rate': 0.0006799165432346914, 'p_miss': 0.21167823776182101}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 21:47:55,541] Trial 103 finished with value: 0.3210619748510535 and parameters: {'model_name': 'VAE', 'batch_size': 241, 'iterations': 4, 'learning_rate': 0.0004592379177127252, 'p_miss': 0.25001413540507506}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:00:21,999] Trial 73 finished with value: 0.3416969478318991 and parameters: {'model_name': 'VAE', 'batch_size': 212, 'iterations': 4422, 'learning_rate': 0.0004958601892081136, 'p_miss': 0.2721640427926336}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:01:31,132] Trial 105 finished with value: 0.31725888487172954 and parameters: {'model_name': 'VAE', 'batch_size': 716, 'iterations': 9, 'learning_rate': 0.00029308237568772904, 'p_miss': 0.1290275326027564}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:01:42,522] Trial 106 finished with value: 0.3136843231378974 and parameters: {'model_name': 'VAE', 'batch_size': 990, 'iterations': 1, 'learning_rate': 0.00013510822573912351, 'p_miss': 0.025852622384017365}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:01:49,922] Trial 107 finished with value: 0.3145990441721192 and parameters: {'model_name': 'VAE', 'batch_size': 787, 'iterations': 1, 'learning_rate': 0.00010472914918321786, 'p_miss': 0.2897773517691551}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:02:01,399] Trial 108 finished with value: 0.31405198036152493 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2, 'learning_rate': 0.0006856909953365176, 'p_miss': 0.2346015784095185}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:02:55,971] Trial 109 finished with value: 0.3225995425109288 and parameters: {'model_name': 'VAE', 'batch_size': 983, 'iterations': 3, 'learning_rate': 0.005853737315828201, 'p_miss': 0.2565122629615072}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:05:08,116] Trial 110 finished with value: 0.31477702752643655 and parameters: {'model_name': 'VAE', 'batch_size': 555, 'iterations': 20, 'learning_rate': 0.0001487965722551886, 'p_miss': 0.2995883186877115}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:07:19,865] Trial 111 finished with value: 0.5467916525554057 and parameters: {'model_name': 'GAIN', 'batch_size': 384, 'hint_rate': 0.3106233695406999, 'alpha': 67, 'iterations': 63, 'learning_rate': 0.00010040576253411868, 'p_miss': 0.04136875807608631}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:07:45,067] Trial 112 finished with value: 0.35290740454610636 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11752, 'weights': 'distance'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:08:43,283] Trial 113 finished with value: 0.342076270884624 and parameters: {'model_name': 'VAE', 'batch_size': 730, 'iterations': 4, 'learning_rate': 0.023924250795186584, 'p_miss': 0.2653125762491165}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:08:44,780] Trial 114 finished with value: 0.3804360336110601 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:08:56,134] Trial 115 finished with value: 0.3182172830111423 and parameters: {'model_name': 'VAE', 'batch_size': 298, 'iterations': 1, 'learning_rate': 0.0011121091743994764, 'p_miss': 0.24721693233119485}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:09:05,395] Trial 116 finished with value: 0.3168630584570643 and parameters: {'model_name': 'VAE', 'batch_size': 950, 'iterations': 1, 'learning_rate': 0.00014093073986929533, 'p_miss': 0.08883402164705326}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:09:14,429] Trial 117 finished with value: 0.3175403745534758 and parameters: {'model_name': 'VAE', 'batch_size': 971, 'iterations': 1, 'learning_rate': 0.00012950746707487165, 'p_miss': 0.15465287293103744}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:09:37,558] Trial 118 finished with value: 0.31261175338687563 and parameters: {'model_name': 'VAE', 'batch_size': 569, 'iterations': 3, 'learning_rate': 0.0003903831961870867, 'p_miss': 0.28851559193610776}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:09:56,391] Trial 119 finished with value: 0.313219944707691 and parameters: {'model_name': 'VAE', 'batch_size': 493, 'iterations': 3, 'learning_rate': 0.0003871720686763712, 'p_miss': 0.28989867129211616}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:10:16,278] Trial 120 finished with value: 0.3180655783499854 and parameters: {'model_name': 'VAE', 'batch_size': 517, 'iterations': 3, 'learning_rate': 0.00035642603302244553, 'p_miss': 0.27915143972477074}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:10:34,211] Trial 121 finished with value: 0.31648413858698843 and parameters: {'model_name': 'VAE', 'batch_size': 447, 'iterations': 3, 'learning_rate': 0.0004242864777674961, 'p_miss': 0.2846936374153919}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:11:05,261] Trial 122 finished with value: 0.31405517029057944 and parameters: {'model_name': 'VAE', 'batch_size': 586, 'iterations': 5, 'learning_rate': 0.00027370968786618406, 'p_miss': 0.2904519123743341}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:11:16,392] Trial 123 finished with value: 0.31339503468924496 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 2, 'learning_rate': 0.0006615143021405955, 'p_miss': 0.27257030227684903}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:12:02,471] Trial 124 finished with value: 0.31595622573933135 and parameters: {'model_name': 'VAE', 'batch_size': 290, 'iterations': 9, 'learning_rate': 0.000818833347613381, 'p_miss': 0.23530081207270157}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:12:35,525] Trial 125 finished with value: 0.31393948974066854 and parameters: {'model_name': 'VAE', 'batch_size': 606, 'iterations': 5, 'learning_rate': 0.0002315917142952504, 'p_miss': 0.21647837780046225}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:12:48,964] Trial 126 finished with value: 0.3141491197102587 and parameters: {'model_name': 'VAE', 'batch_size': 817, 'iterations': 2, 'learning_rate': 0.00039733957074086394, 'p_miss': 0.2963897944303039}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:13:06,697] Trial 127 finished with value: 0.31744762084154987 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0005967669796095369, 'p_miss': 0.27658779592081617}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:15:00,289] Trial 128 finished with value: 0.3132591558619944 and parameters: {'model_name': 'VAE', 'batch_size': 366, 'iterations': 15, 'learning_rate': 0.0003274925973596882, 'p_miss': 0.29305820527638715}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:15:04,373] Trial 65 finished with value: 0.34009429639254163 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 4979, 'learning_rate': 0.00020399037364736904, 'p_miss': 0.21673055380060108}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:16:26,780] Trial 129 finished with value: 0.313342378482101 and parameters: {'model_name': 'VAE', 'batch_size': 352, 'iterations': 14, 'learning_rate': 0.0003205379090815444, 'p_miss': 0.26666455559366}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:18:16,235] Trial 130 finished with value: 0.31412480682333677 and parameters: {'model_name': 'VAE', 'batch_size': 362, 'iterations': 44, 'learning_rate': 0.0003295092869567443, 'p_miss': 0.26572499381861014}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:19:58,430] Trial 131 finished with value: 0.3146818975960889 and parameters: {'model_name': 'VAE', 'batch_size': 470, 'iterations': 48, 'learning_rate': 0.000441008213341568, 'p_miss': 0.2844460887787185}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:20:40,357] Trial 133 finished with value: 0.5442477690738838 and parameters: {'model_name': 'GAIN', 'batch_size': 639, 'hint_rate': 0.9788584195451533, 'alpha': 31, 'iterations': 18, 'learning_rate': 0.0007815987667086823, 'p_miss': 0.2893260409873635}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:21:01,498] Trial 134 finished with value: 0.3322090166382266 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12060, 'weights': 'uniform'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:21:13,397] Trial 135 finished with value: 0.3170625911754991 and parameters: {'model_name': 'VAE', 'batch_size': 273, 'iterations': 2, 'learning_rate': 0.0005668018313713407, 'p_miss': 0.278583991989158}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:21:43,131] Trial 132 finished with value: 0.31546543639397057 and parameters: {'model_name': 'VAE', 'batch_size': 460, 'iterations': 43, 'learning_rate': 0.00043374992936058424, 'p_miss': 0.2910588021134539}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:22:14,998] Trial 136 finished with value: 0.3169993925208708 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 12, 'learning_rate': 0.00023643661000345118, 'p_miss': 0.25233920468584686}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:23:01,459] Trial 137 finished with value: 0.3145275564291681 and parameters: {'model_name': 'VAE', 'batch_size': 189, 'iterations': 14, 'learning_rate': 0.00030263580033961944, 'p_miss': 0.2510949923523534}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:24:24,420] Trial 139 finished with value: 0.3152901708437816 and parameters: {'model_name': 'VAE', 'batch_size': 349, 'iterations': 17, 'learning_rate': 0.0001754502723973021, 'p_miss': 0.2677208861307353}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:24:25,240] Trial 140 finished with value: 0.336569395056512 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:24:35,980] Trial 81 finished with value: 0.3423333280659792 and parameters: {'model_name': 'VAE', 'batch_size': 370, 'iterations': 3924, 'learning_rate': 0.0020316362293155477, 'p_miss': 0.22291518379812986}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:27:53,822] Trial 141 finished with value: 0.3133563917280613 and parameters: {'model_name': 'VAE', 'batch_size': 625, 'iterations': 26, 'learning_rate': 0.0003497719740056084, 'p_miss': 0.20236551963991767}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:28:26,163] Trial 143 finished with value: 0.3199923409421591 and parameters: {'model_name': 'VAE', 'batch_size': 252, 'iterations': 7, 'learning_rate': 0.0010650550696200258, 'p_miss': 0.2418159562719417}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:28:55,508] Trial 144 finished with value: 0.31608633022081545 and parameters: {'model_name': 'VAE', 'batch_size': 819, 'iterations': 4, 'learning_rate': 0.0017313118417955783, 'p_miss': 0.2312354032238464}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:31:37,769] Trial 145 finished with value: 0.3156691550178635 and parameters: {'model_name': 'VAE', 'batch_size': 513, 'iterations': 36, 'learning_rate': 0.0005378386874841019, 'p_miss': 0.2594476352819045}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:31:40,235] Trial 142 finished with value: 0.31540916575256805 and parameters: {'model_name': 'VAE', 'batch_size': 255, 'iterations': 98, 'learning_rate': 0.0003862136600602746, 'p_miss': 0.20145947781357554}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:31:46,341] Trial 138 finished with value: 0.31695720721049503 and parameters: {'model_name': 'VAE', 'batch_size': 354, 'iterations': 111, 'learning_rate': 0.00030509766813361896, 'p_miss': 0.26286244169425327}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:32:10,465] Trial 148 finished with value: 0.31341687146577357 and parameters: {'model_name': 'VAE', 'batch_size': 636, 'iterations': 5, 'learning_rate': 0.0002553807763490781, 'p_miss': 0.29517043705666834}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:33:47,848] Trial 147 finished with value: 0.31481261356877643 and parameters: {'model_name': 'VAE', 'batch_size': 673, 'iterations': 21, 'learning_rate': 0.0003184069093459972, 'p_miss': 0.19225269591347918}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:35:02,471] Trial 149 finished with value: 0.3129881928729702 and parameters: {'model_name': 'VAE', 'batch_size': 752, 'iterations': 28, 'learning_rate': 0.00036731695310607645, 'p_miss': 0.20621074392973213}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:36:29,680] Trial 150 finished with value: 0.31614931468387886 and parameters: {'model_name': 'VAE', 'batch_size': 423, 'iterations': 31, 'learning_rate': 0.0007690564947286622, 'p_miss': 0.2231986848815155}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:36:32,732] Trial 151 finished with value: 0.3162344416313208 and parameters: {'model_name': 'VAE', 'batch_size': 779, 'iterations': 15, 'learning_rate': 0.0007259677639484312, 'p_miss': 0.17698001924958878}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:37:55,628] Trial 153 finished with value: 0.3176031392703759 and parameters: {'model_name': 'VAE', 'batch_size': 513, 'iterations': 10, 'learning_rate': 0.0027478820808785544, 'p_miss': 0.2819879326302937}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:38:29,759] Trial 152 finished with value: 0.32193194480162435 and parameters: {'model_name': 'VAE', 'batch_size': 844, 'iterations': 13, 'learning_rate': 0.002625844920178247, 'p_miss': 0.27513178036703173}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:38:30,559] Trial 154 finished with value: 0.3139149273006292 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 7, 'learning_rate': 0.0009253361308897642, 'p_miss': 0.20768172262698392}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:39:13,238] Trial 155 finished with value: 0.31458464624383026 and parameters: {'model_name': 'VAE', 'batch_size': 329, 'iterations': 8, 'learning_rate': 0.0009298715216762416, 'p_miss': 0.20761674677382125}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:40:02,529] Trial 146 finished with value: 0.31820890289207016 and parameters: {'model_name': 'VAE', 'batch_size': 749, 'iterations': 92, 'learning_rate': 0.00037879497408810196, 'p_miss': 0.2000707674442148}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:41:06,583] Trial 156 finished with value: 0.3146280671755178 and parameters: {'model_name': 'VAE', 'batch_size': 579, 'iterations': 26, 'learning_rate': 0.0004971273823257899, 'p_miss': 0.19654904130360185}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:42:21,681] Trial 158 finished with value: 0.3148164008654092 and parameters: {'model_name': 'VAE', 'batch_size': 552, 'iterations': 21, 'learning_rate': 0.0006094690605397966, 'p_miss': 0.21747294879489212}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:42:24,673] Trial 157 finished with value: 0.3176257618650123 and parameters: {'model_name': 'VAE', 'batch_size': 674, 'iterations': 28, 'learning_rate': 0.0005038489761398903, 'p_miss': 0.19708968351373346}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:42:55,364] Trial 161 finished with value: 0.3528936280074918 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25933, 'weights': 'distance'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:43:17,408] Trial 159 finished with value: 0.31648349199877734 and parameters: {'model_name': 'VAE', 'batch_size': 411, 'iterations': 23, 'learning_rate': 0.00021440169661386254, 'p_miss': 0.2948647721641927}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:43:32,387] Trial 160 finished with value: 0.3189036645160178 and parameters: {'model_name': 'VAE', 'batch_size': 393, 'iterations': 14, 'learning_rate': 0.0001952019193311607, 'p_miss': 0.23084554902418775}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:43:56,382] Trial 163 finished with value: 0.5412859878756713 and parameters: {'model_name': 'GAIN', 'batch_size': 814, 'hint_rate': 0.33909477123442755, 'alpha': 71, 'iterations': 16, 'learning_rate': 0.08199725843495775, 'p_miss': 0.24199598134388414}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:43:57,168] Trial 165 finished with value: 0.336569395056512 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:45:57,029] Trial 164 finished with value: 0.5443505804569614 and parameters: {'model_name': 'GAIN', 'batch_size': 839, 'hint_rate': 0.3043985677338905, 'alpha': 77, 'iterations': 66, 'learning_rate': 0.00015815751666238778, 'p_miss': 0.24324978453162846}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:46:41,702] Trial 167 finished with value: 0.31262476690912844 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 11, 'learning_rate': 0.00012429197711450772, 'p_miss': 0.29294789247896985}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:47:14,937] Trial 166 finished with value: 0.31598291883050805 and parameters: {'model_name': 'VAE', 'batch_size': 886, 'iterations': 34, 'learning_rate': 0.00012277212816906872, 'p_miss': 0.2998911389936447}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:47:18,784] Trial 168 finished with value: 0.31659592685389126 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 10, 'learning_rate': 0.00032843056458890736, 'p_miss': 0.28478640741728933}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:48:38,283] Trial 169 finished with value: 0.3241598710317861 and parameters: {'model_name': 'VAE', 'batch_size': 455, 'iterations': 12, 'learning_rate': 0.004036489034785491, 'p_miss': 0.2839505614278766}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:49:15,729] Trial 171 finished with value: 0.313320099492555 and parameters: {'model_name': 'VAE', 'batch_size': 307, 'iterations': 6, 'learning_rate': 0.0012239522579813283, 'p_miss': 0.2177471939867342}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 22:49:40,821] Trial 172 finished with value: 0.31449798037415305 and parameters: {'model_name': 'VAE', 'batch_size': 121, 'iterations': 4, 'learning_rate': 0.0011607719376119864, 'p_miss': 0.2924246068454554}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:26:16,686] Trial 31 finished with value: 0.34205730388014666 and parameters: {'model_name': 'VAE', 'batch_size': 971, 'iterations': 4557, 'learning_rate': 0.00010075460392645219, 'p_miss': 0.27907452511592057}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:26:48,473] Trial 174 finished with value: 0.3206557332702048 and parameters: {'model_name': 'VAE', 'batch_size': 220, 'iterations': 6, 'learning_rate': 0.0001145066408042378, 'p_miss': 0.2701406160280591}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:27:31,990] Trial 74 finished with value: 0.3411138560202103 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 5467, 'learning_rate': 0.0006485343200688093, 'p_miss': 0.27604892877786597}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:28:27,398] Trial 175 finished with value: 0.31381353032992376 and parameters: {'model_name': 'VAE', 'batch_size': 291, 'iterations': 17, 'learning_rate': 0.0012423519810302432, 'p_miss': 0.22223973780929096}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:29:06,074] Trial 176 finished with value: 0.3172447976404966 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 16, 'learning_rate': 0.00039401545289315505, 'p_miss': 0.21606004978173646}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:29:43,158] Trial 177 finished with value: 0.314436690984178 and parameters: {'model_name': 'VAE', 'batch_size': 642, 'iterations': 11, 'learning_rate': 0.0015599232915418878, 'p_miss': 0.215064415594021}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:29:53,205] Trial 178 finished with value: 0.3163522225762908 and parameters: {'model_name': 'VAE', 'batch_size': 617, 'iterations': 8, 'learning_rate': 0.0014232207778052007, 'p_miss': 0.2097238984210305}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:29:55,491] Trial 179 finished with value: 0.31486234524105305 and parameters: {'model_name': 'VAE', 'batch_size': 492, 'iterations': 2, 'learning_rate': 0.00044410335458143735, 'p_miss': 0.20886385867438265}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:07,158] Trial 180 finished with value: 0.31315616706850746 and parameters: {'model_name': 'VAE', 'batch_size': 502, 'iterations': 2, 'learning_rate': 0.00045435070010485523, 'p_miss': 0.2894076401051661}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:14,758] Trial 181 finished with value: 0.312848524897669 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5, 'learning_rate': 0.00028020279420356767, 'p_miss': 0.28884269012646896}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:24,646] Trial 182 finished with value: 0.3138317098033494 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 3, 'learning_rate': 0.00026542182719843367, 'p_miss': 0.28903788932079216}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:35,440] Trial 183 finished with value: 0.31554405197688423 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 5, 'learning_rate': 0.0006040983527761931, 'p_miss': 0.2859870386958079}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:46,099] Trial 184 finished with value: 0.31701831301662176 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 5, 'learning_rate': 0.0006234363920189796, 'p_miss': 0.2944338975371654}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:48,984] Trial 185 finished with value: 0.3123427547167363 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 3, 'learning_rate': 0.00016474606795756713, 'p_miss': 0.292413499068318}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:30:57,997] Trial 186 finished with value: 0.31324226105602965 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.00015588482480553275, 'p_miss': 0.27928724425554563}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:03,338] Trial 187 finished with value: 0.3140149372197988 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.00017499739060740138, 'p_miss': 0.2792704020141118}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:12,316] Trial 188 finished with value: 0.3165084091768891 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 3, 'learning_rate': 0.00015454792526347944, 'p_miss': 0.28175032558727775}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:28,078] Trial 190 finished with value: 0.3226252005471386 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4, 'learning_rate': 0.0001267393152206292, 'p_miss': 0.2935646528138396}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:37,567] Trial 191 finished with value: 0.31587384217039877 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.0004650013461318125, 'p_miss': 0.27433243932117035}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:44,118] Trial 192 finished with value: 0.31608610892187095 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 1, 'learning_rate': 0.00011676021130492236, 'p_miss': 0.2985035950500874}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:31:52,831] Trial 193 finished with value: 0.3140461713687 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.0002170542395699688, 'p_miss': 0.2875258656054339}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:32:08,430] Trial 194 finished with value: 0.3142018897222914 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 3, 'learning_rate': 0.0001549536498479468, 'p_miss': 0.2915410295756032}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:32:28,436] Trial 195 finished with value: 0.3318834512929963 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10545, 'weights': 'uniform'}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:32:48,308] Trial 196 finished with value: 0.3173064417246426 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.00013965208313573705, 'p_miss': 0.29895401421937184}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:33:08,976] Trial 197 finished with value: 0.3159318020270854 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 6, 'learning_rate': 0.00025596060940203373, 'p_miss': 0.22928671691721786}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:33:32,275] Trial 198 finished with value: 0.3186556503563428 and parameters: {'model_name': 'VAE', 'batch_size': 999, 'iterations': 4, 'learning_rate': 0.000878518754028729, 'p_miss': 0.27816562596225863}. Best is trial 58 with value: 0.31191509219645297.
running
[I 2024-11-22 23:33:40,435] Trial 199 finished with value: 0.3143661991221957 and parameters: {'model_name': 'VAE', 'batch_size': 714, 'iterations': 1, 'learning_rate': 0.000362862466808102, 'p_miss': 0.2884025018842236}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 00:01:34,085] Trial 30 finished with value: 0.3423467178765788 and parameters: {'model_name': 'VAE', 'batch_size': 726, 'iterations': 6295, 'learning_rate': 0.00011695483954338538, 'p_miss': 0.28376861057318936}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 01:17:14,413] Trial 29 finished with value: 0.3422009268484595 and parameters: {'model_name': 'VAE', 'batch_size': 816, 'iterations': 5142, 'learning_rate': 0.00014979996867742632, 'p_miss': 0.28971468614184603}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 01:22:48,838] Trial 170 finished with value: 0.342348517441481 and parameters: {'model_name': 'VAE', 'batch_size': 495, 'iterations': 2118, 'learning_rate': 0.00043513884172054044, 'p_miss': 0.29217465311078883}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 01:42:04,326] Trial 70 finished with value: 0.34219568861526767 and parameters: {'model_name': 'VAE', 'batch_size': 919, 'iterations': 5811, 'learning_rate': 0.00019953040162237564, 'p_miss': 0.27422811587264234}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 02:19:04,415] Trial 34 finished with value: 0.34242179999701594 and parameters: {'model_name': 'VAE', 'batch_size': 646, 'iterations': 9515, 'learning_rate': 0.0001256472491710287, 'p_miss': 0.2990639367502926}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 02:43:27,286] Trial 162 finished with value: 0.5463575141555697 and parameters: {'model_name': 'GAIN', 'batch_size': 425, 'hint_rate': 0.3359573182230041, 'alpha': 77, 'iterations': 9426, 'learning_rate': 0.00020906142718994975, 'p_miss': 0.24287944351091223}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 02:53:16,874] Trial 32 finished with value: 0.34155507752098496 and parameters: {'model_name': 'VAE', 'batch_size': 391, 'iterations': 8686, 'learning_rate': 0.09349165487492525, 'p_miss': 0.2849964140322876}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:01:02,162] Trial 25 finished with value: 0.3426303862598816 and parameters: {'model_name': 'VAE', 'batch_size': 815, 'iterations': 8286, 'learning_rate': 0.00013540769964052172, 'p_miss': 0.2807312471249209}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:07:11,495] Trial 84 finished with value: 0.34209425153151 and parameters: {'model_name': 'VAE', 'batch_size': 248, 'iterations': 9807, 'learning_rate': 0.001777326742445879, 'p_miss': 0.2027066217917246}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:09:55,987] Trial 27 finished with value: 0.34214859171234885 and parameters: {'model_name': 'VAE', 'batch_size': 626, 'iterations': 9070, 'learning_rate': 0.00014249171493539473, 'p_miss': 0.2768743994779163}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:10:14,619] Trial 26 finished with value: 0.3416074755164013 and parameters: {'model_name': 'VAE', 'batch_size': 747, 'iterations': 9178, 'learning_rate': 0.00013908371994708534, 'p_miss': 0.2902035232249946}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:23:36,330] Trial 28 finished with value: 0.3422732614529828 and parameters: {'model_name': 'VAE', 'batch_size': 954, 'iterations': 8216, 'learning_rate': 0.0001490988528539802, 'p_miss': 0.2837625443081619}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:29:27,353] Trial 189 finished with value: 0.3414876445765239 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 9775, 'learning_rate': 0.0001504854720582534, 'p_miss': 0.29253780643058686}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:32:12,793] Trial 173 finished with value: 0.34263465986191455 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 8695, 'learning_rate': 0.0006340163353333591, 'p_miss': 0.21532298206689648}. Best is trial 58 with value: 0.31191509219645297.
[I 2024-11-23 03:33:09,797] Trial 104 finished with value: 0.3420892975076792 and parameters: {'model_name': 'VAE', 'batch_size': 1000, 'iterations': 7569, 'learning_rate': 0.0040864801121013134, 'p_miss': 0.2363354939252453}. Best is trial 58 with value: 0.31191509219645297.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.31191509219645297
{'model_name': 'VAE', 'batch_size': 986, 'iterations': 1, 'learning_rate': 0.0002644470300838604, 'p_miss': 0.24910545901240724}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.39724090091448716
Generation:   4%|         | 1/25 [01:46<42:38, 106.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474712230> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.39724090091448716
Generation:   8%|         | 2/25 [05:40<1:09:39, 181.73s/it]Generation:  3
Best f1_score score: 0.4004784738073918
Generation:  12%|        | 3/25 [09:04<1:10:13, 191.51s/it]Generation:  4
Best f1_score score: 0.4004784738073918
Generation:  16%|        | 4/25 [15:00<1:29:48, 256.57s/it]Generation:  5
Best f1_score score: 0.4004784738073918
Generation:  20%|        | 5/25 [16:46<1:07:29, 202.49s/it]Generation:  6
Best f1_score score: 0.4004784738073918
Generation:  24%|       | 6/25 [22:10<1:17:10, 243.71s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465d450> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.4004784738073918
Generation:  28%|       | 7/25 [25:08<1:06:41, 222.32s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e3aa10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.4031880430168872
Generation:  32%|      | 8/25 [29:05<1:04:16, 226.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e303a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.4031880430168872
Generation:  36%|      | 9/25 [32:05<56:33, 212.10s/it]  Generation:  10
Best f1_score score: 0.4031880430168872
Generation:  40%|      | 10/25 [34:51<49:29, 197.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f3ffd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b98dc0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.4034334448635321
Generation:  44%|     | 11/25 [42:03<1:02:54, 269.57s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f03640> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.4034334448635321
Generation:  48%|     | 12/25 [45:22<53:45, 248.09s/it]  Generation:  13
Best f1_score score: 0.4034334448635321
Generation:  52%|    | 13/25 [48:16<45:09, 225.79s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.4034334448635321
Generation:  56%|    | 14/25 [51:38<40:04, 218.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f42290> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.4034334448635321
Generation:  60%|    | 15/25 [55:45<37:49, 226.92s/it]Generation:  16
Best f1_score score: 0.4034334448635321
Generation:  64%|   | 16/25 [1:00:52<37:40, 251.17s/it]Generation:  17
Best f1_score score: 0.4034334448635321
Generation:  68%|   | 17/25 [1:05:31<34:37, 259.65s/it]Generation:  18
Best f1_score score: 0.4034334448635321
Generation:  72%|  | 18/25 [1:10:47<32:15, 276.50s/it]Generation:  19
Best f1_score score: 0.4034334448635321
Generation:  76%|  | 19/25 [1:13:07<23:33, 235.51s/it]Generation:  20
Best f1_score score: 0.4034334448635321
Generation:  80%|  | 20/25 [1:16:08<18:15, 219.12s/it]Generation:  21
Best f1_score score: 0.4034334448635321
Generation:  84%| | 21/25 [1:18:37<13:12, 198.01s/it]Generation:  22
Best f1_score score: 0.4034334448635321
Generation:  88%| | 22/25 [1:21:38<09:38, 192.79s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f02320> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.4034334448635321
Generation:  92%|| 23/25 [1:23:59<05:54, 177.33s/it]Generation:  24
Best f1_score score: 0.4034334448635321
Generation:  96%|| 24/25 [1:31:13<04:14, 254.31s/it]Generation:  25
Best f1_score score: 0.4034334448635321
Generation: 100%|| 25/25 [1:32:56<00:00, 209.12s/it]Generation: 100%|| 25/25 [1:32:59<00:00, 223.19s/it]
2024-11-23 05:06:25,459 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42295' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0', 'ndarray-83ad7a73d2525f62d6fa31a2320f2a58'} (stimulus_id='handle-worker-cleanup-1732367185.4591193')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.2455276018927,
                                        min_samples_leaf=15,
                                        min_samples_split=6,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.848434411627014, 'accuracy': 0.6889694603263143, 'balanced_accuracy': 0.7443270897340776, 'logloss': 0.8755852523748426, 'f1': 0.6822525723379692}
original test score: {'auroc': 0.5574806511746148, 'accuracy': 0.428603302097278, 'balanced_accuracy': 0.3539178572774593, 'logloss': 1.02351713723677, 'f1': 0.3184354218686517}
imputed test score: {'auroc': 0.480137271909914, 'accuracy': 0.3885542168674699, 'balanced_accuracy': 0.3186490770465244, 'logloss': 1.0553153420708015, 'f1': 0.31704624455812463}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1270> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.47377456766671033
Generation:   4%|         | 1/25 [04:43<1:53:26, 283.59s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655fdfc0> 

Generation:  2
Best f1_score score: 0.5721543718305004
Generation:   8%|         | 2/25 [14:47<3:00:57, 472.07s/it]Generation:  3
Best f1_score score: 0.6063793688480219
Generation:  12%|        | 3/25 [20:29<2:31:15, 412.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474718160> 

Generation:  4
Best f1_score score: 0.6063793688480219
Generation:  16%|        | 4/25 [30:33<2:50:55, 488.37s/it]Generation:  5
Best f1_score score: 0.6063793688480219
Generation:  20%|        | 5/25 [35:15<2:17:54, 413.73s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15548648b130> 

Generation:  6
Best f1_score score: 0.6063793688480219
Generation:  24%|       | 6/25 [45:19<2:31:33, 478.58s/it]Generation:  7
Best f1_score score: 0.6069881863183236
Generation:  28%|       | 7/25 [50:52<2:09:13, 430.74s/it]Generation:  8
Best f1_score score: 0.6069881863183236
Generation:  32%|      | 8/25 [56:22<1:53:02, 398.97s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467617bb0> 

Generation:  9
Best f1_score score: 0.6084470731871441
Generation:  36%|      | 9/25 [1:06:29<2:03:43, 464.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467647010> 

Generation:  10
Best f1_score score: 0.6084470731871441
Generation:  40%|      | 10/25 [1:16:35<2:06:56, 507.79s/it]Generation:  11
Best f1_score score: 0.6084470731871441
Generation:  44%|     | 11/25 [1:21:27<1:43:03, 441.67s/it]Generation:  12
Best f1_score score: 0.6084470731871441
Generation:  48%|     | 12/25 [1:26:15<1:25:34, 394.92s/it]Generation:  13
Best f1_score score: 0.6089689922072041
Generation:  52%|    | 13/25 [1:31:47<1:15:09, 375.82s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658cbe20> 

Generation:  14
Best f1_score score: 0.6089689922072041
Generation:  56%|    | 14/25 [1:41:55<1:21:45, 445.97s/it]Generation:  15
Best f1_score score: 0.6089689922072041
Generation:  60%|    | 15/25 [1:46:41<1:06:16, 397.66s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464a12200> 

Generation:  16
Best f1_score score: 0.6089689922072041
Generation:  64%|   | 16/25 [1:56:46<1:09:02, 460.29s/it]Generation:  17
Best f1_score score: 0.610482961695546
Generation:  68%|   | 17/25 [2:00:41<52:20, 392.53s/it]  Generation:  18
Best f1_score score: 0.610482961695546
Generation:  72%|  | 18/25 [2:02:24<35:38, 305.54s/it]Generation:  19
Best f1_score score: 0.610482961695546
Generation:  76%|  | 19/25 [2:06:59<29:36, 296.17s/it]Generation:  20
Best f1_score score: 0.610482961695546
Generation:  80%|  | 20/25 [2:12:10<25:04, 300.81s/it]Generation:  21
Best f1_score score: 0.610482961695546
Generation:  84%| | 21/25 [2:16:46<19:33, 293.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3d90> 

Generation:  22
Best f1_score score: 0.610482961695546
Generation:  88%| | 22/25 [2:26:55<19:24, 388.05s/it]Generation:  23
Best f1_score score: 0.610482961695546
Generation:  92%|| 23/25 [2:28:50<10:12, 306.06s/it]Generation:  24
Best f1_score score: 0.610482961695546
Generation:  96%|| 24/25 [2:29:59<03:54, 234.78s/it]Generation:  25
Best f1_score score: 0.610482961695546
Generation: 100%|| 25/25 [2:34:37<00:00, 247.87s/it]Generation: 100%|| 25/25 [2:34:37<00:00, 371.10s/it]
2024-11-23 07:41:15,864 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36093' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0', 'DataFrame-30f0fbc16303f3a872f112b89db62a5a'} (stimulus_id='handle-worker-cleanup-1732376475.864682')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=7,
                                n_estimators=96, n_jobs=1, num_leaves=197,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8924112137278634, 'accuracy': 0.693766559754567, 'balanced_accuracy': 0.7363741221647743, 'logloss': 0.638147187216297, 'f1': 0.6502833227216932}
test score: {'auroc': 0.8553331614187548, 'accuracy': 0.6514948683623383, 'balanced_accuracy': 0.6700925629580605, 'logloss': 0.7067712468194971, 'f1': 0.6023865244653256}
original test score: {'auroc': 0.9608343010463032, 'accuracy': 0.8247434181169121, 'balanced_accuracy': 0.8536903984264127, 'logloss': 0.3817104183415402, 'f1': 0.786994773607399}
score end
41027
lvl
0.3
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
15.316547691755824
hours
DONE
