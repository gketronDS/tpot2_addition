Run: 36
/cm/local/apps/slurm/var/spool/job1047535/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1481/1481.pkl
working on 
../data/c/1481/class_full_MNAR_0.5_2
4.122320175170898
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-13 13:07:02,040] A new study created in memory with name: no-name-4100a57f-f77a-4a28-985f-d21dbfbf2e92
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-13 13:07:02,519] Trial 1 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 1 with value: 0.43269985213476964.
running
[I 2024-11-13 13:07:09,423] Trial 16 finished with value: 0.24174735132334266 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.002797453667921806, 'p_miss': 0.1910466757419753}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:10,001] Trial 17 finished with value: 0.29047129448028475 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:10,825] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.6354145597262041, 'alpha': 10, 'iterations': 1, 'learning_rate': 0.04832258151874011, 'p_miss': 0.15878372150016432}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:12,495] Trial 0 finished with value: 0.24276854243869064 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.00011318926251696749, 'p_miss': 0.13619420246341488}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:14,057] Trial 10 finished with value: 0.4333335427492863 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.15540726546845343, 'alpha': 36, 'iterations': 4, 'learning_rate': 0.005517597736157151, 'p_miss': 0.22481683559533494}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:16,607] Trial 21 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8708722790636716, 'alpha': 77, 'iterations': 17, 'learning_rate': 0.06494255273861249, 'p_miss': 0.09663829993242085}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:17,162] Trial 7 finished with value: 0.2900938687422151 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8695, 'weights': 'uniform'}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:20,183] Trial 9 finished with value: 0.30352364815123545 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5552, 'weights': 'distance'}. Best is trial 16 with value: 0.24174735132334266.
running
[I 2024-11-13 13:07:26,732] Trial 2 finished with value: 0.24140027688206017 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 11, 'learning_rate': 0.002988488399454788, 'p_miss': 0.29601225957643434}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:07:31,555] Trial 6 finished with value: 0.2994926064012885 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 23, 'learning_rate': 0.02081516839459498, 'p_miss': 0.287052676949828}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:07:34,507] Trial 14 finished with value: 0.28582111534709503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:07:37,073] Trial 24 finished with value: 0.3034772610819955 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3593, 'weights': 'distance'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:07:39,283] Trial 23 finished with value: 0.3035968945178286 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13536, 'weights': 'distance'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:07:52,353] Trial 5 finished with value: 0.29842379158759347 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:08:01,283] Trial 22 finished with value: 0.3052682447352061 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:08:05,203] Trial 25 finished with value: 0.3122353838069508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:08:09,890] Trial 26 finished with value: 0.2995156599540679 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:11:02,196] Trial 18 finished with value: 0.43005306442950336 and parameters: {'model_name': 'GAIN', 'batch_size': 317, 'hint_rate': 0.2812226342840844, 'alpha': 15, 'iterations': 142, 'learning_rate': 0.0009030057495452738, 'p_miss': 0.23457237579998366}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:11:37,375] Trial 12 finished with value: 0.43614385858903837 and parameters: {'model_name': 'GAIN', 'batch_size': 130, 'hint_rate': 0.1327695683640273, 'alpha': 45, 'iterations': 172, 'learning_rate': 0.0058939398097174025, 'p_miss': 0.20944682805816212}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:18:55,119] Trial 3 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.4118609343203454, 'alpha': 20, 'iterations': 2386, 'learning_rate': 0.0002528605137011331, 'p_miss': 0.22938405133769568}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:19:00,673] Trial 36 finished with value: 0.24291908372402532 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 1, 'learning_rate': 0.00015400542433398486, 'p_miss': 0.07995115385435256}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:19:26,066] Trial 37 finished with value: 0.2437023269232487 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 5, 'learning_rate': 0.0012419028965652166, 'p_miss': 0.14562088289135736}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:19:36,579] Trial 38 finished with value: 0.2455491952883923 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0014173898690099814, 'p_miss': 0.1563352706205542}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:20:35,801] Trial 39 finished with value: 0.24587337639391996 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 18, 'learning_rate': 0.00045493833881300283, 'p_miss': 0.2956576994373299}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:20:45,663] Trial 40 finished with value: 0.2428429884513891 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 1, 'learning_rate': 0.003031167568139498, 'p_miss': 0.042238904916656855}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:21:04,262] Trial 41 finished with value: 0.2551948316375885 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.015665220335354915, 'p_miss': 0.11464184049428404}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:22:15,068] Trial 13 finished with value: 0.2863016984699953 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:22:44,998] Trial 42 finished with value: 0.24758203576934715 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 37, 'learning_rate': 0.0025071851713573735, 'p_miss': 0.17422824810127407}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:22:45,873] Trial 44 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:22:53,952] Trial 45 finished with value: 0.2468126145970313 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 2, 'learning_rate': 0.00010434444735120505, 'p_miss': 0.2663879896575463}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:23:00,601] Trial 46 finished with value: 0.24270263724351088 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 1, 'learning_rate': 0.0038368348459084695, 'p_miss': 0.02544910369216874}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:23:45,008] Trial 47 finished with value: 0.26240670238805597 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 9, 'learning_rate': 0.00784826226595682, 'p_miss': 0.029042610019899995}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:23:51,357] Trial 48 finished with value: 0.24298495554120692 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 1, 'learning_rate': 0.0005536629756336198, 'p_miss': 0.056535419496388614}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:24:00,279] Trial 49 finished with value: 0.24751347115023803 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.0029300665175345094, 'p_miss': 0.010515765759641582}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:24:25,511] Trial 50 finished with value: 0.2534416083102372 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 8, 'learning_rate': 0.014738326873065356, 'p_miss': 0.19323148517051747}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:24:26,141] Trial 51 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:24:35,374] Trial 52 finished with value: 0.24327285897214584 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 2, 'learning_rate': 0.0018426011442898129, 'p_miss': 0.11974465641608095}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:25:02,658] Trial 43 finished with value: 0.256329053204513 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 52, 'learning_rate': 0.0033286277040026086, 'p_miss': 0.18650701381424195}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:27:14,468] Trial 28 finished with value: 0.29271496368638295 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 320, 'learning_rate': 0.0009703103217335942, 'p_miss': 0.2871565961270742}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:27:27,672] Trial 8 finished with value: 0.28686854759646974 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:27:34,366] Trial 56 finished with value: 0.24222755352157513 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 1, 'learning_rate': 0.004217287623214071, 'p_miss': 0.04341574944675525}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:27:39,513] Trial 57 finished with value: 0.2453305468179472 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 1, 'learning_rate': 0.009034230444608342, 'p_miss': 0.062057501286867336}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:27:50,819] Trial 58 finished with value: 0.242856275731957 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 2, 'learning_rate': 0.004465549618400902, 'p_miss': 0.014720039339020628}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:29:18,784] Trial 53 finished with value: 0.2972607097488571 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 88, 'learning_rate': 0.007550471095039892, 'p_miss': 0.2560476233415135}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:29:19,376] Trial 59 finished with value: 0.2831771146509946 and parameters: {'model_name': 'VAE', 'batch_size': 747, 'iterations': 7, 'learning_rate': 0.009618009066454004, 'p_miss': 0.2596597004590514}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:29:30,584] Trial 61 finished with value: 0.29047129448028475 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20677, 'weights': 'uniform'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:29:31,352] Trial 62 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 2 with value: 0.24140027688206017.
running
[I 2024-11-13 13:29:40,965] Trial 63 finished with value: 0.24100031622389934 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 2, 'learning_rate': 0.0003311231733976619, 'p_miss': 0.07795044655454153}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:29:51,421] Trial 64 finished with value: 0.24610756856188867 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2, 'learning_rate': 0.0020473425284017075, 'p_miss': 0.060745978398577226}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:29:54,129] Trial 60 finished with value: 0.24171434583830692 and parameters: {'model_name': 'VAE', 'batch_size': 390, 'iterations': 8, 'learning_rate': 0.0005469946337187388, 'p_miss': 0.08548605495959824}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:35:18,776] Trial 4 finished with value: 0.29439337335944804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:35:20,647] Trial 20 finished with value: 0.2922977916013413 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:35:43,661] Trial 68 finished with value: 0.2427265682395643 and parameters: {'model_name': 'VAE', 'batch_size': 745, 'iterations': 3, 'learning_rate': 0.00026616941988024756, 'p_miss': 0.08443212689583375}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:36:31,667] Trial 69 finished with value: 0.24352247307412994 and parameters: {'model_name': 'VAE', 'batch_size': 355, 'iterations': 10, 'learning_rate': 0.00038879806409089913, 'p_miss': 0.026860774497972216}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:43:10,088] Trial 32 finished with value: 0.29504356503313994 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 642, 'learning_rate': 0.001222457288996593, 'p_miss': 0.2895143260169152}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:43:23,572] Trial 71 finished with value: 0.24268615438131458 and parameters: {'model_name': 'VAE', 'batch_size': 298, 'iterations': 1, 'learning_rate': 0.00443188474250874, 'p_miss': 0.04843085070437042}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:43:39,922] Trial 72 finished with value: 0.4328371312421771 and parameters: {'model_name': 'GAIN', 'batch_size': 343, 'hint_rate': 0.9612610600832874, 'alpha': 98, 'iterations': 4, 'learning_rate': 0.0002693381056263142, 'p_miss': 0.04663337387672134}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:43:49,604] Trial 73 finished with value: 0.29047129448028475 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22202, 'weights': 'uniform'}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:46:24,751] Trial 74 finished with value: 0.28055934307175784 and parameters: {'model_name': 'VAE', 'batch_size': 525, 'iterations': 14, 'learning_rate': 0.005169784755546585, 'p_miss': 0.07737237710495314}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:49:29,659] Trial 75 finished with value: 0.295471067001528 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 29, 'learning_rate': 0.026845773170829427, 'p_miss': 0.09896105847352168}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:49:37,413] Trial 76 finished with value: 0.24266302482300633 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 1, 'learning_rate': 0.0043379482920082955, 'p_miss': 0.03531648542068412}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:49:45,782] Trial 77 finished with value: 0.24507393533901806 and parameters: {'model_name': 'VAE', 'batch_size': 239, 'iterations': 1, 'learning_rate': 0.0006640624390952403, 'p_miss': 0.04836944689278175}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:49:59,593] Trial 78 finished with value: 0.24727197708901957 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 2, 'learning_rate': 0.0059994089258655105, 'p_miss': 0.0646089686664383}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:58:12,825] Trial 33 finished with value: 0.29368405713459494 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 702, 'learning_rate': 0.0010670688099251354, 'p_miss': 0.29216548754771904}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 13:58:15,585] Trial 80 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.6641353308191581, 'alpha': 67, 'iterations': 3, 'learning_rate': 0.00018752544918802677, 'p_miss': 0.040879430511002325}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 14:17:15,652] Trial 30 finished with value: 0.293890146469285 and parameters: {'model_name': 'VAE', 'batch_size': 142, 'iterations': 1163, 'learning_rate': 0.0006867005023676597, 'p_miss': 0.27279488185238454}. Best is trial 63 with value: 0.24100031622389934.
running
[I 2024-11-13 14:17:21,130] Trial 82 finished with value: 0.24096289637105225 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 1, 'learning_rate': 0.0019790290327380664, 'p_miss': 0.24391289445865913}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 14:17:36,319] Trial 83 finished with value: 0.28482817631448676 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 14:17:37,568] Trial 84 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 14:17:59,429] Trial 85 finished with value: 0.24247524786620658 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 5, 'learning_rate': 0.0023148619553381117, 'p_miss': 0.2399705344732356}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:07:52,331] Trial 27 finished with value: 0.2946410650599186 and parameters: {'model_name': 'VAE', 'batch_size': 260, 'iterations': 2018, 'learning_rate': 0.0009982687418593741, 'p_miss': 0.2958505400661641}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:08:03,537] Trial 87 finished with value: 0.24193081305185998 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 3, 'learning_rate': 0.0017618996282022532, 'p_miss': 0.24216155766918926}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:08:33,025] Trial 88 finished with value: 0.24554816035965205 and parameters: {'model_name': 'VAE', 'batch_size': 92, 'iterations': 5, 'learning_rate': 0.0016365626867620355, 'p_miss': 0.2376702322804462}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:09:30,982] Trial 31 finished with value: 0.294307290869612 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 2003, 'learning_rate': 0.0010190973853283956, 'p_miss': 0.29828393891259675}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:09:43,563] Trial 89 finished with value: 0.2455841182675779 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 14, 'learning_rate': 0.0024280315457190184, 'p_miss': 0.22123867383335694}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:09:45,811] Trial 90 finished with value: 0.2429929116543458 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 4, 'learning_rate': 0.002360433837171986, 'p_miss': 0.24762302006400047}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:09:52,190] Trial 91 finished with value: 0.28851120505627287 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 136, 'weights': 'uniform'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:09:57,611] Trial 92 finished with value: 0.29060712279498735 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14921, 'weights': 'uniform'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:10:17,281] Trial 93 finished with value: 0.2419485182414733 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 6, 'learning_rate': 0.0008169289031702434, 'p_miss': 0.21177912180346253}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:10:26,329] Trial 94 finished with value: 0.24105938069624872 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 6, 'learning_rate': 0.0016208136701733134, 'p_miss': 0.2121148573971005}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:10:46,427] Trial 95 finished with value: 0.24113356354672938 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 7, 'learning_rate': 0.0008080238512975065, 'p_miss': 0.2083205236811314}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:11:00,990] Trial 96 finished with value: 0.24240872068636898 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 10, 'learning_rate': 0.0008208866294005947, 'p_miss': 0.21161021796033733}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:11:23,023] Trial 98 finished with value: 0.24462372606198524 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.00036792218200209256, 'p_miss': 0.20478983156287692}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:11:34,123] Trial 99 finished with value: 0.24399105802888216 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.0013494711056150214, 'p_miss': 0.22200584431772138}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:13:30,499] Trial 100 finished with value: 0.2440063913539352 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 22, 'learning_rate': 0.000864509927953634, 'p_miss': 0.18509039046866718}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:13:52,876] Trial 101 finished with value: 0.43667869863692016 and parameters: {'model_name': 'GAIN', 'batch_size': 178, 'hint_rate': 0.043022368980521586, 'alpha': 99, 'iterations': 11, 'learning_rate': 0.0005701347350780647, 'p_miss': 0.2768408105372413}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:14:01,135] Trial 102 finished with value: 0.2838404695082445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:14:34,212] Trial 103 finished with value: 0.24156325352228603 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 7, 'learning_rate': 0.0016801723060961892, 'p_miss': 0.17109652467238548}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:14:48,353] Trial 104 finished with value: 0.24209445317315295 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 3, 'learning_rate': 0.0014627335489835107, 'p_miss': 0.1673254288812045}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:15:44,779] Trial 105 finished with value: 0.24163534842490497 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 16, 'learning_rate': 0.0016479686388922474, 'p_miss': 0.1454577063771873}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:16:21,241] Trial 106 finished with value: 0.24205863485401866 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8, 'learning_rate': 0.001621460679112381, 'p_miss': 0.14304370478203735}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:17:00,161] Trial 107 finished with value: 0.24401641127470503 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 15, 'learning_rate': 0.003127905257392033, 'p_miss': 0.19437858161924962}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:18:24,002] Trial 108 finished with value: 0.24513031886221323 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 20, 'learning_rate': 0.0011308473527630303, 'p_miss': 0.18090781827997937}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:20:13,376] Trial 109 finished with value: 0.2457379811892782 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 35, 'learning_rate': 0.0017809891901084702, 'p_miss': 0.19710694130105444}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:20:34,309] Trial 110 finished with value: 0.24330245900419717 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.0011913299685876212, 'p_miss': 0.16652968027357098}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:21:58,646] Trial 111 finished with value: 0.24488109312781936 and parameters: {'model_name': 'VAE', 'batch_size': 471, 'iterations': 12, 'learning_rate': 0.00271051206674734, 'p_miss': 0.13059228161543993}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:21:59,331] Trial 112 finished with value: 0.29047129448028475 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:22:26,556] Trial 113 finished with value: 0.2445312329371206 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 8, 'learning_rate': 0.002152139467050463, 'p_miss': 0.22453084719166982}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:34:12,853] Trial 70 finished with value: 0.2951682513298586 and parameters: {'model_name': 'VAE', 'batch_size': 224, 'iterations': 1558, 'learning_rate': 0.0006563561197576064, 'p_miss': 0.046159015291936355}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 15:39:06,066] Trial 29 finished with value: 0.2959122436273124 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 1792, 'learning_rate': 0.000899071006166577, 'p_miss': 0.29553813317421146}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:34:14,861] Trial 34 finished with value: 0.2938963513090499 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 3502, 'learning_rate': 0.0017019261134282313, 'p_miss': 0.03719476066889327}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:34:45,924] Trial 117 finished with value: 0.2451583877841018 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 7, 'learning_rate': 0.0003567865261551496, 'p_miss': 0.20561337631389567}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:35:07,141] Trial 118 finished with value: 0.24315535559199083 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 5, 'learning_rate': 0.0005095939861968091, 'p_miss': 0.2107689058622018}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:35:33,148] Trial 119 finished with value: 0.2449826394152959 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6, 'learning_rate': 0.0007690396657098515, 'p_miss': 0.23049901719224494}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:46:44,858] Trial 120 finished with value: 0.2662802053580978 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 185, 'learning_rate': 0.000954767197975532, 'p_miss': 0.28188497560048964}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:47:06,643] Trial 121 finished with value: 0.24472507341344948 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 4, 'learning_rate': 0.0019269341812687406, 'p_miss': 0.21672770453966583}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:47:26,451] Trial 122 finished with value: 0.2414972003236655 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 6, 'learning_rate': 0.0014378914949007239, 'p_miss': 0.2450789136857995}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:48:03,276] Trial 123 finished with value: 0.3718960618164332 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:48:11,686] Trial 124 finished with value: 0.24239237926612098 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 2, 'learning_rate': 0.0034736243557970245, 'p_miss': 0.26552170712609086}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:48:33,572] Trial 125 finished with value: 0.4311726262295551 and parameters: {'model_name': 'GAIN', 'batch_size': 142, 'hint_rate': 0.7386655730328205, 'alpha': 65, 'iterations': 11, 'learning_rate': 0.0012202270160710687, 'p_miss': 0.24803596751284596}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:48:54,391] Trial 126 finished with value: 0.24193608570047162 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 6, 'learning_rate': 0.0015100166653013011, 'p_miss': 0.19897487153833757}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:49:58,292] Trial 127 finished with value: 0.2436282557396273 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 17, 'learning_rate': 0.00147598933164648, 'p_miss': 0.17451014638708315}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:50:20,140] Trial 128 finished with value: 0.24258584421629842 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 4, 'learning_rate': 0.0019699823116028545, 'p_miss': 0.15073770915213047}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:50:50,862] Trial 129 finished with value: 0.24312603211958997 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 7, 'learning_rate': 0.0026219055719385203, 'p_miss': 0.19751688002337003}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:51:27,880] Trial 130 finished with value: 0.24110343166732756 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 10, 'learning_rate': 0.0014254862539873766, 'p_miss': 0.2472505522261209}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:52:07,396] Trial 131 finished with value: 0.2425597091120685 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 9, 'learning_rate': 0.0010605965929912468, 'p_miss': 0.24718142644887037}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:52:42,355] Trial 132 finished with value: 0.24240075152133725 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 9, 'learning_rate': 0.003513844574498614, 'p_miss': 0.2559331529614749}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:53:36,135] Trial 133 finished with value: 0.2457819649397745 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 13, 'learning_rate': 0.00043731331605815214, 'p_miss': 0.09545154701826093}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:53:50,870] Trial 134 finished with value: 0.24110658523993672 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 3, 'learning_rate': 0.00030770823536321776, 'p_miss': 0.26747850563676856}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 16:53:52,065] Trial 135 finished with value: 0.43269985213476964 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:00:57,299] Trial 19 finished with value: 0.29619245198469313 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 3581, 'learning_rate': 0.0010636662652543562, 'p_miss': 0.28726415003991246}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:01:18,857] Trial 137 finished with value: 0.2510222743638231 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 4, 'learning_rate': 0.00023441766750682762, 'p_miss': 0.23230659038741078}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:03:36,295] Trial 138 finished with value: 0.24567512171010203 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 28, 'learning_rate': 0.0003032605913286873, 'p_miss': 0.2706919747619889}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:03:51,164] Trial 139 finished with value: 0.24210960535149845 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 3, 'learning_rate': 0.00016614779119211896, 'p_miss': 0.24186533608781347}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:04:05,193] Trial 140 finished with value: 0.2456779023017696 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 3, 'learning_rate': 0.002127844117856583, 'p_miss': 0.26258294700034424}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:07:51,144] Trial 141 finished with value: 0.25520476827516736 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 64, 'learning_rate': 0.0013287956281443844, 'p_miss': 0.25669890923092165}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:08:06,007] Trial 142 finished with value: 0.30360570628620526 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17454, 'weights': 'distance'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:08:26,668] Trial 143 finished with value: 0.31317739613190404 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.09009831620665573, 'p_miss': 0.28161496704432887}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:08:51,287] Trial 144 finished with value: 0.24427350599440997 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.00020992988604600854, 'p_miss': 0.25135332200614485}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:13:20,054] Trial 66 finished with value: 0.29590907821882756 and parameters: {'model_name': 'VAE', 'batch_size': 351, 'iterations': 3433, 'learning_rate': 0.00029497509252042687, 'p_miss': 0.0843741779575454}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:13:46,874] Trial 146 finished with value: 0.24316871416759406 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 7, 'learning_rate': 0.001388722558621645, 'p_miss': 0.0695320504685674}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:14:20,661] Trial 147 finished with value: 0.24218962155524645 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 10, 'learning_rate': 0.0016703589735001772, 'p_miss': 0.18690982021220398}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:15:11,154] Trial 148 finished with value: 0.2419644050081792 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 16, 'learning_rate': 0.002821175131201434, 'p_miss': 0.22794749492957628}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:15:34,626] Trial 149 finished with value: 0.24755788524842598 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6, 'learning_rate': 0.0016264641283127174, 'p_miss': 0.20155471201937314}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:15:53,376] Trial 150 finished with value: 0.24295984176352498 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 5, 'learning_rate': 0.0006011011709113787, 'p_miss': 0.23980850411602872}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:16:02,594] Trial 151 finished with value: 0.24480034349541197 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 2, 'learning_rate': 0.0007339420250483885, 'p_miss': 0.16233925324529358}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:16:31,056] Trial 152 finished with value: 0.24479643804828352 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 7, 'learning_rate': 0.0018687343045317895, 'p_miss': 0.17872559704354224}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:17:04,965] Trial 153 finished with value: 0.3700339472692149 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:17:43,324] Trial 154 finished with value: 0.2420804672378325 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 13, 'learning_rate': 0.00013417332765939697, 'p_miss': 0.21688932307380585}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:23:36,809] Trial 81 finished with value: 0.2958767336221114 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 3616, 'learning_rate': 0.0017421120359722908, 'p_miss': 0.2237814060345637}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:24:05,101] Trial 156 finished with value: 0.24117103713355306 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 8, 'learning_rate': 0.0009708757336191405, 'p_miss': 0.19113060197192774}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:24:35,983] Trial 157 finished with value: 0.24105344462501127 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 8, 'learning_rate': 0.0009593534365643123, 'p_miss': 0.18977540195682982}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:25:38,517] Trial 158 finished with value: 0.2415369827760506 and parameters: {'model_name': 'VAE', 'batch_size': 917, 'iterations': 11, 'learning_rate': 0.0009232177930043979, 'p_miss': 0.18741296685714084}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:26:27,485] Trial 159 finished with value: 0.2431144718740998 and parameters: {'model_name': 'VAE', 'batch_size': 526, 'iterations': 8, 'learning_rate': 0.0010344901343513435, 'p_miss': 0.19007538292672144}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 17:26:47,028] Trial 160 finished with value: 0.43358698090640785 and parameters: {'model_name': 'GAIN', 'batch_size': 30, 'hint_rate': 0.43725851476137667, 'alpha': 34, 'iterations': 11, 'learning_rate': 0.000948800917767848, 'p_miss': 0.18069487216668842}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:02:32,340] Trial 86 finished with value: 0.29526757978947993 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 4461, 'learning_rate': 0.0018149405887043313, 'p_miss': 0.2309869401673484}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:03:31,873] Trial 162 finished with value: 0.24266315866868063 and parameters: {'model_name': 'VAE', 'batch_size': 638, 'iterations': 9, 'learning_rate': 0.00047139377574578425, 'p_miss': 0.1706655253823702}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:05:17,481] Trial 163 finished with value: 0.24643574280069674 and parameters: {'model_name': 'VAE', 'batch_size': 984, 'iterations': 21, 'learning_rate': 0.0006720975189065179, 'p_miss': 0.19119731823856928}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:06:59,381] Trial 164 finished with value: 0.2451880128090862 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 25, 'learning_rate': 0.0012280849325788056, 'p_miss': 0.29512974238322637}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:08:15,630] Trial 165 finished with value: 0.24265749093321248 and parameters: {'model_name': 'VAE', 'batch_size': 289, 'iterations': 12, 'learning_rate': 0.0011328219129056614, 'p_miss': 0.2051550133115282}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:08:39,952] Trial 166 finished with value: 0.24862749879529122 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 5, 'learning_rate': 0.0023928955298857784, 'p_miss': 0.10821994881006276}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:09:54,691] Trial 167 finished with value: 0.24336430112078963 and parameters: {'model_name': 'VAE', 'batch_size': 962, 'iterations': 15, 'learning_rate': 0.0008354704219723181, 'p_miss': 0.18533307988491562}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:10:29,880] Trial 168 finished with value: 0.24301665294101285 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 8, 'learning_rate': 0.0009255789324870515, 'p_miss': 0.17456658888454235}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:11:11,809] Trial 169 finished with value: 0.2411287269959672 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 10, 'learning_rate': 0.0013062474065706927, 'p_miss': 0.2725533456044458}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:11:56,825] Trial 170 finished with value: 0.24366131511232297 and parameters: {'model_name': 'VAE', 'batch_size': 390, 'iterations': 10, 'learning_rate': 0.0013261012227269533, 'p_miss': 0.2888428700159161}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:11:57,678] Trial 171 finished with value: 0.29047129448028475 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:13:16,353] Trial 172 finished with value: 0.2428316317380692 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 18, 'learning_rate': 0.000336394865828148, 'p_miss': 0.2699310190745624}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:13:51,538] Trial 173 finished with value: 0.24387837891977338 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 7, 'learning_rate': 0.0010541023742957124, 'p_miss': 0.2747871282266772}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:14:05,731] Trial 174 finished with value: 0.30357051303396354 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9799, 'weights': 'distance'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 18:47:53,366] Trial 54 finished with value: 0.29438539572873385 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 5568, 'learning_rate': 0.00906448710894978, 'p_miss': 0.25291780355957116}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:46:12,598] Trial 35 finished with value: 0.2964070278794887 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 7102, 'learning_rate': 0.0013083190187893423, 'p_miss': 0.01576401676904579}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:46:36,504] Trial 177 finished with value: 0.24387048374518328 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 4, 'learning_rate': 0.002103026266308749, 'p_miss': 0.2610167983427548}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:47:23,486] Trial 178 finished with value: 0.24414837556316585 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 12, 'learning_rate': 0.0014703848575137245, 'p_miss': 0.07477814356346349}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:47:55,099] Trial 179 finished with value: 0.24466460125052683 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.0012271236240477695, 'p_miss': 0.2994506045091749}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:48:12,762] Trial 180 finished with value: 0.24539098798914322 and parameters: {'model_name': 'VAE', 'batch_size': 103, 'iterations': 5, 'learning_rate': 0.0007213759970723611, 'p_miss': 0.09444069734652433}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:48:40,323] Trial 181 finished with value: 0.24516044659024802 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 8, 'learning_rate': 0.0015386487009633651, 'p_miss': 0.15991204325396682}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:48:52,964] Trial 182 finished with value: 0.2444821732911293 and parameters: {'model_name': 'VAE', 'batch_size': 155, 'iterations': 3, 'learning_rate': 0.0018985856719178915, 'p_miss': 0.23578736835219838}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:49:47,934] Trial 183 finished with value: 0.2430336732070252 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 14, 'learning_rate': 0.00041857222896687896, 'p_miss': 0.24289413029133405}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:50:12,392] Trial 184 finished with value: 0.2422936083464192 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 6, 'learning_rate': 0.0005604362623899666, 'p_miss': 0.08819449372516676}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:50:45,032] Trial 185 finished with value: 0.2413754613984247 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 11, 'learning_rate': 0.0022587395680076605, 'p_miss': 0.28473610118688186}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:51:15,676] Trial 186 finished with value: 0.24479227843416823 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9, 'learning_rate': 0.002273702493154535, 'p_miss': 0.28180644993202225}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:51:50,949] Trial 187 finished with value: 0.24361505180815338 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 11, 'learning_rate': 0.0028260000632298675, 'p_miss': 0.29096252766971475}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:52:32,604] Trial 188 finished with value: 0.2432095640880302 and parameters: {'model_name': 'VAE', 'batch_size': 209, 'iterations': 7, 'learning_rate': 0.002538972648959974, 'p_miss': 0.2858243616810766}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:53:25,759] Trial 189 finished with value: 0.24749034413961252 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 17, 'learning_rate': 0.0031277229551938237, 'p_miss': 0.2689805934099583}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:54:09,929] Trial 190 finished with value: 0.24633879835390782 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 11, 'learning_rate': 0.0008998824953374171, 'p_miss': 0.27519199629165736}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:54:16,877] Trial 191 finished with value: 0.28384014659273793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:54:44,670] Trial 192 finished with value: 0.24356754306366896 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 6, 'learning_rate': 0.0016878234367454668, 'p_miss': 0.1277694604799902}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:54:55,883] Trial 193 finished with value: 0.43099587687032 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.5448649280357963, 'alpha': 2, 'iterations': 4, 'learning_rate': 0.003676860293060668, 'p_miss': 0.19508250484512327}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 19:55:44,906] Trial 194 finished with value: 0.24670486294692262 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 13, 'learning_rate': 0.0013530541661173749, 'p_miss': 0.21653682668834653}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 20:08:58,987] Trial 79 finished with value: 0.3010283718841993 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8342, 'learning_rate': 0.004238251149927519, 'p_miss': 0.035409737959368824}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 20:09:19,477] Trial 196 finished with value: 0.24591554490871106 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 6, 'learning_rate': 0.0015115522628225072, 'p_miss': 0.198579317247566}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 20:09:42,650] Trial 197 finished with value: 0.24580785765408644 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8, 'learning_rate': 0.0011269084283771383, 'p_miss': 0.20251876356759674}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 20:20:46,037] Trial 195 finished with value: 0.290457129134739 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 454, 'learning_rate': 0.0011166592435745636, 'p_miss': 0.2523833244813329}. Best is trial 82 with value: 0.24096289637105225.
running
[I 2024-11-13 20:20:55,968] Trial 199 finished with value: 0.24430062978621062 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 2, 'learning_rate': 0.0019126748070018584, 'p_miss': 0.19014433410937054}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 20:42:21,806] Trial 198 finished with value: 0.2949796827130736 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 518, 'learning_rate': 0.0019241463129460721, 'p_miss': 0.19099915074629953}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 21:42:13,386] Trial 155 finished with value: 0.43504076473650033 and parameters: {'model_name': 'GAIN', 'batch_size': 429, 'hint_rate': 0.47632352514584714, 'alpha': 1, 'iterations': 9371, 'learning_rate': 0.0009709901868171672, 'p_miss': 0.0905933864576598}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:06:58,549] Trial 116 finished with value: 0.2950399841427393 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 6408, 'learning_rate': 0.00046776721011623383, 'p_miss': 0.2147366963562185}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:35:39,394] Trial 11 finished with value: 0.29558058798752185 and parameters: {'model_name': 'VAE', 'batch_size': 535, 'iterations': 7226, 'learning_rate': 0.0010540368561738512, 'p_miss': 0.19086282311356023}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:36:47,671] Trial 115 finished with value: 0.2957189538664345 and parameters: {'model_name': 'VAE', 'batch_size': 994, 'iterations': 4856, 'learning_rate': 0.000343611418590192, 'p_miss': 0.2780682932944023}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:38:29,191] Trial 97 finished with value: 0.2939876005497066 and parameters: {'model_name': 'VAE', 'batch_size': 169, 'iterations': 6502, 'learning_rate': 0.0008164954549688533, 'p_miss': 0.2124985679505318}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:43:03,216] Trial 65 finished with value: 0.29548852774904466 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 8997, 'learning_rate': 0.0005611940309519016, 'p_miss': 0.036480293774340915}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:43:29,825] Trial 145 finished with value: 0.29512830968552917 and parameters: {'model_name': 'VAE', 'batch_size': 977, 'iterations': 4680, 'learning_rate': 0.0003113494018844794, 'p_miss': 0.2393777059974468}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 22:52:23,616] Trial 67 finished with value: 0.2945979059622935 and parameters: {'model_name': 'VAE', 'batch_size': 958, 'iterations': 6701, 'learning_rate': 0.0002620257082938902, 'p_miss': 0.08379276450710063}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:08:52,679] Trial 114 finished with value: 0.30189718062841586 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 8217, 'learning_rate': 0.0004362921613994904, 'p_miss': 0.20625279653853545}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:32:22,322] Trial 161 finished with value: 0.296263596339426 and parameters: {'model_name': 'VAE', 'batch_size': 637, 'iterations': 6479, 'learning_rate': 0.000447684941150438, 'p_miss': 0.16703413373797069}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:32:52,254] Trial 176 finished with value: 0.2928063836547766 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 9267, 'learning_rate': 0.0020726608156345374, 'p_miss': 0.26151743862518145}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:33:57,333] Trial 136 finished with value: 0.2949251223755581 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 9870, 'learning_rate': 0.000303893728547842, 'p_miss': 0.2736565843155417}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:35:03,344] Trial 175 finished with value: 0.30199441092072743 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9825, 'learning_rate': 0.0020737990926855427, 'p_miss': 0.29922744963403675}. Best is trial 82 with value: 0.24096289637105225.
[I 2024-11-13 23:37:02,841] Trial 55 finished with value: 0.2966023603795419 and parameters: {'model_name': 'VAE', 'batch_size': 483, 'iterations': 9847, 'learning_rate': 0.010326225328781845, 'p_miss': 0.25796760607095814}. Best is trial 82 with value: 0.24096289637105225.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.24096289637105225
{'model_name': 'VAE', 'batch_size': 89, 'iterations': 1, 'learning_rate': 0.0019790290327380664, 'p_miss': 0.24391289445865913}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.05775532142201326
Generation:   4%|▍         | 1/25 [06:30<2:36:06, 390.28s/it]Generation:  2
Best f1_score score: 0.060581541603901265
Generation:   8%|▊         | 2/25 [14:09<2:45:14, 431.08s/it]Generation:  3
Best f1_score score: 0.0623249992333106
Generation:  12%|█▏        | 3/25 [18:24<2:08:27, 350.33s/it]Generation:  4
Best f1_score score: 0.06329358227926118
Generation:  16%|█▌        | 4/25 [25:03<2:09:23, 369.71s/it]Generation:  5
Best f1_score score: 0.06551176266868926
Generation:  20%|██        | 5/25 [27:03<1:33:11, 279.55s/it]Generation:  6
Best f1_score score: 0.06551176266868926
Generation:  24%|██▍       | 6/25 [33:37<1:40:53, 318.63s/it]Generation:  7
Best f1_score score: 0.06551176266868926
Generation:  28%|██▊       | 7/25 [37:32<1:27:23, 291.30s/it]Generation:  8
Best f1_score score: 0.06619133358512592
Generation:  32%|███▏      | 8/25 [40:40<1:13:12, 258.36s/it]Generation:  9
Best f1_score score: 0.06619133358512592
Generation:  36%|███▌      | 9/25 [44:28<1:06:20, 248.75s/it]Generation:  10
Best f1_score score: 0.06744157538467163
Generation:  40%|████      | 10/25 [50:51<1:12:35, 290.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474718670> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.06744157538467163
Generation:  44%|████▍     | 11/25 [56:23<1:10:40, 302.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e89fc0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.06744157538467163
Generation:  48%|████▊     | 12/25 [1:00:04<1:00:14, 278.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0d6c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b58b610> 

Generation:  13
Best f1_score score: 0.06744157538467163
Generation:  52%|█████▏    | 13/25 [1:10:13<1:15:38, 378.24s/it]Generation:  14
Best f1_score score: 0.06744157538467163
Generation:  56%|█████▌    | 14/25 [1:16:34<1:09:30, 379.11s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe560> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.06744157538467163
Generation:  60%|██████    | 15/25 [1:20:19<55:26, 332.68s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0efe0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.06999223398585211
Generation:  64%|██████▍   | 16/25 [1:25:46<49:39, 331.00s/it]Generation:  17
Best f1_score score: 0.06999223398585211
Generation:  68%|██████▊   | 17/25 [1:32:15<46:27, 348.44s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554670c2da0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a82230> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676dfb50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.06999223398585211
Generation:  72%|███████▏  | 18/25 [1:40:20<45:25, 389.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b76ce0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.06999223398585211
Generation:  76%|███████▌  | 19/25 [1:45:12<36:01, 360.18s/it]Generation:  20
Best f1_score score: 0.06999223398585211
Generation:  80%|████████  | 20/25 [1:51:59<31:11, 374.38s/it]Generation:  21
Best f1_score score: 0.06999223398585211
Generation:  84%|████████▍ | 21/25 [1:56:15<22:35, 338.86s/it]Generation:  22
Best f1_score score: 0.06999223398585211
Generation:  88%|████████▊ | 22/25 [2:01:27<16:31, 330.58s/it]Generation:  23
Best f1_score score: 0.06999223398585211
Generation:  92%|█████████▏| 23/25 [2:07:09<11:08, 334.12s/it]Generation:  24
Best f1_score score: 0.06999223398585211
Generation:  96%|█████████▌| 24/25 [2:13:09<05:41, 341.79s/it]Generation:  25
Best f1_score score: 0.06999223398585211
Generation: 100%|██████████| 25/25 [2:16:10<00:00, 293.73s/it]Generation: 100%|██████████| 25/25 [2:16:13<00:00, 326.95s/it]
2024-11-14 01:53:35,307 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:40251' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-0276a45d26f4a1a97db128f7de285b36', 'ndarray-04ef1e3a7246aa787bf6714e77e9803f'} (stimulus_id='handle-worker-cleanup-1731578015.3072')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(boosting_type='dart', class_weight='balanced',
                                max_depth=10, n_estimators=56, n_jobs=1,
                                num_leaves=110, verbose=-1))])
score start
train score: {'auroc': 0.9541334597838829, 'accuracy': 0.6103635715558724, 'balanced_accuracy': 0.797798304816525, 'logloss': 1.7369364766132036, 'f1': 0.5768095212012708}
original test score: {'auroc': 0.5153209755374188, 'accuracy': 0.13399857448325017, 'balanced_accuracy': 0.06196051107024431, 'logloss': 2.6310078981019585, 'f1': 0.05487499318408569}
imputed test score: {'auroc': 0.5079811411385876, 'accuracy': 0.08481824661439771, 'balanced_accuracy': 0.05894387408073032, 'logloss': 2.726221079955046, 'f1': 0.05436386771245574}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4130> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 589, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a16c0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.15500760461504035
Generation:   4%|▍         | 1/25 [07:23<2:57:27, 443.65s/it]Generation:  2
Best f1_score score: 0.16213845121615605
Generation:   8%|▊         | 2/25 [10:48<1:56:15, 303.29s/it]Generation:  3
Best f1_score score: 0.16213845121615605
Generation:  12%|█▏        | 3/25 [14:56<1:41:58, 278.12s/it]Generation:  4
Best f1_score score: 0.16213845121615605
Generation:  16%|█▌        | 4/25 [18:34<1:28:59, 254.28s/it]Generation:  5
Best f1_score score: 0.17435386801376382
Generation:  20%|██        | 5/25 [23:20<1:28:31, 265.59s/it]Generation:  6
Best f1_score score: 0.17435386801376382
Generation:  24%|██▍       | 6/25 [31:28<1:48:07, 341.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474704730> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546795a140> 

Generation:  7
Best f1_score score: 0.18466593422432911
Generation:  28%|██▊       | 7/25 [41:33<2:08:13, 427.43s/it]Generation:  8
Best f1_score score: 0.1859130954208062
Generation:  32%|███▏      | 8/25 [49:39<2:06:24, 446.16s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554653aa5c0> 

Generation:  9
Best f1_score score: 0.1870106133802793
Generation:  36%|███▌      | 9/25 [59:44<2:12:14, 495.88s/it]Generation:  10
Best f1_score score: 0.1870106133802793
Generation:  40%|████      | 10/25 [1:03:14<1:41:52, 407.49s/it]Generation:  11
Best f1_score score: 0.1870106133802793
Generation:  44%|████▍     | 11/25 [1:12:57<1:47:36, 461.21s/it]Generation:  12
Best f1_score score: 0.1994221130362412
Generation:  48%|████▊     | 12/25 [1:16:07<1:22:04, 378.82s/it]Generation:  13
Best f1_score score: 0.1994221130362412
Generation:  52%|█████▏    | 13/25 [1:23:11<1:18:28, 392.38s/it]Generation:  14
Best f1_score score: 0.1994221130362412
Generation:  56%|█████▌    | 14/25 [1:26:38<1:01:41, 336.47s/it]Generation:  15
Best f1_score score: 0.1994221130362412
Generation:  60%|██████    | 15/25 [1:30:51<51:53, 311.39s/it]  Generation:  16
Best f1_score score: 0.1994221130362412
Generation:  64%|██████▍   | 16/25 [1:35:09<44:17, 295.30s/it]Generation:  17
Best f1_score score: 0.20594109377674222
Generation:  68%|██████▊   | 17/25 [1:38:24<35:20, 265.02s/it]Generation:  18
Best f1_score score: 0.20594109377674222
Generation:  72%|███████▏  | 18/25 [1:41:24<27:57, 239.63s/it]Generation:  19
Best f1_score score: 0.20594109377674222
Generation:  76%|███████▌  | 19/25 [1:49:08<30:41, 306.97s/it]Generation:  20
Best f1_score score: 0.20594109377674222
Generation:  80%|████████  | 20/25 [1:58:00<31:11, 374.34s/it]Generation:  21
Best f1_score score: 0.20594109377674222
Generation:  84%|████████▍ | 21/25 [2:05:43<26:43, 400.98s/it]Generation:  22
Best f1_score score: 0.20594109377674222
Generation:  88%|████████▊ | 22/25 [2:15:12<22:34, 451.42s/it]Generation:  23
Best f1_score score: 0.20594109377674222
Generation:  92%|█████████▏| 23/25 [2:17:55<12:09, 364.97s/it]Generation:  24
Best f1_score score: 0.20594109377674222
Generation:  96%|█████████▌| 24/25 [2:20:48<05:07, 307.40s/it]Generation:  25
Best f1_score score: 0.20594109377674222
Generation: 100%|██████████| 25/25 [2:24:45<00:00, 286.31s/it]Generation: 100%|██████████| 25/25 [2:24:45<00:00, 347.44s/it]
2024-11-14 04:19:02,161 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34441' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-04ef1e3a7246aa787bf6714e77e9803f', 'DataFrame-a287e9b4dac9952e7a353c8f9f865ecf'} (stimulus_id='handle-worker-cleanup-1731586742.1617558')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(max_depth=6, n_estimators=59, n_jobs=1,
                                num_leaves=225, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.887231741369743, 'accuracy': 0.37012119051862413, 'balanced_accuracy': 0.3131730971984565, 'logloss': 1.7679002062855362, 'f1': 0.36597533810738436}
test score: {'auroc': 0.8195877704435992, 'accuracy': 0.28884533143264435, 'balanced_accuracy': 0.1912716236353042, 'logloss': 2.015779220306527, 'f1': 0.20533613692762254}
original test score: {'auroc': 0.9434027847970479, 'accuracy': 0.5400926585887385, 'balanced_accuracy': 0.45211620117933965, 'logloss': 1.3150030042957366, 'f1': 0.45644177334389713}
score end
1481
lvl
0.5
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
15.208860261440277
hours
DONE
