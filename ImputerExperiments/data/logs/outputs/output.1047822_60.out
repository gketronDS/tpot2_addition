Run: 60
/cm/local/apps/slurm/var/spool/job1047822/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1496/1496.pkl
working on 
../data/c/1496/class_full_MNAR_0.5_3
2.2283568382263184
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-13 16:06:32,557] A new study created in memory with name: no-name-bce687a5-924e-45e0-9c61-331ed70e163d
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-13 16:06:32,922] Trial 9 finished with value: 0.20289280969658177 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 9 with value: 0.20289280969658177.
running
[I 2024-11-13 16:06:33,373] Trial 14 finished with value: 0.31771613097487716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 9 with value: 0.20289280969658177.
running
[I 2024-11-13 16:06:34,266] Trial 16 finished with value: 0.3830582651968245 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 9 with value: 0.20289280969658177.
running
[I 2024-11-13 16:06:38,671] Trial 15 finished with value: 0.2028928096965818 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5173, 'weights': 'uniform'}. Best is trial 9 with value: 0.20289280969658177.
running
[I 2024-11-13 16:06:38,859] Trial 4 finished with value: 0.2028928096965818 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4853, 'weights': 'uniform'}. Best is trial 9 with value: 0.20289280969658177.
running
[I 2024-11-13 16:06:41,628] Trial 5 finished with value: 0.20217255399898174 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1530, 'weights': 'distance'}. Best is trial 5 with value: 0.20217255399898174.
running
[I 2024-11-13 16:06:42,501] Trial 8 finished with value: 0.20222003396307536 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1900, 'weights': 'distance'}. Best is trial 5 with value: 0.20217255399898174.
running
[I 2024-11-13 16:06:43,304] Trial 17 finished with value: 0.20278881102246987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5594, 'weights': 'distance'}. Best is trial 5 with value: 0.20217255399898174.
running
[I 2024-11-13 16:06:43,830] Trial 23 finished with value: 0.31771613097487716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.20217255399898174.
running
[I 2024-11-13 16:06:44,513] Trial 18 finished with value: 0.20229019652715782 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2221, 'weights': 'distance'}. Best is trial 5 with value: 0.20217255399898174.
running
[I 2024-11-13 16:06:47,881] Trial 6 finished with value: 0.2007996500225083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 20, 'imputation_order': 'roman'}. Best is trial 6 with value: 0.2007996500225083.
running
[I 2024-11-13 16:06:50,173] Trial 21 finished with value: 0.20255048381370297 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3396, 'weights': 'uniform'}. Best is trial 6 with value: 0.2007996500225083.
running
[I 2024-11-13 16:06:55,046] Trial 25 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9786901929950593, 'alpha': 30, 'iterations': 22, 'learning_rate': 0.00033132950068985963, 'p_miss': 0.13953522552381484}. Best is trial 6 with value: 0.2007996500225083.
running
[I 2024-11-13 16:06:56,651] Trial 7 finished with value: 0.09787878600437039 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.00044452917164636204, 'p_miss': 0.011687498906311166}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:06:58,320] Trial 2 finished with value: 0.11904466266458555 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 1, 'learning_rate': 0.018064320492195425, 'p_miss': 0.02290232213938386}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:06:59,926] Trial 19 finished with value: 0.3776837632804099 and parameters: {'model_name': 'GAIN', 'batch_size': 48, 'hint_rate': 0.9145088477155557, 'alpha': 54, 'iterations': 4, 'learning_rate': 0.07348820624152443, 'p_miss': 0.13070064822047853}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:04,774] Trial 30 finished with value: 0.1229434484429713 and parameters: {'model_name': 'VAE', 'batch_size': 134, 'iterations': 1, 'learning_rate': 0.029849176967041605, 'p_miss': 0.024304127655462693}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:06,704] Trial 31 finished with value: 0.09792342920518494 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1, 'learning_rate': 0.013574894171357372, 'p_miss': 0.014055198511575858}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:07,431] Trial 1 finished with value: 0.20260932309242335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:07,701] Trial 26 finished with value: 0.2007996500225083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 19, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:12,368] Trial 27 finished with value: 0.2007996500225083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 19, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:14,646] Trial 28 finished with value: 0.2007996500225083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 20, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:15,564] Trial 29 finished with value: 0.2007996500225083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 20, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:16,241] Trial 36 finished with value: 0.09945475811347751 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.0062358535677991935, 'p_miss': 0.01649240595849221}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:18,283] Trial 37 finished with value: 0.0980714199497733 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.0059237407993977115, 'p_miss': 0.01660305833592858}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:19,670] Trial 38 finished with value: 0.09789275803570882 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.005721757132866985, 'p_miss': 0.01065809474853931}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:26,623] Trial 3 finished with value: 0.2209386511428868 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:40,714] Trial 10 finished with value: 0.2018666775723991 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:07:56,817] Trial 0 finished with value: 0.276026168845285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:08:04,318] Trial 20 finished with value: 0.27963409236978054 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:08:34,089] Trial 13 finished with value: 0.21974548275959266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'descending'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:11:17,208] Trial 22 finished with value: 0.22062193495127796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 17, 'imputation_order': 'roman'}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:56:55,694] Trial 40 finished with value: 0.21891524008356064 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1090, 'learning_rate': 0.0006612097425737524, 'p_miss': 0.07109556952647642}. Best is trial 7 with value: 0.09787878600437039.
running
[I 2024-11-13 16:57:18,110] Trial 48 finished with value: 0.097699116632498 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.0033734855300981033, 'p_miss': 0.2724750418800287}. Best is trial 48 with value: 0.097699116632498.
running
[I 2024-11-13 16:57:59,529] Trial 49 finished with value: 0.09749829150820669 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 14, 'learning_rate': 0.0016902643346906772, 'p_miss': 0.29879023371815494}. Best is trial 49 with value: 0.09749829150820669.
running
[I 2024-11-13 16:58:49,482] Trial 50 finished with value: 0.09869699617633716 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 16, 'learning_rate': 0.0012582043614581878, 'p_miss': 0.27975493431084203}. Best is trial 49 with value: 0.09749829150820669.
running
[I 2024-11-13 16:59:21,210] Trial 51 finished with value: 0.09979343506747468 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 9, 'learning_rate': 0.00010921116622592524, 'p_miss': 0.29580893495541977}. Best is trial 49 with value: 0.09749829150820669.
running
[I 2024-11-13 17:02:39,307] Trial 52 finished with value: 0.19796279217763038 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 68, 'learning_rate': 0.002659970556612776, 'p_miss': 0.24257132721367947}. Best is trial 49 with value: 0.09749829150820669.
running
[I 2024-11-13 17:02:59,585] Trial 53 finished with value: 0.0934120152520056 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 5, 'learning_rate': 0.0017092866547384138, 'p_miss': 0.19856960472818136}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:03:53,263] Trial 54 finished with value: 0.0935684800658945 and parameters: {'model_name': 'VAE', 'batch_size': 744, 'iterations': 6, 'learning_rate': 0.0015062586490537837, 'p_miss': 0.22129169810351892}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:09:47,924] Trial 55 finished with value: 0.2077918028670239 and parameters: {'model_name': 'VAE', 'batch_size': 678, 'iterations': 68, 'learning_rate': 0.0015865043112082845, 'p_miss': 0.22062095940574933}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:10:07,118] Trial 56 finished with value: 0.0949406240046163 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 6, 'learning_rate': 0.000718919590395114, 'p_miss': 0.19709489692094237}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:10:29,779] Trial 57 finished with value: 0.0963254102846437 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 6, 'learning_rate': 0.001476794695453416, 'p_miss': 0.19958246310268227}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:11:28,745] Trial 58 finished with value: 0.09559046582446666 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 19, 'learning_rate': 0.001052495678784308, 'p_miss': 0.1857083051821338}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:11:42,948] Trial 33 finished with value: 0.22223538247114322 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1650, 'learning_rate': 0.0008062611955730803, 'p_miss': 0.2899346904059325}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:11:57,734] Trial 60 finished with value: 0.0970872392926265 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 4, 'learning_rate': 0.0009645225539363652, 'p_miss': 0.1917312530089022}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:12:14,760] Trial 24 finished with value: 0.2048220134131161 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:13:15,943] Trial 62 finished with value: 0.35314572456882776 and parameters: {'model_name': 'GAIN', 'batch_size': 229, 'hint_rate': 0.06161843128551969, 'alpha': 90, 'iterations': 36, 'learning_rate': 0.0003785584476556617, 'p_miss': 0.1753300987932505}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:13:19,316] Trial 59 finished with value: 0.10336354625662558 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 29, 'learning_rate': 0.0010570631343501066, 'p_miss': 0.19046480102311544}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:13:27,770] Trial 63 finished with value: 0.1000865390216513 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.0024012725732105353, 'p_miss': 0.20742369199607133}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:13:33,460] Trial 64 finished with value: 0.09814989808745414 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 3, 'learning_rate': 0.002592665172930402, 'p_miss': 0.21741634140796323}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:14:06,860] Trial 66 finished with value: 0.09404079575328009 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 9, 'learning_rate': 0.0006972151857291407, 'p_miss': 0.16921962529553244}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:14:07,451] Trial 65 finished with value: 0.09882019228094945 and parameters: {'model_name': 'VAE', 'batch_size': 137, 'iterations': 8, 'learning_rate': 0.0001845041698058394, 'p_miss': 0.24256662602681198}. Best is trial 53 with value: 0.0934120152520056.
running
[I 2024-11-13 17:14:22,170] Trial 61 finished with value: 0.09217661623354771 and parameters: {'model_name': 'VAE', 'batch_size': 796, 'iterations': 29, 'learning_rate': 0.00025933783060046905, 'p_miss': 0.18171791969727202}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:15:00,613] Trial 67 finished with value: 0.09830305898713394 and parameters: {'model_name': 'VAE', 'batch_size': 764, 'iterations': 9, 'learning_rate': 0.0005229954742258761, 'p_miss': 0.1637311745600147}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:15:15,259] Trial 68 finished with value: 0.09754957463926454 and parameters: {'model_name': 'VAE', 'batch_size': 623, 'iterations': 10, 'learning_rate': 0.0005397027103336981, 'p_miss': 0.16434934935025916}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:15:15,778] Trial 71 finished with value: 0.3830582651968245 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:16:34,756] Trial 72 finished with value: 0.36339810546099693 and parameters: {'model_name': 'GAIN', 'batch_size': 280, 'hint_rate': 0.26944000722567296, 'alpha': 3, 'iterations': 46, 'learning_rate': 0.00024019758666741654, 'p_miss': 0.14124097147385511}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:18:33,938] Trial 44 finished with value: 0.2190756698763885 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1427, 'learning_rate': 0.0006261415392762822, 'p_miss': 0.29961152381107126}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:21:39,937] Trial 46 finished with value: 0.21781365090821048 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1511, 'learning_rate': 0.001996268735059003, 'p_miss': 0.012936035581665997}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:21:44,733] Trial 75 finished with value: 0.20279379605504966 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44, 'weights': 'uniform'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:22:04,045] Trial 76 finished with value: 0.09839682714704027 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 5, 'learning_rate': 0.001213819656249943, 'p_miss': 0.18979469801260726}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:29:41,407] Trial 70 finished with value: 0.16644845477300968 and parameters: {'model_name': 'VAE', 'batch_size': 345, 'iterations': 183, 'learning_rate': 0.00028537815777737686, 'p_miss': 0.15010297470387118}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:30:10,078] Trial 74 finished with value: 0.14103136359721005 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 192, 'learning_rate': 0.0002675569292087465, 'p_miss': 0.17935163683016936}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:30:10,488] Trial 79 finished with value: 0.3830582651968245 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:30:18,775] Trial 80 finished with value: 0.10198014549650955 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2, 'learning_rate': 0.0008350865087069705, 'p_miss': 0.20725274994795728}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:30:30,599] Trial 78 finished with value: 0.09813762252394853 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 15, 'learning_rate': 0.0008170331869878163, 'p_miss': 0.20442274994325804}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:30:38,256] Trial 82 finished with value: 0.09938846406554465 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 2, 'learning_rate': 0.003778021020706418, 'p_miss': 0.2382648081110967}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:31:28,765] Trial 83 finished with value: 0.3500043754055874 and parameters: {'model_name': 'GAIN', 'batch_size': 464, 'hint_rate': 0.5930934535534693, 'alpha': 99, 'iterations': 26, 'learning_rate': 0.0013902427272518571, 'p_miss': 0.22606364206487453}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:31:37,253] Trial 81 finished with value: 0.16489840708110914 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 20, 'learning_rate': 0.0035914694215159874, 'p_miss': 0.23763658950408445}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:31:46,991] Trial 85 finished with value: 0.20269683589249426 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3933, 'weights': 'uniform'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:31:50,477] Trial 84 finished with value: 0.09813521857312199 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 6, 'learning_rate': 0.00015916421854619587, 'p_miss': 0.10961336457443237}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:31:55,505] Trial 73 finished with value: 0.21206266272738056 and parameters: {'model_name': 'VAE', 'batch_size': 98, 'iterations': 274, 'learning_rate': 0.0007202633616983188, 'p_miss': 0.18004981824582383}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:04,830] Trial 87 finished with value: 0.09611669404676283 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 4, 'learning_rate': 0.0009308530382012173, 'p_miss': 0.19127602823409395}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:10,355] Trial 86 finished with value: 0.09715385031492954 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 5, 'learning_rate': 0.0009796987741327297, 'p_miss': 0.18942603677306705}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:11,513] Trial 88 finished with value: 0.10062373038767805 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4, 'learning_rate': 0.0010883367045205527, 'p_miss': 0.1973941960755073}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:12,827] Trial 89 finished with value: 0.09767280001175002 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 2, 'learning_rate': 0.00041919671002467034, 'p_miss': 0.19790373855977403}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:18,996] Trial 90 finished with value: 0.09869961211694937 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.0004259301773983978, 'p_miss': 0.16515548264751745}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:19,478] Trial 91 finished with value: 0.10040928766172175 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 2, 'learning_rate': 0.00041783532550343337, 'p_miss': 0.16698896268261929}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:20,057] Trial 94 finished with value: 0.20289280969658177 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:32:20,813] Trial 93 finished with value: 0.3830582651968245 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:33:00,008] Trial 95 finished with value: 0.09345122645541991 and parameters: {'model_name': 'VAE', 'batch_size': 189, 'iterations': 9, 'learning_rate': 0.0018265061931466548, 'p_miss': 0.11631503616240697}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:33:17,987] Trial 77 finished with value: 0.2113416316846617 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 238, 'learning_rate': 0.0009811422936489562, 'p_miss': 0.20765843120051372}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:33:33,950] Trial 92 finished with value: 0.09631387683119437 and parameters: {'model_name': 'VAE', 'batch_size': 923, 'iterations': 11, 'learning_rate': 0.0018470880309731997, 'p_miss': 0.1677917733750449}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:34:04,907] Trial 96 finished with value: 0.10182252617303844 and parameters: {'model_name': 'VAE', 'batch_size': 956, 'iterations': 12, 'learning_rate': 0.0017558047737927418, 'p_miss': 0.18247192556017733}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:34:10,188] Trial 98 finished with value: 0.09822299187415902 and parameters: {'model_name': 'VAE', 'batch_size': 157, 'iterations': 11, 'learning_rate': 0.0018616375816295522, 'p_miss': 0.12102416447962881}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:34:39,420] Trial 99 finished with value: 0.1016943982443349 and parameters: {'model_name': 'VAE', 'batch_size': 447, 'iterations': 12, 'learning_rate': 0.002044857939468333, 'p_miss': 0.11534264557275968}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:35:51,158] Trial 102 finished with value: 0.14697002589760885 and parameters: {'model_name': 'VAE', 'batch_size': 991, 'iterations': 7, 'learning_rate': 0.004814552410037219, 'p_miss': 0.0942326700969294}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:36:27,418] Trial 100 finished with value: 0.16173448481756586 and parameters: {'model_name': 'VAE', 'batch_size': 457, 'iterations': 18, 'learning_rate': 0.0019785427642175822, 'p_miss': 0.12185510035800465}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:36:29,091] Trial 101 finished with value: 0.21199604097776764 and parameters: {'model_name': 'VAE', 'batch_size': 999, 'iterations': 17, 'learning_rate': 0.04353666372417053, 'p_miss': 0.091478773013794}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:36:33,163] Trial 104 finished with value: 0.20258103712293277 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 99, 'weights': 'distance'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:36:35,376] Trial 105 finished with value: 0.20209480804705224 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 229, 'weights': 'distance'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:37:09,790] Trial 106 finished with value: 0.09667798603280306 and parameters: {'model_name': 'VAE', 'batch_size': 185, 'iterations': 7, 'learning_rate': 0.0013424961090986447, 'p_miss': 0.1479808474491355}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:37:19,830] Trial 69 finished with value: 0.21082793066879865 and parameters: {'model_name': 'VAE', 'batch_size': 737, 'iterations': 357, 'learning_rate': 0.0004674302277452406, 'p_miss': 0.16339780794774098}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:37:21,154] Trial 103 finished with value: 0.09393482598056117 and parameters: {'model_name': 'VAE', 'batch_size': 213, 'iterations': 21, 'learning_rate': 0.0006383217890492788, 'p_miss': 0.14599533500270134}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:37:26,897] Trial 108 finished with value: 0.10206020542690475 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0006348902712248971, 'p_miss': 0.038390170005857996}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:38:41,614] Trial 111 finished with value: 0.3624399643353763 and parameters: {'model_name': 'GAIN', 'batch_size': 574, 'hint_rate': 0.5545050243264859, 'alpha': 65, 'iterations': 37, 'learning_rate': 0.0007471395523408068, 'p_miss': 0.1335146888370259}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:38:51,876] Trial 11 finished with value: 0.20051285317777742 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:40:51,548] Trial 110 finished with value: 0.098913983826938 and parameters: {'model_name': 'VAE', 'batch_size': 577, 'iterations': 38, 'learning_rate': 0.0006103385414010855, 'p_miss': 0.17283221392349263}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:41:11,397] Trial 113 finished with value: 0.19794560745369405 and parameters: {'model_name': 'VAE', 'batch_size': 351, 'iterations': 23, 'learning_rate': 0.002716300962341, 'p_miss': 0.17399392680280135}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:41:17,926] Trial 43 finished with value: 0.2199637592550842 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1932, 'learning_rate': 0.0006759954758692487, 'p_miss': 0.2685883444918922}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:41:50,487] Trial 116 finished with value: 0.09755318998818227 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 8, 'learning_rate': 0.00149534653945922, 'p_miss': 0.21694969966229694}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:42:12,780] Trial 117 finished with value: 0.1125797161250498 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 5, 'learning_rate': 0.008609808378614456, 'p_miss': 0.15757508597606573}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:42:21,974] Trial 47 finished with value: 0.21866602526468476 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1845, 'learning_rate': 0.0021366745578552883, 'p_miss': 0.016639127673542}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:42:29,787] Trial 118 finished with value: 0.09860766077629422 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 3, 'learning_rate': 0.0012966041269367055, 'p_miss': 0.18582488657503712}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:43:04,194] Trial 114 finished with value: 0.17693204649447103 and parameters: {'model_name': 'VAE', 'batch_size': 289, 'iterations': 22, 'learning_rate': 0.0030105197870225597, 'p_miss': 0.15229722845195592}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:43:46,587] Trial 35 finished with value: 0.22025904890910644 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2334, 'learning_rate': 0.0008934331472742953, 'p_miss': 0.011485434183626037}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:44:33,882] Trial 122 finished with value: 0.09502700123923678 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 10, 'learning_rate': 0.0011559145642992845, 'p_miss': 0.2252795303505744}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 17:51:04,721] Trial 41 finished with value: 0.21798275357256722 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2126, 'learning_rate': 0.0005340142510692008, 'p_miss': 0.08673255206307198}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:10:44,142] Trial 45 finished with value: 0.21971894243548373 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2495, 'learning_rate': 0.00062202975529279, 'p_miss': 0.08763253744053622}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:19:05,836] Trial 112 finished with value: 0.22106458136023055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:19:53,775] Trial 115 finished with value: 0.22152260358846507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:19:56,343] Trial 126 finished with value: 0.09707663176580072 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 10, 'learning_rate': 0.001635001607420246, 'p_miss': 0.1971622406703516}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:20:53,281] Trial 128 finished with value: 0.09487140633905812 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 14, 'learning_rate': 0.0011324983282926756, 'p_miss': 0.22692651016176257}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:21:33,597] Trial 120 finished with value: 0.2215775833997838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:22:21,215] Trial 119 finished with value: 0.22138563684534063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:22:22,450] Trial 130 finished with value: 0.09958789156018436 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 14, 'learning_rate': 0.0012024454699950593, 'p_miss': 0.22996061898987713}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:23:11,625] Trial 131 finished with value: 0.09724902613140654 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 14, 'learning_rate': 0.0011416401051644312, 'p_miss': 0.2257563488284543}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:24:31,783] Trial 132 finished with value: 0.1021448089666566 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 29, 'learning_rate': 0.0008791803303780087, 'p_miss': 0.2511220235225028}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:25:02,434] Trial 134 finished with value: 0.0977372300417592 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 9, 'learning_rate': 0.0003271560385595796, 'p_miss': 0.2176508382131001}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:26:23,482] Trial 133 finished with value: 0.10535878102173653 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 51, 'learning_rate': 0.0008514455792599611, 'p_miss': 0.21414598686924888}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:26:49,702] Trial 136 finished with value: 0.09887027670474743 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 6, 'learning_rate': 0.001538913524397852, 'p_miss': 0.24978598461506565}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:30:18,034] Trial 135 finished with value: 0.2131499064030224 and parameters: {'model_name': 'VAE', 'batch_size': 769, 'iterations': 54, 'learning_rate': 0.002194891264347939, 'p_miss': 0.20751366847532077}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:30:18,323] Trial 124 finished with value: 0.22191288471444937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:30:34,353] Trial 139 finished with value: 0.09630780695595272 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 4, 'learning_rate': 0.0010546590237348328, 'p_miss': 0.19899438449806797}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:35:40,131] Trial 140 finished with value: 0.18967568391451536 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 103, 'learning_rate': 0.0010244474295772433, 'p_miss': 0.1844043084318341}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:35:58,166] Trial 141 finished with value: 0.09765454659623347 and parameters: {'model_name': 'VAE', 'batch_size': 102, 'iterations': 4, 'learning_rate': 0.0007171585969066134, 'p_miss': 0.19560070327804013}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:45:28,885] Trial 121 finished with value: 0.2091605507054548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:45:55,130] Trial 143 finished with value: 0.10379415630637541 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 7, 'learning_rate': 0.0005544051082798825, 'p_miss': 0.17413179853894112}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:46:06,329] Trial 144 finished with value: 0.09794066044047814 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 3, 'learning_rate': 0.0009599625103724231, 'p_miss': 0.2026023875989464}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:46:16,820] Trial 123 finished with value: 0.20988164329761072 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:46:19,639] Trial 145 finished with value: 0.34773888993546853 and parameters: {'model_name': 'GAIN', 'batch_size': 82, 'hint_rate': 0.3307713525128697, 'alpha': 3, 'iterations': 5, 'learning_rate': 0.00010519936547367982, 'p_miss': 0.23174260224057708}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:46:35,003] Trial 146 finished with value: 0.09898151098252612 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 5, 'learning_rate': 0.0014918965355774087, 'p_miss': 0.2301313503292906}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:46:49,504] Trial 147 finished with value: 0.09411792865878602 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 10, 'learning_rate': 0.0014591262798291883, 'p_miss': 0.2111582088200887}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:47:22,739] Trial 148 finished with value: 0.09269641827486623 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 12, 'learning_rate': 0.0011605887379971915, 'p_miss': 0.21238288461566632}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:47:31,956] Trial 149 finished with value: 0.09598118331363031 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 11, 'learning_rate': 0.0017912367139692011, 'p_miss': 0.21318941934126473}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:48:18,046] Trial 150 finished with value: 0.09476100354415172 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 17, 'learning_rate': 0.0011534208376459028, 'p_miss': 0.21385595886278858}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:48:33,370] Trial 151 finished with value: 0.09678166424426979 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 17, 'learning_rate': 0.0012391222579295025, 'p_miss': 0.20969207522223973}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:49:18,299] Trial 153 finished with value: 0.09981544459947422 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 13, 'learning_rate': 0.0007817101378241676, 'p_miss': 0.22255834598768484}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:49:34,334] Trial 152 finished with value: 0.09453462353179311 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 20, 'learning_rate': 0.0012267173450900956, 'p_miss': 0.2120339734488216}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:49:35,023] Trial 155 finished with value: 0.20289280969658177 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:50:20,903] Trial 154 finished with value: 0.1053535639654638 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 20, 'learning_rate': 0.0023417823306864367, 'p_miss': 0.21497710468608333}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:50:49,937] Trial 156 finished with value: 0.11557157073756433 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 25, 'learning_rate': 0.002214309928014032, 'p_miss': 0.2120607122544532}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:50:51,287] Trial 157 finished with value: 0.09262047037977791 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 9, 'learning_rate': 0.0011716877336962234, 'p_miss': 0.2121890982904323}. Best is trial 61 with value: 0.09217661623354771.
running
[I 2024-11-13 18:51:23,412] Trial 159 finished with value: 0.09190548939585938 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 8, 'learning_rate': 0.0011803712997386115, 'p_miss': 0.22204243000423027}. Best is trial 159 with value: 0.09190548939585938.
running
[I 2024-11-13 18:52:51,610] Trial 158 finished with value: 0.1221331065471313 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 30, 'learning_rate': 0.0013611930315881875, 'p_miss': 0.22054154448248062}. Best is trial 159 with value: 0.09190548939585938.
running
[I 2024-11-13 18:53:18,865] Trial 161 finished with value: 0.09436206581561044 and parameters: {'model_name': 'VAE', 'batch_size': 142, 'iterations': 7, 'learning_rate': 0.0011573290966419485, 'p_miss': 0.233986024531739}. Best is trial 159 with value: 0.09190548939585938.
running
[I 2024-11-13 18:53:53,393] Trial 162 finished with value: 0.09294682004443801 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 8, 'learning_rate': 0.0016721252203983773, 'p_miss': 0.23696815549028374}. Best is trial 159 with value: 0.09190548939585938.
running
[I 2024-11-13 18:54:28,172] Trial 163 finished with value: 0.09134014012677727 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 8, 'learning_rate': 0.0016363292354758775, 'p_miss': 0.2546554982122228}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:55:13,279] Trial 164 finished with value: 0.09430984893175356 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 8, 'learning_rate': 0.0016157882327564415, 'p_miss': 0.2547664344626376}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:55:53,520] Trial 165 finished with value: 0.09370253654749713 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 8, 'learning_rate': 0.0016794182739504903, 'p_miss': 0.26478584329783605}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:56:28,479] Trial 166 finished with value: 0.09425961917960238 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 8, 'learning_rate': 0.0014615598602192698, 'p_miss': 0.2640589147971266}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:56:53,651] Trial 167 finished with value: 0.09401440780940967 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 8, 'learning_rate': 0.0016384260516653822, 'p_miss': 0.2585464691844336}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:57:30,465] Trial 168 finished with value: 0.09543659800556088 and parameters: {'model_name': 'VAE', 'batch_size': 115, 'iterations': 8, 'learning_rate': 0.0016837323009176984, 'p_miss': 0.24450186621434272}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:58:10,522] Trial 169 finished with value: 0.09599415593394531 and parameters: {'model_name': 'VAE', 'batch_size': 179, 'iterations': 8, 'learning_rate': 0.001923430268615765, 'p_miss': 0.26682382100040625}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 18:58:39,148] Trial 170 finished with value: 0.09256892584912638 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 9, 'learning_rate': 0.0026013687492516748, 'p_miss': 0.26742532436387445}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:08:42,029] Trial 125 finished with value: 0.2066569990126475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:09:10,869] Trial 172 finished with value: 0.09814113955567023 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 6, 'learning_rate': 0.0028883267758438593, 'p_miss': 0.28294850873044036}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:09:19,646] Trial 173 finished with value: 0.20276551576344742 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4197, 'weights': 'uniform'}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:09:55,121] Trial 174 finished with value: 0.09333281828316001 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 9, 'learning_rate': 0.002327326293472019, 'p_miss': 0.26507943486724006}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:10:32,232] Trial 175 finished with value: 0.0954260335316874 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 10, 'learning_rate': 0.0022975378019017, 'p_miss': 0.27681652737375845}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:11:16,276] Trial 176 finished with value: 0.1246498483595194 and parameters: {'model_name': 'VAE', 'batch_size': 115, 'iterations': 9, 'learning_rate': 0.0038566324332420386, 'p_miss': 0.26607677983021877}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:11:44,060] Trial 177 finished with value: 0.09386243196068753 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 6, 'learning_rate': 0.0024926244408930705, 'p_miss': 0.2600730517571504}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:12:15,017] Trial 178 finished with value: 0.09661565737224646 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 6, 'learning_rate': 0.0026314449011658877, 'p_miss': 0.28868934348503045}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:13:21,066] Trial 179 finished with value: 0.13965150014234393 and parameters: {'model_name': 'VAE', 'batch_size': 214, 'iterations': 12, 'learning_rate': 0.0032265056456560097, 'p_miss': 0.2617314464122287}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:13:52,930] Trial 180 finished with value: 0.09518379938468931 and parameters: {'model_name': 'VAE', 'batch_size': 210, 'iterations': 5, 'learning_rate': 0.001984847645896169, 'p_miss': 0.2585905903227922}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:14:14,543] Trial 181 finished with value: 0.09366218332887746 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 7, 'learning_rate': 0.0024588315607649122, 'p_miss': 0.26993061939597407}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:14:28,377] Trial 182 finished with value: 0.3427281922188705 and parameters: {'model_name': 'GAIN', 'batch_size': 77, 'hint_rate': 0.7793684611494088, 'alpha': 31, 'iterations': 7, 'learning_rate': 0.0025325496181391716, 'p_miss': 0.2707277181797394}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:14:56,197] Trial 183 finished with value: 0.0996560268923801 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 6, 'learning_rate': 0.0043430023222806435, 'p_miss': 0.27313603637542805}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:15:37,952] Trial 184 finished with value: 0.09483873822767837 and parameters: {'model_name': 'VAE', 'batch_size': 105, 'iterations': 12, 'learning_rate': 0.002121656160337903, 'p_miss': 0.2557335750403085}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:16:20,811] Trial 185 finished with value: 0.10718817042132278 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 9, 'learning_rate': 0.003001380167545044, 'p_miss': 0.24597215760231667}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:16:52,432] Trial 186 finished with value: 0.09883614795971492 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 10, 'learning_rate': 0.0001646742022403645, 'p_miss': 0.2811853281220517}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:17:38,292] Trial 187 finished with value: 0.0930268601725682 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 15, 'learning_rate': 0.0017899343776378212, 'p_miss': 0.2602433728062258}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:18:51,628] Trial 188 finished with value: 0.1041234481355668 and parameters: {'model_name': 'VAE', 'batch_size': 148, 'iterations': 15, 'learning_rate': 0.0017404853569984904, 'p_miss': 0.2399288995792689}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:10,551] Trial 34 finished with value: 0.22700465459725683 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3820, 'learning_rate': 0.0005203220033439882, 'p_miss': 0.011196567915312124}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:17,468] Trial 189 finished with value: 0.09794001802184873 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 7, 'learning_rate': 0.00021321960937775353, 'p_miss': 0.2595160274318331}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:35,064] Trial 190 finished with value: 0.09352647910558876 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 7, 'learning_rate': 0.0019406526619164476, 'p_miss': 0.2522058802637594}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:40,020] Trial 191 finished with value: 0.09537754343134656 and parameters: {'model_name': 'VAE', 'batch_size': 128, 'iterations': 5, 'learning_rate': 0.002446774921047849, 'p_miss': 0.24921233656162936}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:40,378] Trial 193 finished with value: 0.3830582651968245 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:19:45,767] Trial 32 finished with value: 0.21789418279461872 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3749, 'learning_rate': 0.0010919895414209086, 'p_miss': 0.022206649647444746}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:20:06,239] Trial 192 finished with value: 0.09389614004624655 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 5, 'learning_rate': 0.0023552704920524127, 'p_miss': 0.24837377567272748}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:20:09,560] Trial 194 finished with value: 0.09424151398385133 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 6, 'learning_rate': 0.0019059404707064123, 'p_miss': 0.2754910684181098}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:20:14,379] Trial 195 finished with value: 0.09414932651550596 and parameters: {'model_name': 'VAE', 'batch_size': 255, 'iterations': 6, 'learning_rate': 0.001846642523392701, 'p_miss': 0.2536469100726657}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:20:27,539] Trial 196 finished with value: 0.097506142943634 and parameters: {'model_name': 'VAE', 'batch_size': 258, 'iterations': 6, 'learning_rate': 0.0019726225682149346, 'p_miss': 0.25570324815277984}. Best is trial 163 with value: 0.09134014012677727.
running
[I 2024-11-13 19:20:28,501] Trial 197 finished with value: 0.09906927488882275 and parameters: {'model_name': 'VAE', 'batch_size': 248, 'iterations': 4, 'learning_rate': 0.002166296001525677, 'p_miss': 0.25423263102571153}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 19:20:48,723] Trial 199 finished with value: 0.09542905473233099 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 4, 'learning_rate': 0.002674856965007632, 'p_miss': 0.26575820452862514}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 19:31:57,865] Trial 42 finished with value: 0.21699321139714614 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3680, 'learning_rate': 0.0006769551901192585, 'p_miss': 0.2682469365315259}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 19:32:44,147] Trial 12 finished with value: 0.21169394086296361 and parameters: {'model_name': 'VAE', 'batch_size': 654, 'iterations': 3530, 'learning_rate': 0.023790585288476593, 'p_miss': 0.010720190699342377}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 20:45:56,655] Trial 160 finished with value: 0.21038014284336654 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 3316, 'learning_rate': 0.0014262489501074176, 'p_miss': 0.22201729824691913}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 20:54:44,029] Trial 127 finished with value: 0.21543406206730326 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 3985, 'learning_rate': 0.0010851048955299526, 'p_miss': 0.2306105647375376}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 20:55:30,567] Trial 171 finished with value: 0.2110808825745331 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 3389, 'learning_rate': 0.0025623763470239897, 'p_miss': 0.2750429972715317}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:07:19,410] Trial 138 finished with value: 0.21272162031042557 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 4968, 'learning_rate': 0.0010307604783425742, 'p_miss': 0.19737311045536626}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:10:41,111] Trial 129 finished with value: 0.21983269315924883 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 4321, 'learning_rate': 0.0011268023915516816, 'p_miss': 0.23043145269803214}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:13:01,440] Trial 39 finished with value: 0.2187263190928565 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8440, 'learning_rate': 0.001735141293127188, 'p_miss': 0.015384933688234556}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:16:55,768] Trial 109 finished with value: 0.21507713493104347 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 5230, 'learning_rate': 0.00926156182783265, 'p_miss': 0.2158598325178395}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:20:29,007] Trial 137 finished with value: 0.2122848616958178 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 5964, 'learning_rate': 0.0022617297722626467, 'p_miss': 0.20021447486183938}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:22:02,431] Trial 97 finished with value: 0.21196517951208543 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 7870, 'learning_rate': 0.0017372521036325688, 'p_miss': 0.12851192234836817}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:23:56,491] Trial 107 finished with value: 0.2157319676810158 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6952, 'learning_rate': 0.0006548178382589933, 'p_miss': 0.1514658746760463}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:24:01,688] Trial 198 finished with value: 0.2109609018579318 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 6785, 'learning_rate': 0.0022708185523591545, 'p_miss': 0.2605147752001018}. Best is trial 163 with value: 0.09134014012677727.
[I 2024-11-13 21:24:37,173] Trial 142 finished with value: 0.21265702788299512 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 8967, 'learning_rate': 0.000544510909059149, 'p_miss': 0.17088565481254617}. Best is trial 163 with value: 0.09134014012677727.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.09134014012677727
{'model_name': 'VAE', 'batch_size': 122, 'iterations': 8, 'learning_rate': 0.0016363292354758775, 'p_miss': 0.2546554982122228}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5241877183853474
Generation:   4%|         | 1/25 [02:25<58:03, 145.14s/it]Generation:  2
Best f1_score score: 0.5313251287133424
Generation:   8%|         | 2/25 [02:54<29:34, 77.15s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747105b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.5313251287133424
Generation:  12%|        | 3/25 [04:05<27:13, 74.24s/it]Generation:  4
Best f1_score score: 0.5313251287133424
Generation:  16%|        | 4/25 [05:14<25:14, 72.12s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467bc2da0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465981f30> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.5313251287133424
Generation:  20%|        | 5/25 [05:46<19:13, 57.66s/it]Generation:  6
Best f1_score score: 0.5313251287133424
Generation:  24%|       | 6/25 [06:36<17:23, 54.94s/it]Generation:  7
Best f1_score score: 0.5313251287133424
Generation:  28%|       | 7/25 [08:02<19:36, 65.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b28220> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5313251287133424
Generation:  32%|      | 8/25 [08:50<16:57, 59.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679db460> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5313251287133424
Generation:  36%|      | 9/25 [10:15<18:01, 67.57s/it]Generation:  10
Best f1_score score: 0.5313251287133424
Generation:  40%|      | 10/25 [10:45<13:58, 55.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fd5060> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5313251287133424
Generation:  44%|     | 11/25 [13:06<19:08, 82.04s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474733730> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.5313251287133424
Generation:  48%|     | 12/25 [14:13<16:47, 77.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474732050> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  13
Best f1_score score: 0.5313251287133424
Generation:  52%|    | 13/25 [15:31<15:32, 77.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465964520> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465799ea0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.5313251287133424
Generation:  56%|    | 14/25 [16:27<13:00, 70.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465947250> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5313251287133424
Generation:  60%|    | 15/25 [17:05<10:11, 61.11s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679523e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1ae0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546795c820> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5313251287133424
Generation:  64%|   | 16/25 [18:10<09:19, 62.15s/it]Generation:  17
Best f1_score score: 0.5313251287133424
Generation:  68%|   | 17/25 [19:42<09:29, 71.19s/it]Generation:  18
Best f1_score score: 0.5313251287133424
Generation:  72%|  | 18/25 [20:51<08:14, 70.70s/it]Generation:  19
Best f1_score score: 0.5313251287133424
Generation:  76%|  | 19/25 [21:55<06:51, 68.53s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679bda20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.5313251287133424
Generation:  80%|  | 20/25 [22:30<04:52, 58.40s/it]Generation:  21
Best f1_score score: 0.5313251287133424
Generation:  84%| | 21/25 [22:45<03:02, 45.59s/it]Generation:  22
Best f1_score score: 0.5313251287133424
Generation:  88%| | 22/25 [23:48<02:31, 50.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff8700> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.5325730986996907
Generation:  92%|| 23/25 [24:44<01:44, 52.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554645a5b40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5325730986996907
Generation:  96%|| 24/25 [26:11<01:02, 62.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f24550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.5325730986996907
Generation: 100%|| 25/25 [26:28<00:00, 49.14s/it]Generation: 100%|| 25/25 [26:31<00:00, 63.68s/it]
2024-11-13 21:51:22,611 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33481' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-2b44a1a69ec1831ab8f5b2671238e9b8', 'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8'} (stimulus_id='handle-worker-cleanup-1731563482.6112103')
Fitted
Pipeline(steps=[('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.0157833055022,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0418367851071, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=12,
                               max_leaves=None, min_child_weight=14,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100, n_jobs=1,
                               nthread=1, num_parallel_tree=None, ...))])
score start
train score: {'auroc': 0.9295653493036392, 'accuracy': 0.847972972972973, 'balanced_accuracy': 0.8478458316225796, 'logloss': 0.5475050104424027, 'f1': 0.8479040736016396}
original test score: {'auroc': 0.5931027429408402, 'accuracy': 0.575, 'balanced_accuracy': 0.5732680608746947, 'logloss': 0.6808611085736724, 'f1': 0.559340117838129}
imputed test score: {'auroc': 0.4815606217503027, 'accuracy': 0.48783783783783785, 'balanced_accuracy': 0.4876130260012309, 'logloss': 0.7171601597757518, 'f1': 0.4874250446396752}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd0940> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd0af0> 

Generation:  1
Best f1_score score: 0.8709208551871963
Generation:   4%|         | 1/25 [10:03<4:01:22, 603.46s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d21d50> 

Generation:  2
Best f1_score score: 0.8780959161131552
Generation:   8%|         | 2/25 [20:07<3:51:22, 603.57s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d56770> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d559c0> 

Generation:  3
Best f1_score score: 0.8840390226887349
Generation:  12%|        | 3/25 [30:12<3:41:35, 604.35s/it]Generation:  4
Best f1_score score: 0.8940691427165224
Generation:  16%|        | 4/25 [32:58<2:30:57, 431.31s/it]Generation:  5
Best f1_score score: 0.8940691427165224
Generation:  20%|        | 5/25 [33:35<1:36:21, 289.08s/it]Generation:  6
Best f1_score score: 0.8940691427165224
Generation:  24%|       | 6/25 [35:13<1:11:00, 224.21s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155386f26110> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d22110> 

Generation:  7
Best f1_score score: 0.8970593028298659
Generation:  28%|       | 7/25 [45:18<1:44:34, 348.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fed5360> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1db70> 

Generation:  8
Best f1_score score: 0.8970593028298659
Generation:  32%|      | 8/25 [55:24<2:02:01, 430.68s/it]Generation:  9
Best f1_score score: 0.9007631121719463
Generation:  36%|      | 9/25 [57:37<1:30:02, 337.64s/it]Generation:  10
Best f1_score score: 0.9007631121719463
Generation:  40%|      | 10/25 [58:35<1:02:49, 251.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545d128b80> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  11
Best f1_score score: 0.9007631121719463
Generation:  44%|     | 11/25 [1:00:49<50:14, 215.32s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545d970430> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455062680> 

Generation:  12
Best f1_score score: 0.9007631121719463
Generation:  48%|     | 12/25 [1:10:57<1:12:30, 334.66s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15535b3fa380> 

Generation:  13
Best f1_score score: 0.9007631121719463
Generation:  52%|    | 13/25 [1:21:05<1:23:31, 417.62s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d38a00> 

Generation:  14
Best f1_score score: 0.9007631121719463
Generation:  56%|    | 14/25 [1:31:13<1:27:06, 475.14s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155432a94ac0> 

Generation:  15
Best f1_score score: 0.9016285932666713
Generation:  60%|    | 15/25 [1:41:21<1:25:52, 515.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545538ca00> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  16
Best f1_score score: 0.9016285932666713
Generation:  64%|   | 16/25 [1:45:30<1:05:14, 434.91s/it]Generation:  17
Best f1_score score: 0.9016285932666713
Generation:  68%|   | 17/25 [1:47:44<45:57, 344.65s/it]  Generation:  18
Best f1_score score: 0.9016285932666713
Generation:  72%|  | 18/25 [1:49:36<32:01, 274.55s/it]Generation:  19
Best f1_score score: 0.9042335454971717
Generation:  76%|  | 19/25 [1:51:55<23:23, 233.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454604790> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.9042335454971717
Generation:  80%|  | 20/25 [1:54:35<17:38, 211.68s/it]Generation:  21
Best f1_score score: 0.9088120636540289
Generation:  84%| | 21/25 [1:56:54<12:39, 189.76s/it]Generation:  22
Best f1_score score: 0.9088120636540289
Generation:  88%| | 22/25 [1:59:32<09:01, 180.42s/it]Generation:  23
Best f1_score score: 0.9088120636540289
Generation:  92%|| 23/25 [2:01:57<05:39, 169.64s/it]Generation:  24
Best f1_score score: 0.9088120636540289
Generation:  96%|| 24/25 [2:03:50<02:32, 152.65s/it]Generation:  25
Best f1_score score: 0.9088120636540289
Generation: 100%|| 25/25 [2:04:47<00:00, 123.98s/it]Generation: 100%|| 25/25 [2:04:47<00:00, 299.49s/it]
2024-11-13 23:56:22,211 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42229' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-7fa97c02c8c51eacccbef58c9b033c88', 'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8'} (stimulus_id='handle-worker-cleanup-1731570982.211757')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='most_frequent')),
                ('adaboostclassifier',
                 AdaBoostClassifier(learning_rate=0.2752350031416,
                                    n_estimators=415))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9807237021358536, 'accuracy': 0.9298986486486487, 'balanced_accuracy': 0.9295625527422909, 'logloss': 0.6609165257357851, 'f1': 0.9297662850781572}
test score: {'auroc': 0.9532372326961324, 'accuracy': 0.8945945945945946, 'balanced_accuracy': 0.8941377150256322, 'logloss': 0.6633094758414004, 'f1': 0.894253951736419}
original test score: {'auroc': 0.9948096159079245, 'accuracy': 0.9655405405405405, 'balanced_accuracy': 0.9657228276452787, 'logloss': 0.6323130708651229, 'f1': 0.9655370004679991}
score end
1496
lvl
0.5
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
7.833466253942913
hours
DONE
