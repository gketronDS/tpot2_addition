Run: 60
/cm/local/apps/slurm/var/spool/job1069287/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MNAR_0.5_3
3.4455020427703857
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 19:32:33,066] A new study created in memory with name: no-name-6c92778a-f52a-454b-b04f-e8765489a36e
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 19:32:33,508] Trial 0 finished with value: 0.31865685123168086 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:34,331] Trial 8 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:34,720] Trial 7 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:35,007] Trial 2 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:35,219] Trial 5 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:35,665] Trial 12 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:36,034] Trial 18 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:36,353] Trial 21 finished with value: 0.31865685123168086 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:36,504] Trial 19 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:36,799] Trial 23 finished with value: 0.31865685123168086 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:48,696] Trial 10 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6144931878221161, 'alpha': 23, 'iterations': 4, 'learning_rate': 0.0014119221530315262, 'p_miss': 0.039579977357142235}. Best is trial 0 with value: 0.31865685123168086.
running
[I 2024-11-22 19:32:51,168] Trial 24 finished with value: 0.2635619682648208 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.008203821139365353, 'p_miss': 0.06463034183086837}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:32:57,600] Trial 27 finished with value: 0.2956193707615142 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 1, 'learning_rate': 0.06277443484927908, 'p_miss': 0.12931754008122281}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:03,313] Trial 28 finished with value: 0.2908899923518521 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 1, 'learning_rate': 0.07138894292249791, 'p_miss': 0.12190816356559117}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:07,882] Trial 4 finished with value: 0.31865685123168086 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32216, 'weights': 'uniform'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:10,302] Trial 16 finished with value: 0.3137576629195816 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14456, 'weights': 'uniform'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:12,601] Trial 11 finished with value: 0.32499994589413483 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9184, 'weights': 'distance'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:13,293] Trial 1 finished with value: 0.45911598176853535 and parameters: {'model_name': 'GAIN', 'batch_size': 107, 'hint_rate': 0.306829375324143, 'alpha': 87, 'iterations': 22, 'learning_rate': 0.00038584973061114327, 'p_miss': 0.04826208182925952}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:20,078] Trial 9 finished with value: 0.3250107837817827 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30805, 'weights': 'distance'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:20,835] Trial 14 finished with value: 0.3250107837817827 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32285, 'weights': 'distance'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:22,183] Trial 20 finished with value: 0.3250107837817827 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32822, 'weights': 'distance'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:25,364] Trial 36 finished with value: 0.30123558555100266 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 1, 'learning_rate': 0.08035889159395858, 'p_miss': 0.16101446933319039}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:27,901] Trial 37 finished with value: 0.2671290113951251 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.05512582064068606, 'p_miss': 0.10865639194019033}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:33,719] Trial 26 finished with value: 0.3137273764683444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:33:36,629] Trial 22 finished with value: 0.40405078304149444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:35:38,491] Trial 13 finished with value: 0.4538388646208906 and parameters: {'model_name': 'GAIN', 'batch_size': 696, 'hint_rate': 0.467797265236079, 'alpha': 2, 'iterations': 124, 'learning_rate': 0.009734360618539568, 'p_miss': 0.23232438792515886}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:37:23,453] Trial 3 finished with value: 0.36711203230802136 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 115, 'learning_rate': 0.06671468138466069, 'p_miss': 0.08670943654335202}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:47:32,526] Trial 15 finished with value: 0.3138153008626347 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 19:50:04,848] Trial 25 finished with value: 0.31078988870959423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 20:00:06,246] Trial 17 finished with value: 0.3138168924901776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 20:26:56,336] Trial 6 finished with value: 0.4557503125169345 and parameters: {'model_name': 'GAIN', 'batch_size': 185, 'hint_rate': 0.7174977628007364, 'alpha': 40, 'iterations': 2169, 'learning_rate': 0.003408288266589725, 'p_miss': 0.2005886105676297}. Best is trial 24 with value: 0.2635619682648208.
running
[I 2024-11-22 20:27:01,445] Trial 46 finished with value: 0.26225062054422343 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.03193700633940188, 'p_miss': 0.1147390256962425}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:27:09,699] Trial 47 finished with value: 0.26235447630219183 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.01851891499546776, 'p_miss': 0.11773946038675666}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:27:27,920] Trial 48 finished with value: 0.2649707393444981 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.012719386004974876, 'p_miss': 0.09256966403706213}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:28:00,838] Trial 49 finished with value: 0.2835855225642048 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7, 'learning_rate': 0.013477769372034548, 'p_miss': 0.07446557842849286}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:28:22,571] Trial 50 finished with value: 0.2673760983533782 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 5, 'learning_rate': 0.013517864596967577, 'p_miss': 0.012532212363590589}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:28:35,311] Trial 51 finished with value: 0.26494218133440955 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.014145178140540806, 'p_miss': 0.29739916893564267}. Best is trial 46 with value: 0.26225062054422343.
running
[I 2024-11-22 20:28:40,581] Trial 52 finished with value: 0.26099727442073367 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.026887576665989867, 'p_miss': 0.2998718451461927}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:28:47,135] Trial 53 finished with value: 0.2645271953958407 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.025788231311275122, 'p_miss': 0.159719499904316}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:29:45,530] Trial 54 finished with value: 0.26581510002445674 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 20, 'learning_rate': 0.004727124224202701, 'p_miss': 0.2925934012820308}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:29:57,287] Trial 55 finished with value: 0.27585268933631807 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2, 'learning_rate': 0.028888260896092886, 'p_miss': 0.1942452572105903}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:30:02,872] Trial 56 finished with value: 0.2651050504302696 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 1, 'learning_rate': 0.02913752623532209, 'p_miss': 0.15123099122126155}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:30:10,532] Trial 57 finished with value: 0.26619790647467645 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.029068259044476057, 'p_miss': 0.2625628998415712}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:30:19,033] Trial 58 finished with value: 0.2620191597334053 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.006374862994083756, 'p_miss': 0.14767295359192584}. Best is trial 52 with value: 0.26099727442073367.
running
[I 2024-11-22 20:30:26,523] Trial 59 finished with value: 0.2602808685835928 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.005696186869196236, 'p_miss': 0.13706376932159164}. Best is trial 59 with value: 0.2602808685835928.
running
[I 2024-11-22 20:30:56,806] Trial 60 finished with value: 0.2600336225051628 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 10, 'learning_rate': 0.001990359550368066, 'p_miss': 0.13739990843187588}. Best is trial 60 with value: 0.2600336225051628.
running
[I 2024-11-22 20:31:01,660] Trial 61 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.06568993637415221, 'alpha': 99, 'iterations': 14, 'learning_rate': 0.0013267375404889586, 'p_miss': 0.14527578935257116}. Best is trial 60 with value: 0.2600336225051628.
running
[I 2024-11-22 20:31:46,400] Trial 62 finished with value: 0.2630257702425977 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.0018363326254633235, 'p_miss': 0.1840933055454822}. Best is trial 60 with value: 0.2600336225051628.
running
[I 2024-11-22 20:31:53,062] Trial 63 finished with value: 0.25926912472507013 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.005323363411884344, 'p_miss': 0.17759244449919218}. Best is trial 63 with value: 0.25926912472507013.
running
[I 2024-11-22 20:33:41,001] Trial 64 finished with value: 0.2912608019621562 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 37, 'learning_rate': 0.005552708662022636, 'p_miss': 0.22078117188493585}. Best is trial 63 with value: 0.25926912472507013.
running
[I 2024-11-22 20:33:47,912] Trial 65 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.940605977444593, 'alpha': 68, 'iterations': 2, 'learning_rate': 0.0006622073828505934, 'p_miss': 0.1810034029559633}. Best is trial 63 with value: 0.25926912472507013.
running
[I 2024-11-22 20:33:57,672] Trial 66 finished with value: 0.2589226987199777 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0028571774576202076, 'p_miss': 0.1376656197187894}. Best is trial 66 with value: 0.2589226987199777.
running
[I 2024-11-22 20:34:08,236] Trial 67 finished with value: 0.25929176038941604 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.002469934276666617, 'p_miss': 0.14061829197415354}. Best is trial 66 with value: 0.2589226987199777.
running
[I 2024-11-22 20:34:30,891] Trial 68 finished with value: 0.26054467299073414 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7, 'learning_rate': 0.0001080232854269521, 'p_miss': 0.13484333849677774}. Best is trial 66 with value: 0.2589226987199777.
running
[I 2024-11-22 20:34:54,147] Trial 69 finished with value: 0.25750936845972305 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7, 'learning_rate': 0.000195735893829517, 'p_miss': 0.16986911011040376}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:35:05,955] Trial 70 finished with value: 0.25982666751123706 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0026346354375188885, 'p_miss': 0.16708873963626156}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:37:48,941] Trial 71 finished with value: 0.2724985519740051 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 60, 'learning_rate': 0.0025684375202123396, 'p_miss': 0.17034732074383493}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:38:04,852] Trial 72 finished with value: 0.30920789116041447 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 799, 'weights': 'uniform'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:38:39,937] Trial 38 finished with value: 0.35949572996534673 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1424, 'learning_rate': 0.015557944091270304, 'p_miss': 0.0978475350253676}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:38:45,989] Trial 74 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9886502545813757, 'alpha': 58, 'iterations': 8, 'learning_rate': 0.000793149011627405, 'p_miss': 0.20787384829406247}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:38:54,877] Trial 75 finished with value: 0.2606280179112914 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.003496009843817747, 'p_miss': 0.17309635023818865}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:39:02,788] Trial 76 finished with value: 0.2608639033951844 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0028366621462837037, 'p_miss': 0.1409611196553534}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 20:39:14,183] Trial 77 finished with value: 0.26052931128272727 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0001414835330448369, 'p_miss': 0.1627495580252308}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:02:35,141] Trial 78 finished with value: 0.3242155851296096 and parameters: {'model_name': 'VAE', 'batch_size': 235, 'iterations': 409, 'learning_rate': 0.001682466361535485, 'p_miss': 0.13409459855345718}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:02:50,323] Trial 79 finished with value: 0.2608097209549025 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5, 'learning_rate': 0.00022698012266817553, 'p_miss': 0.18892761294560861}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:02:58,871] Trial 80 finished with value: 0.2601113257082235 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.000991312841038591, 'p_miss': 0.13029015547239808}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:06,666] Trial 81 finished with value: 0.3110282003878377 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:09,042] Trial 73 finished with value: 0.31649581671890553 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 568, 'learning_rate': 0.0007075962876551742, 'p_miss': 0.20618065002209435}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:29,185] Trial 82 finished with value: 0.3163070584812795 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21848, 'weights': 'uniform'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:29,862] Trial 84 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:31,637] Trial 83 finished with value: 0.316697731458606 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22824, 'weights': 'uniform'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:33,176] Trial 34 finished with value: 0.3294137463672885 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1727, 'learning_rate': 0.05119396291137136, 'p_miss': 0.17268319850584962}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:40,183] Trial 86 finished with value: 0.2611449291264411 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.003745619337438681, 'p_miss': 0.1273964292663328}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:42,117] Trial 87 finished with value: 0.2627458329241268 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0042793533347073, 'p_miss': 0.12712863425058235}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:03:51,302] Trial 88 finished with value: 0.26082838493683447 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.002223663145429113, 'p_miss': 0.15745097629857505}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:04:00,625] Trial 89 finished with value: 0.26050318539006634 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0022353148418595855, 'p_miss': 0.15275282170873106}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:04:19,918] Trial 85 finished with value: 0.2609243283435375 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 13, 'learning_rate': 0.0010837949669727537, 'p_miss': 0.10314541529601289}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:04:39,014] Trial 92 finished with value: 0.2625585983641673 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.0004229199272343563, 'p_miss': 0.11866506612887606}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:04:46,448] Trial 31 finished with value: 0.3273460842936301 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1818, 'learning_rate': 0.07232602311350177, 'p_miss': 0.10721150007983234}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:17,094] Trial 93 finished with value: 0.32967420691717253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:24,780] Trial 94 finished with value: 0.32967420691717253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:35,950] Trial 95 finished with value: 0.26417773257429505 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 7, 'learning_rate': 0.007459316736564277, 'p_miss': 0.16951556858941297}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:41,032] Trial 96 finished with value: 0.26456086349685526 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.007852390665743643, 'p_miss': 0.1442372751411646}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:47,938] Trial 97 finished with value: 0.26093670869684826 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.002137275680461038, 'p_miss': 0.1445525642206473}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:51,849] Trial 98 finished with value: 0.26221993137071153 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.002021761644336757, 'p_miss': 0.15535623875128848}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:57,052] Trial 99 finished with value: 0.2627559464002467 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0030982446788900176, 'p_miss': 0.15800173916414786}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:05:59,912] Trial 100 finished with value: 0.2628901847307734 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.003008832646865253, 'p_miss': 0.13438782535810612}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:06:06,018] Trial 101 finished with value: 0.26003781330925724 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 2, 'learning_rate': 0.0013601100080260547, 'p_miss': 0.17847802258585663}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:06:06,961] Trial 103 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:06:24,939] Trial 104 finished with value: 0.45551784065690226 and parameters: {'model_name': 'GAIN', 'batch_size': 42, 'hint_rate': 0.10431040303907563, 'alpha': 4, 'iterations': 9, 'learning_rate': 0.0012307000449263616, 'p_miss': 0.17631621231089312}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:06:28,047] Trial 102 finished with value: 0.25922347122262535 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 9, 'learning_rate': 0.0014738841640065776, 'p_miss': 0.1748251939018673}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:07:21,504] Trial 105 finished with value: 0.2606337634772624 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 17, 'learning_rate': 0.0010389162923485898, 'p_miss': 0.19591382312622568}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:07:25,930] Trial 106 finished with value: 0.26172428737019765 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 19, 'learning_rate': 0.0016319951877966446, 'p_miss': 0.19468561204232163}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:09:08,456] Trial 107 finished with value: 0.30193563618570796 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 31, 'learning_rate': 0.004551266929967097, 'p_miss': 0.11241158368220064}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:12:23,265] Trial 29 finished with value: 0.32889251622233323 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2249, 'learning_rate': 0.06230411261989029, 'p_miss': 0.11149432112738462}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:12:32,656] Trial 110 finished with value: 0.2590756035401528 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 2, 'learning_rate': 0.0005153300250615296, 'p_miss': 0.18431172114926636}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:12:54,547] Trial 111 finished with value: 0.2615773113125733 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 6, 'learning_rate': 0.0005373039751796456, 'p_miss': 0.16582300531419847}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:13:06,899] Trial 32 finished with value: 0.32994040091639215 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2043, 'learning_rate': 0.06097829542726152, 'p_miss': 0.10793198588811395}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:13:35,626] Trial 112 finished with value: 0.26152521554217595 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 11, 'learning_rate': 0.0002235806414701423, 'p_miss': 0.18334793542162758}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:13:48,203] Trial 113 finished with value: 0.2602179464755584 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 10, 'learning_rate': 0.00028581655851115, 'p_miss': 0.18014146106982248}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:13:59,583] Trial 40 finished with value: 0.3488111010182231 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1922, 'learning_rate': 0.015732264807234917, 'p_miss': 0.10921781826718167}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:14:23,381] Trial 116 finished with value: 0.26623549659811985 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 5, 'learning_rate': 0.00030838377045799533, 'p_miss': 0.17956525348322916}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:16:00,984] Trial 39 finished with value: 0.3365176125786287 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2446, 'learning_rate': 0.014021025323231455, 'p_miss': 0.09735026842645458}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:17:17,086] Trial 118 finished with value: 0.25997300990471206 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 27, 'learning_rate': 0.0002963743976473328, 'p_miss': 0.16975319624185078}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:18:52,185] Trial 119 finished with value: 0.25921129211954963 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 26, 'learning_rate': 0.0008297561446538302, 'p_miss': 0.1660748838639068}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:20:43,942] Trial 120 finished with value: 0.2596793135387996 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 31, 'learning_rate': 0.00048758410237773346, 'p_miss': 0.16570311234190477}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:22:23,668] Trial 121 finished with value: 0.25967858308796565 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 29, 'learning_rate': 0.00047734387433271677, 'p_miss': 0.16692380449693728}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:24:08,262] Trial 122 finished with value: 0.26239045931478644 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 37, 'learning_rate': 0.00043409052807620894, 'p_miss': 0.16624005966817323}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:27:43,152] Trial 123 finished with value: 0.26262432101140654 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 72, 'learning_rate': 0.00033712206127257873, 'p_miss': 0.203517093549326}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:27:43,902] Trial 124 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:28:54,949] Trial 125 finished with value: 0.25853663319329223 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 26, 'learning_rate': 0.00023762798692410683, 'p_miss': 0.1646774380546273}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:30:35,273] Trial 126 finished with value: 0.2632645217543543 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 31, 'learning_rate': 0.00019382836404945942, 'p_miss': 0.18782646953653612}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:31:43,224] Trial 127 finished with value: 0.2620899224118068 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 24, 'learning_rate': 0.000579080080082329, 'p_miss': 0.16493444436806068}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:34:09,023] Trial 128 finished with value: 0.2626654824503422 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 53, 'learning_rate': 0.0004684577206932044, 'p_miss': 0.17155547109575478}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:37:50,728] Trial 129 finished with value: 0.2653870751749464 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 90, 'learning_rate': 0.0008549537719396351, 'p_miss': 0.15377070636005333}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:38:05,645] Trial 130 finished with value: 0.32588378750744396 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 66, 'weights': 'distance'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:39:19,384] Trial 131 finished with value: 0.4541515737671111 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.3530748024150653, 'alpha': 33, 'iterations': 48, 'learning_rate': 0.00016402221571168115, 'p_miss': 0.16197623197282432}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:40:28,727] Trial 41 finished with value: 0.32900508419654406 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2682, 'learning_rate': 0.016025642189574037, 'p_miss': 0.10737708715506068}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:40:34,555] Trial 132 finished with value: 0.2619336188260927 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 25, 'learning_rate': 0.0005628638235219776, 'p_miss': 0.21636120611556783}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:41:22,902] Trial 45 finished with value: 0.33256780003665226 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1962, 'learning_rate': 0.010303631141611562, 'p_miss': 0.1242615348805749}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:42:00,231] Trial 133 finished with value: 0.25907436889498997 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 25, 'learning_rate': 0.00036481681517175644, 'p_miss': 0.1886264198513517}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:42:15,111] Trial 135 finished with value: 0.2581411591479793 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 14, 'learning_rate': 0.0003487624755434218, 'p_miss': 0.1504251557220137}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:42:52,317] Trial 136 finished with value: 0.258887200806445 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 14, 'learning_rate': 0.0002824802723236985, 'p_miss': 0.19135059012014105}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:43:02,520] Trial 137 finished with value: 0.2613663661957847 and parameters: {'model_name': 'VAE', 'batch_size': 119, 'iterations': 15, 'learning_rate': 0.0002563018816730659, 'p_miss': 0.18999526429747637}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:43:15,534] Trial 134 finished with value: 0.26113544384088916 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 44, 'learning_rate': 0.00036953132852649576, 'p_miss': 0.18786796462511846}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:43:55,095] Trial 138 finished with value: 0.25966296647451664 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 19, 'learning_rate': 0.0004925622641404133, 'p_miss': 0.18846580952749065}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:44:03,119] Trial 140 finished with value: 0.2584724096355894 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 13, 'learning_rate': 0.0003553823557788969, 'p_miss': 0.14968968575046132}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:44:48,009] Trial 141 finished with value: 0.26384149082797964 and parameters: {'model_name': 'VAE', 'batch_size': 726, 'iterations': 14, 'learning_rate': 0.0003903902471717799, 'p_miss': 0.2144772751221914}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:44:53,026] Trial 142 finished with value: 0.2642852397063479 and parameters: {'model_name': 'VAE', 'batch_size': 224, 'iterations': 13, 'learning_rate': 0.00018509734975793763, 'p_miss': 0.1481931353566658}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:44:59,802] Trial 144 finished with value: 0.3110281889285416 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:45:54,858] Trial 139 finished with value: 0.2629344238928743 and parameters: {'model_name': 'VAE', 'batch_size': 241, 'iterations': 44, 'learning_rate': 0.00034293230107640155, 'p_miss': 0.1484744598157724}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:46:00,808] Trial 143 finished with value: 0.26263210576271273 and parameters: {'model_name': 'VAE', 'batch_size': 229, 'iterations': 19, 'learning_rate': 0.0002478019684664902, 'p_miss': 0.19849517957732596}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:46:11,609] Trial 145 finished with value: 0.2582887656505461 and parameters: {'model_name': 'VAE', 'batch_size': 183, 'iterations': 19, 'learning_rate': 0.0002504733826140566, 'p_miss': 0.1965031716423707}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:47:11,373] Trial 146 finished with value: 0.2587689088854387 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 20, 'learning_rate': 0.0006358559066801796, 'p_miss': 0.1952287697138731}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:47:14,277] Trial 147 finished with value: 0.2610919312406424 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 22, 'learning_rate': 0.00063696387524721, 'p_miss': 0.1777080991102442}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:47:28,252] Trial 148 finished with value: 0.26099672498483445 and parameters: {'model_name': 'VAE', 'batch_size': 147, 'iterations': 23, 'learning_rate': 0.00012012266887554137, 'p_miss': 0.20927144220595364}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:48:11,758] Trial 151 finished with value: 0.2601447562356387 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 15, 'learning_rate': 0.00075877462738186, 'p_miss': 0.23218647315499585}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:48:34,358] Trial 149 finished with value: 0.2627229909544472 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 22, 'learning_rate': 0.0001413570764443873, 'p_miss': 0.22586367190402645}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:48:43,895] Trial 152 finished with value: 0.2587175236668847 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 8, 'learning_rate': 0.00020835234073798974, 'p_miss': 0.1961483240135786}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:49:04,691] Trial 153 finished with value: 0.2635526940378683 and parameters: {'model_name': 'VAE', 'batch_size': 293, 'iterations': 8, 'learning_rate': 0.0002656655064743384, 'p_miss': 0.20257483672057594}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:49:05,963] Trial 155 finished with value: 0.4581502251721942 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:49:09,986] Trial 154 finished with value: 0.2625065307566897 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 8, 'learning_rate': 0.00021173393874543019, 'p_miss': 0.20140129089148864}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:49:40,479] Trial 156 finished with value: 0.25838599632679926 and parameters: {'model_name': 'VAE', 'batch_size': 92, 'iterations': 11, 'learning_rate': 0.00019865856388906852, 'p_miss': 0.1936415033876639}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:49:42,323] Trial 157 finished with value: 0.2609541435606398 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 10, 'learning_rate': 0.00017380693324899703, 'p_miss': 0.17455851958427077}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:50:15,236] Trial 158 finished with value: 0.26111294127894713 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 12, 'learning_rate': 0.000190400798733139, 'p_miss': 0.19256887258028116}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:50:18,689] Trial 159 finished with value: 0.2586239209195853 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 11, 'learning_rate': 0.00015433182301726841, 'p_miss': 0.19343479610354491}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:50:37,503] Trial 160 finished with value: 0.3250004482477676 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8495, 'weights': 'distance'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:51:23,646] Trial 161 finished with value: 0.26069287111402745 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 17, 'learning_rate': 0.00015477219906273948, 'p_miss': 0.18481340503720917}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:51:50,245] Trial 163 finished with value: 0.26020459742773816 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 6, 'learning_rate': 0.00023406543036417137, 'p_miss': 0.21096172228342727}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:52:12,058] Trial 164 finished with value: 0.45759421279089063 and parameters: {'model_name': 'GAIN', 'batch_size': 44, 'hint_rate': 0.7667149893024922, 'alpha': 75, 'iterations': 12, 'learning_rate': 0.000331103355099252, 'p_miss': 0.19727635205248759}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:52:41,047] Trial 165 finished with value: 0.25886629735097527 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 9, 'learning_rate': 0.00040468327291716047, 'p_miss': 0.1817604098106876}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:53:12,857] Trial 166 finished with value: 0.2611582284626167 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 9, 'learning_rate': 0.0003924039834226728, 'p_miss': 0.19202431654035274}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:53:36,240] Trial 167 finished with value: 0.25845095665988327 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 7, 'learning_rate': 0.0001390535547303049, 'p_miss': 0.1843959510122584}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:56:39,774] Trial 42 finished with value: 0.3419123261078517 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2487, 'learning_rate': 0.011489972330913693, 'p_miss': 0.09943616802613682}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:57:02,887] Trial 169 finished with value: 0.2597242855381625 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 6, 'learning_rate': 0.00014197156156587454, 'p_miss': 0.18234624898591295}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 21:57:51,297] Trial 170 finished with value: 0.26137962486332683 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 16, 'learning_rate': 0.0002757566994857118, 'p_miss': 0.19502596105245756}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:02:29,751] Trial 168 finished with value: 0.26054731638822404 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 147, 'learning_rate': 0.00014442941682155414, 'p_miss': 0.18422752452427318}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:02:53,448] Trial 172 finished with value: 0.2595979825559099 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 7, 'learning_rate': 0.00011956836127810746, 'p_miss': 0.20012517551998987}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:03:39,645] Trial 173 finished with value: 0.25964138462112457 and parameters: {'model_name': 'VAE', 'batch_size': 368, 'iterations': 11, 'learning_rate': 0.0003604621975978456, 'p_miss': 0.1601299298651916}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:21:06,599] Trial 30 finished with value: 0.3264869948972401 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 3332, 'learning_rate': 0.05503960905877696, 'p_miss': 0.11524366655328049}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:22:56,065] Trial 175 finished with value: 0.26086432193199993 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 36, 'learning_rate': 0.0002057208733116643, 'p_miss': 0.20618500389113045}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:23:21,197] Trial 176 finished with value: 0.26522363609064004 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 9, 'learning_rate': 0.0008936155852099344, 'p_miss': 0.1742073972378874}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:24:14,214] Trial 177 finished with value: 0.25978017056019964 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 14, 'learning_rate': 0.0002921269639759693, 'p_miss': 0.18461717926631532}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:25:22,004] Trial 178 finished with value: 0.26086522653571215 and parameters: {'model_name': 'VAE', 'batch_size': 178, 'iterations': 19, 'learning_rate': 0.0004212954046382177, 'p_miss': 0.19055896949426035}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 22:26:00,029] Trial 179 finished with value: 0.25757215876984285 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 11, 'learning_rate': 0.00010126787767000463, 'p_miss': 0.17490114919352415}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:32:23,233] Trial 33 finished with value: 0.335026103837884 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4642, 'learning_rate': 0.049656042699717934, 'p_miss': 0.17612690382410165}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:33:05,341] Trial 181 finished with value: 0.2623935523869852 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 12, 'learning_rate': 0.00010889213725536827, 'p_miss': 0.1546485229202179}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:33:22,640] Trial 182 finished with value: 0.3153867537899462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:34:19,052] Trial 183 finished with value: 0.26637019903400183 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 16, 'learning_rate': 0.00012196620775518979, 'p_miss': 0.19789734730466368}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:34:44,582] Trial 184 finished with value: 0.26271440328936757 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 7, 'learning_rate': 0.0002295034831741598, 'p_miss': 0.18048403254964238}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:35:18,552] Trial 185 finished with value: 0.26001618399139736 and parameters: {'model_name': 'VAE', 'batch_size': 139, 'iterations': 11, 'learning_rate': 0.00017989062635650086, 'p_miss': 0.1728355097444595}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:36:02,942] Trial 186 finished with value: 0.26395673733418445 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 9, 'learning_rate': 0.0001020970949059014, 'p_miss': 0.17625071050826618}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:36:26,210] Trial 187 finished with value: 0.2607856944062473 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 6, 'learning_rate': 0.000621860614357377, 'p_miss': 0.15997316382121912}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:37:11,095] Trial 188 finished with value: 0.25889776464467507 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 13, 'learning_rate': 0.0003027725713488853, 'p_miss': 0.18877769489853585}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:38:13,037] Trial 189 finished with value: 0.2609858492851681 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 17, 'learning_rate': 0.0002502912565759992, 'p_miss': 0.18825440545834987}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:39:45,777] Trial 190 finished with value: 0.2601676439084254 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 25, 'learning_rate': 0.0003046550490002373, 'p_miss': 0.19326224366258607}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:40:35,208] Trial 191 finished with value: 0.26009693029025954 and parameters: {'model_name': 'VAE', 'batch_size': 198, 'iterations': 13, 'learning_rate': 0.00015854955076102513, 'p_miss': 0.20306134609233328}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:41:27,843] Trial 192 finished with value: 0.25995922918213504 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 19, 'learning_rate': 0.00020328130663894759, 'p_miss': 0.14112135659949798}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:41:59,546] Trial 193 finished with value: 0.2609858264896018 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 8, 'learning_rate': 0.0003296544531035948, 'p_miss': 0.18224620217057103}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:42:20,659] Trial 194 finished with value: 0.2599271316811457 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 5, 'learning_rate': 0.00025655167521831116, 'p_miss': 0.1958106688522783}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:42:42,917] Trial 195 finished with value: 0.3177528702977435 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25392, 'weights': 'uniform'}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:43:23,162] Trial 196 finished with value: 0.26169511590585903 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 14, 'learning_rate': 0.0005293898707569221, 'p_miss': 0.16866495942283388}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:43:53,544] Trial 197 finished with value: 0.2598286992036377 and parameters: {'model_name': 'VAE', 'batch_size': 107, 'iterations': 10, 'learning_rate': 0.00043642254522792726, 'p_miss': 0.18683274513296347}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:44:23,442] Trial 198 finished with value: 0.2586908880964914 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 10, 'learning_rate': 0.00021168560039788126, 'p_miss': 0.17486448812376762}. Best is trial 69 with value: 0.25750936845972305.
running
[I 2024-11-22 23:45:01,144] Trial 199 finished with value: 0.261875575755692 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 11, 'learning_rate': 0.00017135326338157698, 'p_miss': 0.028769811325060735}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 00:02:57,199] Trial 115 finished with value: 0.3170576961180647 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 3439, 'learning_rate': 0.0008594583867216737, 'p_miss': 0.16392817558358347}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 00:40:13,138] Trial 117 finished with value: 0.32158158939021486 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 4445, 'learning_rate': 0.0009017868977287467, 'p_miss': 0.2053565134105991}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 00:55:21,143] Trial 171 finished with value: 0.3241961454564041 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 4067, 'learning_rate': 0.00012681029526738423, 'p_miss': 0.20047477029747027}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:07:47,262] Trial 162 finished with value: 0.32256842657217827 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 3791, 'learning_rate': 0.00013291705242704337, 'p_miss': 0.21155675547427313}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:15:40,108] Trial 174 finished with value: 0.32117215815007516 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 3723, 'learning_rate': 0.0002967287722255901, 'p_miss': 0.20579328897966015}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:19:23,940] Trial 108 finished with value: 0.3219583730277498 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 4722, 'learning_rate': 0.005066306201911991, 'p_miss': 0.11681870375471637}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:24:37,528] Trial 109 finished with value: 0.3209316874146544 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 5747, 'learning_rate': 0.0015221351729001124, 'p_miss': 0.18307246567268248}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:25:29,878] Trial 35 finished with value: 0.33177231063883483 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6202, 'learning_rate': 0.046862238719242326, 'p_miss': 0.1842886484685693}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:38:16,779] Trial 180 finished with value: 0.3246675450246902 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 4698, 'learning_rate': 0.0001156802121569519, 'p_miss': 0.043562859189616845}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:45:40,770] Trial 44 finished with value: 0.32657127831278177 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9438, 'learning_rate': 0.014644716103233925, 'p_miss': 0.12219405154048421}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:45:44,899] Trial 43 finished with value: 0.3321636862138164 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8774, 'learning_rate': 0.010577175694343816, 'p_miss': 0.12314645580638298}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:47:46,829] Trial 114 finished with value: 0.32011721168931706 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7728, 'learning_rate': 0.0010283437055016876, 'p_miss': 0.216648084161033}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:52:47,063] Trial 90 finished with value: 0.33348482704813953 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9368, 'learning_rate': 0.0011899680910872213, 'p_miss': 0.10573912444997655}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:53:20,949] Trial 91 finished with value: 0.32802808818279544 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9641, 'learning_rate': 0.0009995237004412354, 'p_miss': 0.10495247830903123}. Best is trial 69 with value: 0.25750936845972305.
[I 2024-11-23 01:53:33,668] Trial 150 finished with value: 0.32462663049107315 and parameters: {'model_name': 'VAE', 'batch_size': 400, 'iterations': 6496, 'learning_rate': 0.0008184023068094895, 'p_miss': 0.2100232334177468}. Best is trial 69 with value: 0.25750936845972305.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.25750936845972305
{'model_name': 'VAE', 'batch_size': 1, 'iterations': 7, 'learning_rate': 0.000195735893829517, 'p_miss': 0.16986911011040376}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714340> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a14b0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  1
Best f1_score score: 0.35678412740195053
Generation:   4%|         | 1/25 [04:30<1:48:00, 270.04s/it]Generation:  2
Best f1_score score: 0.3719151063571155
Generation:   8%|         | 2/25 [11:39<2:19:26, 363.75s/it]Generation:  3
Best f1_score score: 0.3719151063571155
Generation:  12%|        | 3/25 [18:22<2:20:01, 381.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e988e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.3719151063571155
Generation:  16%|        | 4/25 [22:56<1:58:42, 339.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554748c9a80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c75210> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f7f40> 

Generation:  5
Best f1_score score: 0.3719151063571155
Generation:  20%|        | 5/25 [33:01<2:24:59, 434.96s/it]Generation:  6
Best f1_score score: 0.37597857836363746
Generation:  24%|       | 6/25 [36:07<1:50:54, 350.25s/it]Generation:  7
Best f1_score score: 0.37597857836363746
Generation:  28%|       | 7/25 [41:46<1:43:59, 346.63s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f96260> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.37597857836363746
Generation:  32%|      | 8/25 [44:06<1:19:33, 280.80s/it]Generation:  9
Best f1_score score: 0.37597857836363746
Generation:  36%|      | 9/25 [48:41<1:14:23, 278.96s/it]Generation:  10
Best f1_score score: 0.37597857836363746
Generation:  40%|      | 10/25 [53:57<1:12:39, 290.64s/it]Generation:  11
Best f1_score score: 0.37597857836363746
Generation:  44%|     | 11/25 [59:17<1:09:53, 299.50s/it]Generation:  12
Best f1_score score: 0.37597857836363746
Generation:  48%|     | 12/25 [1:05:45<1:10:43, 326.44s/it]Generation:  13
Best f1_score score: 0.37597857836363746
Generation:  52%|    | 13/25 [1:08:24<55:07, 275.64s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747305e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.37597857836363746
Generation:  56%|    | 14/25 [1:11:45<46:24, 253.13s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676ed1e0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  15
Best f1_score score: 0.37597857836363746
Generation:  60%|    | 15/25 [1:16:33<43:57, 263.70s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554677e0040> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.37597857836363746
Generation:  64%|   | 16/25 [1:21:34<41:14, 275.00s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f969e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.37597857836363746
Generation:  68%|   | 17/25 [1:27:14<39:15, 294.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657766b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.37597857836363746
Generation:  72%|  | 18/25 [1:33:52<37:59, 325.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655b2470> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546534f820> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.37597857836363746
Generation:  76%|  | 19/25 [1:36:09<26:53, 268.93s/it]Generation:  20
Best f1_score score: 0.37597857836363746
Generation:  80%|  | 20/25 [1:40:10<21:43, 260.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a5f670> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467117f40> 

Generation:  21
Best f1_score score: 0.37597857836363746
Generation:  84%| | 21/25 [1:50:21<24:23, 365.75s/it]Generation:  22
Best f1_score score: 0.37597857836363746
Generation:  88%| | 22/25 [1:54:35<16:36, 332.07s/it]Generation:  23
Best f1_score score: 0.37597857836363746
Generation:  92%|| 23/25 [1:58:03<09:49, 294.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650b4910> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.37597857836363746
Generation:  96%|| 24/25 [2:05:03<05:32, 332.34s/it]Generation:  25
Best f1_score score: 0.3760264853261862
Generation: 100%|| 25/25 [2:08:15<00:00, 290.47s/it]Generation: 100%|| 25/25 [2:08:18<00:00, 307.95s/it]
2024-11-23 04:02:04,958 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33179' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0', 'ndarray-93a39ed30596c0d618e7459d1d732183'} (stimulus_id='handle-worker-cleanup-1732363324.9584033')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        max_features=0.2358720718479,
                                        min_samples_leaf=18,
                                        min_samples_split=9,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.839105952099815, 'accuracy': 0.670199414307628, 'balanced_accuracy': 0.7150393716700832, 'logloss': 0.9139879951700233, 'f1': 0.6642712205006871}
original test score: {'auroc': 0.542088427692321, 'accuracy': 0.5305667112896029, 'balanced_accuracy': 0.39676572358248147, 'logloss': 1.039024196337299, 'f1': 0.39675739808042226}
imputed test score: {'auroc': 0.5296931735587617, 'accuracy': 0.43172690763052207, 'balanced_accuracy': 0.35046158660931437, 'logloss': 1.0372087275026254, 'f1': 0.348031006160892}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014580>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a10f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0eb0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f10> 

Generation:  1
Best f1_score score: 0.47209855562717473
Generation:   4%|         | 1/25 [10:03<4:01:14, 603.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0eb0> 

Generation:  2
Best f1_score score: 0.5029259659114094
Generation:   8%|         | 2/25 [20:08<3:51:44, 604.53s/it]Generation:  3
Best f1_score score: 0.5101251258317343
Generation:  12%|        | 3/25 [28:35<3:25:17, 559.87s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547473b160> 

Generation:  4
Best f1_score score: 0.5117204497362137
Generation:  16%|        | 4/25 [38:39<3:22:04, 577.37s/it]Generation:  5
Best f1_score score: 0.5256848939594433
Generation:  20%|        | 5/25 [48:37<3:14:56, 584.85s/it]Generation:  6
Best f1_score score: 0.5290665924983606
Generation:  24%|       | 6/25 [56:52<2:55:28, 554.11s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f31ff0> 

Generation:  7
Best f1_score score: 0.5312865228357169
Generation:  28%|       | 7/25 [1:06:57<2:51:17, 570.97s/it]Generation:  8
Best f1_score score: 0.5312865228357169
Generation:  32%|      | 8/25 [1:16:13<2:40:23, 566.08s/it]Generation:  9
Best f1_score score: 0.5316576765257018
Generation:  36%|      | 9/25 [1:25:08<2:28:22, 556.43s/it]Generation:  10
Best f1_score score: 0.5360287327680732
Generation:  40%|      | 10/25 [1:31:58<2:07:49, 511.29s/it]Generation:  11
Best f1_score score: 0.5360287327680732
Generation:  44%|     | 11/25 [1:37:52<1:48:04, 463.18s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554648b8b80> 

Generation:  12
Best f1_score score: 0.5372901525570064
Generation:  48%|     | 12/25 [1:47:56<1:49:37, 505.99s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471d120> 

Generation:  13
Best f1_score score: 0.5372901525570064
Generation:  52%|    | 13/25 [1:58:04<1:47:19, 536.66s/it]Generation:  14
Best f1_score score: 0.5372901525570064
Generation:  56%|    | 14/25 [2:03:57<1:28:13, 481.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474718790> 

Generation:  15
Best f1_score score: 0.5386310124424367
Generation:  60%|    | 15/25 [2:14:02<1:26:25, 518.51s/it]Generation:  16
Best f1_score score: 0.5386310124424367
Generation:  64%|   | 16/25 [2:14:51<56:37, 377.47s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467997070> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29930> 

Generation:  17
Best f1_score score: 0.5386310124424367
Generation:  68%|   | 17/25 [2:24:59<59:32, 446.53s/it]Generation:  18
Best f1_score score: 0.5386310124424367
Generation:  72%|  | 18/25 [2:31:08<49:23, 423.32s/it]Generation:  19
Best f1_score score: 0.5386310124424367
Generation:  76%|  | 19/25 [2:37:05<40:21, 403.56s/it]Generation:  20
Best f1_score score: 0.5386310124424367
Generation:  80%|  | 20/25 [2:37:39<24:23, 292.60s/it]Generation:  21
Best f1_score score: 0.5386310124424367
Generation:  84%| | 21/25 [2:44:08<21:25, 321.49s/it]Generation:  22
Best f1_score score: 0.5386310124424367
Generation:  88%| | 22/25 [2:50:30<16:59, 339.70s/it]Generation:  23
Best f1_score score: 0.5417046539112863
Generation:  92%|| 23/25 [2:56:45<11:40, 350.08s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546506c5b0> 

Generation:  24
Best f1_score score: 0.5417046539112863
Generation:  96%|| 24/25 [3:06:53<07:07, 427.46s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679a1930> 

Generation:  25
Best f1_score score: 0.5417046539112863
Generation: 100%|| 25/25 [3:16:59<00:00, 481.26s/it]Generation: 100%|| 25/25 [3:16:59<00:00, 472.80s/it]
2024-11-23 07:19:22,347 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33099' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0', 'DataFrame-c579763041cc57f2f1fc651a1c418672'} (stimulus_id='handle-worker-cleanup-1732375162.3470302')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=8,
                                n_estimators=92, n_jobs=1, num_leaves=56,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.829460916512712, 'accuracy': 0.6184911448891368, 'balanced_accuracy': 0.6481910229059641, 'logloss': 0.7877915978363011, 'f1': 0.5756448153819167}
test score: {'auroc': 0.7674405632624531, 'accuracy': 0.57095046854083, 'balanced_accuracy': 0.5674370748868699, 'logloss': 0.8573358087413402, 'f1': 0.5198099139638641}
original test score: {'auroc': 0.9491847040596326, 'accuracy': 0.8162650602409639, 'balanced_accuracy': 0.8336888095930596, 'logloss': 0.42675992942044466, 'f1': 0.7798715894333169}
score end
41027
lvl
0.5
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
11.784162954158253
hours
DONE
