Run: 1
/cm/local/apps/slurm/var/spool/job1033657/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/881/881.pkl
             x1       x2     x3       x4        x5        x6   x7      x8  \
0      3.505910 -13.1140  brown -6.55701  0.018846 -17.37050   no  normal   
1      0.254831 -10.0493  brown -5.02465 -0.155673  -3.72734   no  normal   
2     -1.726990 -10.0929    red -5.04645  0.682773 -19.76930   no   large   
3     -4.941350 -13.7953  brown -6.89764 -0.093552  -2.17294  yes  normal   
4     -2.125960 -11.5536  brown -5.77679 -0.667886 -15.36640   no  normal   
...         ...      ...    ...      ...       ...       ...  ...     ...   
40763  2.037850 -14.5954    red -7.29768 -0.145692 -22.19220   no  normal   
40764 -3.900100 -11.9768    red -5.98842  0.307765 -15.34020   no  normal   
40765 -3.335740 -13.1695    red -6.58475 -0.232768 -31.66890   no  normal   
40766  3.895180 -10.5750  brown  1.94759  0.362844   4.39543   no  normal   
40767 -4.565710 -13.7396  brown -2.28286  0.943271  -9.75381   no   large   

            x9     x10  
0      153.043  1026.0  
1      191.097  1126.0  
2      256.141  1091.0  
3      165.520  1039.0  
4      311.389  1152.0  
...        ...     ...  
40763  178.268  1030.0  
40764  254.608  1196.0  
40765  172.487  1012.0  
40766  156.839  1130.0  
40767  334.192  1048.0  

[40768 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
             x1       x2     x3        x4        x5         x6   x7      x8  \
6073   4.186590 -12.0052    red -6.002620 -0.755155  -2.130320  yes  normal   
12738 -2.475990 -11.5519  brown -5.775950 -0.268810  -0.551893   no  normal   
35647 -4.154940 -13.2072  brown -6.603590  0.244093 -19.873800   no  normal   
22826  1.272430 -10.7644    red  0.636213 -0.038586   2.119000   no  normal   
369   -3.813420 -13.3270  brown -6.663510  0.965247  -1.147500   no   large   
...         ...      ...    ...       ...       ...        ...  ...     ...   
8988  -3.577090 -12.1904  brown -1.788550 -0.857280  -2.184970   no  normal   
6149  -1.909300 -12.0495  brown -6.024760 -0.692566  -4.631790   no  normal   
25687 -1.029440 -10.0361  brown -5.018030 -0.400557  -0.482011   no  normal   
2084   1.081340 -12.3831  green  0.540671  0.801182   1.925400  yes   large   
30235 -0.178036 -11.0484  brown -5.524210 -0.453207 -16.738700   no  normal   

            x9     x10  
6073   467.932  1118.0  
12738  450.637  1143.0  
35647  381.020  1179.0  
22826  330.629  1000.0  
369    319.019  1066.0  
...        ...     ...  
8988   328.463  1120.0  
6149   279.315  1083.0  
25687  155.781  1058.0  
2084   253.397  1021.0  
30235  392.793  1015.0  

[32614 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
              0         1         2         3         4         5      6    7  \
0      0.918721  0.598996  0.149732  0.122401  0.708224  0.919828  0.590  1.0   
1      0.252410  0.689670  0.172400  0.365583  0.739963  0.876589  0.715  0.0   
2      0.084502  0.358557  0.089632  0.622044  0.351440  0.702543  0.895  0.0   
3      0.627282  0.847196  0.813647  0.480699  0.793669  0.576562  0.000  1.0   
4      0.118656  0.334594  0.083640  0.982634  0.727986  0.547536  0.330  0.0   
...         ...       ...       ...       ...       ...       ...    ...  ...   
32609  0.142291  0.561950  0.571159  0.071337  0.707125  0.571147  0.600  0.0   
32610  0.309083  0.590134  0.147518  0.153697  0.657925  0.448274  0.415  0.0   
32611  0.397076  0.992879  0.248196  0.299707  0.741368  0.139431  0.290  0.0   
32612  0.608171  0.523404  0.804092  0.900598  0.789776  0.383477  0.105  0.5   
32613  0.482223  0.790386  0.197575  0.273381  0.414480  0.731976  0.075  0.0   

         8    9  
0      1.0  1.0  
1      0.0  1.0  
2      0.0  1.0  
3      0.0  1.0  
4      0.0  0.0  
...    ...  ...  
32609  0.0  1.0  
32610  0.0  1.0  
32611  0.0  1.0  
32612  1.0  0.0  
32613  0.0  1.0  

[32614 rows x 10 columns]
<class 'numpy.ndarray'>
             0         1         2         3         4         5      6    7  \
0     0.578933  0.968875  0.242193  0.434801  0.498006  0.279439  0.865  0.0   
1     0.172297  0.792507  0.198104  0.375145  0.521909  0.185522  0.065  0.0   
2     0.769719  0.919407  0.229827  0.317977  0.359113  0.828223  0.485  0.0   
3     0.302818  0.146283  0.651420  0.488608  0.681318  0.887157  0.935  0.0   
4     0.630876  0.520683  0.130159  0.873833  0.156375  0.704313  0.005  0.0   
...        ...       ...       ...       ...       ...       ...    ...  ...   
8149  0.616477  0.606857  0.151701  0.628090  0.183702  0.778172  0.555  0.5   
8150  0.603908  0.579853  0.144950  0.256515  0.714961  0.747291  0.700  0.5   
8151  0.278792  0.450672  0.112655  0.143464  0.689298  0.753121  0.670  0.0   
8152  0.798780  0.940871  0.899393  0.919027  0.845102  0.079829  0.230  1.0   
8153  0.056381  0.611718  0.528206  0.081620  0.555298  0.804595  0.925  0.0   

        8    9  
0     0.0  1.0  
1     0.0  1.0  
2     0.0  1.0  
3     1.0  1.0  
4     0.0  0.0  
...   ...  ...  
8149  0.0  1.0  
8150  0.0  1.0  
8151  0.0  1.0  
8152  1.0  0.0  
8153  0.0  1.0  

[8154 rows x 10 columns]
<class 'numpy.ndarray'>
working on 
../data/c/881/class_full_MCAR_0.01_1
3.045363426208496
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-31 00:40:58,236] A new study created in memory with name: no-name-a00992cf-d7e7-4a4d-ba3a-06f2c29aa205
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-31 00:40:59,258] Trial 6 finished with value: 0.37680866015377235 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.37680866015377235.
running
[I 2024-10-31 00:40:59,715] Trial 16 finished with value: 0.5885495791296352 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.37680866015377235.
running
[I 2024-10-31 00:41:08,616] Trial 10 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.4459529221622646, 'alpha': 37, 'iterations': 5, 'learning_rate': 0.00010805406971703269, 'p_miss': 0.11466187887762484}. Best is trial 6 with value: 0.37680866015377235.
running
[I 2024-10-31 00:41:10,154] Trial 12 finished with value: 0.3664842987801506 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.0003103368143190369, 'p_miss': 0.11545282182168048}. Best is trial 12 with value: 0.3664842987801506.
running
[I 2024-10-31 00:41:10,822] Trial 4 finished with value: 0.5644087512433849 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.31441140819952756, 'alpha': 6, 'iterations': 1, 'learning_rate': 0.001597352090340229, 'p_miss': 0.23405133469413084}. Best is trial 12 with value: 0.3664842987801506.
running
[I 2024-10-31 00:41:11,906] Trial 20 finished with value: 0.3366932334173287 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 20 with value: 0.3366932334173287.
running
[I 2024-10-31 00:41:28,556] Trial 9 finished with value: 0.30489175612240516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 9 with value: 0.30489175612240516.
running
[I 2024-10-31 00:41:29,946] Trial 2 finished with value: 0.304891607113203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 2 with value: 0.304891607113203.
running
[I 2024-10-31 00:41:39,903] Trial 1 finished with value: 0.3048914678119926 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:41:41,028] Trial 8 finished with value: 0.3244690041937595 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9380, 'weights': 'uniform'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:41:49,671] Trial 21 finished with value: 0.30506301742742326 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:41:59,657] Trial 3 finished with value: 0.32711560904885106 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17169, 'weights': 'distance'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:10,443] Trial 11 finished with value: 0.3583996349039615 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 68, 'learning_rate': 0.00034151650101213585, 'p_miss': 0.07415738975089793}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:14,890] Trial 17 finished with value: 0.3048984349621019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:36,747] Trial 26 finished with value: 0.3048927724884781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:58,095] Trial 5 finished with value: 0.3383457447983284 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 96, 'learning_rate': 0.043546387287329257, 'p_miss': 0.1680731520150407}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:58,789] Trial 24 finished with value: 0.3050271600209308 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:42:59,438] Trial 25 finished with value: 0.3049567712238074 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:43:04,019] Trial 29 finished with value: 0.3048927724884781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:43:06,524] Trial 7 finished with value: 0.33816618003900495 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 70, 'learning_rate': 0.0038305835212403866, 'p_miss': 0.2676818525058612}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:43:26,284] Trial 15 finished with value: 0.31766800322256333 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:43:40,073] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8349858311464299, 'alpha': 60, 'iterations': 1279, 'learning_rate': 0.00030834289115293554, 'p_miss': 0.05108515569881551}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:43:43,132] Trial 18 finished with value: 0.31690369756622494 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.3048914678119926.
running
[I 2024-10-31 00:44:01,721] Trial 27 finished with value: 0.30485923717298097 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:44:21,605] Trial 32 finished with value: 0.3088691201410326 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:44:23,594] Trial 33 finished with value: 0.3088691201410326 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:44:44,832] Trial 41 finished with value: 0.3366932334173287 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28841, 'weights': 'uniform'}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:47:04,358] Trial 14 finished with value: 0.5864167103558241 and parameters: {'model_name': 'GAIN', 'batch_size': 320, 'hint_rate': 0.8243805095087455, 'alpha': 10, 'iterations': 1028, 'learning_rate': 0.00827358942175016, 'p_miss': 0.023167332384039552}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:52:42,673] Trial 23 finished with value: 0.5542244495703069 and parameters: {'model_name': 'GAIN', 'batch_size': 37, 'hint_rate': 0.7547446306721819, 'alpha': 93, 'iterations': 4794, 'learning_rate': 0.00011422011120721434, 'p_miss': 0.2920432273073329}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:53:01,225] Trial 44 finished with value: 0.3056468573688152 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 915, 'weights': 'distance'}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:53:21,220] Trial 0 finished with value: 0.3383151263146972 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 2330, 'learning_rate': 0.004726888415954845, 'p_miss': 0.2950712731104163}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 00:55:36,188] Trial 13 finished with value: 0.33790348926442815 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 3875, 'learning_rate': 0.045247422065959546, 'p_miss': 0.09068670342307006}. Best is trial 27 with value: 0.30485923717298097.
running
[I 2024-10-31 03:09:55,937] Trial 35 finished with value: 0.2822034963037764 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:09:58,231] Trial 34 finished with value: 0.2830670955314596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:10:03,452] Trial 22 finished with value: 0.2839831705120427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:10:10,737] Trial 36 finished with value: 0.2826816075196957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:10:21,055] Trial 37 finished with value: 0.28279131718489364 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:11:47,625] Trial 38 finished with value: 0.28326938500216803 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2822034963037764.
running
[I 2024-10-31 03:12:18,686] Trial 39 finished with value: 0.2821612956138889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.2821612956138889.
running
[I 2024-10-31 03:12:18,994] Trial 54 finished with value: 0.5465683105943127 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 39 with value: 0.2821612956138889.
running
[I 2024-10-31 03:26:05,944] Trial 31 finished with value: 0.2827722539208374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.2821612956138889.
running
[I 2024-10-31 03:26:13,144] Trial 30 finished with value: 0.2823472978906137 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.2821612956138889.
running
[I 2024-10-31 03:29:36,620] Trial 40 finished with value: 0.2821114408751445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.2821114408751445.
running
[I 2024-10-31 03:31:10,745] Trial 42 finished with value: 0.2818307591579825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 42 with value: 0.2818307591579825.
running
[I 2024-10-31 03:33:32,037] Trial 43 finished with value: 0.2822416496236233 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 42 with value: 0.2818307591579825.
running
[I 2024-10-31 03:33:57,336] Trial 60 finished with value: 0.3320640317348956 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32539, 'weights': 'distance'}. Best is trial 42 with value: 0.2818307591579825.
running
[I 2024-10-31 03:38:52,083] Trial 46 finished with value: 0.281908874943195 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 42 with value: 0.2818307591579825.
running
[I 2024-10-31 03:39:34,195] Trial 45 finished with value: 0.2815319256109491 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 45 with value: 0.2815319256109491.
running
[I 2024-10-31 03:39:41,865] Trial 63 finished with value: 0.3379174437268433 and parameters: {'model_name': 'VAE', 'batch_size': 890, 'iterations': 14, 'learning_rate': 0.019446236235126414, 'p_miss': 0.1959386813864303}. Best is trial 45 with value: 0.2815319256109491.
running
[I 2024-10-31 03:42:11,766] Trial 47 finished with value: 0.28182798071827125 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 45 with value: 0.2815319256109491.
running
[I 2024-10-31 03:42:12,083] Trial 65 finished with value: 0.5465683105943127 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 45 with value: 0.2815319256109491.
running
[I 2024-10-31 03:44:42,555] Trial 28 finished with value: 0.2814415542761875 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:05:03,998] Trial 55 finished with value: 0.28559869018864287 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:19:09,248] Trial 52 finished with value: 0.28426334246474066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:21:04,425] Trial 58 finished with value: 0.2857564947095329 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:21:10,435] Trial 70 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.02980865930949983, 'alpha': 99, 'iterations': 263, 'learning_rate': 0.0009567498137062481, 'p_miss': 0.2125334864027672}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:21:18,240] Trial 71 finished with value: 0.3379239197018074 and parameters: {'model_name': 'VAE', 'batch_size': 990, 'iterations': 14, 'learning_rate': 0.011053362788163185, 'p_miss': 0.011421415633810023}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:21:39,189] Trial 53 finished with value: 0.28449545184669234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:27:04,045] Trial 61 finished with value: 0.2864220796944691 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:34:23,210] Trial 64 finished with value: 0.28678474601127707 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:34:48,397] Trial 75 finished with value: 0.33403129814806504 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22148, 'weights': 'uniform'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:35:42,800] Trial 49 finished with value: 0.2831286352929781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:35:57,875] Trial 51 finished with value: 0.282701219960951 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:37:45,226] Trial 50 finished with value: 0.283654691126822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:50:25,307] Trial 62 finished with value: 0.2835443961101417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:54:58,842] Trial 48 finished with value: 0.28158354147595843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 05:55:02,257] Trial 81 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.031240426085173967, 'alpha': 68, 'iterations': 375, 'learning_rate': 0.09785769689569808, 'p_miss': 0.15098477040458375}. Best is trial 28 with value: 0.2814415542761875.
running
[I 2024-10-31 06:09:23,732] Trial 57 finished with value: 0.2814352095134547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:09:24,067] Trial 83 finished with value: 0.3366932334173287 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:10:40,529] Trial 56 finished with value: 0.2814759816992652 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:16:25,896] Trial 59 finished with value: 0.2820451427718188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:17:41,947] Trial 85 finished with value: 0.3427365258018373 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 9407, 'learning_rate': 0.00096414349726576, 'p_miss': 0.15046558014512237}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:27:13,192] Trial 66 finished with value: 0.28156692483613643 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.2814352095134547.
running
[I 2024-10-31 06:47:25,945] Trial 67 finished with value: 0.2808716779122598 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:08:20,459] Trial 68 finished with value: 0.28110493356583016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:20:07,953] Trial 69 finished with value: 0.28127498705191756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:20:20,147] Trial 91 finished with value: 0.3048957013316524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:21:00,520] Trial 92 finished with value: 0.43697054916068206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:21:40,879] Trial 93 finished with value: 0.3173435948459836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.2808716779122598.
running
[I 2024-10-31 08:22:53,306] Trial 72 finished with value: 0.28081835939721456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:26:06,176] Trial 73 finished with value: 0.2811422806567276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:30:02,219] Trial 74 finished with value: 0.28090747434604807 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:37:15,434] Trial 78 finished with value: 0.2809032221826592 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:37:38,185] Trial 77 finished with value: 0.28127835514589106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:39:01,725] Trial 76 finished with value: 0.2811541439012256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:39:46,214] Trial 100 finished with value: 0.4350774207810577 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:39:46,789] Trial 101 finished with value: 0.5613723306086418 and parameters: {'model_name': 'GAIN', 'batch_size': 275, 'hint_rate': 0.9845387482029184, 'alpha': 34, 'iterations': 1, 'learning_rate': 0.0017805627583403667, 'p_miss': 0.2518812629771035}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:39:58,759] Trial 102 finished with value: 0.3048942094540496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 72 with value: 0.28081835939721456.
running
[I 2024-10-31 08:40:52,065] Trial 79 finished with value: 0.28072358529014346 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 08:53:58,311] Trial 80 finished with value: 0.2814424229991168 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 08:54:36,572] Trial 105 finished with value: 0.3173435948459836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 08:57:25,444] Trial 82 finished with value: 0.2814433238026609 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:11:27,682] Trial 84 finished with value: 0.2809808048691461 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:19:40,933] Trial 87 finished with value: 0.28114805254555075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:20:53,756] Trial 86 finished with value: 0.2811130280079781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:31:04,298] Trial 88 finished with value: 0.28105420552907595 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:51:08,658] Trial 89 finished with value: 0.28154646795492094 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:51:26,050] Trial 112 finished with value: 0.3084478435973815 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1015, 'weights': 'uniform'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 09:51:26,264] Trial 113 finished with value: 0.5885495791296352 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:11:39,707] Trial 90 finished with value: 0.2815123190040636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:22:31,235] Trial 94 finished with value: 0.28162900399217927 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:23:23,500] Trial 95 finished with value: 0.28117812088744354 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:28:25,045] Trial 96 finished with value: 0.28100379316332685 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:32:18,381] Trial 97 finished with value: 0.28123853819639805 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:37:48,530] Trial 98 finished with value: 0.2815426289053972 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:38:28,417] Trial 99 finished with value: 0.28097486138764255 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:42:08,867] Trial 104 finished with value: 0.28089205434517706 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:42:10,650] Trial 122 finished with value: 0.33974431449030174 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 20, 'learning_rate': 0.019133214906732907, 'p_miss': 0.18643282574461134}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:43:49,224] Trial 103 finished with value: 0.2816181276909116 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:44:31,279] Trial 124 finished with value: 0.43079686348911633 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:44:42,306] Trial 125 finished with value: 0.3048942094540496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:55:48,262] Trial 106 finished with value: 0.28159622305081644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 79 with value: 0.28072358529014346.
running
[I 2024-10-31 11:56:18,623] Trial 107 finished with value: 0.28061215048871374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:10:46,409] Trial 108 finished with value: 0.2811007203378727 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:18:01,967] Trial 109 finished with value: 0.28109510087727 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:21:09,244] Trial 110 finished with value: 0.2811340488242102 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:30:25,715] Trial 127 finished with value: 0.33945774603029805 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:31:20,259] Trial 111 finished with value: 0.28114967359874526 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:31:20,628] Trial 133 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.30634123972554816, 'alpha': 78, 'iterations': 4, 'learning_rate': 0.07795768437474841, 'p_miss': 0.04469254726486099}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:52:43,382] Trial 114 finished with value: 0.2811690717693506 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 12:53:23,210] Trial 135 finished with value: 0.3178095899384755 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:11:34,629] Trial 115 finished with value: 0.281164255338182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:19:07,633] Trial 116 finished with value: 0.2814648982884955 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:20:49,846] Trial 117 finished with value: 0.28127685578556944 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:27:22,164] Trial 118 finished with value: 0.28138852691867045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:27:45,349] Trial 140 finished with value: 0.32194081770227084 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9622, 'weights': 'distance'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:32:47,116] Trial 119 finished with value: 0.2807836412982933 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 107 with value: 0.28061215048871374.
running
[I 2024-10-31 14:35:35,155] Trial 120 finished with value: 0.28039600129930436 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 14:35:35,517] Trial 143 finished with value: 0.37680866015377235 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 14:35:57,022] Trial 121 finished with value: 0.2814292754693737 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 14:41:42,914] Trial 123 finished with value: 0.28114334765344584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 14:44:49,625] Trial 126 finished with value: 0.2809669383443983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 14:52:52,552] Trial 128 finished with value: 0.2811397296020045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:07:55,884] Trial 129 finished with value: 0.2809512959145536 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:15:41,755] Trial 130 finished with value: 0.28126191721815746 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:19:34,849] Trial 131 finished with value: 0.2812731281537201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:27:28,792] Trial 132 finished with value: 0.2808906369894256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:28:00,336] Trial 152 finished with value: 0.33770977289844356 and parameters: {'model_name': 'VAE', 'batch_size': 311, 'iterations': 352, 'learning_rate': 0.006725735035818116, 'p_miss': 0.12626674736559307}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:30:26,932] Trial 134 finished with value: 0.2823928414052679 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 15:52:26,546] Trial 136 finished with value: 0.28124794613748894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 16:35:30,080] Trial 151 finished with value: 0.2968581852395789 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 17:11:09,671] Trial 137 finished with value: 0.2809245088778919 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 17:16:27,169] Trial 138 finished with value: 0.28078287259341433 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 17:18:11,984] Trial 145 finished with value: 0.28240576882633295 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 120 with value: 0.28039600129930436.
running
[I 2024-10-31 17:18:29,809] Trial 139 finished with value: 0.28039323610809685 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:27:58,691] Trial 141 finished with value: 0.28114500817546584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:31:58,448] Trial 142 finished with value: 0.281101959506767 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:33:30,142] Trial 144 finished with value: 0.2808514091250783 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:35:52,633] Trial 148 finished with value: 0.2813787230255916 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:35:53,200] Trial 164 finished with value: 0.5637539630097244 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.6282324173199807, 'alpha': 26, 'iterations': 2, 'learning_rate': 0.0005452108497699015, 'p_miss': 0.22526987092958536}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:41:35,080] Trial 146 finished with value: 0.2815201103295752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 17:44:15,852] Trial 147 finished with value: 0.2808858869970107 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:05:12,287] Trial 149 finished with value: 0.281281307566733 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:14:49,443] Trial 150 finished with value: 0.2811439867068022 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:25:57,359] Trial 153 finished with value: 0.2817848285549785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:26:43,354] Trial 170 finished with value: 0.43312331463443937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:31:26,581] Trial 154 finished with value: 0.28087424166143815 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:31:37,785] Trial 172 finished with value: 0.30489210581408843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:53:25,680] Trial 155 finished with value: 0.28069567186090283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 18:53:54,175] Trial 174 finished with value: 0.330732191093574 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23005, 'weights': 'distance'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 19:36:38,438] Trial 156 finished with value: 0.2810290411827037 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:10:25,068] Trial 157 finished with value: 0.28067359222684457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:13:45,702] Trial 158 finished with value: 0.28129524102448294 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:15:00,315] Trial 159 finished with value: 0.28118465466681897 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:15:33,397] Trial 160 finished with value: 0.28100671356204143 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:16:11,770] Trial 180 finished with value: 0.3164218242276749 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:16:12,064] Trial 181 finished with value: 0.3366932334173287 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:28:09,703] Trial 161 finished with value: 0.2811959849542525 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:31:08,799] Trial 163 finished with value: 0.2811658219231811 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:31:59,928] Trial 162 finished with value: 0.28129784878915365 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:34:37,824] Trial 165 finished with value: 0.2819608858049677 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 139 with value: 0.28039323610809685.
running
[I 2024-10-31 20:41:24,103] Trial 166 finished with value: 0.2800692280730416 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 20:44:34,946] Trial 167 finished with value: 0.2813053034619988 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:02:25,699] Trial 168 finished with value: 0.28109002814643447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:13:45,358] Trial 169 finished with value: 0.2801789067110826 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:24:32,564] Trial 171 finished with value: 0.28139303995876597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:24:38,594] Trial 191 finished with value: 0.3432863456927459 and parameters: {'model_name': 'VAE', 'batch_size': 593, 'iterations': 28, 'learning_rate': 0.0022136041860661734, 'p_miss': 0.09168157751888502}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:32:37,123] Trial 173 finished with value: 0.28128543629286784 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 21:54:23,667] Trial 175 finished with value: 0.28134424833375926 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 22:06:26,789] Trial 185 finished with value: 0.2922700886134183 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 22:15:42,493] Trial 187 finished with value: 0.2921336080304201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 22:19:46,097] Trial 188 finished with value: 0.2922134818779061 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 166 with value: 0.2800692280730416.
running
[I 2024-10-31 22:37:52,068] Trial 176 finished with value: 0.27972182627915554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
running
[I 2024-10-31 23:12:16,475] Trial 177 finished with value: 0.2808294888140316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
running
[I 2024-10-31 23:12:17,962] Trial 178 finished with value: 0.2804838577732915 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-10-31 23:13:26,370] Trial 179 finished with value: 0.2811786640991847 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-10-31 23:15:16,708] Trial 182 finished with value: 0.28169497371687446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-10-31 23:30:04,511] Trial 183 finished with value: 0.2806214550510699 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-10-31 23:30:43,989] Trial 184 finished with value: 0.28139047007133783 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-10-31 23:35:16,055] Trial 186 finished with value: 0.2815201536342987 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 00:02:22,565] Trial 189 finished with value: 0.28074918445971825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 00:12:54,435] Trial 190 finished with value: 0.2813408128140392 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 00:23:40,706] Trial 192 finished with value: 0.28126510850946634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 00:33:00,923] Trial 193 finished with value: 0.2819277540490569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 00:55:38,768] Trial 194 finished with value: 0.28082322468419413 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 01:06:55,107] Trial 195 finished with value: 0.28097618671880153 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 01:16:25,001] Trial 196 finished with value: 0.2811497018227353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 01:21:55,409] Trial 197 finished with value: 0.28078167925430153 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 01:36:43,433] Trial 198 finished with value: 0.28145384887662506 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
[I 2024-11-01 02:10:57,988] Trial 199 finished with value: 0.2812314950940738 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 176 with value: 0.27972182627915554.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.27972182627915554
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747143a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e50> 

Generation:  1
Best f1_score score: 0.9958957969815208
Generation:   4%|▍         | 1/25 [10:03<4:01:19, 603.32s/it]Generation:  2
Best f1_score score: 0.9958957969815208
Generation:   8%|▊         | 2/25 [16:38<3:04:21, 480.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0d90> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  3
Best f1_score score: 0.9958957969815208
Generation:  12%|█▏        | 3/25 [17:42<1:46:26, 290.30s/it]Generation:  4
Best f1_score score: 0.9958957969815208
Generation:  16%|█▌        | 4/25 [20:03<1:21:00, 231.44s/it]Generation:  5
Best f1_score score: 0.9958957969815208
Generation:  20%|██        | 5/25 [24:10<1:19:00, 237.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3160> 
 l1_ratio must be specified when penalty is elasticnet. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1204, in fit
    raise ValueError("l1_ratio must be specified when penalty is elasticnet.")
ValueError: l1_ratio must be specified when penalty is elasticnet.

Generation:  6
Best f1_score score: 0.9958957969815208
Generation:  24%|██▍       | 6/25 [24:58<54:43, 172.83s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a0d240> 

Generation:  7
Best f1_score score: 0.9958957969815208
Generation:  28%|██▊       | 7/25 [35:05<1:34:29, 314.96s/it]Generation:  8
Best f1_score score: 0.9958957969815208
Generation:  32%|███▏      | 8/25 [35:20<1:02:08, 219.34s/it]Generation:  9
Best f1_score score: 0.9958957969815208
Generation:  36%|███▌      | 9/25 [37:13<49:35, 185.97s/it]  Generation:  10
Best f1_score score: 0.9958957969815208
Generation:  40%|████      | 10/25 [38:08<36:24, 145.62s/it]Generation:  11
Best f1_score score: 0.9958957969815208
Generation:  44%|████▍     | 11/25 [39:10<28:01, 120.11s/it]Generation:  12
Best f1_score score: 0.9958957969815208
Generation:  48%|████▊     | 12/25 [41:36<27:41, 127.82s/it]Generation:  13
Best f1_score score: 0.9958957969815208
Generation:  52%|█████▏    | 13/25 [43:25<24:28, 122.37s/it]Generation:  14
Best f1_score score: 0.9958957969815208
Generation:  56%|█████▌    | 14/25 [44:10<18:08, 98.92s/it] Generation:  15
Best f1_score score: 0.9958957969815208
Generation:  60%|██████    | 15/25 [45:03<14:08, 84.87s/it]Generation:  16
Best f1_score score: 0.9958957969815208
Generation:  64%|██████▍   | 16/25 [46:05<11:42, 78.05s/it]Generation:  17
Best f1_score score: 0.9958957969815208
Generation:  68%|██████▊   | 17/25 [46:25<08:04, 60.56s/it]Generation:  18
Best f1_score score: 0.9958957969815208
Generation:  72%|███████▏  | 18/25 [46:56<06:03, 51.92s/it]Generation:  19
Best f1_score score: 0.9958957969815208
Generation:  76%|███████▌  | 19/25 [50:55<10:47, 107.94s/it]Generation:  20
Best f1_score score: 0.9960837502328775
Generation:  80%|████████  | 20/25 [51:14<06:46, 81.34s/it] Generation:  21
Best f1_score score: 0.9960837502328775
Generation:  84%|████████▍ | 21/25 [52:21<05:07, 76.87s/it]Generation:  22
Best f1_score score: 0.9960837502328775
Generation:  88%|████████▊ | 22/25 [52:40<02:58, 59.62s/it]Generation:  23
Best f1_score score: 0.9960837502328775
Generation:  92%|█████████▏| 23/25 [53:18<01:46, 53.03s/it]Generation:  24
Best f1_score score: 0.9960837502328775
Generation:  96%|█████████▌| 24/25 [53:46<00:45, 45.50s/it]Generation:  25
Best f1_score score: 0.9960837502328775
Generation: 100%|██████████| 25/25 [54:08<00:00, 38.48s/it]Generation: 100%|██████████| 25/25 [54:11<00:00, 130.07s/it]
2024-11-01 03:51:37,007 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34819' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-4fa83db7edc21762e1175d46b19569f3', 'ndarray-16205b9c29c2cbd81f55a3a14ad321d1'} (stimulus_id='handle-worker-cleanup-1730458297.0071535')
Fitted
Pipeline(steps=[('sgdclassifier',
                 SGDClassifier(alpha=1.19843614e-05, class_weight='balanced',
                               eta0=0.622839079322, l1_ratio=0.8798855250513,
                               loss='modified_huber', n_jobs=1,
                               penalty='elasticnet',
                               power_t=0.0003717701006))])
score start
train score: {'auroc': 0.9977177628836328, 'accuracy': 0.9964125835530754, 'balanced_accuracy': 0.996685747699662, 'logloss': 0.09293177836688549, 'f1': 0.9962765871853383}
original test score: {'auroc': 0.999996250599904, 'accuracy': 0.9990188864361049, 'balanced_accuracy': 0.9989809130539113, 'logloss': 0.0023962289480723713, 'f1': 0.9989809130539113}
imputed test score: {'auroc': 0.997309492981123, 'accuracy': 0.9959529065489331, 'balanced_accuracy': 0.9963126524756039, 'logloss': 0.11285555123155269, 'f1': 0.9958005744655319}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014640>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4c70> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.9931452336577712
Generation:   4%|▍         | 1/25 [01:37<39:07, 97.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474596260> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1ea10> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.9931452336577712
Generation:   8%|▊         | 2/25 [02:43<30:18, 79.08s/it]Generation:  3
Best f1_score score: 0.9946150162333932
Generation:  12%|█▏        | 3/25 [06:51<57:18, 156.31s/it]Generation:  4
Best f1_score score: 0.9946150162333932
Generation:  16%|█▌        | 4/25 [07:44<40:21, 115.29s/it]Generation:  5
Best f1_score score: 0.9947154576139285
Generation:  20%|██        | 5/25 [10:22<43:31, 130.58s/it]Generation:  6
Best f1_score score: 0.9948464654219616
Generation:  24%|██▍       | 6/25 [11:23<33:56, 107.21s/it]Generation:  7
Best f1_score score: 0.9948464654219616
Generation:  28%|██▊       | 7/25 [14:57<42:36, 142.02s/it]Generation:  8
Best f1_score score: 0.995036732402426
Generation:  32%|███▏      | 8/25 [17:25<40:43, 143.74s/it]Generation:  9
Best f1_score score: 0.995036732402426
Generation:  36%|███▌      | 9/25 [18:07<29:53, 112.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc461d0> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  10
Best f1_score score: 0.995036732402426
Generation:  40%|████      | 10/25 [18:55<23:03, 92.22s/it]Generation:  11
Best f1_score score: 0.995036732402426
Generation:  44%|████▍     | 11/25 [20:18<20:52, 89.48s/it]Generation:  12
Best f1_score score: 0.9950688411859246
Generation:  48%|████▊     | 12/25 [24:31<30:09, 139.23s/it]Generation:  13
Best f1_score score: 0.9950688411859246
Generation:  52%|█████▏    | 13/25 [25:29<22:55, 114.64s/it]Generation:  14
Best f1_score score: 0.9950688411859246
Generation:  56%|█████▌    | 14/25 [26:26<17:50, 97.33s/it] Generation:  15
Best f1_score score: 0.9950688411859246
Generation:  60%|██████    | 15/25 [27:55<15:45, 94.59s/it]Generation:  16
Best f1_score score: 0.9950688411859246
Generation:  64%|██████▍   | 16/25 [29:36<14:29, 96.56s/it]Generation:  17
Best f1_score score: 0.9952594695797707
Generation:  68%|██████▊   | 17/25 [31:00<12:22, 92.82s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547459ded0> 

Generation:  18
Best f1_score score: 0.9952594695797707
Generation:  72%|███████▏  | 18/25 [41:08<28:53, 247.65s/it]Generation:  19
Best f1_score score: 0.9952594695797707
Generation:  76%|███████▌  | 19/25 [42:38<20:02, 200.34s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4fd0> 

Generation:  20
Best f1_score score: 0.9952594695797707
Generation:  80%|████████  | 20/25 [52:47<26:55, 323.01s/it]Generation:  21
Best f1_score score: 0.9952594695797707
Generation:  84%|████████▍ | 21/25 [55:51<18:45, 281.33s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745969e0> 

Generation:  22
Best f1_score score: 0.9952594695797707
Generation:  88%|████████▊ | 22/25 [1:06:01<18:59, 379.86s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15543317ecb0> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  23
Best f1_score score: 0.9952594695797707
Generation:  92%|█████████▏| 23/25 [1:08:48<10:31, 315.95s/it]Generation:  24
Best f1_score score: 0.9952594695797707
Generation:  96%|█████████▌| 24/25 [1:10:07<04:04, 244.84s/it]Generation:  25
Best f1_score score: 0.9952594695797707
Generation: 100%|██████████| 25/25 [1:13:25<00:00, 230.77s/it]Generation: 100%|██████████| 25/25 [1:13:25<00:00, 176.21s/it]
2024-11-01 05:05:21,003 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35051' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-8e8938d2764b3dcaac038e27dfa544f8', 'ndarray-16205b9c29c2cbd81f55a3a14ad321d1'} (stimulus_id='handle-worker-cleanup-1730462721.0031598')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=10)),
                ('logisticregression',
                 LogisticRegression(C=4714.00200693432, class_weight='balanced',
                                    l1_ratio=0.8703684441388, max_iter=1000,
                                    n_jobs=1, penalty='elasticnet',
                                    solver='saga'))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9987107442163033, 'accuracy': 0.9951861163917336, 'balanced_accuracy': 0.9956086204384589, 'logloss': 0.047742116950941604, 'f1': 0.9950055646316781}
test score: {'auroc': 0.9988396856502959, 'accuracy': 0.9948491537895512, 'balanced_accuracy': 0.9955842065269557, 'logloss': 0.04680812962640272, 'f1': 0.9946596532395465}
original test score: {'auroc': 0.9999978753399456, 'accuracy': 0.9977924944812362, 'balanced_accuracy': 0.9981496710526316, 'logloss': 0.023432301430520906, 'f1': 0.9977090707823018}
score end
881
lvl
0.01
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
28.418299419813685
hours
DONE
