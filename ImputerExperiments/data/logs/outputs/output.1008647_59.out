Run: 59
/cm/local/apps/slurm/var/spool/job1008647/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/184/184.pkl
working on 
../data/c/184/class_full_MNAR_0.3_3
2.3423678874969482
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-19 19:00:12,873] A new study created in memory with name: no-name-04d2685e-5a73-4bf5-9bc2-e238b893baf8
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-19 19:00:13,264] Trial 4 finished with value: 0.30562633732716904 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 4 with value: 0.30562633732716904.
running
[I 2024-10-19 19:00:13,507] Trial 7 finished with value: 0.5342622497978963 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.30562633732716904.
running
[I 2024-10-19 19:00:13,965] Trial 17 finished with value: 0.3281953057917571 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.30562633732716904.
running
[I 2024-10-19 19:00:19,845] Trial 14 finished with value: 0.29461154875971607 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 14 with value: 0.29461154875971607.
running
[I 2024-10-19 19:00:23,372] Trial 5 finished with value: 0.5344704159334701 and parameters: {'model_name': 'GAIN', 'batch_size': 38, 'hint_rate': 0.2573640639202913, 'alpha': 44, 'iterations': 1, 'learning_rate': 0.003633764727694132, 'p_miss': 0.25688917692023117}. Best is trial 14 with value: 0.29461154875971607.
running
[I 2024-10-19 19:00:24,404] Trial 10 finished with value: 0.5325919209866432 and parameters: {'model_name': 'GAIN', 'batch_size': 455, 'hint_rate': 0.7758171152052814, 'alpha': 66, 'iterations': 2, 'learning_rate': 0.03302542985542747, 'p_miss': 0.23704323301091312}. Best is trial 14 with value: 0.29461154875971607.
running
[I 2024-10-19 19:00:24,826] Trial 2 finished with value: 0.5342724291282073 and parameters: {'model_name': 'GAIN', 'batch_size': 856, 'hint_rate': 0.6337193514808701, 'alpha': 39, 'iterations': 2, 'learning_rate': 0.01175966123445575, 'p_miss': 0.0730375349196004}. Best is trial 14 with value: 0.29461154875971607.
running
[I 2024-10-19 19:00:25,400] Trial 18 finished with value: 0.2936768843589201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:28,565] Trial 6 finished with value: 0.30215741617059744 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12540, 'weights': 'uniform'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:29,377] Trial 24 finished with value: 0.3281953057917571 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:30,166] Trial 13 finished with value: 0.53002309283821 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.21573839659683108, 'alpha': 1, 'iterations': 9, 'learning_rate': 0.005661294052818523, 'p_miss': 0.1378784581697965}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:33,227] Trial 3 finished with value: 0.301835531353717 and parameters: {'model_name': 'VAE', 'batch_size': 508, 'iterations': 1, 'learning_rate': 0.023504733018432256, 'p_miss': 0.24741782297244333}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:35,522] Trial 1 finished with value: 0.31933093380154853 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15405, 'weights': 'distance'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:35,912] Trial 16 finished with value: 0.3193223897819905 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14582, 'weights': 'distance'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:39,884] Trial 22 finished with value: 0.30562633732716904 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19470, 'weights': 'uniform'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:44,398] Trial 23 finished with value: 0.29391394602485044 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 18 with value: 0.2936768843589201.
running
[I 2024-10-19 19:00:45,454] Trial 26 finished with value: 0.2936768311239382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:46,557] Trial 27 finished with value: 0.2936768311239382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:47,674] Trial 9 finished with value: 0.3186217916949876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:47,941] Trial 25 finished with value: 0.2936769434415435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:49,219] Trial 29 finished with value: 0.2936768311239382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:50,319] Trial 28 finished with value: 0.2936768843589201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:52,609] Trial 0 finished with value: 0.5302000248822066 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.100270552266746, 'alpha': 51, 'iterations': 59, 'learning_rate': 0.06788087739702507, 'p_miss': 0.26437366096837683}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:53,954] Trial 30 finished with value: 0.2936768843589201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.2936768311239382.
running
[I 2024-10-19 19:00:55,535] Trial 21 finished with value: 0.2921040731082159 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 39, 'learning_rate': 0.0005453697449927348, 'p_miss': 0.25064644608830594}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:00:58,585] Trial 34 finished with value: 0.2936768746572267 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:00:58,952] Trial 33 finished with value: 0.2936768311239383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:00:59,519] Trial 31 finished with value: 0.29367674144460426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:00:59,813] Trial 32 finished with value: 0.2936769434415435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:01:01,711] Trial 36 finished with value: 0.2936768311239383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:01:20,714] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.2934963360103912, 'alpha': 1, 'iterations': 239, 'learning_rate': 0.021239675105319666, 'p_miss': 0.15356434991850276}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:03:20,331] Trial 8 finished with value: 0.320920734896125 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 94, 'learning_rate': 0.006415541002873151, 'p_miss': 0.021177006115782313}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:05:55,554] Trial 11 finished with value: 0.3107978229230267 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 131, 'learning_rate': 0.0031148581869473403, 'p_miss': 0.28741746422697345}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:11:26,679] Trial 12 finished with value: 0.3029428158285889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:12:26,623] Trial 38 finished with value: 0.3013092249565634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:16:16,056] Trial 20 finished with value: 0.30154136934379105 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:19:17,961] Trial 15 finished with value: 0.5335122600418797 and parameters: {'model_name': 'GAIN', 'batch_size': 38, 'hint_rate': 0.1087955976544885, 'alpha': 51, 'iterations': 801, 'learning_rate': 0.00011646625769581136, 'p_miss': 0.06642620700268625}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 19:30:29,193] Trial 37 finished with value: 0.3178154796819427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 21:18:40,507] Trial 45 finished with value: 0.3858254858546363 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2884, 'learning_rate': 0.00030123869167570624, 'p_miss': 0.16729690183092377}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 21:19:20,688] Trial 54 finished with value: 0.294771277832577 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 14, 'learning_rate': 0.0008941760486176261, 'p_miss': 0.20249676201888062}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 21:57:23,860] Trial 52 finished with value: 0.34514361029986357 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3288, 'learning_rate': 0.0005571374073227291, 'p_miss': 0.20188173268933235}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 21:58:28,513] Trial 56 finished with value: 0.2922247130131896 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 18, 'learning_rate': 0.0013597473785001803, 'p_miss': 0.2992704704903}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 21:59:29,380] Trial 57 finished with value: 0.29542826473220885 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 15, 'learning_rate': 0.001400864586719925, 'p_miss': 0.29451200355240736}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:01:02,419] Trial 58 finished with value: 0.29250180025886285 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 28, 'learning_rate': 0.0002688424905277587, 'p_miss': 0.2119501274658358}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:03:02,130] Trial 59 finished with value: 0.29359589633029404 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 32, 'learning_rate': 0.00022782658110850665, 'p_miss': 0.21018931340414765}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:04:33,373] Trial 60 finished with value: 0.293019537834054 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 25, 'learning_rate': 0.0002070291939057332, 'p_miss': 0.21538749973468135}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:06:33,665] Trial 61 finished with value: 0.2968721016088521 and parameters: {'model_name': 'VAE', 'batch_size': 141, 'iterations': 29, 'learning_rate': 0.0002350030246382529, 'p_miss': 0.21196668946834757}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:08:33,635] Trial 62 finished with value: 0.2922116483359352 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 29, 'learning_rate': 0.00027939505130214715, 'p_miss': 0.2203268618786456}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:09:07,879] Trial 63 finished with value: 0.2927987728753382 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 12, 'learning_rate': 0.00040735056967362626, 'p_miss': 0.23409040849676196}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:09:32,312] Trial 64 finished with value: 0.29437654361528925 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 6, 'learning_rate': 0.0005904345762705242, 'p_miss': 0.2733177912172645}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:10:01,138] Trial 65 finished with value: 0.29217344481714147 and parameters: {'model_name': 'VAE', 'batch_size': 307, 'iterations': 6, 'learning_rate': 0.0014452409357314589, 'p_miss': 0.23901179350422663}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:10:25,487] Trial 66 finished with value: 0.29347401636994846 and parameters: {'model_name': 'VAE', 'batch_size': 244, 'iterations': 5, 'learning_rate': 0.0011379664108240005, 'p_miss': 0.23660202780097753}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:11:09,730] Trial 43 finished with value: 0.361489744373585 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3775, 'learning_rate': 0.00022619757069662624, 'p_miss': 0.17298053970165228}. Best is trial 21 with value: 0.2921040731082159.
running
[I 2024-10-19 22:13:31,520] Trial 67 finished with value: 0.29151561650014873 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 52, 'learning_rate': 0.00044542692080524435, 'p_miss': 0.23602588675324448}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:14:25,130] Trial 68 finished with value: 0.29590507005168165 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 47, 'learning_rate': 0.00048373446005054626, 'p_miss': 0.24131591165102811}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:16:50,338] Trial 69 finished with value: 0.3013188089696613 and parameters: {'model_name': 'VAE', 'batch_size': 337, 'iterations': 51, 'learning_rate': 0.002072100572501117, 'p_miss': 0.26849013363637747}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:25:16,990] Trial 70 finished with value: 0.31033325750749247 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 218, 'learning_rate': 0.0015075249637844627, 'p_miss': 0.2756891130067949}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:26:02,354] Trial 71 finished with value: 0.30265784251238526 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 155, 'learning_rate': 0.00075396776911815, 'p_miss': 0.29899486720519886}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:26:11,942] Trial 73 finished with value: 0.29331246730345367 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 222, 'weights': 'uniform'}. Best is trial 67 with value: 0.29151561650014873.
running
[I 2024-10-19 22:26:23,988] Trial 72 finished with value: 0.290206467367886 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 20, 'learning_rate': 0.0007686926549047259, 'p_miss': 0.18578962281247058}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:26:24,643] Trial 75 finished with value: 0.5342622497978963 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:27:39,029] Trial 74 finished with value: 0.2925989981136832 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 21, 'learning_rate': 0.00014142976573747296, 'p_miss': 0.18231521921591926}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:27:44,378] Trial 76 finished with value: 0.292092142035687 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 23, 'learning_rate': 0.0001339507950539793, 'p_miss': 0.18154695188924683}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:31:06,382] Trial 77 finished with value: 0.292064150431064 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 56, 'learning_rate': 0.000372761165276446, 'p_miss': 0.22375045225423262}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:31:18,085] Trial 79 finished with value: 0.29912126517019516 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 4, 'learning_rate': 0.00037568157198846185, 'p_miss': 0.1874268975325376}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:31:46,113] Trial 78 finished with value: 0.29589672514540877 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 60, 'learning_rate': 0.0008841504558631533, 'p_miss': 0.22617492795609634}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:32:43,805] Trial 80 finished with value: 0.5301257033273054 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.9217411945979279, 'alpha': 94, 'iterations': 55, 'learning_rate': 0.0007271114217160733, 'p_miss': 0.22866384568785075}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:33:28,968] Trial 81 finished with value: 0.5314554483016436 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.9644629824399242, 'alpha': 96, 'iterations': 78, 'learning_rate': 0.00014287163776191975, 'p_miss': 0.13199153595152913}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:34:12,434] Trial 83 finished with value: 0.29333467116565803 and parameters: {'model_name': 'VAE', 'batch_size': 740, 'iterations': 8, 'learning_rate': 0.0003900785169629108, 'p_miss': 0.2505447160725701}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:34:22,518] Trial 84 finished with value: 0.3191925633628768 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2475, 'weights': 'distance'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:34:29,499] Trial 85 finished with value: 0.29315918965479554 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.00010532251600166844, 'p_miss': 0.25316851437776106}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:35:22,064] Trial 86 finished with value: 0.2923535043044939 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 17, 'learning_rate': 0.0012224918048662884, 'p_miss': 0.1958138282628575}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:37:28,359] Trial 87 finished with value: 0.2956138381421062 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 35, 'learning_rate': 0.002432895330661746, 'p_miss': 0.25962264972495874}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:38:02,553] Trial 82 finished with value: 0.29268924419783654 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 87, 'learning_rate': 0.000145729274149313, 'p_miss': 0.25400097068893734}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:38:03,360] Trial 89 finished with value: 0.5342622497978963 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:39:01,137] Trial 90 finished with value: 0.3290213204196001 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 19, 'learning_rate': 0.0885327692893694, 'p_miss': 0.21925324513579883}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:39:13,220] Trial 91 finished with value: 0.29503607101087503 and parameters: {'model_name': 'VAE', 'batch_size': 461, 'iterations': 3, 'learning_rate': 0.0005802681385414174, 'p_miss': 0.18489620672030643}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:41:13,468] Trial 88 finished with value: 0.29146387166106447 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 82, 'learning_rate': 0.0006260771180508898, 'p_miss': 0.22259408029338157}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:47:51,053] Trial 93 finished with value: 0.2947572869663306 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 125, 'learning_rate': 0.00031157897384796073, 'p_miss': 0.15118186059286196}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:48:44,238] Trial 92 finished with value: 0.29851241299860576 and parameters: {'model_name': 'VAE', 'batch_size': 195, 'iterations': 119, 'learning_rate': 0.0003412360557254422, 'p_miss': 0.1621298719847847}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:49:58,813] Trial 94 finished with value: 0.2978711354347755 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 41, 'learning_rate': 0.00045549078669307946, 'p_miss': 0.16804656418215907}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:50:32,965] Trial 96 finished with value: 0.2960712662137966 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 8, 'learning_rate': 0.0017265181134863289, 'p_miss': 0.22572221959213354}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:51:13,270] Trial 97 finished with value: 0.29264379075509944 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 12, 'learning_rate': 0.0009544800789575777, 'p_miss': 0.19689808945996143}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:55:12,608] Trial 98 finished with value: 0.2931799423033065 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 62, 'learning_rate': 0.0006618593329231006, 'p_miss': 0.24323163311227697}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:56:22,018] Trial 99 finished with value: 0.2924847460659514 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 24, 'learning_rate': 0.004355122702833904, 'p_miss': 0.28066588807917237}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:56:33,809] Trial 100 finished with value: 0.31926598771623993 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7923, 'weights': 'distance'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 22:59:56,786] Trial 42 finished with value: 0.36638304289088525 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5150, 'learning_rate': 0.0002625916710700297, 'p_miss': 0.17028725533209077}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:01:44,210] Trial 102 finished with value: 0.29060535525827674 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 39, 'learning_rate': 0.00016856171371282204, 'p_miss': 0.2613461681425568}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:01:44,835] Trial 103 finished with value: 0.5342622497978963 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:19:52,763] Trial 101 finished with value: 0.2964799871191417 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 404, 'learning_rate': 0.00017110985398356696, 'p_miss': 0.12983804788830694}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:21:51,194] Trial 95 finished with value: 0.3119079680227349 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 532, 'learning_rate': 0.0005279084893628609, 'p_miss': 0.22445532184088585}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:22:09,947] Trial 105 finished with value: 0.2951392346786205 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 38, 'learning_rate': 0.00028362275470210905, 'p_miss': 0.2607666298296876}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:22:57,803] Trial 104 finished with value: 0.2934375303677593 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 429, 'learning_rate': 0.00017990676372352577, 'p_miss': 0.11916417805347596}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:23:54,767] Trial 106 finished with value: 0.2962665863299415 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 38, 'learning_rate': 0.00019102149701731008, 'p_miss': 0.2663101551698198}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:27:12,407] Trial 108 finished with value: 0.2908700144193247 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 79, 'learning_rate': 0.0009664485887124095, 'p_miss': 0.243264236145307}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:27:23,118] Trial 107 finished with value: 0.2921051407388602 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 90, 'learning_rate': 0.00019007523413791592, 'p_miss': 0.24289238555064363}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:28:17,589] Trial 109 finished with value: 0.2996729527944943 and parameters: {'model_name': 'VAE', 'batch_size': 181, 'iterations': 81, 'learning_rate': 0.0011274929451044107, 'p_miss': 0.2375293540536625}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:30:30,837] Trial 111 finished with value: 0.5311041178108571 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.506273238174654, 'alpha': 23, 'iterations': 139, 'learning_rate': 0.0007976603225856918, 'p_miss': 0.24527199723738208}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:32:23,612] Trial 110 finished with value: 0.3004692985352258 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 88, 'learning_rate': 0.0010005282692062364, 'p_miss': 0.2385784782290118}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:33:32,931] Trial 112 finished with value: 0.5290444883495906 and parameters: {'model_name': 'GAIN', 'batch_size': 37, 'hint_rate': 0.512200539520625, 'alpha': 23, 'iterations': 185, 'learning_rate': 0.0008008933010934712, 'p_miss': 0.2450649851899069}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:35:18,579] Trial 48 finished with value: 0.38404267079020654 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6080, 'learning_rate': 0.0002877364492314777, 'p_miss': 0.18954124856623944}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:35:36,306] Trial 114 finished with value: 0.29348117496964266 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 65, 'learning_rate': 0.00043180644900188035, 'p_miss': 0.20516167707666452}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:37:07,911] Trial 117 finished with value: 0.2916780374758807 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 26, 'learning_rate': 0.00012076585393896782, 'p_miss': 0.21673157238557653}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:38:07,567] Trial 116 finished with value: 0.29168068742281156 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 61, 'learning_rate': 0.00045885947913779725, 'p_miss': 0.20640620396728587}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:38:52,896] Trial 115 finished with value: 0.315940285723597 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 100, 'learning_rate': 0.011333197657992605, 'p_miss': 0.20461281189919367}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:38:58,961] Trial 113 finished with value: 0.2953189298466617 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 193, 'learning_rate': 0.00011900066432668477, 'p_miss': 0.23423475739526656}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:41:28,912] Trial 121 finished with value: 0.29341288981121405 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 49, 'learning_rate': 0.0002140985903689455, 'p_miss': 0.1770755978062659}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:41:40,732] Trial 120 finished with value: 0.2925562751540279 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 49, 'learning_rate': 0.00012372492813821038, 'p_miss': 0.21386901167310618}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:41:49,129] Trial 123 finished with value: 0.30562633732716904 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21904, 'weights': 'uniform'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:42:48,298] Trial 122 finished with value: 0.295411310678377 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 23, 'learning_rate': 0.00010285897612846413, 'p_miss': 0.21504542382963743}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:43:35,386] Trial 125 finished with value: 0.29394514627178897 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 13, 'learning_rate': 0.00015562129043588207, 'p_miss': 0.19575959924330316}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:43:43,946] Trial 119 finished with value: 0.2915125574732096 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 108, 'learning_rate': 0.00012322894886096966, 'p_miss': 0.21485689401380462}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:43:52,683] Trial 124 finished with value: 0.2925314778040707 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 27, 'learning_rate': 0.0006181351444117092, 'p_miss': 0.22947615739308905}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:44:28,178] Trial 118 finished with value: 0.29476159108730104 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 100, 'learning_rate': 0.00011926604305688421, 'p_miss': 0.21350336771892828}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:45:33,314] Trial 126 finished with value: 0.29320239902688117 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 34, 'learning_rate': 0.0006418574090286111, 'p_miss': 0.22769474819798172}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:45:33,879] Trial 130 finished with value: 0.30562633732716904 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:47:27,152] Trial 127 finished with value: 0.2931614079796816 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 72, 'learning_rate': 0.0006145823274227555, 'p_miss': 0.22922033165555677}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:47:42,160] Trial 129 finished with value: 0.30190704322961726 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 72, 'learning_rate': 0.00023972643695195162, 'p_miss': 0.2522349708526951}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:49:01,154] Trial 131 finished with value: 0.2942409304140039 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 68, 'learning_rate': 0.0002281183943533386, 'p_miss': 0.2049739384492422}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:50:08,248] Trial 128 finished with value: 0.2957973605256654 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 105, 'learning_rate': 0.00013022607717385023, 'p_miss': 0.21840938489146094}. Best is trial 72 with value: 0.290206467367886.
running
[I 2024-10-19 23:50:14,204] Trial 132 finished with value: 0.2899225047167246 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 64, 'learning_rate': 0.00023623439842697152, 'p_miss': 0.2525847646124422}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:50:27,612] Trial 133 finished with value: 0.2949459128338483 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 48, 'learning_rate': 0.000492584278006152, 'p_miss': 0.2055220740197618}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:50:52,979] Trial 134 finished with value: 0.296607488114495 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 42, 'learning_rate': 0.00035799795907068315, 'p_miss': 0.05719580493421657}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:51:59,733] Trial 137 finished with value: 0.29233520925190215 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 32, 'learning_rate': 0.00033180785868331135, 'p_miss': 0.2571336209459663}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:52:49,451] Trial 136 finished with value: 0.29067374832559634 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 49, 'learning_rate': 0.00034742158609262576, 'p_miss': 0.25977385754710486}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:53:44,339] Trial 140 finished with value: 0.2917309639178497 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 17, 'learning_rate': 0.0004025167275154106, 'p_miss': 0.2697434569510883}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:54:27,366] Trial 141 finished with value: 0.2916388157068889 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 10, 'learning_rate': 0.00015684779548679641, 'p_miss': 0.2770901207282849}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:55:21,082] Trial 142 finished with value: 0.2934343014273122 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 10, 'learning_rate': 0.00025888808503023576, 'p_miss': 0.2739352944130719}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:56:53,430] Trial 51 finished with value: 0.36836311932957205 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5341, 'learning_rate': 0.00029734924431683307, 'p_miss': 0.19588156299586268}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:57:41,766] Trial 144 finished with value: 0.2914022265706443 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 16, 'learning_rate': 0.00042216464024052666, 'p_miss': 0.28182457931157345}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:58:34,045] Trial 145 finished with value: 0.2987319641454108 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 15, 'learning_rate': 0.0004285599976117834, 'p_miss': 0.2882750595755784}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-19 23:59:40,819] Trial 146 finished with value: 0.29632877176407274 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 18, 'learning_rate': 0.00016358263748685693, 'p_miss': 0.2878156740171806}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:00:28,268] Trial 139 finished with value: 0.2910707859126598 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 158, 'learning_rate': 0.0001542927905433148, 'p_miss': 0.267719455574947}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:01:01,504] Trial 148 finished with value: 0.330008706994574 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 10, 'learning_rate': 0.045615978981719006, 'p_miss': 0.2651854285521671}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:03:06,101] Trial 147 finished with value: 0.2925441415592933 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 56, 'learning_rate': 0.000509670012895705, 'p_miss': 0.26563206496822206}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:04:56,211] Trial 50 finished with value: 0.384322391814108 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6034, 'learning_rate': 0.0003674688781649905, 'p_miss': 0.20568032315476242}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:06:04,030] Trial 151 finished with value: 0.2910948822057273 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 21, 'learning_rate': 0.00020401335758015728, 'p_miss': 0.2775554292460159}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:07:31,344] Trial 152 finished with value: 0.29413679966989525 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 29, 'learning_rate': 0.00015971972035044347, 'p_miss': 0.2847416931325946}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:07:41,691] Trial 153 finished with value: 0.3192478168600027 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5983, 'weights': 'distance'}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:08:02,142] Trial 138 finished with value: 0.2942886195319078 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 294, 'learning_rate': 0.00017132232934291666, 'p_miss': 0.24798839292087582}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:08:02,860] Trial 155 finished with value: 0.3281953057917571 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:09:09,682] Trial 156 finished with value: 0.29201706766609814 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 19, 'learning_rate': 0.0002071492657928783, 'p_miss': 0.2774055864803393}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:09:45,209] Trial 135 finished with value: 0.3032421200814063 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 291, 'learning_rate': 0.0003514615172749519, 'p_miss': 0.1936867562480672}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:15:15,056] Trial 150 finished with value: 0.2968458009569976 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 246, 'learning_rate': 0.0002971479979232934, 'p_miss': 0.27949309333755534}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:15:27,532] Trial 40 finished with value: 0.37906657833879215 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7338, 'learning_rate': 0.00020527364832425567, 'p_miss': 0.17199587502564745}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:16:08,839] Trial 157 finished with value: 0.2949989681051279 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 140, 'learning_rate': 0.0002907603372091195, 'p_miss': 0.27186161312754736}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:16:17,157] Trial 159 finished with value: 0.2913332547896851 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 15, 'learning_rate': 0.00025863492364000036, 'p_miss': 0.27024408887580004}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:16:58,677] Trial 149 finished with value: 0.30574933498195606 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 325, 'learning_rate': 0.0005145634734974713, 'p_miss': 0.2791536670285825}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:17:02,646] Trial 161 finished with value: 0.29627523537846023 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 16, 'learning_rate': 0.00014088087137597842, 'p_miss': 0.25996420866000697}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:17:25,776] Trial 162 finished with value: 0.29291673633338255 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 22, 'learning_rate': 0.00014020534382345155, 'p_miss': 0.2567033906163263}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:17:39,190] Trial 158 finished with value: 0.2915846211296938 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 144, 'learning_rate': 0.0002985623230982649, 'p_miss': 0.2820262737731373}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:17:47,870] Trial 165 finished with value: 0.5265772618341156 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.727204176312412, 'alpha': 72, 'iterations': 11, 'learning_rate': 0.00025262716328955566, 'p_miss': 0.2934947320145132}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:18:04,192] Trial 166 finished with value: 0.29577344861302735 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7, 'learning_rate': 0.0002406319541307681, 'p_miss': 0.2953382789523792}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:19:53,314] Trial 154 finished with value: 0.29366223472424585 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 262, 'learning_rate': 0.00021347606379784755, 'p_miss': 0.2810221982726268}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:21:31,202] Trial 163 finished with value: 0.5321540647963243 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.7463736603018247, 'alpha': 78, 'iterations': 169, 'learning_rate': 0.00025278387879747763, 'p_miss': 0.2931070747841243}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:21:58,713] Trial 160 finished with value: 0.29406386083388053 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 159, 'learning_rate': 0.00026497165020911433, 'p_miss': 0.2688644748917012}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:25:25,697] Trial 168 finished with value: 0.29618069557505533 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 110, 'learning_rate': 0.0001940121989083374, 'p_miss': 0.2835527946746557}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:25:58,808] Trial 164 finished with value: 0.2924863246511065 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 162, 'learning_rate': 0.0001058654412558742, 'p_miss': 0.29160242448539797}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:26:42,126] Trial 44 finished with value: 0.3480855052314296 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6222, 'learning_rate': 0.00020034025250530586, 'p_miss': 0.1585478522972697}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:27:28,141] Trial 167 finished with value: 0.29486567356657056 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 181, 'learning_rate': 0.00019630723005785618, 'p_miss': 0.2839933071492832}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:27:34,526] Trial 171 finished with value: 0.2935980079485181 and parameters: {'model_name': 'VAE', 'batch_size': 96, 'iterations': 115, 'learning_rate': 0.0001856723604564035, 'p_miss': 0.2624331236280324}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:28:19,836] Trial 176 finished with value: 0.29766360054990837 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 13, 'learning_rate': 0.0003933224884781589, 'p_miss': 0.26969202745119886}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:29:01,512] Trial 170 finished with value: 0.293379663758931 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 116, 'learning_rate': 0.00010305344119040804, 'p_miss': 0.2692583860686887}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:29:10,297] Trial 174 finished with value: 0.29490837883886106 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 39, 'learning_rate': 0.0003177554509425863, 'p_miss': 0.2629352267798634}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:29:37,594] Trial 172 finished with value: 0.2909040016125956 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 79, 'learning_rate': 0.00010664784971409787, 'p_miss': 0.26340071312355323}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:30:17,884] Trial 169 finished with value: 0.29301641995390476 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 175, 'learning_rate': 0.00018737816161627704, 'p_miss': 0.26373506927417395}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:30:34,435] Trial 173 finished with value: 0.29310070481746553 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 63, 'learning_rate': 0.0004499772372300241, 'p_miss': 0.26235981982486223}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:30:38,429] Trial 175 finished with value: 0.2951568539761663 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 42, 'learning_rate': 0.00017029180391048393, 'p_miss': 0.26349633923221266}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:30:43,534] Trial 177 finished with value: 0.2931935489168812 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 42, 'learning_rate': 0.00045437721233379665, 'p_miss': 0.2730053131200493}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:30:48,577] Trial 178 finished with value: 0.29133969841267116 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 40, 'learning_rate': 0.00032330235168760127, 'p_miss': 0.2500094976953804}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:31:55,778] Trial 185 finished with value: 0.29843778796908105 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 25, 'learning_rate': 0.0001229789640929869, 'p_miss': 0.25030950469100427}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:34:18,590] Trial 181 finished with value: 0.29508573207839944 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 76, 'learning_rate': 0.00012575829488919714, 'p_miss': 0.24976653114392805}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:34:37,995] Trial 180 finished with value: 0.29802706802140333 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 84, 'learning_rate': 0.0001267336728315315, 'p_miss': 0.24955109128873373}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:35:05,776] Trial 183 finished with value: 0.2909486484843372 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 82, 'learning_rate': 0.00012490045747782266, 'p_miss': 0.25146659966713675}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:35:18,851] Trial 179 finished with value: 0.2940811593129668 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 81, 'learning_rate': 0.00045946308295787816, 'p_miss': 0.27247410141223316}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:35:36,604] Trial 190 finished with value: 0.3194467949149639 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:36:07,037] Trial 184 finished with value: 0.2931386348459791 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 82, 'learning_rate': 0.00011884914726723889, 'p_miss': 0.23351561293002945}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:36:16,023] Trial 192 finished with value: 0.2997651797852757 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8886, 'weights': 'uniform'}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:36:47,103] Trial 186 finished with value: 0.29096602090950585 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 85, 'learning_rate': 0.00015547974624091727, 'p_miss': 0.23288043587729318}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:37:01,136] Trial 189 finished with value: 0.2952323768361762 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 33, 'learning_rate': 0.00015950185082802873, 'p_miss': 0.2554315198362594}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:37:18,637] Trial 191 finished with value: 0.29247140769831337 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 32, 'learning_rate': 0.000156991019820008, 'p_miss': 0.2336002981022635}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:37:58,709] Trial 188 finished with value: 0.2925185719444364 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 60, 'learning_rate': 0.0001505281786488726, 'p_miss': 0.23366696193902262}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:39:06,000] Trial 195 finished with value: 0.2902479878914746 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 51, 'learning_rate': 0.00014664020214314623, 'p_miss': 0.23372281356173485}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:39:18,224] Trial 193 finished with value: 0.2904853106161287 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 52, 'learning_rate': 0.00016071662303661341, 'p_miss': 0.25453490616942487}. Best is trial 132 with value: 0.2899225047167246.
running
[I 2024-10-20 00:40:01,722] Trial 196 finished with value: 0.2947787325017992 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 51, 'learning_rate': 0.00010057537359822755, 'p_miss': 0.2414857325850247}. Best is trial 132 with value: 0.2899225047167246.
[I 2024-10-20 00:40:36,340] Trial 197 finished with value: 0.2897063386036302 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 51, 'learning_rate': 0.0006998578944218592, 'p_miss': 0.2425363618994974}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 00:41:14,535] Trial 198 finished with value: 0.292457016325938 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 47, 'learning_rate': 0.00032217229922391633, 'p_miss': 0.24133724740983387}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 00:43:25,592] Trial 199 finished with value: 0.2950778623080455 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 97, 'learning_rate': 0.0006983222618940793, 'p_miss': 0.24272402930153084}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:02:48,490] Trial 47 finished with value: 0.36244844756599226 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8808, 'learning_rate': 0.0002465887065573042, 'p_miss': 0.19235473027361286}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:05:44,742] Trial 35 finished with value: 0.3655110879477159 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8032, 'learning_rate': 0.00011788053730312135, 'p_miss': 0.015672611506374085}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:11:19,710] Trial 143 finished with value: 0.3303010428672402 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1810, 'learning_rate': 0.0004221965451434529, 'p_miss': 0.2858958305385158}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:15:30,500] Trial 194 finished with value: 0.3035547772432565 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 1154, 'learning_rate': 0.00014471363215040975, 'p_miss': 0.2548981539775879}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:20:27,856] Trial 53 finished with value: 0.36010488095873294 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7919, 'learning_rate': 0.00039295640942683567, 'p_miss': 0.19872469141866783}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:23:27,532] Trial 182 finished with value: 0.30403702928860676 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1641, 'learning_rate': 0.00012043906836252058, 'p_miss': 0.25197921673514223}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:26:05,749] Trial 39 finished with value: 0.35702708488638624 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9305, 'learning_rate': 0.00011118387864511142, 'p_miss': 0.030151481081799936}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:26:19,711] Trial 46 finished with value: 0.3656237278462962 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8359, 'learning_rate': 0.00023351573837169956, 'p_miss': 0.20115592099702412}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:27:42,435] Trial 187 finished with value: 0.34722846631202053 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2019, 'learning_rate': 0.0007210248119957771, 'p_miss': 0.24442466550476571}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:28:25,270] Trial 49 finished with value: 0.39138373963492257 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9579, 'learning_rate': 0.00035551656888811316, 'p_miss': 0.1969739179195161}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:28:40,650] Trial 41 finished with value: 0.3977227538541449 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9545, 'learning_rate': 0.0002871575495699813, 'p_miss': 0.1692319521017111}. Best is trial 197 with value: 0.2897063386036302.
[I 2024-10-20 01:30:15,781] Trial 55 finished with value: 0.3129403037270289 and parameters: {'model_name': 'VAE', 'batch_size': 206, 'iterations': 6605, 'learning_rate': 0.0009523569217149274, 'p_miss': 0.20228654301780036}. Best is trial 197 with value: 0.2897063386036302.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.2897063386036302
{'model_name': 'VAE', 'batch_size': 60, 'iterations': 51, 'learning_rate': 0.0006998578944218592, 'p_miss': 0.2425363618994974}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4f40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.06816363781272201
Generation:   4%|         | 1/25 [06:25<2:34:16, 385.70s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5c90> 

Generation:  2
Best f1_score score: 0.06816363781272201
Generation:   8%|         | 2/25 [16:30<3:17:13, 514.50s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e614b0> 

Generation:  3
Best f1_score score: 0.06854568057886028
Generation:  12%|        | 3/25 [26:33<3:23:30, 555.04s/it]Generation:  4
Best f1_score score: 0.06882284985570489
Generation:  16%|        | 4/25 [28:06<2:10:24, 372.59s/it]Generation:  5
Best f1_score score: 0.06882284985570489
Generation:  20%|        | 5/25 [29:56<1:32:35, 277.76s/it]Generation:  6
Best f1_score score: 0.06882284985570489
Generation:  24%|       | 6/25 [36:17<1:39:04, 312.87s/it]Generation:  7
Best f1_score score: 0.06960150434666909
Generation:  28%|       | 7/25 [40:38<1:28:50, 296.12s/it]Generation:  8
Best f1_score score: 0.06960150434666909
Generation:  32%|      | 8/25 [41:29<1:01:46, 218.00s/it]Generation:  9
Best f1_score score: 0.07005739613186514
Generation:  36%|      | 9/25 [43:26<49:42, 186.39s/it]  Generation:  10
Best f1_score score: 0.07005739613186514
Generation:  40%|      | 10/25 [43:47<33:49, 135.32s/it]Generation:  11
Best f1_score score: 0.07005739613186514
Generation:  44%|     | 11/25 [50:19<49:52, 213.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b940> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a6f20> 

Generation:  12
Best f1_score score: 0.07005739613186514
Generation:  48%|     | 12/25 [1:00:27<1:12:18, 333.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467924100> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554654bb700> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.07005739613186514
Generation:  52%|    | 13/25 [1:03:48<58:43, 293.59s/it]  Generation:  14
Best f1_score score: 0.07098247542057114
Generation:  56%|    | 14/25 [1:13:24<1:09:28, 378.98s/it]Generation:  15
Best f1_score score: 0.07098247542057114
Generation:  60%|    | 15/25 [1:14:46<48:14, 289.45s/it]  Generation:  16
Best f1_score score: 0.07098247542057114
Generation:  64%|   | 16/25 [1:16:21<34:37, 230.80s/it]Generation:  17
Best f1_score score: 0.07098247542057114
Generation:  68%|   | 17/25 [1:17:19<23:51, 178.98s/it]Generation:  18
Best f1_score score: 0.07098247542057114
Generation:  72%|  | 18/25 [1:18:41<17:27, 149.65s/it]Generation:  19
Best f1_score score: 0.07098247542057114
Generation:  76%|  | 19/25 [1:21:50<16:08, 161.46s/it]Generation:  20
Best f1_score score: 0.07098247542057114
Generation:  80%|  | 20/25 [1:22:25<10:17, 123.58s/it]Generation:  21
Best f1_score score: 0.07454383865541389
Generation:  84%| | 21/25 [1:23:45<07:22, 110.67s/it]Generation:  22
Best f1_score score: 0.07454383865541389
Generation:  88%| | 22/25 [1:24:32<04:34, 91.56s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b25d20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464da3eb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.07454383865541389
Generation:  92%|| 23/25 [1:32:46<07:04, 212.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554643d42b0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  24
Best f1_score score: 0.07454383865541389
Generation:  96%|| 24/25 [1:33:31<02:42, 162.04s/it]Generation:  25
Best f1_score score: 0.07454383865541389
Generation: 100%|| 25/25 [1:34:17<00:00, 127.06s/it]Generation: 100%|| 25/25 [1:34:20<00:00, 226.40s/it]
2024-10-20 03:04:50,685 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42645' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-38b7b4cc5f54c083a4f7584107caf218', 'ndarray-e6a0bf6ab5eddd1f3b7bbf1cee526317'} (stimulus_id='handle-worker-cleanup-1729418690.685067')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=9,
                                n_estimators=61, n_jobs=1, num_leaves=241,
                                verbose=-1))])
score start
train score: {'auroc': 0.9810905387120985, 'accuracy': 0.7734806629834254, 'balanced_accuracy': 0.8889204425650917, 'logloss': 1.2819531260071397, 'f1': 0.7861085309766036}
original test score: {'auroc': 0.47855837089988434, 'accuracy': 0.09319315751960086, 'balanced_accuracy': 0.06864536768742863, 'logloss': 2.6488182990606126, 'f1': 0.04491675496067375}
imputed test score: {'auroc': 0.514942886860158, 'accuracy': 0.09497505345687812, 'balanced_accuracy': 0.05705450994021726, 'logloss': 2.7224374255359924, 'f1': 0.05571552028646597}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4cd0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  1
Best f1_score score: 0.2519822332999725
Generation:   4%|         | 1/25 [02:50<1:08:18, 170.77s/it]Generation:  2
Best f1_score score: 0.2640251226193329
Generation:   8%|         | 2/25 [05:26<1:02:00, 161.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f09fc0> 

Generation:  3
Best f1_score score: 0.2640251226193329
Generation:  12%|        | 3/25 [15:29<2:13:16, 363.50s/it]Generation:  4
Best f1_score score: 0.2795339418657748
Generation:  16%|        | 4/25 [17:21<1:32:24, 264.02s/it]Generation:  5
Best f1_score score: 0.30638268547831254
Generation:  20%|        | 5/25 [19:47<1:13:47, 221.36s/it]corrupted size vs. prev_size
2024-10-20 03:27:37,544 - distributed.nanny - WARNING - Restarting worker
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655a42b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f040d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474739f00> 

Generation:  6
Best f1_score score: 0.30638268547831254
Generation:  24%|       | 6/25 [32:08<2:06:07, 398.31s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659c3d00> 

Generation:  7
Best f1_score score: 0.31758072413712074
Generation:  28%|       | 7/25 [42:15<2:19:55, 466.43s/it]Generation:  8
Best f1_score score: 0.31758072413712074
Generation:  32%|      | 8/25 [44:40<1:43:11, 364.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546792e410> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.31758072413712074
Generation:  36%|      | 9/25 [47:26<1:20:36, 302.25s/it]Generation:  10
Best f1_score score: 0.31758072413712074
Generation:  40%|      | 10/25 [49:54<1:03:38, 254.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678b3ca0> 

Generation:  11
Best f1_score score: 0.31758072413712074
Generation:  44%|     | 11/25 [1:00:03<1:24:41, 362.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465ca4130> 

Generation:  12
Best f1_score score: 0.31758072413712074
Generation:  48%|     | 12/25 [1:10:10<1:34:45, 437.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554654bd2d0> 

Generation:  13
Best f1_score score: 0.31758072413712074
Generation:  52%|    | 13/25 [1:20:19<1:37:49, 489.10s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b01360> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544f994400> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465163700> 

Generation:  14
Best f1_score score: 0.31758072413712074
Generation:  56%|    | 14/25 [1:30:27<1:36:17, 525.19s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2d4e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.31758072413712074
Generation:  60%|    | 15/25 [1:38:27<1:25:15, 511.57s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459520b80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655810f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ea3d90> 

Generation:  16
Best f1_score score: 0.31758072413712074
Generation:  64%|   | 16/25 [1:48:34<1:21:02, 540.33s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650c0730> 

Generation:  17
Best f1_score score: 0.31758072413712074
Generation:  68%|   | 17/25 [1:58:42<1:14:43, 560.46s/it]Generation:  18
Best f1_score score: 0.31758072413712074
Generation:  72%|  | 18/25 [2:00:56<50:27, 432.55s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155363a0ea10> 

Generation:  19
Best f1_score score: 0.31758072413712074
Generation:  76%|  | 19/25 [2:11:06<48:34, 485.78s/it]Generation:  20
Best f1_score score: 0.31758072413712074
Generation:  80%|  | 20/25 [2:16:15<36:02, 432.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a18820> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546564f040> 

Generation:  21
Best f1_score score: 0.31758072413712074
Generation:  84%| | 21/25 [2:26:24<32:22, 485.65s/it]Generation:  22
Best f1_score score: 0.31758072413712074
Generation:  88%| | 22/25 [2:30:11<20:24, 408.17s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b2afb0> 

Generation:  23
Best f1_score score: 0.31758072413712074
Generation:  92%|| 23/25 [2:40:17<15:34, 467.47s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676da470> 

Generation:  24
Best f1_score score: 0.31758072413712074
Generation:  96%|| 24/25 [2:50:25<08:29, 509.40s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554647e1090> 

Generation:  25
Best f1_score score: 0.31758072413712074
Generation: 100%|| 25/25 [3:00:30<00:00, 538.18s/it]Generation: 100%|| 25/25 [3:00:30<00:00, 433.21s/it]
2024-10-20 06:06:03,146 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37751' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-76e8cdd0b88d4a830e6070344b4a2b4a', 'ndarray-e6a0bf6ab5eddd1f3b7bbf1cee526317'} (stimulus_id='handle-worker-cleanup-1729429563.1459277')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.0003930665776,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.2407672418054, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=12,
                               max_leaves=None, min_child_weight=4, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9826713349902527, 'accuracy': 0.728301550525753, 'balanced_accuracy': 0.6255162775858785, 'logloss': 0.8426590926181424, 'f1': 0.6601931400294874}
test score: {'auroc': 0.868829279666397, 'accuracy': 0.36564504632929434, 'balanced_accuracy': 0.2734557558307602, 'logloss': 1.8577490295122494, 'f1': 0.2884537335548314}
original test score: {'auroc': 0.970973087049444, 'accuracy': 0.663399857448325, 'balanced_accuracy': 0.6354190565427471, 'logloss': 0.9251443930299548, 'f1': 0.6404533805148594}
score end
184
lvl
0.3
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
11.104216217266188
hours
DONE
