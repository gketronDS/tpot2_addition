Run: 55
/cm/local/apps/slurm/var/spool/job1069152/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MAR_0.3_3
3.435685157775879
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 15:17:31,887] A new study created in memory with name: no-name-66217bd5-4247-482b-825b-7dcea9ffa931
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 15:17:32,492] Trial 12 finished with value: 0.5042096607432617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.5042096607432617.
running
[I 2024-11-22 15:17:32,811] Trial 0 finished with value: 0.3313715695105852 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:32,990] Trial 3 finished with value: 0.5042096607432617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3313715695105852.
[I 2024-11-22 15:17:33,118] Trial 1 finished with value: 0.5042096607432617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3313715695105852.
running
running
[I 2024-11-22 15:17:33,361] Trial 14 finished with value: 0.5042096607432617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:33,608] Trial 16 finished with value: 0.5042096607432617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:33,854] Trial 18 finished with value: 0.3313715695105852 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:34,147] Trial 22 finished with value: 0.5562786778776538 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:34,324] Trial 21 finished with value: 0.5562786778776538 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.3313715695105852.
running
[I 2024-11-22 15:17:39,672] Trial 2 finished with value: 0.3241329765354797 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 2 with value: 0.3241329765354797.
running
[I 2024-11-22 15:17:41,769] Trial 20 finished with value: 0.32270337189204595 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 20 with value: 0.32270337189204595.
running
[I 2024-11-22 15:17:45,385] Trial 11 finished with value: 0.32122457654399983 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0080343638781561, 'p_miss': 0.10589418519326606}. Best is trial 11 with value: 0.32122457654399983.
running
[I 2024-11-22 15:17:46,131] Trial 10 finished with value: 0.3187184104721398 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 3, 'learning_rate': 0.0002381393734985558, 'p_miss': 0.2776473233711841}. Best is trial 10 with value: 0.3187184104721398.
running
[I 2024-11-22 15:17:48,644] Trial 4 finished with value: 0.32499556540592195 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13906, 'weights': 'uniform'}. Best is trial 10 with value: 0.3187184104721398.
running
[I 2024-11-22 15:17:49,473] Trial 24 finished with value: 0.33006455154090997 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 34374, 'weights': 'uniform'}. Best is trial 10 with value: 0.3187184104721398.
running
[I 2024-11-22 15:17:49,945] Trial 27 finished with value: 0.3245918058588729 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.00910567525712231, 'p_miss': 0.10619668270350809}. Best is trial 10 with value: 0.3187184104721398.
running
[I 2024-11-22 15:17:50,954] Trial 6 finished with value: 0.33270033331690996 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6, 'learning_rate': 0.035179637438091695, 'p_miss': 0.24762279305001153}. Best is trial 10 with value: 0.3187184104721398.
running
[I 2024-11-22 15:17:51,462] Trial 28 finished with value: 0.31758867578001826 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 2, 'learning_rate': 0.003970109075902778, 'p_miss': 0.12810737915697928}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:52,224] Trial 8 finished with value: 0.3797292662474627 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32640, 'weights': 'distance'}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:53,081] Trial 30 finished with value: 0.3179817590118016 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.0042609827538282585, 'p_miss': 0.12847461167981158}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:53,757] Trial 29 finished with value: 0.3278535871602179 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2, 'learning_rate': 0.003605246854259561, 'p_miss': 0.12996883212406435}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:54,788] Trial 31 finished with value: 0.3186460898526713 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 2, 'learning_rate': 0.0001256920461462805, 'p_miss': 0.28000257122918093}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:55,084] Trial 25 finished with value: 0.3241329765354797 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:17:58,511] Trial 26 finished with value: 0.3241894485115821 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:18:52,182] Trial 15 finished with value: 0.5560927543404806 and parameters: {'model_name': 'GAIN', 'batch_size': 185, 'hint_rate': 0.8256499499061348, 'alpha': 71, 'iterations': 63, 'learning_rate': 0.0012094047480050456, 'p_miss': 0.1115259835442171}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:19:32,791] Trial 9 finished with value: 0.32569115924791137 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 42, 'learning_rate': 0.001732688065782481, 'p_miss': 0.21055873503371325}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:20:17,563] Trial 5 finished with value: 0.5561186365088859 and parameters: {'model_name': 'GAIN', 'batch_size': 57, 'hint_rate': 0.1561932347384648, 'alpha': 15, 'iterations': 132, 'learning_rate': 0.05559203628465927, 'p_miss': 0.029471121494176855}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:21:39,198] Trial 39 finished with value: 0.5546443310337594 and parameters: {'model_name': 'GAIN', 'batch_size': 386, 'hint_rate': 0.5779518140182635, 'alpha': 92, 'iterations': 154, 'learning_rate': 0.000372640538410988, 'p_miss': 0.1917841390672891}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:22:09,065] Trial 43 finished with value: 0.32536318679271803 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 11, 'learning_rate': 0.00593321363672533, 'p_miss': 0.1657452200681853}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:23:02,250] Trial 37 finished with value: 0.5563101537604334 and parameters: {'model_name': 'GAIN', 'batch_size': 466, 'hint_rate': 0.6326589764352776, 'alpha': 41, 'iterations': 210, 'learning_rate': 0.0008724427287892923, 'p_miss': 0.021163460161526787}. Best is trial 28 with value: 0.31758867578001826.
running
[I 2024-11-22 15:23:40,124] Trial 45 finished with value: 0.3165968268796937 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 15, 'learning_rate': 0.00011436766216552534, 'p_miss': 0.07471581230740294}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:24:41,873] Trial 36 finished with value: 0.5586827787642867 and parameters: {'model_name': 'GAIN', 'batch_size': 184, 'hint_rate': 0.6476921368023387, 'alpha': 100, 'iterations': 299, 'learning_rate': 0.000125585834524436, 'p_miss': 0.22400696163109293}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:31:37,139] Trial 33 finished with value: 0.552953635833644 and parameters: {'model_name': 'GAIN', 'batch_size': 225, 'hint_rate': 0.61470908677414, 'alpha': 66, 'iterations': 596, 'learning_rate': 0.0001238503433814366, 'p_miss': 0.28634389655028936}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:32:08,757] Trial 32 finished with value: 0.5550284535325096 and parameters: {'model_name': 'GAIN', 'batch_size': 182, 'hint_rate': 0.291024648991969, 'alpha': 24, 'iterations': 636, 'learning_rate': 0.00026767319808804386, 'p_miss': 0.028007120720752357}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:32:10,251] Trial 48 finished with value: 0.3251864664656839 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 12, 'learning_rate': 0.00046529793209027127, 'p_miss': 0.05668668861764532}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:32:14,874] Trial 50 finished with value: 0.31890625746531714 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.004127001486574362, 'p_miss': 0.0813845266573193}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:32:42,993] Trial 49 finished with value: 0.3743571033668579 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 13, 'learning_rate': 0.02008774085990336, 'p_miss': 0.06937241083989551}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:42:21,410] Trial 35 finished with value: 0.5561438207823173 and parameters: {'model_name': 'GAIN', 'batch_size': 758, 'hint_rate': 0.7498709264310593, 'alpha': 56, 'iterations': 922, 'learning_rate': 0.000796868539496287, 'p_miss': 0.020800057307472156}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:46:21,117] Trial 7 finished with value: 0.35961564444971017 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:55:17,092] Trial 34 finished with value: 0.5505755760718906 and parameters: {'model_name': 'GAIN', 'batch_size': 164, 'hint_rate': 0.6859466203000332, 'alpha': 9, 'iterations': 1555, 'learning_rate': 0.00011184282812027, 'p_miss': 0.28326021834644904}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 15:55:40,101] Trial 38 finished with value: 0.5530153416940435 and parameters: {'model_name': 'GAIN', 'batch_size': 244, 'hint_rate': 0.608348705179378, 'alpha': 8, 'iterations': 1542, 'learning_rate': 0.0005690547073261875, 'p_miss': 0.18960733914427297}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:07:40,446] Trial 17 finished with value: 0.3431805037352785 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 965, 'learning_rate': 0.008207423920536623, 'p_miss': 0.06555688564403372}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:07:57,364] Trial 57 finished with value: 0.31879009201446357 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 4, 'learning_rate': 0.00019833450610533688, 'p_miss': 0.1425015646767293}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:08:13,144] Trial 58 finished with value: 0.31801633858488143 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 4, 'learning_rate': 0.002018045477965466, 'p_miss': 0.27077797855931157}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:09:48,894] Trial 59 finished with value: 0.3217217747871546 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 28, 'learning_rate': 0.002990669875499128, 'p_miss': 0.2584195336705147}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:09:53,937] Trial 60 finished with value: 0.3191353518687789 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 1, 'learning_rate': 0.0020679704420825448, 'p_miss': 0.16145037966194642}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:35:54,794] Trial 23 finished with value: 0.554603049224584 and parameters: {'model_name': 'GAIN', 'batch_size': 105, 'hint_rate': 0.3186132178334011, 'alpha': 0, 'iterations': 3157, 'learning_rate': 0.0008783286172642956, 'p_miss': 0.2809174938876334}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:36:16,496] Trial 62 finished with value: 0.3269852859055286 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.017007537212123242, 'p_miss': 0.1306147645481304}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:36:27,665] Trial 63 finished with value: 0.31761785445548085 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 2, 'learning_rate': 0.0019267350773874402, 'p_miss': 0.2531381763789157}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:36:37,060] Trial 64 finished with value: 0.3794035309733716 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 478, 'weights': 'distance'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:37:51,492] Trial 65 finished with value: 0.3210115974232261 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 21, 'learning_rate': 0.0020163680747004777, 'p_miss': 0.24916103509584786}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:38:03,352] Trial 66 finished with value: 0.31985153762414986 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 2, 'learning_rate': 0.005143321364882881, 'p_miss': 0.2616095579549247}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:38:31,193] Trial 67 finished with value: 0.34197821712389426 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 5, 'learning_rate': 0.09117508754102464, 'p_miss': 0.23433937097838534}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:38:42,856] Trial 68 finished with value: 0.3209485099775054 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 2, 'learning_rate': 0.0026429184851809078, 'p_miss': 0.088360022729779}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:38:54,883] Trial 69 finished with value: 0.32038297564447155 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 3, 'learning_rate': 0.0013056617393056602, 'p_miss': 0.29888774249353994}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:39:29,960] Trial 70 finished with value: 0.3333126741693101 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 7, 'learning_rate': 0.01450036763789946, 'p_miss': 0.045462474220917495}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:39:35,922] Trial 71 finished with value: 0.32096431545429405 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.00017429115711962932, 'p_miss': 0.26420748955058215}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:39:50,319] Trial 72 finished with value: 0.3796089274028077 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17893, 'weights': 'distance'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:04,349] Trial 73 finished with value: 0.31933269130406977 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 3, 'learning_rate': 0.0013977278843044399, 'p_miss': 0.1794151898710222}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:14,036] Trial 74 finished with value: 0.3227640673479101 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 2, 'learning_rate': 0.006037216935870737, 'p_miss': 0.12089203403702926}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:27,995] Trial 75 finished with value: 0.31921740275423643 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0022351032679269237, 'p_miss': 0.2145221268554128}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:39,309] Trial 76 finished with value: 0.3186694015522188 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 2, 'learning_rate': 0.0002078539573499212, 'p_miss': 0.27221175916571133}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:49,056] Trial 77 finished with value: 0.31734828603134924 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 2, 'learning_rate': 0.00028241632419191844, 'p_miss': 0.270359346240734}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:40:55,043] Trial 78 finished with value: 0.3188447234857236 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 1, 'learning_rate': 0.00028763878259134573, 'p_miss': 0.24785098920876109}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:41:13,441] Trial 79 finished with value: 0.32544487073193534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:42:55,367] Trial 13 finished with value: 0.547913998007431 and parameters: {'model_name': 'GAIN', 'batch_size': 393, 'hint_rate': 0.3112508908506001, 'alpha': 84, 'iterations': 3256, 'learning_rate': 0.003556487342705717, 'p_miss': 0.2620261439387336}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:43:16,206] Trial 81 finished with value: 0.3194294440026353 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 7, 'learning_rate': 0.000150542240104275, 'p_miss': 0.29621909141589076}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:46:30,114] Trial 42 finished with value: 0.3337138068892253 and parameters: {'model_name': 'VAE', 'batch_size': 366, 'iterations': 1379, 'learning_rate': 0.00010584614120108921, 'p_miss': 0.18466722044319928}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:46:47,514] Trial 83 finished with value: 0.32567100119365167 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 3, 'learning_rate': 0.011803524588858645, 'p_miss': 0.1446407800029585}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:46:48,201] Trial 84 finished with value: 0.33006455154090997 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:46:57,742] Trial 85 finished with value: 0.32182975563971883 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2667, 'weights': 'uniform'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:47:07,011] Trial 86 finished with value: 0.3168672886852577 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 2, 'learning_rate': 0.00023048102075784628, 'p_miss': 0.28344771927455914}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:47:14,264] Trial 87 finished with value: 0.3188300715041359 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2, 'learning_rate': 0.0001477305825268761, 'p_miss': 0.2754197167635887}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:47:28,785] Trial 88 finished with value: 0.3214405305267959 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 4, 'learning_rate': 0.00027139920893964593, 'p_miss': 0.0933058367373239}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:48:02,044] Trial 82 finished with value: 0.32234964822724327 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 75, 'learning_rate': 0.00033220929055529177, 'p_miss': 0.08565903076942764}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:48:07,002] Trial 90 finished with value: 0.324178947505493 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.004090000416265257, 'p_miss': 0.2886158607878985}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 16:48:38,711] Trial 91 finished with value: 0.3519720169207591 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 17:09:11,188] Trial 46 finished with value: 0.38003620447442543 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2444, 'learning_rate': 0.00011081054946239906, 'p_miss': 0.07055164912135878}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 17:09:24,253] Trial 93 finished with value: 0.3191953705871909 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.0006404485827667658, 'p_miss': 0.23999528643206544}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 17:09:54,940] Trial 94 finished with value: 0.3212087790059817 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 9, 'learning_rate': 0.000438725430900822, 'p_miss': 0.27692489379055546}. Best is trial 45 with value: 0.3165968268796937.
running
[I 2024-11-22 17:10:07,048] Trial 95 finished with value: 0.31655678067392656 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 3, 'learning_rate': 0.00022427660445584844, 'p_miss': 0.11567839563493357}. Best is trial 95 with value: 0.31655678067392656.
running
[I 2024-11-22 17:10:24,642] Trial 96 finished with value: 0.3161450364850687 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5, 'learning_rate': 0.0002392086611448515, 'p_miss': 0.114141113367612}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:10:43,638] Trial 97 finished with value: 0.31714748891109246 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 5, 'learning_rate': 0.00023165279455151957, 'p_miss': 0.11090397092777274}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:11:46,577] Trial 98 finished with value: 0.3207380755802129 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 17, 'learning_rate': 0.00024851179686025517, 'p_miss': 0.11129392180211667}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:01,924] Trial 44 finished with value: 0.42847632455119555 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2553, 'learning_rate': 0.0007748404783171397, 'p_miss': 0.05886363210727365}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:06,609] Trial 99 finished with value: 0.3202192671847331 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.0001805449421475092, 'p_miss': 0.10000304069190186}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:07,689] Trial 101 finished with value: 0.33006455154090997 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:19,566] Trial 100 finished with value: 0.31965534208103136 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 5, 'learning_rate': 0.00018463645738519755, 'p_miss': 0.09897161722273397}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:31,867] Trial 103 finished with value: 0.32093249271273816 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 3, 'learning_rate': 0.000507499189066322, 'p_miss': 0.11864904908844758}. Best is trial 96 with value: 0.3161450364850687.
running
[I 2024-11-22 17:12:32,673] Trial 102 finished with value: 0.31578637093044876 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.0003432225469377776, 'p_miss': 0.1208735791400785}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:13:00,379] Trial 105 finished with value: 0.35179231663297983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:13:07,796] Trial 104 finished with value: 0.3187625611502275 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.000338386665685782, 'p_miss': 0.1345052091163317}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:13:28,155] Trial 107 finished with value: 0.31940405130270155 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 6, 'learning_rate': 0.00021967099127464696, 'p_miss': 0.12028909856760085}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:16:16,609] Trial 108 finished with value: 0.31900544203615744 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 49, 'learning_rate': 0.00035640797816810976, 'p_miss': 0.14700162046085208}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:16:28,285] Trial 109 finished with value: 0.3189272350472341 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 3, 'learning_rate': 0.00014292678838496894, 'p_miss': 0.12831859647817112}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:16:59,441] Trial 110 finished with value: 0.33280955218026165 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 10, 'learning_rate': 0.0004059927479952932, 'p_miss': 0.15607649732387527}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:17:11,479] Trial 111 finished with value: 0.3296071305109549 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 26302, 'weights': 'uniform'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:17:27,883] Trial 112 finished with value: 0.3186555131660777 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 4, 'learning_rate': 0.0002678869540269661, 'p_miss': 0.10920575052951756}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:18:28,373] Trial 113 finished with value: 0.3190198150236636 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 16, 'learning_rate': 0.0010223798016100252, 'p_miss': 0.14050183631526358}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:18:38,444] Trial 114 finished with value: 0.322528490613436 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 2, 'learning_rate': 0.0002376285685690588, 'p_miss': 0.11763878870392633}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:18:48,320] Trial 115 finished with value: 0.317468019657371 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 2, 'learning_rate': 0.008181509005590745, 'p_miss': 0.10237262920675824}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:18:59,586] Trial 116 finished with value: 0.32252873243266167 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 2, 'learning_rate': 0.005819280192123854, 'p_miss': 0.10477313044909253}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:19:13,947] Trial 117 finished with value: 0.32110304276968754 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.010865608332508941, 'p_miss': 0.1254840898018135}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:19:33,491] Trial 118 finished with value: 0.33140125136496795 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 5, 'learning_rate': 0.024033821823551516, 'p_miss': 0.13574738618579327}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:21:06,515] Trial 119 finished with value: 0.34740099909574085 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 30, 'learning_rate': 0.007626020687901468, 'p_miss': 0.11288043201944566}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:21:41,169] Trial 120 finished with value: 0.3223284348145031 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 8, 'learning_rate': 0.0033137679575655147, 'p_miss': 0.09784641606767437}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:21:42,228] Trial 121 finished with value: 0.5562786778776538 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:21:57,636] Trial 122 finished with value: 0.3209247939170091 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4, 'learning_rate': 0.007647727510337203, 'p_miss': 0.08476152004767401}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:22:04,767] Trial 123 finished with value: 0.3191575474247155 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 2, 'learning_rate': 0.00010230499786694146, 'p_miss': 0.07668560033356947}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:22:28,541] Trial 124 finished with value: 0.3245299469403966 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 6, 'learning_rate': 0.00480541099708107, 'p_miss': 0.15114599346486107}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:22:34,526] Trial 125 finished with value: 0.3203609676958325 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 1, 'learning_rate': 0.0006427087855690592, 'p_miss': 0.17360577248233272}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:33:57,301] Trial 41 finished with value: 0.3350053033707196 and parameters: {'model_name': 'VAE', 'batch_size': 318, 'iterations': 2171, 'learning_rate': 0.00012077443640540199, 'p_miss': 0.024746479272362176}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:34:10,741] Trial 127 finished with value: 0.3195866385050262 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 3, 'learning_rate': 0.002895568618008996, 'p_miss': 0.26497730349957355}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:34:27,630] Trial 128 finished with value: 0.317948763100242 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 4, 'learning_rate': 0.0016412664150022346, 'p_miss': 0.040378094225516914}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:34:42,942] Trial 129 finished with value: 0.3209884971508137 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 4, 'learning_rate': 0.0002967664760405746, 'p_miss': 0.015398474187686154}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:35:59,827] Trial 51 finished with value: 0.42672455725789404 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3044, 'learning_rate': 0.014786842048627714, 'p_miss': 0.15418191453403382}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:36:21,686] Trial 131 finished with value: 0.32081510933260915 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 6, 'learning_rate': 0.00014805420172053077, 'p_miss': 0.06344466091332128}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:51:59,515] Trial 52 finished with value: 0.3378116744708137 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 2683, 'learning_rate': 0.002101030476669471, 'p_miss': 0.14171471049533843}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:52:40,436] Trial 133 finished with value: 0.3206047003733559 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 13, 'learning_rate': 0.001406754967177764, 'p_miss': 0.03863672286861604}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:52:54,115] Trial 134 finished with value: 0.3795546888917569 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13084, 'weights': 'distance'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:53:17,954] Trial 135 finished with value: 0.4606496409272539 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:53:28,920] Trial 136 finished with value: 0.3184791759400807 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 3, 'learning_rate': 0.0018157767734041507, 'p_miss': 0.2902714008097046}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:53:43,300] Trial 137 finished with value: 0.3178984415351075 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 4, 'learning_rate': 0.0024850003860123404, 'p_miss': 0.10400846391758686}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:54:02,473] Trial 138 finished with value: 0.3244557413421295 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 5, 'learning_rate': 0.0038843014831489485, 'p_miss': 0.049333360124847195}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:54:16,872] Trial 139 finished with value: 0.31819264883482246 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 4, 'learning_rate': 0.002459779628816539, 'p_miss': 0.10496309634382374}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:54:25,314] Trial 140 finished with value: 0.3170150297775457 and parameters: {'model_name': 'VAE', 'batch_size': 143, 'iterations': 2, 'learning_rate': 0.00020706758384596212, 'p_miss': 0.09444844296256612}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:54:36,836] Trial 141 finished with value: 0.32406593823765784 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 3, 'learning_rate': 0.00021399347211794212, 'p_miss': 0.08967252233653022}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:55:01,960] Trial 142 finished with value: 0.31797696500825934 and parameters: {'model_name': 'VAE', 'batch_size': 278, 'iterations': 7, 'learning_rate': 0.0001737306033566832, 'p_miss': 0.09398090174925795}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 17:55:10,794] Trial 143 finished with value: 0.5572557828449309 and parameters: {'model_name': 'GAIN', 'batch_size': 66, 'hint_rate': 0.05481176680290878, 'alpha': 37, 'iterations': 2, 'learning_rate': 0.0016600731920359448, 'p_miss': 0.07752596903038403}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:15:32,628] Trial 47 finished with value: 0.38197109491092746 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3722, 'learning_rate': 0.00012443756936423932, 'p_miss': 0.08015769478944182}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:20:38,537] Trial 144 finished with value: 0.321572957292391 and parameters: {'model_name': 'VAE', 'batch_size': 840, 'iterations': 337, 'learning_rate': 0.000133582101283297, 'p_miss': 0.1158813466177229}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:21:05,318] Trial 146 finished with value: 0.31838690434789985 and parameters: {'model_name': 'VAE', 'batch_size': 315, 'iterations': 8, 'learning_rate': 0.00016185214109505028, 'p_miss': 0.10856311993036907}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:21:22,526] Trial 147 finished with value: 0.3242547764989155 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 6, 'learning_rate': 0.00019967428752020014, 'p_miss': 0.09449439745216046}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:21:44,990] Trial 148 finished with value: 0.3207331249000757 and parameters: {'model_name': 'VAE', 'batch_size': 253, 'iterations': 5, 'learning_rate': 0.00029307112157625893, 'p_miss': 0.10251316611295071}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:07,245] Trial 149 finished with value: 0.3210103781274686 and parameters: {'model_name': 'VAE', 'batch_size': 139, 'iterations': 7, 'learning_rate': 0.00017077752633069755, 'p_miss': 0.09509419878684705}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:24,658] Trial 150 finished with value: 0.32537591867711885 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 4, 'learning_rate': 0.00024280674519197213, 'p_miss': 0.12384327168501498}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:34,972] Trial 151 finished with value: 0.3173105638501116 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 3, 'learning_rate': 0.0016294956593423107, 'p_miss': 0.11403576940746811}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:35,918] Trial 152 finished with value: 0.33006455154090997 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:51,264] Trial 153 finished with value: 0.32157544320285886 and parameters: {'model_name': 'VAE', 'batch_size': 564, 'iterations': 3, 'learning_rate': 0.0004053357535409946, 'p_miss': 0.2558415815274827}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:22:58,850] Trial 154 finished with value: 0.319632520863639 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0011495192106117827, 'p_miss': 0.13334740163350073}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:28:12,455] Trial 155 finished with value: 0.3284221767792065 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 101, 'learning_rate': 0.001659193882371811, 'p_miss': 0.03294383599413811}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:28:40,422] Trial 156 finished with value: 0.3187858720583397 and parameters: {'model_name': 'VAE', 'batch_size': 162, 'iterations': 5, 'learning_rate': 0.002521356216258023, 'p_miss': 0.11105861158941244}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:29:18,029] Trial 157 finished with value: 0.3214924538711842 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 11, 'learning_rate': 0.0003165854997666556, 'p_miss': 0.19823736365707845}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:29:35,214] Trial 158 finished with value: 0.32092477193299274 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.00012244973682479324, 'p_miss': 0.10230265857787828}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:30:15,687] Trial 159 finished with value: 0.31595182095569985 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 15, 'learning_rate': 0.00022964884872950074, 'p_miss': 0.07286437270411321}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:31:51,097] Trial 160 finished with value: 0.3171915238587869 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 25, 'learning_rate': 0.00022072802743269227, 'p_miss': 0.06901672187580385}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:33:10,599] Trial 161 finished with value: 0.3218393304721524 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 23, 'learning_rate': 0.0002309359855894881, 'p_miss': 0.05492763751849654}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:34:44,320] Trial 162 finished with value: 0.3179251195668513 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 33, 'learning_rate': 0.0002640993045784321, 'p_miss': 0.07537006546556997}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 18:35:31,156] Trial 163 finished with value: 0.31907626823347457 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 17, 'learning_rate': 0.0002002814145658836, 'p_miss': 0.08275989243852148}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:05:19,675] Trial 164 finished with value: 0.3592497488129332 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:05:32,108] Trial 165 finished with value: 0.32881323696785864 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24498, 'weights': 'uniform'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:08:44,045] Trial 166 finished with value: 0.31840730804033746 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 52, 'learning_rate': 0.00027035841145367593, 'p_miss': 0.06374970577956895}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:10:14,174] Trial 167 finished with value: 0.3208051502284641 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 35, 'learning_rate': 0.00033854357508588534, 'p_miss': 0.07079380301104547}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:11:18,280] Trial 168 finished with value: 0.3169716465009908 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 20, 'learning_rate': 0.00024057582849723767, 'p_miss': 0.07344469604051913}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:12:00,837] Trial 169 finished with value: 0.3256749937080044 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 15, 'learning_rate': 0.00023598635611600573, 'p_miss': 0.07296305779754203}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:13:11,950] Trial 170 finished with value: 0.31856178481119224 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 24, 'learning_rate': 0.0003915096139218964, 'p_miss': 0.28288777304788376}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:14:09,773] Trial 171 finished with value: 0.32142371233430767 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 19, 'learning_rate': 0.00019610255471960584, 'p_miss': 0.1155479086013116}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:14:42,160] Trial 172 finished with value: 0.31678390280681573 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 11, 'learning_rate': 0.0004869146453649516, 'p_miss': 0.08874022213780666}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:15:03,481] Trial 173 finished with value: 0.5541728934031506 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.4217825534030822, 'alpha': 30, 'iterations': 11, 'learning_rate': 0.0004972210276243095, 'p_miss': 0.06656471487602118}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:15:47,378] Trial 174 finished with value: 0.31862442581960454 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 14, 'learning_rate': 0.000291856094374487, 'p_miss': 0.08608699947639692}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:16:27,661] Trial 175 finished with value: 0.3166775627914039 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 13, 'learning_rate': 0.0003471476480937587, 'p_miss': 0.07998966125451333}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:17:54,895] Trial 176 finished with value: 0.3201419760238563 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 26, 'learning_rate': 0.0003586435078061147, 'p_miss': 0.09091557710986356}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:18:20,083] Trial 177 finished with value: 0.31868110093141744 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 9, 'learning_rate': 0.0002292058855265512, 'p_miss': 0.06007895307022863}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:18:54,400] Trial 178 finished with value: 0.31816406303223443 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 12, 'learning_rate': 0.0003225656584796318, 'p_miss': 0.07999201984922959}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:19:48,092] Trial 179 finished with value: 0.32163923862478494 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 16, 'learning_rate': 0.0006054194365031146, 'p_miss': 0.12090724533313445}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:20:56,469] Trial 180 finished with value: 0.3240972833364986 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 22, 'learning_rate': 0.00044699249129695495, 'p_miss': 0.07986499812567731}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:21:43,845] Trial 181 finished with value: 0.3201269451423651 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 12, 'learning_rate': 0.00015898678958408742, 'p_miss': 0.1269472867355787}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:22:51,316] Trial 182 finished with value: 0.3182247583110274 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 20, 'learning_rate': 0.00020641422157713216, 'p_miss': 0.0873570803677695}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:22:52,710] Trial 183 finished with value: 0.3313715695105852 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:23:20,502] Trial 184 finished with value: 0.31879573685702456 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 9, 'learning_rate': 0.0005303102093594541, 'p_miss': 0.07169214636015683}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:25:23,170] Trial 185 finished with value: 0.31964824886913884 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 39, 'learning_rate': 0.0007220967721691615, 'p_miss': 0.05451734877161262}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:25:31,920] Trial 186 finished with value: 0.3214867617341766 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 2, 'learning_rate': 0.0002800472933988004, 'p_miss': 0.10630049209196128}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:30:03,802] Trial 55 finished with value: 0.3389647612214534 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 4429, 'learning_rate': 0.0021484877197195007, 'p_miss': 0.15387003511076022}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:30:49,532] Trial 188 finished with value: 0.32944948536728924 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 14, 'learning_rate': 0.0002449296771064686, 'p_miss': 0.10114740954014985}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:30:58,795] Trial 189 finished with value: 0.3177014670048857 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 2, 'learning_rate': 0.0029283889704966983, 'p_miss': 0.10631583985111114}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:31:09,790] Trial 190 finished with value: 0.31814879263049634 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 3, 'learning_rate': 0.006826992756328254, 'p_miss': 0.09675798491969066}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:32:13,811] Trial 191 finished with value: 0.33650909172531024 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 19, 'learning_rate': 0.036307063859013916, 'p_miss': 0.11374457736632307}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:32:24,925] Trial 192 finished with value: 0.3182228555081264 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 2, 'learning_rate': 0.004725295383872468, 'p_miss': 0.0680338220878639}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:32:33,146] Trial 193 finished with value: 0.3171808291431703 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 2, 'learning_rate': 0.00036652178384090914, 'p_miss': 0.12145984913034616}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:33:07,336] Trial 194 finished with value: 0.3290497483752993 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 10, 'learning_rate': 0.009584252544530436, 'p_miss': 0.13799090388057747}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:33:38,000] Trial 195 finished with value: 0.31814206156470115 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 8, 'learning_rate': 0.00036936920313125046, 'p_miss': 0.11861435959314856}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:33:46,162] Trial 196 finished with value: 0.31898843977523395 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 2, 'learning_rate': 0.0032440414126477983, 'p_miss': 0.1300980686424152}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:33:55,988] Trial 197 finished with value: 0.3202635731623105 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0003110874529172194, 'p_miss': 0.11035787029715785}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:34:08,990] Trial 198 finished with value: 0.3276877065320695 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 3, 'learning_rate': 0.0004111086337911125, 'p_miss': 0.12351923282482749}. Best is trial 102 with value: 0.31578637093044876.
running
[I 2024-11-22 19:34:17,444] Trial 199 finished with value: 0.3193258046819131 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 2, 'learning_rate': 0.00018686688763973236, 'p_miss': 0.107903285907891}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 20:10:27,844] Trial 19 finished with value: 0.3427754760960773 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 4967, 'learning_rate': 0.004657633414529118, 'p_miss': 0.0598343082617589}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 20:32:38,970] Trial 54 finished with value: 0.33590348116439056 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 6234, 'learning_rate': 0.0017911409007420175, 'p_miss': 0.1526200309677285}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:01:30,793] Trial 40 finished with value: 0.33855792898323217 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 7606, 'learning_rate': 0.0007341172631386272, 'p_miss': 0.18751325314229547}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:14:45,743] Trial 130 finished with value: 0.3393696387613014 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 4362, 'learning_rate': 0.0015968936035795443, 'p_miss': 0.0632256190835122}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:19:35,812] Trial 56 finished with value: 0.3348434903674332 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 7739, 'learning_rate': 0.00021334984290715515, 'p_miss': 0.262267272338692}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:38:41,005] Trial 53 finished with value: 0.3367995933964222 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 7694, 'learning_rate': 0.0019795357884018934, 'p_miss': 0.15856739542851794}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:41:57,299] Trial 106 finished with value: 0.3384749704256562 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 5618, 'learning_rate': 0.0003759171544440583, 'p_miss': 0.13934056969550554}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 21:59:06,138] Trial 92 finished with value: 0.35768591810536376 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6833, 'learning_rate': 0.00010062811823365246, 'p_miss': 0.2324772660802993}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:05:55,398] Trial 89 finished with value: 0.34363787943316226 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 7213, 'learning_rate': 0.0003941316260426326, 'p_miss': 0.28772305398039466}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:08:48,602] Trial 132 finished with value: 0.34234870291764163 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 7495, 'learning_rate': 0.0002293933410307323, 'p_miss': 0.048561541667612756}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:10:55,003] Trial 145 finished with value: 0.37425592177928363 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7999, 'learning_rate': 0.00031765974019253127, 'p_miss': 0.11428624480405104}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:11:36,256] Trial 80 finished with value: 0.33477464657028355 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 9317, 'learning_rate': 0.000148801000593872, 'p_miss': 0.0914518091689992}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:11:51,206] Trial 61 finished with value: 0.33697603134696485 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 9721, 'learning_rate': 0.01438701997810265, 'p_miss': 0.12799003143475227}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:12:58,393] Trial 126 finished with value: 0.3447871396193152 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 8251, 'learning_rate': 0.0016474584644531507, 'p_miss': 0.2667739842844339}. Best is trial 102 with value: 0.31578637093044876.
[I 2024-11-22 22:13:51,314] Trial 187 finished with value: 0.34117394526267175 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7020, 'learning_rate': 0.0002516444917722227, 'p_miss': 0.10089059856009992}. Best is trial 102 with value: 0.31578637093044876.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.31578637093044876
{'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.0003432225469377776, 'p_miss': 0.1208735791400785}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.39239867698275777
Generation:   4%|▍         | 1/25 [02:19<55:42, 139.28s/it]Generation:  2
Best f1_score score: 0.39239867698275777
Generation:   8%|▊         | 2/25 [05:43<1:07:57, 177.26s/it]Generation:  3
Best f1_score score: 0.3938798573981036
Generation:  12%|█▏        | 3/25 [07:17<51:08, 139.47s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554656f4040> 

Generation:  4
Best f1_score score: 0.3938798573981036
Generation:  16%|█▌        | 4/25 [17:22<1:53:08, 323.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474733610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.3938798573981036
Generation:  20%|██        | 5/25 [21:07<1:35:58, 287.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f04ac0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.3938798573981036
Generation:  24%|██▍       | 6/25 [23:45<1:17:07, 243.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff2aa0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.394349723751548
Generation:  28%|██▊       | 7/25 [28:55<1:19:38, 265.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554677b7790> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.394349723751548
Generation:  32%|███▏      | 8/25 [35:49<1:28:33, 312.56s/it]Generation:  9
Best f1_score score: 0.394349723751548
Generation:  36%|███▌      | 9/25 [38:11<1:09:08, 259.28s/it]Generation:  10
Best f1_score score: 0.394349723751548
Generation:  40%|████      | 10/25 [44:04<1:12:03, 288.22s/it]Generation:  11
Best f1_score score: 0.394349723751548
Generation:  44%|████▍     | 11/25 [49:46<1:11:05, 304.69s/it]Generation:  12
Best f1_score score: 0.394349723751548
Generation:  48%|████▊     | 12/25 [53:42<1:01:29, 283.78s/it]Generation:  13
Best f1_score score: 0.394349723751548
Generation:  52%|█████▏    | 13/25 [58:10<55:47, 278.96s/it]  Generation:  14
Best f1_score score: 0.394349723751548
Generation:  56%|█████▌    | 14/25 [1:03:01<51:50, 282.76s/it]Generation:  15
Best f1_score score: 0.394349723751548
Generation:  60%|██████    | 15/25 [1:04:48<38:17, 229.71s/it]Generation:  16
Best f1_score score: 0.394349723751548
Generation:  64%|██████▍   | 16/25 [1:10:34<39:43, 264.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464d420e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.394349723751548
Generation:  68%|██████▊   | 17/25 [1:12:45<29:55, 224.38s/it]Generation:  18
Best f1_score score: 0.3950526957102535
Generation:  72%|███████▏  | 18/25 [1:15:57<25:03, 214.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554673dbe80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f4880> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.3950526957102535
Generation:  76%|███████▌  | 19/25 [1:18:24<19:26, 194.49s/it]Generation:  20
Best f1_score score: 0.39558275381504415
Generation:  80%|████████  | 20/25 [1:24:33<20:33, 246.71s/it]Generation:  21
Best f1_score score: 0.39558275381504415
Generation:  84%|████████▍ | 21/25 [1:29:29<17:26, 261.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655a7100> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.39558275381504415
Generation:  88%|████████▊ | 22/25 [1:35:55<14:56, 298.83s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464eede40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.395775637659357
Generation:  92%|█████████▏| 23/25 [1:39:09<08:54, 267.50s/it]Generation:  24
Best f1_score score: 0.395775637659357
Generation:  96%|█████████▌| 24/25 [1:42:08<04:00, 240.88s/it]Generation:  25
Best f1_score score: 0.39666581817762087
Generation: 100%|██████████| 25/25 [1:45:30<00:00, 229.31s/it]Generation: 100%|██████████| 25/25 [1:45:34<00:00, 253.36s/it]
2024-11-22 23:59:58,408 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:40235' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-900ffc112f6c1f8249f201916d97c5de', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732348798.4081113')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.6431756258343,
                                        min_samples_leaf=20,
                                        min_samples_split=12,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.8388405131687496, 'accuracy': 0.6579835448333565, 'balanced_accuracy': 0.7147999588628041, 'logloss': 0.8810960148155981, 'f1': 0.6645818909100144}
original test score: {'auroc': 0.6055370196361985, 'accuracy': 0.49821508255243196, 'balanced_accuracy': 0.40818603711450674, 'logloss': 1.0297249477517838, 'f1': 0.3543130394511352}
imputed test score: {'auroc': 0.5637325000376245, 'accuracy': 0.4773538598839804, 'balanced_accuracy': 0.3910990202287012, 'logloss': 1.0261350912988765, 'f1': 0.3877376352157027}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0a30> 

Generation:  1
Best f1_score score: 0.6765062276414133
Generation:   4%|▍         | 1/25 [10:03<4:01:13, 603.06s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f261a0> 

Generation:  2
Best f1_score score: 0.6771484567673617
Generation:   8%|▊         | 2/25 [20:08<3:51:36, 604.21s/it]Generation:  3
Best f1_score score: 0.6771484567673617
Generation:  12%|█▏        | 3/25 [22:39<2:25:39, 397.27s/it]Generation:  4
Best f1_score score: 0.6847557519073477
Generation:  16%|█▌        | 4/25 [25:38<1:48:58, 311.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546758ad40> 

Generation:  5
Best f1_score score: 0.6861339682619636
Generation:  20%|██        | 5/25 [35:45<2:19:16, 417.83s/it]Generation:  6
Best f1_score score: 0.68788368644887
Generation:  24%|██▍       | 6/25 [38:23<1:44:20, 329.52s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c41420> 

Generation:  7
Best f1_score score: 0.6937905095206479
Generation:  28%|██▊       | 7/25 [48:30<2:06:07, 420.40s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679e0430> 

Generation:  8
Best f1_score score: 0.6955728867952525
Generation:  32%|███▏      | 8/25 [58:38<2:15:58, 479.94s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466952170> 

Generation:  9
Best f1_score score: 0.6962098962861981
Generation:  36%|███▌      | 9/25 [1:08:44<2:18:32, 519.52s/it]Generation:  10
Best f1_score score: 0.6965513289618744
Generation:  40%|████      | 10/25 [1:11:48<1:43:56, 415.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466c77dc0> 

Generation:  11
Best f1_score score: 0.6995239369677048
Generation:  44%|████▍     | 11/25 [1:21:56<1:50:46, 474.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464df77f0> 

Generation:  12
Best f1_score score: 0.6995239369677048
Generation:  48%|████▊     | 12/25 [1:32:07<1:51:49, 516.14s/it]Generation:  13
Best f1_score score: 0.6995239369677048
Generation:  52%|█████▏    | 13/25 [1:35:20<1:23:39, 418.27s/it]Generation:  14
Best f1_score score: 0.6995239369677048
Generation:  56%|█████▌    | 14/25 [1:38:36<1:04:22, 351.14s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fccd0> 

Generation:  15
Best f1_score score: 0.6995239369677048
Generation:  60%|██████    | 15/25 [1:48:47<1:11:34, 429.46s/it]Generation:  16
Best f1_score score: 0.6995239369677048
Generation:  64%|██████▍   | 16/25 [1:52:10<54:11, 361.27s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464d19ab0> 

Generation:  17
Best f1_score score: 0.6995239369677048
Generation:  68%|██████▊   | 17/25 [2:02:22<58:13, 436.73s/it]Generation:  18
Best f1_score score: 0.6995239369677048
Generation:  72%|███████▏  | 18/25 [2:06:17<43:51, 375.90s/it]Generation:  19
Best f1_score score: 0.6995239369677048
Generation:  76%|███████▌  | 19/25 [2:11:08<35:02, 350.38s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452377be0> 

Generation:  20
Best f1_score score: 0.6995239369677048
Generation:  80%|████████  | 20/25 [2:21:13<35:34, 426.95s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465143c10> 

Generation:  21
Best f1_score score: 0.6995239369677048
Generation:  84%|████████▍ | 21/25 [2:31:23<32:07, 481.92s/it]Generation:  22
Best f1_score score: 0.6995239369677048
Generation:  88%|████████▊ | 22/25 [2:34:19<19:29, 389.99s/it]Generation:  23
Best f1_score score: 0.6995239369677048
Generation:  92%|█████████▏| 23/25 [2:39:28<12:11, 365.69s/it]Generation:  24
Best f1_score score: 0.6995239369677048
Generation:  96%|█████████▌| 24/25 [2:42:23<05:08, 308.58s/it]Generation:  25
Best f1_score score: 0.7030106498317105
Generation: 100%|██████████| 25/25 [2:47:12<00:00, 302.57s/it]Generation: 100%|██████████| 25/25 [2:47:12<00:00, 401.29s/it]
2024-11-23 02:48:01,222 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:43047' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-bb49503d9a9a0828e9d27d0f60185a5c', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732358881.2227027')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=91)),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=0.0001613209829,
                                                learning_rate=0.0424148602299,
                                                max_features=0.9699865559448,
                                                max_leaf_nodes=1333,
                                                min_samples_leaf=184,
                                                tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9464844565262824, 'accuracy': 0.8162878259656952, 'balanced_accuracy': 0.7300681692715328, 'logloss': 0.41012742399203356, 'f1': 0.7519292576589525}
test score: {'auroc': 0.9100914737247968, 'accuracy': 0.7597054886211513, 'balanced_accuracy': 0.7031566180367882, 'logloss': 0.5143086593769368, 'f1': 0.7113234751772487}
original test score: {'auroc': 0.9692931274253941, 'accuracy': 0.856091030789826, 'balanced_accuracy': 0.7938828201983407, 'logloss': 0.3155328522414592, 'f1': 0.8056627395938961}
score end
41027
lvl
0.3
type
MAR
num_run
3
class_full
finished
all finished
full run takes
11.585334775646528
hours
DONE
