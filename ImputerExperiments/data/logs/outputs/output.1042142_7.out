Run: 7
/cm/local/apps/slurm/var/spool/job1042142/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1558/1558.pkl
working on 
../data/c/1558/class_full_MAR_0.3_1
0.8006596565246582
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-06 03:02:40,330] A new study created in memory with name: no-name-7c5c6ee2-d4ad-4129-97eb-790f8874f5fa
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-06 03:02:40,478] Trial 6 finished with value: 0.23658810937271585 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.23658810937271585.
running
[I 2024-11-06 03:02:40,739] Trial 10 finished with value: 0.366019019402028 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.23658810937271585.
running
[I 2024-11-06 03:02:40,962] Trial 12 finished with value: 0.366019019402028 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.23658810937271585.
running
[I 2024-11-06 03:02:41,089] Trial 1 finished with value: 0.2557333239733533 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.23658810937271585.
running
[I 2024-11-06 03:02:42,636] Trial 4 finished with value: 0.22962591529468024 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1699, 'weights': 'distance'}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:44,268] Trial 20 finished with value: 0.23135918262659522 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2273, 'weights': 'distance'}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:45,582] Trial 21 finished with value: 0.3271124244864763 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:46,050] Trial 22 finished with value: 0.23658810937271585 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:55,050] Trial 3 finished with value: 0.3715426747684996 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.1710428635252419, 'alpha': 7, 'iterations': 3, 'learning_rate': 0.00042688549431084313, 'p_miss': 0.04839527558068276}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:56,525] Trial 2 finished with value: 0.38200882966295674 and parameters: {'model_name': 'GAIN', 'batch_size': 136, 'hint_rate': 0.8438968637982317, 'alpha': 17, 'iterations': 3, 'learning_rate': 0.004777905130587343, 'p_miss': 0.13979991741150677}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:58,021] Trial 5 finished with value: 0.34093275581462745 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 1, 'learning_rate': 0.007930693832771547, 'p_miss': 0.25485765690613826}. Best is trial 4 with value: 0.22962591529468024.
running
[I 2024-11-06 03:02:58,861] Trial 24 finished with value: 0.22427824671617821 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 427, 'weights': 'distance'}. Best is trial 24 with value: 0.22427824671617821.
running
[I 2024-11-06 03:03:00,373] Trial 8 finished with value: 0.23408410641350602 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 24 with value: 0.22427824671617821.
running
[I 2024-11-06 03:03:01,794] Trial 27 finished with value: 0.22333790360278516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 51, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:03,207] Trial 26 finished with value: 0.23050281529353142 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1968, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:03,631] Trial 28 finished with value: 0.22363650420720643 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 146, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:05,021] Trial 29 finished with value: 0.22358376347169898 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 39, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:05,826] Trial 30 finished with value: 0.2252922719168189 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 79, 'weights': 'uniform'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:06,742] Trial 31 finished with value: 0.22505034272778496 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 54, 'weights': 'uniform'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:08,808] Trial 9 finished with value: 0.23647848567018076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:09,855] Trial 19 finished with value: 0.2369915964880333 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:13,270] Trial 23 finished with value: 0.2390101407849611 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:13,646] Trial 36 finished with value: 0.22666360487285955 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 956, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:16,611] Trial 37 finished with value: 0.22665069956003786 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 954, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:41,947] Trial 17 finished with value: 0.3317014616946804 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 16, 'learning_rate': 0.0032355592441902924, 'p_miss': 0.046229863553267435}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:44,991] Trial 40 finished with value: 0.22557691587755632 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 756, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:47,266] Trial 41 finished with value: 0.22335636930562405 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 60, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:03:50,865] Trial 42 finished with value: 0.2333256180389136 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3506, 'weights': 'distance'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:12:58,975] Trial 13 finished with value: 0.23783796087852402 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 195, 'learning_rate': 0.000786149147443104, 'p_miss': 0.10267687531892206}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:29:24,317] Trial 18 finished with value: 0.23010412002372224 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:34:27,879] Trial 11 finished with value: 0.42981987299928043 and parameters: {'model_name': 'GAIN', 'batch_size': 98, 'hint_rate': 0.5937458591471619, 'alpha': 70, 'iterations': 1242, 'learning_rate': 0.015114403247059937, 'p_miss': 0.23567472437362177}. Best is trial 27 with value: 0.22333790360278516.
running
[I 2024-11-06 03:34:30,468] Trial 46 finished with value: 0.22319884682966906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 48, 'weights': 'distance'}. Best is trial 46 with value: 0.22319884682966906.
running
[I 2024-11-06 03:34:33,731] Trial 47 finished with value: 0.22496322992879753 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 568, 'weights': 'distance'}. Best is trial 46 with value: 0.22319884682966906.
running
[I 2024-11-06 03:34:36,361] Trial 48 finished with value: 0.22513768131120263 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28, 'weights': 'distance'}. Best is trial 46 with value: 0.22319884682966906.
running
[I 2024-11-06 03:35:02,766] Trial 32 finished with value: 0.21381769513814247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 32 with value: 0.21381769513814247.
running
[I 2024-11-06 03:35:33,247] Trial 34 finished with value: 0.21377667917425636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 34 with value: 0.21377667917425636.
running
[I 2024-11-06 03:35:57,278] Trial 33 finished with value: 0.2164824496262992 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 34 with value: 0.21377667917425636.
running
[I 2024-11-06 03:37:56,393] Trial 7 finished with value: 0.2755667741373674 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 687, 'learning_rate': 0.00152323826156537, 'p_miss': 0.2544645617384334}. Best is trial 34 with value: 0.21377667917425636.
running
[I 2024-11-06 04:08:47,284] Trial 51 finished with value: 0.2122136597346139 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:09:02,790] Trial 52 finished with value: 0.21260936480021453 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:10:37,851] Trial 53 finished with value: 0.21221686205535545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:11:24,541] Trial 14 finished with value: 0.2624264402278167 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1456, 'learning_rate': 0.006510898868029629, 'p_miss': 0.02065842348722101}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:25:30,088] Trial 16 finished with value: 0.2619288717524449 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1604, 'learning_rate': 0.0003244405666412456, 'p_miss': 0.13250543461498265}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:42:20,747] Trial 54 finished with value: 0.21366334505198809 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:42:42,248] Trial 55 finished with value: 0.212956907108999 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:43:50,192] Trial 56 finished with value: 0.21294065375496807 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:45:19,166] Trial 57 finished with value: 0.21242205845252612 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 04:59:04,728] Trial 58 finished with value: 0.21362217432593938 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:00:30,480] Trial 63 finished with value: 0.3804071122018591 and parameters: {'model_name': 'GAIN', 'batch_size': 980, 'hint_rate': 0.028909204410383416, 'alpha': 99, 'iterations': 33, 'learning_rate': 0.00010055525911373504, 'p_miss': 0.19948852386660426}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:01:19,998] Trial 64 finished with value: 0.22238104950924908 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:09:56,956] Trial 49 finished with value: 0.35824457053105874 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.04388662365821289, 'alpha': 94, 'iterations': 4051, 'learning_rate': 0.09240505375322627, 'p_miss': 0.29569448860623476}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:12:38,798] Trial 0 finished with value: 0.27848356391158025 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2790, 'learning_rate': 0.006454772498697704, 'p_miss': 0.2079938041118911}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:14:58,673] Trial 61 finished with value: 0.21640727183176703 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:15:09,444] Trial 60 finished with value: 0.21425202865244156 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.2122136597346139.
running
[I 2024-11-06 05:15:54,588] Trial 59 finished with value: 0.2106580176244503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:35:49,302] Trial 65 finished with value: 0.21653855387623863 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:45:33,116] Trial 66 finished with value: 0.21387713180729534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:48:44,815] Trial 67 finished with value: 0.21445289157157496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:52:21,642] Trial 73 finished with value: 0.323475824878115 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:52:44,337] Trial 68 finished with value: 0.21137627738484718 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:52:54,801] Trial 74 finished with value: 0.22241766358116485 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:53:11,172] Trial 69 finished with value: 0.21417442192708708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:53:18,621] Trial 75 finished with value: 0.22241766358116485 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 05:54:21,918] Trial 70 finished with value: 0.21308729679929198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:13:20,723] Trial 71 finished with value: 0.21202964468903204 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:23:50,321] Trial 72 finished with value: 0.21443454810702195 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:23:51,229] Trial 81 finished with value: 0.3271124244864763 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:24:30,407] Trial 35 finished with value: 0.2751628750197993 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5743, 'learning_rate': 0.057908281811106965, 'p_miss': 0.29989987019230435}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:28:51,068] Trial 77 finished with value: 0.21184910972509438 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:28:52,329] Trial 78 finished with value: 0.21523417379218657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:28:55,126] Trial 76 finished with value: 0.21305209444703613 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:30:24,723] Trial 79 finished with value: 0.21307382703944838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:32:44,514] Trial 86 finished with value: 0.30907899368856817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:34:12,098] Trial 87 finished with value: 0.3214364748728621 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:35:51,619] Trial 85 finished with value: 0.3841578226591129 and parameters: {'model_name': 'GAIN', 'batch_size': 856, 'hint_rate': 0.9086211185826552, 'alpha': 45, 'iterations': 156, 'learning_rate': 0.028839689892691367, 'p_miss': 0.09335881857067385}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:38:57,018] Trial 89 finished with value: 0.3821959982162063 and parameters: {'model_name': 'GAIN', 'batch_size': 741, 'hint_rate': 0.4112932012735508, 'alpha': 41, 'iterations': 135, 'learning_rate': 0.027682655826521563, 'p_miss': 0.09220834138109076}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:49:51,863] Trial 80 finished with value: 0.21517873443550473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:54:22,014] Trial 88 finished with value: 0.22971130840040743 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:55:23,611] Trial 93 finished with value: 0.35936184905882795 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 14, 'learning_rate': 0.00010690161336286218, 'p_miss': 0.1922118301358764}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:55:24,158] Trial 94 finished with value: 0.2557333239733533 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 06:57:09,362] Trial 50 finished with value: 0.4123501379456509 and parameters: {'model_name': 'GAIN', 'batch_size': 998, 'hint_rate': 0.013768654274200487, 'alpha': 95, 'iterations': 5607, 'learning_rate': 0.09377856297061948, 'p_miss': 0.29698659519782195}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:00:44,143] Trial 83 finished with value: 0.21555025482535015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:09:28,495] Trial 84 finished with value: 0.21218464373154583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:09:56,934] Trial 98 finished with value: 0.2440814616075114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:10:25,094] Trial 90 finished with value: 0.215502585819971 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:14:01,955] Trial 91 finished with value: 0.215814045112736 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:16:29,623] Trial 92 finished with value: 0.23344060483863954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:21:46,586] Trial 15 finished with value: 0.43695529869149147 and parameters: {'model_name': 'GAIN', 'batch_size': 643, 'hint_rate': 0.5595348657011343, 'alpha': 2, 'iterations': 7475, 'learning_rate': 0.002842184519361763, 'p_miss': 0.1931860097689182}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:31:44,282] Trial 95 finished with value: 0.21627859914424863 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:32:12,124] Trial 104 finished with value: 0.23784852482179852 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:32:19,422] Trial 105 finished with value: 0.3586661857627719 and parameters: {'model_name': 'VAE', 'batch_size': 222, 'iterations': 1, 'learning_rate': 0.0002426863974352736, 'p_miss': 0.1627869366278802}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:35:38,855] Trial 96 finished with value: 0.21433662439918813 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:39:41,353] Trial 97 finished with value: 0.2150376828337853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:43:16,918] Trial 100 finished with value: 0.222538282521724 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:47:50,959] Trial 101 finished with value: 0.2197847800619646 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:50:24,270] Trial 99 finished with value: 0.21360776070211354 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:52:23,427] Trial 102 finished with value: 0.21793166083643595 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 07:58:14,143] Trial 103 finished with value: 0.22033886830908367 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:12:19,423] Trial 106 finished with value: 0.21471134177078283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:13:42,206] Trial 107 finished with value: 0.2156358420575498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:17:44,475] Trial 108 finished with value: 0.2139519569720454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:18:30,932] Trial 45 finished with value: 0.41846182331497095 and parameters: {'model_name': 'GAIN', 'batch_size': 959, 'hint_rate': 0.017296544312656814, 'alpha': 99, 'iterations': 7574, 'learning_rate': 0.08282011233161327, 'p_miss': 0.29096291678898945}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:21:57,084] Trial 109 finished with value: 0.2149207554139362 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:22:52,670] Trial 44 finished with value: 0.41367748643246954 and parameters: {'model_name': 'GAIN', 'batch_size': 590, 'hint_rate': 0.01772736690962079, 'alpha': 99, 'iterations': 8997, 'learning_rate': 0.09129633533073991, 'p_miss': 0.28470053829611874}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:27:17,703] Trial 110 finished with value: 0.21396948140818206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:27:18,402] Trial 120 finished with value: 0.2557333239733533 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:30:12,523] Trial 111 finished with value: 0.2127310185132877 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:32:28,578] Trial 112 finished with value: 0.2137002646220969 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:34:35,307] Trial 39 finished with value: 0.30880633528625145 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7952, 'learning_rate': 0.09330818783416009, 'p_miss': 0.2824216397176427}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:39:10,590] Trial 113 finished with value: 0.2136022007377234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:41:01,984] Trial 25 finished with value: 0.2935532747097498 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8230, 'learning_rate': 0.09127932702827894, 'p_miss': 0.299002073747219}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:55:51,437] Trial 114 finished with value: 0.21388878122640148 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 08:56:35,555] Trial 115 finished with value: 0.21323480629426772 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:00:08,931] Trial 43 finished with value: 0.40708977116680495 and parameters: {'model_name': 'GAIN', 'batch_size': 825, 'hint_rate': 0.9711260071781576, 'alpha': 97, 'iterations': 9478, 'learning_rate': 0.08276902023087654, 'p_miss': 0.28445003239842526}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:00:52,483] Trial 129 finished with value: 0.22207429456914932 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:02:01,036] Trial 116 finished with value: 0.21212522460126051 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:03:47,114] Trial 117 finished with value: 0.21530377827399355 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:07:16,318] Trial 118 finished with value: 0.21395328472292338 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:07:53,052] Trial 119 finished with value: 0.21358131999631774 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:12:42,641] Trial 121 finished with value: 0.21485057706545443 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:14:04,573] Trial 122 finished with value: 0.2132898278942285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:16:02,498] Trial 38 finished with value: 0.3165660315468176 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7925, 'learning_rate': 0.05912700105484748, 'p_miss': 0.2733921217107395}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:16:57,779] Trial 62 finished with value: 0.3954524917344679 and parameters: {'model_name': 'GAIN', 'batch_size': 960, 'hint_rate': 0.05920577390324572, 'alpha': 100, 'iterations': 6982, 'learning_rate': 0.09958900651289446, 'p_miss': 0.1985426155296523}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:18:01,149] Trial 123 finished with value: 0.21258179327142868 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:19:27,478] Trial 124 finished with value: 0.21385332014469238 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:22:55,002] Trial 125 finished with value: 0.21584406318892785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:25:47,000] Trial 126 finished with value: 0.21267609728689102 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:26:01,717] Trial 141 finished with value: 0.22245311128408587 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:28:56,302] Trial 142 finished with value: 0.2225623924081035 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:29:33,632] Trial 144 finished with value: 0.24320082534550008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:29:34,016] Trial 145 finished with value: 0.366019019402028 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:40:47,385] Trial 128 finished with value: 0.21575233802244834 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:41:27,090] Trial 127 finished with value: 0.2146914174449702 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:45:09,148] Trial 130 finished with value: 0.2126710889460394 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:45:23,277] Trial 131 finished with value: 0.21148893554552278 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:47:45,921] Trial 132 finished with value: 0.2107678797405343 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:49:39,953] Trial 134 finished with value: 0.2121513257945844 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:50:28,925] Trial 133 finished with value: 0.21256942142947083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:56:09,388] Trial 135 finished with value: 0.2137426468378057 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:56:41,756] Trial 154 finished with value: 0.22209424069622252 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:57:53,432] Trial 136 finished with value: 0.21194455888543368 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:58:56,809] Trial 137 finished with value: 0.2138005213367437 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 09:59:50,582] Trial 138 finished with value: 0.21336810682870394 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:00:11,870] Trial 139 finished with value: 0.21451483810711922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:01:09,055] Trial 140 finished with value: 0.21236195313585146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:06:20,982] Trial 143 finished with value: 0.21593900902265312 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:08:04,305] Trial 146 finished with value: 0.21557502517879307 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:18:02,194] Trial 147 finished with value: 0.21723481155564292 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:20:28,539] Trial 148 finished with value: 0.21677572179219734 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:22:06,548] Trial 150 finished with value: 0.21527907793272294 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:23:07,030] Trial 149 finished with value: 0.21634155444875708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:25:48,838] Trial 151 finished with value: 0.21631229368207916 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:26:43,919] Trial 152 finished with value: 0.21448279025943986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:28:20,362] Trial 153 finished with value: 0.2148975604316508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:33:37,500] Trial 155 finished with value: 0.21330232827107598 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:34:49,300] Trial 156 finished with value: 0.2147086093638691 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:35:24,907] Trial 171 finished with value: 0.2440814616075114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:36:05,256] Trial 157 finished with value: 0.21472078373130504 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:36:37,623] Trial 158 finished with value: 0.21385084414406422 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:36:56,683] Trial 159 finished with value: 0.21463167139085876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:37:39,146] Trial 160 finished with value: 0.21492183456153952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:42:21,433] Trial 161 finished with value: 0.21299884367744162 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:45:27,155] Trial 162 finished with value: 0.21530529544663005 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:45:44,984] Trial 178 finished with value: 0.3545756733024488 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 5, 'learning_rate': 0.001091829781912575, 'p_miss': 0.16541915121098577}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:46:15,450] Trial 165 finished with value: 0.23535730967228266 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 398, 'learning_rate': 0.0011769691984938652, 'p_miss': 0.17252147137023263}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:47:58,683] Trial 163 finished with value: 0.23481697560278106 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 438, 'learning_rate': 0.0010736367171197852, 'p_miss': 0.21994283913249757}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:51:36,801] Trial 164 finished with value: 0.23524902281088633 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 394, 'learning_rate': 0.00131636811094226, 'p_miss': 0.22252893726646542}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:57:23,411] Trial 173 finished with value: 0.23657368080233449 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 313, 'learning_rate': 0.001325679699155701, 'p_miss': 0.16626774144984863}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:58:02,738] Trial 166 finished with value: 0.21301865362205974 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 10:58:03,910] Trial 184 finished with value: 0.3271124244864763 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:00:38,776] Trial 168 finished with value: 0.21520289754391855 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:02:49,798] Trial 176 finished with value: 0.234193109676952 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 380, 'learning_rate': 0.001107360908782425, 'p_miss': 0.06678965435078588}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:03:17,588] Trial 169 finished with value: 0.21268823854925212 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:04:36,891] Trial 172 finished with value: 0.23690429274474992 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 446, 'learning_rate': 0.0121435658755626, 'p_miss': 0.16979649582186615}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:06:23,764] Trial 167 finished with value: 0.23496175253542093 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 559, 'learning_rate': 0.0014019006339961737, 'p_miss': 0.2212397829722167}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:06:33,645] Trial 170 finished with value: 0.23516883147039996 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 470, 'learning_rate': 0.0014689179218423816, 'p_miss': 0.22803593611901934}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:12:10,076] Trial 174 finished with value: 0.21319375953032269 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:12:16,816] Trial 175 finished with value: 0.213582101040738 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:21:15,184] Trial 180 finished with value: 0.21165808545695658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:22:17,528] Trial 179 finished with value: 0.21308649095039084 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:23:03,514] Trial 181 finished with value: 0.215573019349101 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:28:18,341] Trial 182 finished with value: 0.21480888917923444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:29:45,016] Trial 177 finished with value: 0.235321154209945 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 531, 'learning_rate': 0.001168050482810888, 'p_miss': 0.2289137915884641}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:34:44,307] Trial 183 finished with value: 0.21329161261114038 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
running
[I 2024-11-06 11:35:23,676] Trial 185 finished with value: 0.21279564663431527 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:37:17,985] Trial 186 finished with value: 0.21288953623385773 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:40:25,249] Trial 187 finished with value: 0.21313849598697257 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:41:10,569] Trial 188 finished with value: 0.21282659182494545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:42:06,380] Trial 189 finished with value: 0.2142648530818491 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:43:03,923] Trial 190 finished with value: 0.2124570366381338 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:43:08,821] Trial 191 finished with value: 0.21378801752580837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:46:43,578] Trial 193 finished with value: 0.21248864617494015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:46:45,901] Trial 192 finished with value: 0.21141153550891864 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:47:50,626] Trial 196 finished with value: 0.22662054355989722 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:47:59,201] Trial 195 finished with value: 0.2248337083833583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:50:53,948] Trial 194 finished with value: 0.21450562402141865 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:55:12,161] Trial 197 finished with value: 0.21510418757408356 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:55:52,746] Trial 198 finished with value: 0.21359697088976679 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 11:58:18,057] Trial 199 finished with value: 0.21458704879903726 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 59 with value: 0.2106580176244503.
[I 2024-11-06 12:09:18,787] Trial 82 finished with value: 0.24127033459338568 and parameters: {'model_name': 'VAE', 'batch_size': 979, 'iterations': 8852, 'learning_rate': 0.08513382550183457, 'p_miss': 0.07768707459553975}. Best is trial 59 with value: 0.2106580176244503.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0.2106580176244503
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'roman'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.7043345181188114
Generation:   4%|▍         | 1/25 [00:18<07:33, 18.88s/it]Generation:  2
Best f1_score score: 0.7043345181188114
Generation:   8%|▊         | 2/25 [01:37<20:44, 54.10s/it]Generation:  3
Best f1_score score: 0.710233890098565
Generation:  12%|█▏        | 3/25 [01:52<13:13, 36.07s/it]Generation:  4
Best f1_score score: 0.710233890098565
Generation:  16%|█▌        | 4/25 [02:05<09:27, 27.02s/it]Generation:  5
Best f1_score score: 0.710233890098565
Generation:  20%|██        | 5/25 [02:21<07:39, 22.95s/it]Generation:  6
Best f1_score score: 0.710233890098565
Generation:  24%|██▍       | 6/25 [03:30<12:16, 38.76s/it]Generation:  7
Best f1_score score: 0.710233890098565
Generation:  28%|██▊       | 7/25 [03:42<08:59, 30.00s/it]Generation:  8
Best f1_score score: 0.710233890098565
Generation:  32%|███▏      | 8/25 [03:56<07:04, 24.96s/it]Generation:  9
Best f1_score score: 0.710233890098565
Generation:  36%|███▌      | 9/25 [04:10<05:45, 21.59s/it]Generation:  10
Best f1_score score: 0.710233890098565
Generation:  40%|████      | 10/25 [04:26<04:57, 19.83s/it]Generation:  11
Best f1_score score: 0.710233890098565
Generation:  44%|████▍     | 11/25 [04:42<04:21, 18.69s/it]Generation:  12
Best f1_score score: 0.710233890098565
Generation:  48%|████▊     | 12/25 [06:02<08:02, 37.10s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465ab60> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  13
Best f1_score score: 0.710233890098565
Generation:  52%|█████▏    | 13/25 [06:20<06:17, 31.48s/it]Generation:  14
Best f1_score score: 0.710233890098565
Generation:  56%|█████▌    | 14/25 [06:35<04:50, 26.44s/it]Generation:  15
Best f1_score score: 0.710233890098565
Generation:  60%|██████    | 15/25 [06:49<03:46, 22.61s/it]Generation:  16
Best f1_score score: 0.710233890098565
Generation:  64%|██████▍   | 16/25 [11:48<15:54, 106.02s/it]Generation:  17
Best f1_score score: 0.710233890098565
Generation:  68%|██████▊   | 17/25 [12:12<10:49, 81.21s/it] Generation:  18
Best f1_score score: 0.7133858463307876
Generation:  72%|███████▏  | 18/25 [12:28<07:12, 61.75s/it]Generation:  19
Best f1_score score: 0.7133858463307876
Generation:  76%|███████▌  | 19/25 [12:47<04:52, 48.71s/it]Generation:  20
Best f1_score score: 0.7133858463307876
Generation:  80%|████████  | 20/25 [13:05<03:17, 39.44s/it]Generation:  21
Best f1_score score: 0.7133858463307876
Generation:  84%|████████▍ | 21/25 [13:25<02:15, 33.77s/it]Generation:  22
Best f1_score score: 0.7133858463307876
Generation:  88%|████████▊ | 22/25 [13:45<01:28, 29.53s/it]Generation:  23
Best f1_score score: 0.7133858463307876
Generation:  92%|█████████▏| 23/25 [14:04<00:52, 26.34s/it]Generation:  24
Best f1_score score: 0.7133858463307876
Generation:  96%|█████████▌| 24/25 [14:24<00:24, 24.64s/it]Generation:  25
Best f1_score score: 0.7133858463307876
Generation: 100%|██████████| 25/25 [14:44<00:00, 23.24s/it]Generation: 100%|██████████| 25/25 [14:48<00:00, 35.53s/it]
2024-11-06 12:27:09,838 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:39771' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-b6f1c60d1f9a0fafa76867fbe2747a6e', 'ndarray-b17d9b65753f3ec2dfc3328ae6aa4262'} (stimulus_id='handle-worker-cleanup-1730924829.8381822')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.5583806242302,
                                        min_samples_leaf=7,
                                        min_samples_split=14,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9845417820167123, 'accuracy': 0.9413716814159292, 'balanced_accuracy': 0.9543517421136551, 'logloss': 0.1950575840877315, 'f1': 0.8792125572351898}
original test score: {'auroc': 0.915838375108038, 'accuracy': 0.9093922651933701, 'balanced_accuracy': 0.7982089695572842, 'logloss': 0.25948686381930386, 'f1': 0.7861728366603661}
imputed test score: {'auroc': 0.9111927398444252, 'accuracy': 0.907182320441989, 'balanced_accuracy': 0.7969605301065975, 'logloss': 0.2675016334463476, 'f1': 0.7826758147512864}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014580>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d30> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4df0> 

Generation:  1
Best f1_score score: 0.6964626838301756
Generation:   4%|▍         | 1/25 [10:03<4:01:18, 603.28s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547457fca0> 

Generation:  2
Best f1_score score: 0.6964626838301756
Generation:   8%|▊         | 2/25 [20:05<3:51:07, 602.93s/it]Generation:  3
Best f1_score score: 0.6964626838301756
Generation:  12%|█▏        | 3/25 [21:47<2:17:07, 373.99s/it]Generation:  4
Best f1_score score: 0.7006512406881414
Generation:  16%|█▌        | 4/25 [21:58<1:20:46, 230.79s/it]Generation:  5
Best f1_score score: 0.7006512406881414
Generation:  20%|██        | 5/25 [22:18<51:33, 154.67s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547459d3f0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.7102751154858226
Generation:  24%|██▍       | 6/25 [22:34<34:02, 107.52s/it]Generation:  7
Best f1_score score: 0.7143574074061674
Generation:  28%|██▊       | 7/25 [23:42<28:25, 94.75s/it] WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1d930> 

Generation:  8
Best f1_score score: 0.7143574074061674
Generation:  32%|███▏      | 8/25 [33:49<1:12:58, 257.57s/it]Generation:  9
Best f1_score score: 0.7148767922969308
Generation:  36%|███▌      | 9/25 [36:18<59:38, 223.64s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bc24d00> 

Generation:  10
Best f1_score score: 0.7148767922969308
Generation:  40%|████      | 10/25 [46:24<1:25:26, 341.77s/it]Generation:  11
Best f1_score score: 0.7194664305779188
Generation:  44%|████▍     | 11/25 [49:18<1:07:47, 290.55s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545e323df0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  12
Best f1_score score: 0.7194664305779188
Generation:  48%|████▊     | 12/25 [49:32<44:42, 206.33s/it]  Generation:  13
Best f1_score score: 0.7194664305779188
Generation:  52%|█████▏    | 13/25 [49:42<29:23, 146.93s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155411032740> 

Generation:  14
Best f1_score score: 0.7194664305779188
Generation:  56%|█████▌    | 14/25 [59:50<52:27, 286.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d3ce20> 

Generation:  15
Best f1_score score: 0.7194664305779188
Generation:  60%|██████    | 15/25 [1:09:58<1:03:50, 383.04s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545d901540> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452a60e50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd6980> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456f99390> 

Generation:  16
Best f1_score score: 0.7194664305779188
Generation:  64%|██████▍   | 16/25 [1:20:07<1:07:41, 451.28s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bd18400> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fdefca0> 

Generation:  17
Best f1_score score: 0.7194664305779188
Generation:  68%|██████▊   | 17/25 [1:30:13<1:06:21, 497.63s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547410e050> 

Generation:  18
Best f1_score score: 0.7207749485076217
Generation:  72%|███████▏  | 18/25 [1:40:19<1:01:52, 530.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545742b280> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.7207749485076217
Generation:  76%|███████▌  | 19/25 [1:40:41<37:45, 377.55s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd6440> 

Generation:  20
Best f1_score score: 0.7207749485076217
Generation:  80%|████████  | 20/25 [1:50:50<37:15, 447.06s/it]Generation:  21
Best f1_score score: 0.7207749485076217
Generation:  84%|████████▍ | 21/25 [1:51:34<21:43, 325.98s/it]Generation:  22
Best f1_score score: 0.7207749485076217
Generation:  88%|████████▊ | 22/25 [1:51:49<11:38, 232.69s/it]Generation:  23
Best f1_score score: 0.7207749485076217
Generation:  92%|█████████▏| 23/25 [1:52:19<05:43, 171.92s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f7bf040> 

Generation:  24
Best f1_score score: 0.7207749485076217
Generation:  96%|█████████▌| 24/25 [2:02:26<05:02, 302.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544fc0b460> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  25
Best f1_score score: 0.7207749485076217
Generation: 100%|██████████| 25/25 [2:04:07<00:00, 241.94s/it]Generation: 100%|██████████| 25/25 [2:04:07<00:00, 297.89s/it]
2024-11-06 14:31:28,510 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34499' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-b6f1c60d1f9a0fafa76867fbe2747a6e', 'DataFrame-e015ffd6444ac941fae1bbb3df83f07b'} (stimulus_id='handle-worker-cleanup-1730932288.5101607')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=BayesianRidge(),
                                  imputation_order='descending',
                                  initial_strategy='most_frequent',
                                  n_nearest_features=93,
                                  sample_posterior=True)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      criterion='entropy',
                                      max_features=0.7528941804275,
                                      min_samples_leaf=4, min_samples_split=10,
                                      n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9572595752719487, 'accuracy': 0.9145464601769911, 'balanced_accuracy': 0.8809535054044917, 'logloss': 0.24074917497252946, 'f1': 0.814603751487933}
test score: {'auroc': 0.8930663593584943, 'accuracy': 0.8806629834254144, 'balanced_accuracy': 0.7726159608182079, 'logloss': 0.3044745531120107, 'f1': 0.74644436293987}
original test score: {'auroc': 0.9078435609334486, 'accuracy': 0.8994475138121547, 'balanced_accuracy': 0.7800405742821472, 'logloss': 0.26789666266744755, 'f1': 0.7654832858253433}
score end
1558
lvl
0.3
type
MAR
num_run
1
class_full
finished
all finished
full run takes
11.483079506225057
hours
DONE
