Run: 5
/cm/local/apps/slurm/var/spool/job920483/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
starting loops
../data/c/30/30.pkl
working on 
../data/c/30/class_full_MAR_0.01_1
0.6851558685302734
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-08-13 01:52:05,266] A new study created in memory with name: no-name-c9f3225d-0169-4aa3-86aa-2460d6834025
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-08-13 01:52:05,641] Trial 8 finished with value: 0.2562702454081923 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.2562702454081923.
running
[I 2024-08-13 01:52:05,823] Trial 7 finished with value: 0.2562702454081923 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.2562702454081923.
[I 2024-08-13 01:52:05,975] Trial 11 finished with value: 0.2562702454081923 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.2562702454081923.
running
running
[I 2024-08-13 01:52:06,246] Trial 12 finished with value: 0.07196724599914348 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.07196724599914348.
running
[I 2024-08-13 01:52:08,211] Trial 3 finished with value: 0.06463394643226221 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2292, 'weights': 'uniform'}. Best is trial 3 with value: 0.06463394643226221.
running
[I 2024-08-13 01:52:08,512] Trial 2 finished with value: 0.06164999694578005 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1609, 'weights': 'uniform'}. Best is trial 2 with value: 0.06164999694578005.
[I 2024-08-13 01:52:08,533] Trial 16 finished with value: 0.0375321954499075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 837, 'weights': 'distance'}. Best is trial 16 with value: 0.0375321954499075.
running
running
[I 2024-08-13 01:52:08,928] Trial 20 finished with value: 0.06717540327167124 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 16 with value: 0.0375321954499075.
running
[I 2024-08-13 01:52:09,171] Trial 10 finished with value: 0.06726343893024066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3349, 'weights': 'uniform'}. Best is trial 16 with value: 0.0375321954499075.
running
[I 2024-08-13 01:52:09,603] Trial 24 finished with value: 0.2562702454081923 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 16 with value: 0.0375321954499075.
running
[I 2024-08-13 01:52:09,988] Trial 22 finished with value: 0.09939822974827915 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 16 with value: 0.0375321954499075.
running
[I 2024-08-13 01:52:12,353] Trial 21 finished with value: 0.06346503051298982 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1988, 'weights': 'uniform'}. Best is trial 16 with value: 0.0375321954499075.
running
[I 2024-08-13 01:52:12,785] Trial 26 finished with value: 0.0318448171649235 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 146, 'weights': 'distance'}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:18,402] Trial 13 finished with value: 0.27134456636450743 and parameters: {'model_name': 'GAIN', 'batch_size': 286, 'hint_rate': 0.6919677697837092, 'alpha': 33, 'iterations': 1, 'learning_rate': 0.06227069722347181, 'p_miss': 0.25836792930318087}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:19,030] Trial 1 finished with value: 0.25522135827967013 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.41271093067053743, 'alpha': 53, 'iterations': 2, 'learning_rate': 0.0032941867533444243, 'p_miss': 0.05562579837889685}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:20,470] Trial 27 finished with value: 0.2722798625756172 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.03362677372991085, 'alpha': 42, 'iterations': 4, 'learning_rate': 0.00013318440853586736, 'p_miss': 0.25993089818146564}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:20,914] Trial 23 finished with value: 0.04271392978778475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:21,689] Trial 14 finished with value: 0.042716807473942645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:24,543] Trial 32 finished with value: 0.033427333664664376 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 269, 'weights': 'distance'}. Best is trial 26 with value: 0.0318448171649235.
running
[I 2024-08-13 01:52:24,827] Trial 33 finished with value: 0.02387752799292589 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 39, 'weights': 'distance'}. Best is trial 33 with value: 0.02387752799292589.
running
[I 2024-08-13 01:52:27,603] Trial 35 finished with value: 0.022080314680150176 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21, 'weights': 'distance'}. Best is trial 35 with value: 0.022080314680150176.
running
[I 2024-08-13 01:52:27,905] Trial 34 finished with value: 0.03330314563059628 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 238, 'weights': 'distance'}. Best is trial 35 with value: 0.022080314680150176.
running
[I 2024-08-13 01:52:30,181] Trial 36 finished with value: 0.020354165491325838 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:31,161] Trial 37 finished with value: 0.021064453044231067 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:32,921] Trial 25 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.6647206142585043, 'alpha': 84, 'iterations': 195, 'learning_rate': 0.021296666723899394, 'p_miss': 0.08417134841240707}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:33,346] Trial 5 finished with value: 0.05229937886000398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:34,463] Trial 38 finished with value: 0.03860335855388276 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 967, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:36,271] Trial 39 finished with value: 0.05075356869569159 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4749, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:37,188] Trial 40 finished with value: 0.04013616749648878 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1167, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:38,073] Trial 41 finished with value: 0.05075356869569159 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4552, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:39,185] Trial 42 finished with value: 0.05075356869569159 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4620, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:40,206] Trial 43 finished with value: 0.039312625859633944 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1056, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:40,798] Trial 44 finished with value: 0.038452860465860814 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 949, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:42,290] Trial 0 finished with value: 0.02948486944565961 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 36 with value: 0.020354165491325838.
[I 2024-08-13 01:52:42,424] Trial 45 finished with value: 0.049799589219651115 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3134, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
running
[I 2024-08-13 01:52:42,985] Trial 46 finished with value: 0.031598124487097964 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 134, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:43,978] Trial 47 finished with value: 0.025121253374047987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 54, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:44,406] Trial 48 finished with value: 0.024280169987575144 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 45, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:44,651] Trial 28 finished with value: 0.046647225901891395 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:46,061] Trial 50 finished with value: 0.031205280974380738 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 106, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:46,659] Trial 49 finished with value: 0.02216878607080912 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:48,212] Trial 52 finished with value: 0.035330793183262654 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 566, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:49,743] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.12205022601697572, 'alpha': 50, 'iterations': 331, 'learning_rate': 0.00013553450705073862, 'p_miss': 0.05885416450096964}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:49,959] Trial 56 finished with value: 0.035641250201351296 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 601, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:50,817] Trial 29 finished with value: 0.040797153882238556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:51,933] Trial 57 finished with value: 0.03542417270433292 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 577, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:53,319] Trial 58 finished with value: 0.03506129757514517 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 534, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:53,656] Trial 59 finished with value: 0.03541312053433965 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 576, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:54,443] Trial 60 finished with value: 0.03473593024211051 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 492, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:55,244] Trial 61 finished with value: 0.03490775199958781 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 514, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:52:56,569] Trial 62 finished with value: 0.0349396743504255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 518, 'weights': 'distance'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:03,050] Trial 51 finished with value: 0.060391632913613456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:04,165] Trial 53 finished with value: 0.060391632913613456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:18,798] Trial 9 finished with value: 0.04322670913979992 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:23,810] Trial 19 finished with value: 0.053443633922176936 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:29,789] Trial 30 finished with value: 0.06686986243563961 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:30,792] Trial 6 finished with value: 0.05013378055669378 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:37,963] Trial 17 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7726013300800104, 'alpha': 39, 'iterations': 1043, 'learning_rate': 0.0015892548824603312, 'p_miss': 0.23071462200870851}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:40,122] Trial 73 finished with value: 0.0212018389594981 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 01:53:42,822] Trial 74 finished with value: 0.060685260562949116 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1441, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:25:58,772] Trial 18 finished with value: 0.2597365675400493 and parameters: {'model_name': 'GAIN', 'batch_size': 191, 'hint_rate': 0.4052808968710339, 'alpha': 96, 'iterations': 952, 'learning_rate': 0.0005439325816435108, 'p_miss': 0.0722362958982915}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:26:00,699] Trial 76 finished with value: 0.021297179646614123 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:26:02,753] Trial 77 finished with value: 0.029483627578549616 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 40, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:26:04,967] Trial 78 finished with value: 0.047574900127689376 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 311, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:26:05,615] Trial 79 finished with value: 0.07196724599914348 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:26:07,485] Trial 80 finished with value: 0.02365535800331808 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:20,280] Trial 81 finished with value: 0.2603064801156407 and parameters: {'model_name': 'GAIN', 'batch_size': 20, 'hint_rate': 0.9483031672549374, 'alpha': 2, 'iterations': 29, 'learning_rate': 0.009655552910340705, 'p_miss': 0.16353458542337088}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:22,721] Trial 82 finished with value: 0.04755346086966062 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 320, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:25,817] Trial 83 finished with value: 0.06603264062472677 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2747, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:28,069] Trial 84 finished with value: 0.05480116907433189 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 787, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:29,187] Trial 85 finished with value: 0.09939822974827915 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:31,368] Trial 86 finished with value: 0.024849952994647664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:33,788] Trial 87 finished with value: 0.047551899133325734 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 325, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:35,821] Trial 88 finished with value: 0.02288223965878698 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:37,892] Trial 89 finished with value: 0.04755631728911273 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 321, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:40,275] Trial 90 finished with value: 0.0212018389594981 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 02:27:42,342] Trial 91 finished with value: 0.04760149604312075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 296, 'weights': 'uniform'}. Best is trial 36 with value: 0.020354165491325838.
running
[I 2024-08-13 03:18:31,680] Trial 4 finished with value: 0.016750645695164445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 4 with value: 0.016750645695164445.
running
[I 2024-08-13 03:18:43,753] Trial 31 finished with value: 0.016668546760771223 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 04:27:08,041] Trial 71 finished with value: 0.3167315448324917 and parameters: {'model_name': 'GAIN', 'batch_size': 870, 'hint_rate': 0.9171697217075828, 'alpha': 4, 'iterations': 3478, 'learning_rate': 0.0020136841766081716, 'p_miss': 0.16142360647891194}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 04:29:59,748] Trial 72 finished with value: 0.32316342276520105 and parameters: {'model_name': 'GAIN', 'batch_size': 652, 'hint_rate': 0.977445449367311, 'alpha': 2, 'iterations': 3592, 'learning_rate': 0.0016274503157242414, 'p_miss': 0.17290461401142432}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 04:35:17,474] Trial 93 finished with value: 0.017070164033657444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 04:35:41,306] Trial 94 finished with value: 0.016881389280821783 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 04:57:50,233] Trial 67 finished with value: 0.31628145078986897 and parameters: {'model_name': 'GAIN', 'batch_size': 769, 'hint_rate': 0.9566337784637908, 'alpha': 4, 'iterations': 4387, 'learning_rate': 0.0017062795891728932, 'p_miss': 0.16280071151672346}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 05:40:24,423] Trial 95 finished with value: 0.01753430420312654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 05:43:48,380] Trial 96 finished with value: 0.017243708984731772 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 05:48:08,984] Trial 97 finished with value: 0.017170120598482087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 05:48:53,584] Trial 98 finished with value: 0.016703680597976965 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 06:11:55,349] Trial 99 finished with value: 0.016816486222913662 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 06:17:44,600] Trial 63 finished with value: 0.2991912381556271 and parameters: {'model_name': 'GAIN', 'batch_size': 532, 'hint_rate': 0.9890149123212462, 'alpha': 94, 'iterations': 6228, 'learning_rate': 0.0015235024283880038, 'p_miss': 0.17206227663351448}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 06:30:09,344] Trial 65 finished with value: 0.32404625873685833 and parameters: {'model_name': 'GAIN', 'batch_size': 799, 'hint_rate': 0.8624212456837017, 'alpha': 1, 'iterations': 6165, 'learning_rate': 0.0015526415952559563, 'p_miss': 0.1728169265233349}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 06:40:29,247] Trial 75 finished with value: 0.3218283790454692 and parameters: {'model_name': 'GAIN', 'batch_size': 643, 'hint_rate': 0.9775930477770163, 'alpha': 9, 'iterations': 6718, 'learning_rate': 0.001303256376261593, 'p_miss': 0.16875064841323958}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 06:57:31,183] Trial 64 finished with value: 0.32425132883936214 and parameters: {'model_name': 'GAIN', 'batch_size': 982, 'hint_rate': 0.919551271743513, 'alpha': 2, 'iterations': 6952, 'learning_rate': 0.0016393974060821572, 'p_miss': 0.19618861117171882}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:00:02,955] Trial 100 finished with value: 0.01712754131105069 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:03:28,042] Trial 101 finished with value: 0.017250180982625325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:06:56,921] Trial 102 finished with value: 0.016963707669716256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:08:37,808] Trial 103 finished with value: 0.017077180851362547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:13:16,793] Trial 66 finished with value: 0.31304950773873025 and parameters: {'model_name': 'GAIN', 'batch_size': 914, 'hint_rate': 0.9526944175419993, 'alpha': 0, 'iterations': 7457, 'learning_rate': 0.0016176774125796383, 'p_miss': 0.17380769754210568}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:14:11,699] Trial 68 finished with value: 0.3138012422383988 and parameters: {'model_name': 'GAIN', 'batch_size': 976, 'hint_rate': 0.972511388112812, 'alpha': 0, 'iterations': 7106, 'learning_rate': 0.0016124722029690777, 'p_miss': 0.1542101269863721}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:25:03,217] Trial 92 finished with value: 0.31331182740833213 and parameters: {'model_name': 'GAIN', 'batch_size': 817, 'hint_rate': 0.2375582142530236, 'alpha': 1, 'iterations': 6856, 'learning_rate': 0.0006982816790618668, 'p_miss': 0.15857918249533573}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:29:03,705] Trial 104 finished with value: 0.016921786331162515 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:35:02,017] Trial 105 finished with value: 0.017029239075111214 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:44:31,821] Trial 54 finished with value: 0.33260589939393986 and parameters: {'model_name': 'GAIN', 'batch_size': 632, 'hint_rate': 0.9070345803586831, 'alpha': 2, 'iterations': 8307, 'learning_rate': 0.00024925016775437166, 'p_miss': 0.16463657328125755}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:45:53,747] Trial 106 finished with value: 0.016896118290618534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:48:06,513] Trial 70 finished with value: 0.30470208719448527 and parameters: {'model_name': 'GAIN', 'batch_size': 530, 'hint_rate': 0.9818123842097917, 'alpha': 3, 'iterations': 8821, 'learning_rate': 0.0015645158827499105, 'p_miss': 0.16883626053909032}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:49:37,832] Trial 55 finished with value: 0.32479736551505617 and parameters: {'model_name': 'GAIN', 'batch_size': 613, 'hint_rate': 0.969957948623191, 'alpha': 1, 'iterations': 8911, 'learning_rate': 0.00015710246260097188, 'p_miss': 0.17430773718097664}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:51:38,848] Trial 69 finished with value: 0.3327446759719374 and parameters: {'model_name': 'GAIN', 'batch_size': 841, 'hint_rate': 0.9691639563439938, 'alpha': 5, 'iterations': 9982, 'learning_rate': 0.0015287051803288027, 'p_miss': 0.172075672784433}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 07:52:56,248] Trial 107 finished with value: 0.016818056430229034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:04:48,917] Trial 108 finished with value: 0.017209611821079655 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:06:43,556] Trial 109 finished with value: 0.016735768080077564 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:09:09,399] Trial 110 finished with value: 0.01691885647316272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:11:32,169] Trial 111 finished with value: 0.01713728286660792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:12:43,185] Trial 112 finished with value: 0.01686008058992107 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:15:59,434] Trial 113 finished with value: 0.016796634991206254 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:16:49,816] Trial 114 finished with value: 0.016834689358195036 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:24:59,828] Trial 115 finished with value: 0.01694883641612769 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:28:05,646] Trial 116 finished with value: 0.017233030384081832 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:33:06,062] Trial 117 finished with value: 0.016867923778212862 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:40:57,921] Trial 118 finished with value: 0.017115465739972652 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 31 with value: 0.016668546760771223.
running
[I 2024-08-13 08:47:43,656] Trial 119 finished with value: 0.016610222599935446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 119 with value: 0.016610222599935446.
running
[I 2024-08-13 08:49:37,345] Trial 120 finished with value: 0.01606350357105926 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 08:51:03,410] Trial 121 finished with value: 0.016895186565039876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 08:52:54,179] Trial 122 finished with value: 0.01619048632954318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 08:54:11,162] Trial 123 finished with value: 0.016882460634783568 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:06:02,632] Trial 124 finished with value: 0.016406641394166765 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:07:58,738] Trial 125 finished with value: 0.01690674378232344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:10:24,391] Trial 126 finished with value: 0.016736015663231137 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:12:40,175] Trial 127 finished with value: 0.016808035315303747 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:13:50,618] Trial 128 finished with value: 0.017040842970334896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:14:05,412] Trial 144 finished with value: 0.04271392978778475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:17:12,657] Trial 129 finished with value: 0.016681832473039514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:18:10,243] Trial 130 finished with value: 0.01688316696835973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:26:21,114] Trial 131 finished with value: 0.016990427219682826 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:26:33,717] Trial 148 finished with value: 0.02072305298858889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:29:17,760] Trial 132 finished with value: 0.016163456057203714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:34:18,645] Trial 133 finished with value: 0.016493360317899004 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:42:12,886] Trial 134 finished with value: 0.01613019443395965 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:48:52,457] Trial 135 finished with value: 0.017069793719932422 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:50:57,717] Trial 136 finished with value: 0.01670998335984004 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:52:24,036] Trial 137 finished with value: 0.016482437107815467 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:54:08,463] Trial 138 finished with value: 0.016694030273721815 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 09:55:23,673] Trial 139 finished with value: 0.016832470211120082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:07:11,362] Trial 140 finished with value: 0.017068935434498663 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:09:14,124] Trial 141 finished with value: 0.016511453932373528 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:11:34,412] Trial 142 finished with value: 0.016437703791149325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:11:51,025] Trial 160 finished with value: 0.042715573935182924 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:13:46,412] Trial 143 finished with value: 0.01641631835114239 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:15:13,875] Trial 145 finished with value: 0.016287606869267307 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:16:30,343] Trial 149 finished with value: 0.020112688615439432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:16:30,659] Trial 164 finished with value: 0.06717540327167124 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:16:42,266] Trial 165 finished with value: 0.02072305298858889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:18:14,086] Trial 146 finished with value: 0.016503090159173762 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:19:21,163] Trial 147 finished with value: 0.016584516728378674 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:30:15,200] Trial 150 finished with value: 0.01620668580414041 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:31:15,215] Trial 169 finished with value: 0.048764978948348206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:36:04,504] Trial 151 finished with value: 0.01621348883027221 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:43:59,469] Trial 152 finished with value: 0.01662379761827912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 120 with value: 0.01606350357105926.
running
[I 2024-08-13 10:50:38,197] Trial 153 finished with value: 0.01602501953731388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 10:52:44,680] Trial 154 finished with value: 0.016335312802856015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 10:54:06,329] Trial 155 finished with value: 0.016514802228752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 10:55:38,233] Trial 156 finished with value: 0.01657027262855667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 10:56:59,121] Trial 157 finished with value: 0.016639982160231083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:08:41,274] Trial 158 finished with value: 0.01636672895533426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:10:47,904] Trial 159 finished with value: 0.016788198749107912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:13:14,093] Trial 161 finished with value: 0.01628151116665078 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:15:03,079] Trial 162 finished with value: 0.016865749193449672 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:16:33,449] Trial 163 finished with value: 0.016139638754763548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:18:03,579] Trial 166 finished with value: 0.016566454368798847 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:19:27,431] Trial 167 finished with value: 0.016179326515183425 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:20:44,269] Trial 168 finished with value: 0.016230626736986487 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:32:06,525] Trial 170 finished with value: 0.0162542826967192 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:37:10,689] Trial 171 finished with value: 0.016144905409926504 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:45:29,087] Trial 172 finished with value: 0.016282368224232954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:46:12,146] Trial 180 finished with value: 0.027882218253188557 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:52:19,624] Trial 173 finished with value: 0.01635680452800277 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:52:19,971] Trial 190 finished with value: 0.09939822974827915 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:53:21,123] Trial 191 finished with value: 0.03655078084758276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:54:54,552] Trial 185 finished with value: 0.025515782207599636 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:55:09,813] Trial 174 finished with value: 0.016656977229136484 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:56:34,040] Trial 182 finished with value: 0.02114814616817647 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:56:39,642] Trial 175 finished with value: 0.01651926636811375 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:58:06,123] Trial 176 finished with value: 0.016104152602020496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 11:59:27,089] Trial 177 finished with value: 0.016531646961113207 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 12:05:53,422] Trial 186 finished with value: 0.02400286839472193 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
running
[I 2024-08-13 12:11:03,245] Trial 187 finished with value: 0.025360725154268283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:11:16,713] Trial 178 finished with value: 0.016204020584039476 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:13:26,629] Trial 179 finished with value: 0.01648349741366591 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:17:21,306] Trial 181 finished with value: 0.016807445169508654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:20:14,973] Trial 183 finished with value: 0.016280711155745628 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:21:33,155] Trial 184 finished with value: 0.016427616048859024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:44:52,155] Trial 188 finished with value: 0.01633714404416175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:45:35,339] Trial 189 finished with value: 0.01685753252391909 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:51:14,667] Trial 192 finished with value: 0.01630710648445283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:52:29,872] Trial 193 finished with value: 0.016282403917504185 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:52:45,787] Trial 194 finished with value: 0.016247001477345212 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:54:04,183] Trial 196 finished with value: 0.016259559008497716 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:54:07,157] Trial 195 finished with value: 0.01638179731655007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:55:22,418] Trial 197 finished with value: 0.01629806117521071 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 12:56:29,085] Trial 198 finished with value: 0.016114131920527866 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
[I 2024-08-13 13:02:03,212] Trial 199 finished with value: 0.01613253651790698 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 153 with value: 0.01602501953731388.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.01602501953731388
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9692788376898086
Generation:   4%|         | 1/25 [00:45<18:04, 45.17s/it]Generation:  2
Best f1_score score: 0.9695437487347206
Generation:   8%|         | 2/25 [01:14<13:49, 36.09s/it]Generation:  3
Best f1_score score: 0.9711924490324982
Generation:  12%|        | 3/25 [01:53<13:38, 37.22s/it]Generation:  4
Best f1_score score: 0.9711924490324982
Generation:  16%|        | 4/25 [02:34<13:33, 38.74s/it]Generation:  5
Best f1_score score: 0.9711924490324982
Generation:  20%|        | 5/25 [04:28<21:54, 65.72s/it]Generation:  6
Best f1_score score: 0.9711924490324982
Generation:  24%|       | 6/25 [09:57<49:09, 155.22s/it]Generation:  7
Best f1_score score: 0.9711924490324982
Generation:  28%|       | 7/25 [12:30<46:25, 154.73s/it]Generation:  8
Best f1_score score: 0.9711924490324982
Generation:  32%|      | 8/25 [13:14<33:50, 119.43s/it]Generation:  9
Best f1_score score: 0.9711924490324982
Generation:  36%|      | 9/25 [13:57<25:27, 95.49s/it] Generation:  10
Best f1_score score: 0.9711924490324982
Generation:  40%|      | 10/25 [17:31<33:02, 132.14s/it]Generation:  11
Best f1_score score: 0.9711924490324982
Generation:  44%|     | 11/25 [17:43<22:15, 95.39s/it] Generation:  12
Best f1_score score: 0.9711924490324982
Generation:  48%|     | 12/25 [18:23<16:58, 78.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474b6eda0> 

Generation:  13
Best f1_score score: 0.9711924490324982
Generation:  52%|    | 13/25 [28:30<47:41, 238.48s/it]Generation:  14
Best f1_score score: 0.9713725930307678
Generation:  56%|    | 14/25 [32:38<44:16, 241.47s/it]Generation:  15
Best f1_score score: 0.9713725930307678
Generation:  60%|    | 15/25 [33:16<30:02, 180.27s/it]Generation:  16
Best f1_score score: 0.9713725930307678
Generation:  64%|   | 16/25 [42:00<42:32, 283.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d17520> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  17
Best f1_score score: 0.9713725930307678
Generation:  68%|   | 17/25 [44:03<31:23, 235.46s/it]Generation:  18
Best f1_score score: 0.9713725930307678
Generation:  72%|  | 18/25 [48:45<29:05, 249.34s/it]Generation:  19
Best f1_score score: 0.9713725930307678
Generation:  76%|  | 19/25 [50:22<20:20, 203.45s/it]Generation:  20
Best f1_score score: 0.9713725930307678
Generation:  80%|  | 20/25 [51:20<13:19, 159.95s/it]Generation:  21
Best f1_score score: 0.9713725930307678
Generation:  84%| | 21/25 [52:26<08:46, 131.70s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547505b820> 

Generation:  22
Best f1_score score: 0.9713725930307678
Generation:  88%| | 22/25 [1:02:36<13:45, 275.09s/it]Generation:  23
Best f1_score score: 0.9713725930307678
Generation:  92%|| 23/25 [1:03:27<06:56, 208.00s/it]Generation:  24
Best f1_score score: 0.9713725930307678
Generation:  96%|| 24/25 [1:04:27<02:43, 163.69s/it]Generation:  25
Best f1_score score: 0.9713725930307678
Generation: 100%|| 25/25 [1:06:06<00:00, 144.18s/it]Generation: 100%|| 25/25 [1:06:10<00:00, 158.82s/it]
2024-08-13 14:14:22,648 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37079' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-1948633d1e863cba722908673d47460f', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723583662.648224')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(criterion='entropy',
                                        max_features=0.7593183797507,
                                        min_samples_leaf=3, min_samples_split=6,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9996990168946457, 'accuracy': 0.9908629441624366, 'balanced_accuracy': 0.9529381203313729, 'logloss': 0.03491726667577778, 'f1': 0.9907920938658522}
original test score: {'auroc': 0.997940256461816, 'accuracy': 0.9726277372262774, 'balanced_accuracy': 0.7515028332101503, 'logloss': 0.06620735472222397, 'f1': 0.9711420475270741}
imputed test score: {'auroc': 0.997940256461816, 'accuracy': 0.9726277372262774, 'balanced_accuracy': 0.7515028332101503, 'logloss': 0.06620735472222397, 'f1': 0.9711420475270741}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155436506230>
Start tpot fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bb1fc0> 

Generation:  1
Best f1_score score: 0.9597921925212651
Generation:   4%|         | 1/25 [10:02<4:00:58, 602.42s/it]Generation:  2
Best f1_score score: 0.9680913802665099
Generation:   8%|         | 2/25 [13:02<2:15:48, 354.27s/it]Generation:  3
Best f1_score score: 0.9680913802665099
Generation:  12%|        | 3/25 [13:39<1:16:44, 209.30s/it]Generation:  4
Best f1_score score: 0.9697246155117984
Generation:  16%|        | 4/25 [14:00<47:08, 134.67s/it]  corrupted size vs. prev_size
2024-08-13 14:33:53,495 - distributed.nanny - WARNING - Restarting worker
WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bd98a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545406fe20> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e90b80> 

Generation:  5
Best f1_score score: 0.9707360328337871
Generation:  20%|        | 5/25 [29:22<2:19:35, 418.80s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554533b79d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547525f970> 

Generation:  6
Best f1_score score: 0.9714199596085882
Generation:  24%|       | 6/25 [39:27<2:32:37, 481.97s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457e41c90> 

Generation:  7
Best f1_score score: 0.9714199596085882
Generation:  28%|       | 7/25 [49:31<2:36:32, 521.82s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475899450> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.9714199596085882
Generation:  32%|      | 8/25 [49:47<1:42:17, 361.04s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457bf8a90> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474df3f40> 

Generation:  9
Best f1_score score: 0.9714199596085882
Generation:  36%|      | 9/25 [59:51<1:56:28, 436.76s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bce1a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453dae980> 

Generation:  10
Best f1_score score: 0.9714199596085882
Generation:  40%|      | 10/25 [1:09:56<2:02:14, 488.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458145ed0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474371b40> 

Generation:  11
Best f1_score score: 0.9714775142806428
Generation:  44%|     | 11/25 [1:20:00<2:02:16, 524.06s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547463f190> 

Generation:  12
Best f1_score score: 0.9714775142806428
Generation:  48%|     | 12/25 [1:30:05<1:58:50, 548.50s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458316d10> 

Generation:  13
Best f1_score score: 0.9716182406208901
Generation:  52%|    | 13/25 [1:40:08<1:53:03, 565.28s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474b83f70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747892d0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.9716182406208901
Generation:  56%|    | 14/25 [1:40:22<1:13:06, 398.74s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457fe8c70> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554581df730> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  15
Best f1_score score: 0.9719102029936204
Generation:  60%|    | 15/25 [1:41:25<49:33, 297.37s/it]  Generation:  16
Best f1_score score: 0.9724934875494077
Generation:  64%|   | 16/25 [1:43:24<36:32, 243.66s/it]Generation:  17
Best f1_score score: 0.9724934875494077
Generation:  68%|   | 17/25 [1:44:01<24:13, 181.66s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554752e8730> 

Generation:  18
Best f1_score score: 0.9724934875494077
Generation:  72%|  | 18/25 [1:54:09<36:07, 309.63s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453307e80> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457fbee00> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547542fd90> 

Generation:  19
Best f1_score score: 0.9724934875494077
Generation:  76%|  | 19/25 [2:04:15<39:51, 398.61s/it]Generation:  20
Best f1_score score: 0.9724934875494077
Generation:  80%|  | 20/25 [2:04:27<23:33, 282.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bfdcf10> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  21
Best f1_score score: 0.9724934875494077
Generation:  84%| | 21/25 [2:06:54<16:07, 241.98s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475b42e00> 

Generation:  22
Best f1_score score: 0.9728269349421026
Generation:  88%| | 22/25 [2:17:00<17:33, 351.01s/it]Generation:  23
Best f1_score score: 0.9728269349421026
Generation:  92%|| 23/25 [2:19:16<09:33, 286.53s/it]Generation:  24
Best f1_score score: 0.9728269349421026
Generation:  96%|| 24/25 [2:19:59<03:33, 213.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15534882ab90> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bf0d30> 

Generation:  25
Best f1_score score: 0.9728269349421026
Generation: 100%|| 25/25 [2:30:07<00:00, 331.85s/it]Generation: 100%|| 25/25 [2:30:07<00:00, 360.29s/it]
2024-08-13 16:44:39,224 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38199' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-682d0bb2d46ca45ef524a4f68ca5b339', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723592679.2241006')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=31)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(criterion='entropy',
                                      max_features=0.9941014555599,
                                      min_samples_leaf=2, min_samples_split=10,
                                      n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9996173136128206, 'accuracy': 0.9886294416243655, 'balanced_accuracy': 0.9257376150549183, 'logloss': 0.03896335947146518, 'f1': 0.9884086173673423}
test score: {'auroc': 0.9977251188767875, 'accuracy': 0.9799270072992701, 'balanced_accuracy': 0.8646341463414634, 'logloss': 0.07214271009950848, 'f1': 0.9795885968678673}
original test score: {'auroc': 0.9977251188767875, 'accuracy': 0.9799270072992701, 'balanced_accuracy': 0.8646341463414634, 'logloss': 0.07226734065692528, 'f1': 0.9795885968678673}
score end
30
lvl
0.01
type
MAR
num_run
1
class_full
finished
all finished
full run takes
14.878909782568615
hours
DONE
