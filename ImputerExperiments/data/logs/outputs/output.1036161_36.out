Run: 36
/cm/local/apps/slurm/var/spool/job1036161/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/881/881.pkl
working on 
../data/c/881/class_full_MNAR_0.5_2
0.09607934951782227
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-01 11:38:44,266] A new study created in memory with name: no-name-ea0b1693-3cc1-4548-9cb4-05114e56f282
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-01 11:38:45,051] Trial 5 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 5 with value: 0.42331479114481274.
running
[I 2024-11-01 11:38:45,836] Trial 11 finished with value: 0.29735467773904295 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:38:46,702] Trial 7 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:38:46,953] Trial 1 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:38:47,287] Trial 17 finished with value: 0.29735467773904295 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.29735467773904295.
[I 2024-11-01 11:38:47,487] Trial 4 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 11 with value: 0.29735467773904295.
running
running
[I 2024-11-01 11:39:02,250] Trial 6 finished with value: 0.40702137740818073 and parameters: {'model_name': 'GAIN', 'batch_size': 126, 'hint_rate': 0.9598311638518685, 'alpha': 18, 'iterations': 2, 'learning_rate': 0.0011997107227520382, 'p_miss': 0.2431910425169057}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:39:02,928] Trial 2 finished with value: 0.41407962358506445 and parameters: {'model_name': 'GAIN', 'batch_size': 113, 'hint_rate': 0.2879061359235299, 'alpha': 22, 'iterations': 2, 'learning_rate': 0.0007769988454089448, 'p_miss': 0.1430584712593656}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:39:04,161] Trial 0 finished with value: 0.4016080642611202 and parameters: {'model_name': 'GAIN', 'batch_size': 191, 'hint_rate': 0.4548497242990306, 'alpha': 33, 'iterations': 4, 'learning_rate': 0.005013465594794647, 'p_miss': 0.22385211575635544}. Best is trial 11 with value: 0.29735467773904295.
running
[I 2024-11-01 11:39:16,936] Trial 14 finished with value: 0.2632649728359547 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 14, 'learning_rate': 0.0035802670472024913, 'p_miss': 0.14879268475335566}. Best is trial 14 with value: 0.2632649728359547.
running
[I 2024-11-01 11:39:24,653] Trial 12 finished with value: 0.2926400298407761 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 439, 'weights': 'uniform'}. Best is trial 14 with value: 0.2632649728359547.
running
[I 2024-11-01 11:39:34,605] Trial 20 finished with value: 0.3082689512530027 and parameters: {'model_name': 'VAE', 'batch_size': 721, 'iterations': 3, 'learning_rate': 0.03591828911017884, 'p_miss': 0.277668942198796}. Best is trial 14 with value: 0.2632649728359547.
running
[I 2024-11-01 11:39:38,404] Trial 21 finished with value: 0.2621081465638714 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 25, 'learning_rate': 0.0002806975427839697, 'p_miss': 0.060185172617155336}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:39:39,119] Trial 15 finished with value: 0.29735467773904295 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30561, 'weights': 'uniform'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:39:44,973] Trial 18 finished with value: 0.29562906526665617 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14453, 'weights': 'uniform'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:39:46,697] Trial 22 finished with value: 0.3097042456945084 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 268, 'weights': 'distance'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:39:48,612] Trial 13 finished with value: 0.29678366555250113 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21748, 'weights': 'uniform'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:40:05,692] Trial 26 finished with value: 0.29313401867718636 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 723, 'weights': 'uniform'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:40:07,814] Trial 19 finished with value: 0.31258827059978395 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23730, 'weights': 'distance'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:40:13,783] Trial 27 finished with value: 0.2937734263084413 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1384, 'weights': 'uniform'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:41:18,525] Trial 3 finished with value: 0.30738892794224604 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:43:06,013] Trial 16 finished with value: 0.2898286753655747 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 118, 'learning_rate': 0.001859570670923282, 'p_miss': 0.2711878358400434}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:44:28,554] Trial 24 finished with value: 0.33448592808668803 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 168, 'learning_rate': 0.002966361154478557, 'p_miss': 0.22032235431088237}. Best is trial 21 with value: 0.2621081465638714.
running
[I 2024-11-01 11:45:25,319] Trial 30 finished with value: 0.26181588091883506 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 145, 'learning_rate': 0.00010593488088749178, 'p_miss': 0.012783368695156505}. Best is trial 30 with value: 0.26181588091883506.
running
[I 2024-11-01 11:46:39,733] Trial 38 finished with value: 0.2655861278959312 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 50, 'learning_rate': 0.0002783733095121151, 'p_miss': 0.030710185262339772}. Best is trial 30 with value: 0.26181588091883506.
running
[I 2024-11-01 11:48:09,605] Trial 23 finished with value: 0.3053403043984409 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 199, 'learning_rate': 0.0015240611267322895, 'p_miss': 0.12450229783891603}. Best is trial 30 with value: 0.26181588091883506.
running
[I 2024-11-01 11:49:09,228] Trial 28 finished with value: 0.2612616329187366 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 302, 'learning_rate': 0.00010722749932131183, 'p_miss': 0.022156155268720466}. Best is trial 28 with value: 0.2612616329187366.
running
[I 2024-11-01 11:49:59,340] Trial 32 finished with value: 0.2621956306842742 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 303, 'learning_rate': 0.00010814016664305324, 'p_miss': 0.03613848707356218}. Best is trial 28 with value: 0.2612616329187366.
running
[I 2024-11-01 11:50:44,865] Trial 35 finished with value: 0.2584282610512128 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 328, 'learning_rate': 0.00012169918081352216, 'p_miss': 0.012850754727776754}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:50:49,321] Trial 31 finished with value: 0.2616236439606695 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 285, 'learning_rate': 0.00010588659578255855, 'p_miss': 0.03332028029301856}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:11,803] Trial 37 finished with value: 0.2615129025945494 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 255, 'learning_rate': 0.0001268073747726628, 'p_miss': 0.06800596342233972}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:19,105] Trial 33 finished with value: 0.2601576704864238 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 355, 'learning_rate': 0.00010031268910543622, 'p_miss': 0.01755381051896171}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:19,723] Trial 29 finished with value: 0.26188618590008617 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 379, 'learning_rate': 0.00014312299968292339, 'p_miss': 0.022269024558307537}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:27,768] Trial 45 finished with value: 0.29597524580406365 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:50,290] Trial 34 finished with value: 0.26246025229988323 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 369, 'learning_rate': 0.00017903496592210826, 'p_miss': 0.018380439215137545}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:53,476] Trial 46 finished with value: 0.29597524580406365 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:51:58,920] Trial 47 finished with value: 0.2961186637457914 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:53:39,495] Trial 36 finished with value: 0.25964518636928247 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 435, 'learning_rate': 0.00011061739596592635, 'p_miss': 0.01609686940128166}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:59:31,974] Trial 49 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.02831272725535494, 'alpha': 99, 'iterations': 2157, 'learning_rate': 0.00046617710150139704, 'p_miss': 0.08184189716552277}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 11:59:41,894] Trial 51 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.07574493438158292, 'alpha': 100, 'iterations': 2088, 'learning_rate': 0.0003865131167526877, 'p_miss': 0.08000847258674956}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:01:55,006] Trial 50 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.04289191400314335, 'alpha': 98, 'iterations': 2718, 'learning_rate': 0.000429582585215168, 'p_miss': 0.08351751249593752}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:02:22,629] Trial 52 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.040651846660396396, 'alpha': 94, 'iterations': 2799, 'learning_rate': 0.0004408558470618849, 'p_miss': 0.07567315741120514}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:03:51,438] Trial 53 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.01727927688498815, 'alpha': 98, 'iterations': 2647, 'learning_rate': 0.0004601892429456356, 'p_miss': 0.08148558985555286}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:19:01,110] Trial 10 finished with value: 0.4245076739683774 and parameters: {'model_name': 'GAIN', 'batch_size': 170, 'hint_rate': 0.31181743824980773, 'alpha': 87, 'iterations': 1943, 'learning_rate': 0.0015671623805804267, 'p_miss': 0.10856235791314371}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:30:35,860] Trial 55 finished with value: 0.28439562556653436 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 818, 'learning_rate': 0.00020742464373732592, 'p_miss': 0.04791667769430176}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:30:38,725] Trial 9 finished with value: 0.41797612931710226 and parameters: {'model_name': 'GAIN', 'batch_size': 32, 'hint_rate': 0.4654487648200349, 'alpha': 29, 'iterations': 2602, 'learning_rate': 0.09489912706754237, 'p_miss': 0.10507083926569175}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:39:03,085] Trial 56 finished with value: 0.2963390948398478 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1018, 'learning_rate': 0.00020458494685926513, 'p_miss': 0.05923328995246263}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:40:49,204] Trial 58 finished with value: 0.290191626972203 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 904, 'learning_rate': 0.00018314749301733932, 'p_miss': 0.05217539381856383}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:43:11,459] Trial 43 finished with value: 0.30498069029282665 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:44:13,971] Trial 44 finished with value: 0.30701980812436275 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:45:49,547] Trial 57 finished with value: 0.29244854766640266 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1014, 'learning_rate': 0.00019050223323489765, 'p_miss': 0.04929671194605165}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:46:23,666] Trial 64 finished with value: 0.2642385726874211 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 68, 'learning_rate': 0.00011296272594518162, 'p_miss': 0.01768936405358523}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:47:22,196] Trial 65 finished with value: 0.2626405272362794 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 61, 'learning_rate': 0.00010017220211948642, 'p_miss': 0.011257916508688098}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:53:49,707] Trial 48 finished with value: 0.3076347354875179 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:55:28,590] Trial 59 finished with value: 0.27416099861329285 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 770, 'learning_rate': 0.00020541703068855874, 'p_miss': 0.0572336810345798}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:55:29,564] Trial 70 finished with value: 0.4220946560899047 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:56:08,332] Trial 25 finished with value: 0.3520785781664137 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2006, 'learning_rate': 0.019186675465247684, 'p_miss': 0.010240931623278882}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 12:59:19,477] Trial 41 finished with value: 0.2944788688479956 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1810, 'learning_rate': 0.00010059490819274354, 'p_miss': 0.01578896093696759}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:07:39,072] Trial 67 finished with value: 0.2603767798281773 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 502, 'learning_rate': 0.00010425536205982422, 'p_miss': 0.03447935231529131}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:09:07,328] Trial 68 finished with value: 0.2604331878391075 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 466, 'learning_rate': 0.0001546067579304006, 'p_miss': 0.03444134625123085}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:10:27,213] Trial 61 finished with value: 0.2773652554386249 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 836, 'learning_rate': 0.00018767159683913897, 'p_miss': 0.010979325728189555}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:13:23,735] Trial 66 finished with value: 0.2630816610127447 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 476, 'learning_rate': 0.00010311594812799286, 'p_miss': 0.010778719828376677}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:15:56,896] Trial 71 finished with value: 0.262993676866241 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 386, 'learning_rate': 0.00014024634106794685, 'p_miss': 0.034037702568431846}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:16:13,314] Trial 60 finished with value: 0.2838911958399041 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 870, 'learning_rate': 0.00018823795491266124, 'p_miss': 0.05786097421265836}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:16:18,094] Trial 79 finished with value: 0.2652145835546799 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 1, 'learning_rate': 0.0003016408951222263, 'p_miss': 0.03969442923985918}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:16:19,094] Trial 80 finished with value: 0.4220946560899047 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:16:35,047] Trial 69 finished with value: 0.2597549230023855 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 539, 'learning_rate': 0.00015080599449606805, 'p_miss': 0.03742575781337143}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:18:00,937] Trial 54 finished with value: 0.3126904365002656 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1618, 'learning_rate': 0.000343273453707018, 'p_miss': 0.09807576023556344}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:19:58,446] Trial 62 finished with value: 0.27496672273015454 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 771, 'learning_rate': 0.0001711621185276696, 'p_miss': 0.01223208033320639}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:20:32,903] Trial 72 finished with value: 0.26045747458096324 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 457, 'learning_rate': 0.00013784597315187795, 'p_miss': 0.03230169166486252}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:22:07,369] Trial 73 finished with value: 0.3237180521770119 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 447, 'learning_rate': 0.0007948883112736917, 'p_miss': 0.04096821333205093}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:23:46,809] Trial 83 finished with value: 0.26334136528664576 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 91, 'learning_rate': 0.0008602965274151291, 'p_miss': 0.16927673270992205}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:24:11,073] Trial 63 finished with value: 0.26042300737084423 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 726, 'learning_rate': 0.00010871573087886027, 'p_miss': 0.013073825920258467}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:26:48,132] Trial 42 finished with value: 0.30997904081859967 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2254, 'learning_rate': 0.00013060325249361605, 'p_miss': 0.01513257722916123}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:28:15,519] Trial 74 finished with value: 0.2613995672085513 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 449, 'learning_rate': 0.00015090676166558506, 'p_miss': 0.03964520586679737}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:29:21,597] Trial 84 finished with value: 0.2732132504908163 and parameters: {'model_name': 'VAE', 'batch_size': 461, 'iterations': 107, 'learning_rate': 0.0006319187264907209, 'p_miss': 0.193402802539056}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:34:55,417] Trial 75 finished with value: 0.3053887744466678 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 508, 'learning_rate': 0.0008980799274578376, 'p_miss': 0.03859808972900179}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:34:56,166] Trial 92 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:36:48,971] Trial 86 finished with value: 0.2616873752649507 and parameters: {'model_name': 'VAE', 'batch_size': 852, 'iterations': 186, 'learning_rate': 0.00014579294616030077, 'p_miss': 0.19144100360823776}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:39:10,333] Trial 90 finished with value: 0.30312983391439696 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 176, 'learning_rate': 0.006760908459670789, 'p_miss': 0.030830931482187955}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:39:42,102] Trial 95 finished with value: 0.31155092435825915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11338, 'weights': 'distance'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:39:43,212] Trial 77 finished with value: 0.28508568150967206 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 517, 'learning_rate': 0.0002883689649607257, 'p_miss': 0.03853292530220256}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:40:10,497] Trial 76 finished with value: 0.26443085080890466 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 464, 'learning_rate': 0.00014516347917255154, 'p_miss': 0.1828778000384667}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:43:32,124] Trial 78 finished with value: 0.324523397854648 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 548, 'learning_rate': 0.0007584977814073068, 'p_miss': 0.039687580232337684}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:45:29,800] Trial 93 finished with value: 0.31039868998357567 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 181, 'learning_rate': 0.013171647259156346, 'p_miss': 0.028432436295042378}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:47:49,053] Trial 8 finished with value: 0.28668030380619597 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:53:18,184] Trial 98 finished with value: 0.2605436456140835 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 248, 'learning_rate': 0.00026803525906645635, 'p_miss': 0.025166449068589107}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:54:52,411] Trial 82 finished with value: 0.30305805032914696 and parameters: {'model_name': 'VAE', 'batch_size': 383, 'iterations': 623, 'learning_rate': 0.0007915003869270587, 'p_miss': 0.20302599377303082}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 13:55:11,126] Trial 96 finished with value: 0.2629893002931951 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 279, 'learning_rate': 0.0002542385098835475, 'p_miss': 0.02506605173603438}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 14:02:25,610] Trial 101 finished with value: 0.26090146253406454 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 249, 'learning_rate': 0.00012837701566164615, 'p_miss': 0.02462773926482403}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 14:10:13,234] Trial 103 finished with value: 0.26202701508988036 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 280, 'learning_rate': 0.0002558836077460073, 'p_miss': 0.026138522209030183}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 14:10:17,941] Trial 104 finished with value: 0.26260377187994877 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 251, 'learning_rate': 0.00023203083765912963, 'p_miss': 0.298236915360659}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 14:18:04,199] Trial 107 finished with value: 0.2643996678554773 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 129, 'learning_rate': 0.0001320193706729757, 'p_miss': 0.023742540824500058}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 14:55:46,155] Trial 97 finished with value: 0.3122333260238702 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1358, 'learning_rate': 0.0002353770358914569, 'p_miss': 0.025906339308714763}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:02:07,963] Trial 39 finished with value: 0.31530027452280335 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3516, 'learning_rate': 0.00011958168838649415, 'p_miss': 0.013058084729114822}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:12:49,808] Trial 40 finished with value: 0.3095954119316653 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4224, 'learning_rate': 0.00010504489807675255, 'p_miss': 0.02172916443335309}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:13:25,500] Trial 111 finished with value: 0.26511691147248884 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 10, 'learning_rate': 0.0001570305441888574, 'p_miss': 0.04771852324278003}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:36:46,273] Trial 108 finished with value: 0.2862070774896184 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1184, 'learning_rate': 0.00012183759159449764, 'p_miss': 0.13458511093319978}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:37:14,702] Trial 113 finished with value: 0.3113525780295022 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7865, 'weights': 'distance'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 15:56:51,882] Trial 114 finished with value: 0.2606933860866431 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 334, 'learning_rate': 0.00013066212062880027, 'p_miss': 0.06680917331668453}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:16:01,036] Trial 115 finished with value: 0.2602734551691225 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 339, 'learning_rate': 0.0001695209033183127, 'p_miss': 0.06916394219799245}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:20:50,228] Trial 109 finished with value: 0.32342871617762825 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1337, 'learning_rate': 0.06887919057998479, 'p_miss': 0.06775010773612511}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:25:19,200] Trial 110 finished with value: 0.2990478453072507 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1383, 'learning_rate': 0.00014665727810056104, 'p_miss': 0.07026380475800771}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:33:28,066] Trial 112 finished with value: 0.33747247439199785 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1425, 'learning_rate': 0.08748204891814865, 'p_miss': 0.020917667931632834}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:37:09,109] Trial 116 finished with value: 0.26128688014693824 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 366, 'learning_rate': 0.00016042322186525713, 'p_miss': 0.0690845425979156}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:41:02,104] Trial 117 finished with value: 0.2610820664670361 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 340, 'learning_rate': 0.00016753699963447188, 'p_miss': 0.09383665481713575}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:41:03,079] Trial 121 finished with value: 0.4220946560899047 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 16:53:53,739] Trial 119 finished with value: 0.26126874007915946 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 349, 'learning_rate': 0.0001610593591266865, 'p_miss': 0.10373913731429577}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:04:33,984] Trial 118 finished with value: 0.26718698515500766 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 662, 'learning_rate': 0.000156513910240597, 'p_miss': 0.11391574699456651}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:06:24,978] Trial 120 finished with value: 0.26035907703088484 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 597, 'learning_rate': 0.00012764689613166427, 'p_miss': 0.09031734120050525}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:07:21,229] Trial 125 finished with value: 0.2933407631575845 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:20:06,590] Trial 122 finished with value: 0.26780301418199753 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 652, 'learning_rate': 0.00011949686401992556, 'p_miss': 0.04825668956101503}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:21:32,588] Trial 126 finished with value: 0.26162787444968794 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 227, 'learning_rate': 0.00012147165964622798, 'p_miss': 0.047134289695912934}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:32:38,313] Trial 127 finished with value: 0.2588946340216687 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 217, 'learning_rate': 0.00011979476563059905, 'p_miss': 0.03207630031204369}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:34:51,341] Trial 91 finished with value: 0.3058464770555983 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4300, 'learning_rate': 0.0065884158804617576, 'p_miss': 0.030763310043076447}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:35:05,265] Trial 130 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.8725341211863744, 'alpha': 1, 'iterations': 40, 'learning_rate': 0.00010128867299168843, 'p_miss': 0.017380310236280845}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:41:55,894] Trial 123 finished with value: 0.2616972458769085 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 706, 'learning_rate': 0.00011958042395107575, 'p_miss': 0.11552725934024993}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:42:17,737] Trial 131 finished with value: 0.2607345844820973 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 146, 'learning_rate': 0.00020928554124219372, 'p_miss': 0.033485955707601024}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:43:27,686] Trial 124 finished with value: 0.26482870243380896 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 615, 'learning_rate': 0.00011941677839695705, 'p_miss': 0.04869125599949335}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:49:28,089] Trial 132 finished with value: 0.2624766111809575 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 136, 'learning_rate': 0.00021434523345484336, 'p_miss': 0.03322050898522863}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:56:21,027] Trial 134 finished with value: 0.3064538123033903 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 216, 'learning_rate': 0.0017996852610846117, 'p_miss': 0.02194487727263717}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:57:23,225] Trial 94 finished with value: 0.30906231216492525 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4214, 'learning_rate': 0.0002652852769643125, 'p_miss': 0.02754992856139623}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 17:58:01,545] Trial 133 finished with value: 0.26199805304462476 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 218, 'learning_rate': 0.0002028953506475751, 'p_miss': 0.017389995172705446}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:05:25,304] Trial 129 finished with value: 0.2778864124853129 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 651, 'learning_rate': 0.00022063102641164115, 'p_miss': 0.03282062476556094}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:08:48,950] Trial 128 finished with value: 0.263631077507377 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 694, 'learning_rate': 0.00010371232638500665, 'p_miss': 0.03189313328418049}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:18:07,071] Trial 136 finished with value: 0.26052166365491614 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 367, 'learning_rate': 0.00010118392592218656, 'p_miss': 0.057591602156126256}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:18:21,456] Trial 137 finished with value: 0.26240123170662905 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 434, 'learning_rate': 0.00018171615348032083, 'p_miss': 0.08949752962794717}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:18:45,434] Trial 141 finished with value: 0.31269708358692355 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 32183, 'weights': 'distance'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:18:57,235] Trial 142 finished with value: 0.31269708358692355 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31659, 'weights': 'distance'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:22:27,655] Trial 135 finished with value: 0.26482399910142174 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 439, 'learning_rate': 0.00019371355525601934, 'p_miss': 0.01732646488304365}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:26:05,494] Trial 139 finished with value: 0.26163938578373946 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 394, 'learning_rate': 0.00013501051111822703, 'p_miss': 0.06106467064720025}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:26:53,331] Trial 138 finished with value: 0.2607854873268647 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 399, 'learning_rate': 0.0001364695134442341, 'p_miss': 0.061450980056235185}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:28:51,669] Trial 140 finished with value: 0.261660604164473 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 414, 'learning_rate': 0.00013420006416338525, 'p_miss': 0.055013749305983156}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:45:05,613] Trial 146 finished with value: 0.2607365266502765 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 314, 'learning_rate': 0.00010021054009863115, 'p_miss': 0.05708288387101292}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:46:03,187] Trial 147 finished with value: 0.2609460241155212 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 317, 'learning_rate': 0.00010043613091879284, 'p_miss': 0.042150309498052554}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:54:39,855] Trial 85 finished with value: 0.32378854262318757 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5981, 'learning_rate': 0.0006892814918083142, 'p_miss': 0.03879521731970023}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:55:35,635] Trial 148 finished with value: 0.26036497608682135 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 292, 'learning_rate': 0.00011403471592062496, 'p_miss': 0.04387529303190939}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:56:53,197] Trial 152 finished with value: 0.30263212782039495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:56:54,229] Trial 153 finished with value: 0.29735467773904295 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 18:57:48,766] Trial 102 finished with value: 0.35639500801529567 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6167, 'learning_rate': 0.00023587993394436548, 'p_miss': 0.024270758183342407}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:05:27,714] Trial 88 finished with value: 0.3510395568046224 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5752, 'learning_rate': 0.007381211093713388, 'p_miss': 0.028713625977620304}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:12:02,854] Trial 155 finished with value: 0.4192176205574748 and parameters: {'model_name': 'GAIN', 'batch_size': 21, 'hint_rate': 0.7499577659461987, 'alpha': 68, 'iterations': 527, 'learning_rate': 0.00034638626437994655, 'p_miss': 0.04500362303773814}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:15:27,502] Trial 99 finished with value: 0.34643457455641674 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5996, 'learning_rate': 0.00013442693616516423, 'p_miss': 0.025547303481841283}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:18:36,860] Trial 143 finished with value: 0.3074792521496251 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 970, 'learning_rate': 0.003156169264500534, 'p_miss': 0.05773692269718846}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:18:46,694] Trial 149 finished with value: 0.2640719102330956 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 553, 'learning_rate': 0.00011359926113718896, 'p_miss': 0.042744076564729984}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:35:22,859] Trial 160 finished with value: 0.26221339069018795 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 298, 'learning_rate': 0.00017655804239591135, 'p_miss': 0.013879028362139653}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:39:30,145] Trial 157 finished with value: 0.2623954574837413 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 525, 'learning_rate': 0.00011384358203464085, 'p_miss': 0.010497347120885212}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:44:03,610] Trial 161 finished with value: 0.262989804724384 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 158, 'learning_rate': 0.0001479721656839432, 'p_miss': 0.06442723063287169}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:44:30,502] Trial 156 finished with value: 0.26324612980302114 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 528, 'learning_rate': 0.00011726227177262631, 'p_miss': 0.044178500503862725}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:49:05,479] Trial 150 finished with value: 0.292101215594907 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1001, 'learning_rate': 0.00017540868137072658, 'p_miss': 0.04295825617310778}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:50:11,168] Trial 159 finished with value: 0.2628180786319188 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 533, 'learning_rate': 0.00011462426316811553, 'p_miss': 0.010015637667743191}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:50:13,001] Trial 162 finished with value: 0.2609265465981831 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 158, 'learning_rate': 0.0001507631490310477, 'p_miss': 0.07561258812431162}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:51:25,916] Trial 154 finished with value: 0.28881488900070007 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 993, 'learning_rate': 0.00016916089317577402, 'p_miss': 0.0438179464391029}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:52:09,997] Trial 151 finished with value: 0.2855688848062652 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1007, 'learning_rate': 0.00016529049450774021, 'p_miss': 0.01015588348697876}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:52:52,122] Trial 158 finished with value: 0.26176303650082244 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 534, 'learning_rate': 0.00011601304057023908, 'p_miss': 0.07488804229086932}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:56:36,557] Trial 168 finished with value: 0.26239773269241906 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 106, 'learning_rate': 0.00014111501210906828, 'p_miss': 0.035370152720343204}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:56:41,863] Trial 166 finished with value: 0.2638304042455402 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 102, 'learning_rate': 0.00014713900748822926, 'p_miss': 0.03627529590753713}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:56:50,781] Trial 167 finished with value: 0.26305895741080904 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 98, 'learning_rate': 0.000134820781018062, 'p_miss': 0.032434440651904595}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 19:57:57,127] Trial 169 finished with value: 0.27939140993959755 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 106, 'learning_rate': 0.0012466773586298503, 'p_miss': 0.03557995870919242}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:00:31,871] Trial 164 finished with value: 0.3126517991718041 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 251, 'learning_rate': 0.0024660377714310604, 'p_miss': 0.051309705281141135}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:03:07,631] Trial 170 finished with value: 0.26267179671446206 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 191, 'learning_rate': 0.00013358806660996946, 'p_miss': 0.03676147556105052}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:05:21,800] Trial 165 finished with value: 0.30893614425209004 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 277, 'learning_rate': 0.00122869129867441, 'p_miss': 0.07617624289691169}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:09:30,161] Trial 106 finished with value: 0.3197873589490438 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5289, 'learning_rate': 0.0001315049928149011, 'p_miss': 0.021567690705443697}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:11:00,483] Trial 173 finished with value: 0.2641051701131792 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 256, 'learning_rate': 0.000311695232801075, 'p_miss': 0.017704854478046494}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:12:05,638] Trial 174 finished with value: 0.26097703333145317 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 255, 'learning_rate': 0.00012620051572649081, 'p_miss': 0.05194199670468708}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:12:29,557] Trial 175 finished with value: 0.2614016474359588 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 197, 'learning_rate': 0.00019099276131439796, 'p_miss': 0.019359174655798658}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:14:16,980] Trial 171 finished with value: 0.3100658247602042 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 260, 'learning_rate': 0.0024993195974974654, 'p_miss': 0.05122886893902853}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:15:20,810] Trial 172 finished with value: 0.25933295486548136 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 272, 'learning_rate': 0.00013149728422910524, 'p_miss': 0.021553165243271624}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:24:22,396] Trial 177 finished with value: 0.2611402186739591 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 319, 'learning_rate': 0.00010277598595517603, 'p_miss': 0.05379122980997301}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:28:31,056] Trial 178 finished with value: 0.2612276272560931 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 324, 'learning_rate': 0.0001026521137868106, 'p_miss': 0.05402614917274859}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:28:31,947] Trial 185 finished with value: 0.42331479114481274 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:29:35,891] Trial 176 finished with value: 0.26077522934755926 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 349, 'learning_rate': 0.00010083497980236655, 'p_miss': 0.053252121220562526}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:30:38,580] Trial 179 finished with value: 0.26263267853262373 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 329, 'learning_rate': 0.0001019921108107298, 'p_miss': 0.05457182126032092}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:37:30,050] Trial 182 finished with value: 0.2592956329979352 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 328, 'learning_rate': 0.00010074031073350766, 'p_miss': 0.02714436957179544}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:38:32,490] Trial 183 finished with value: 0.2611439277880515 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 343, 'learning_rate': 0.00010111765805117582, 'p_miss': 0.25620818289349245}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:38:43,419] Trial 181 finished with value: 0.2616558633556128 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 351, 'learning_rate': 0.0001024168459237903, 'p_miss': 0.22942521568624472}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:39:05,791] Trial 163 finished with value: 0.2804526411311793 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 843, 'learning_rate': 0.0001682738058982575, 'p_miss': 0.05392528775107113}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:39:47,207] Trial 190 finished with value: 0.383290637738577 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:40:00,340] Trial 191 finished with value: 0.383290637738577 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:40:21,829] Trial 192 finished with value: 0.3850908679741106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:43:15,267] Trial 184 finished with value: 0.26260442433379 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 359, 'learning_rate': 0.00015666286161796603, 'p_miss': 0.028269680463443227}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:44:36,885] Trial 188 finished with value: 0.2630038975789051 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 402, 'learning_rate': 0.00011990368578818531, 'p_miss': 0.02809925871460664}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:45:20,094] Trial 186 finished with value: 0.26057442784206397 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 357, 'learning_rate': 0.00010164147624144978, 'p_miss': 0.027903482887003037}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:46:19,162] Trial 187 finished with value: 0.263625553185174 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 413, 'learning_rate': 0.00011778735250486059, 'p_miss': 0.2552968809737054}. Best is trial 35 with value: 0.2584282610512128.
running
[I 2024-11-01 20:52:23,043] Trial 199 finished with value: 0.42165864207028464 and parameters: {'model_name': 'GAIN', 'batch_size': 43, 'hint_rate': 0.6288964476455858, 'alpha': 55, 'iterations': 217, 'learning_rate': 0.00013042575573304148, 'p_miss': 0.02379160972820323}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 20:52:50,576] Trial 195 finished with value: 0.4214750658522096 and parameters: {'model_name': 'GAIN', 'batch_size': 31, 'hint_rate': 0.6748865924149502, 'alpha': 52, 'iterations': 444, 'learning_rate': 0.0001236751824233195, 'p_miss': 0.02832865408066054}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:02:25,158] Trial 193 finished with value: 0.26277078878039434 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 418, 'learning_rate': 0.0001246202327636604, 'p_miss': 0.026436637449236237}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:05:28,787] Trial 196 finished with value: 0.2584873301066651 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 436, 'learning_rate': 0.00011660501810662808, 'p_miss': 0.027630750349526313}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:06:03,464] Trial 194 finished with value: 0.2621766688437384 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 413, 'learning_rate': 0.00012199971197000622, 'p_miss': 0.028985846200318365}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:07:13,901] Trial 197 finished with value: 0.26277088569821105 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 441, 'learning_rate': 0.0001242057843139095, 'p_miss': 0.021731479195478336}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:10:28,588] Trial 189 finished with value: 0.2714266912048572 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 787, 'learning_rate': 0.00012134191786986954, 'p_miss': 0.0269485786554488}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:11:45,680] Trial 198 finished with value: 0.26398309400281256 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 452, 'learning_rate': 0.00012516700696727, 'p_miss': 0.024179048550675777}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:34:13,722] Trial 87 finished with value: 0.3514450051615138 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9348, 'learning_rate': 0.00013983952872379985, 'p_miss': 0.027410584529092834}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:36:12,704] Trial 81 finished with value: 0.3028435176100288 and parameters: {'model_name': 'VAE', 'batch_size': 663, 'iterations': 7048, 'learning_rate': 0.0006555231103506419, 'p_miss': 0.18154610560061163}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:37:26,970] Trial 100 finished with value: 0.3595099340942601 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9312, 'learning_rate': 0.08822147179785113, 'p_miss': 0.02509278523514232}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:42:21,999] Trial 89 finished with value: 0.3022341922733676 and parameters: {'model_name': 'VAE', 'batch_size': 645, 'iterations': 7018, 'learning_rate': 0.008523186831721005, 'p_miss': 0.035704787280365274}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:44:04,137] Trial 105 finished with value: 0.33414320047759843 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8904, 'learning_rate': 0.0002526285512693182, 'p_miss': 0.29071273712164425}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:50:36,697] Trial 145 finished with value: 0.3125365746019376 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 8678, 'learning_rate': 0.00013985886637453592, 'p_miss': 0.06003990468493721}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:50:48,695] Trial 144 finished with value: 0.31089217275388376 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8922, 'learning_rate': 0.0001368981473248879, 'p_miss': 0.05485562169779856}. Best is trial 35 with value: 0.2584282610512128.
[I 2024-11-01 21:52:00,845] Trial 180 finished with value: 0.3119214291687668 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 8989, 'learning_rate': 0.00010105448759209738, 'p_miss': 0.02858016740060907}. Best is trial 35 with value: 0.2584282610512128.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.2584282610512128
{'model_name': 'VAE', 'batch_size': 1, 'iterations': 328, 'learning_rate': 0.00012169918081352216, 'p_miss': 0.012850754727776754}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469d120> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.6078530295211523
Generation:   4%|▍         | 1/25 [02:15<54:12, 135.51s/it]Generation:  2
Best f1_score score: 0.6078530295211523
Generation:   8%|▊         | 2/25 [05:40<1:07:35, 176.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467783850> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.6107075374364824
Generation:  12%|█▏        | 3/25 [12:12<1:40:48, 274.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f283a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.6107075374364824
Generation:  16%|█▌        | 4/25 [16:54<1:37:07, 277.51s/it]Generation:  5
Best f1_score score: 0.6107075374364824
Generation:  20%|██        | 5/25 [20:38<1:26:06, 258.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469dcc0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  6
Best f1_score score: 0.6107075374364824
Generation:  24%|██▍       | 6/25 [23:23<1:11:45, 226.60s/it]Generation:  7
Best f1_score score: 0.6107075374364824
Generation:  28%|██▊       | 7/25 [26:28<1:03:52, 212.93s/it]Generation:  8
Best f1_score score: 0.6107075374364824
Generation:  32%|███▏      | 8/25 [30:15<1:01:37, 217.48s/it]Generation:  9
Best f1_score score: 0.6107075374364824
Generation:  36%|███▌      | 9/25 [35:34<1:06:27, 249.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eed510> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.6107075374364824
Generation:  40%|████      | 10/25 [44:38<1:25:04, 340.29s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554671a8400> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.6107075374364824
Generation:  44%|████▍     | 11/25 [48:23<1:11:07, 304.86s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fcad10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.6107075374364824
Generation:  48%|████▊     | 12/25 [48:47<47:31, 219.36s/it]  Generation:  13
Best f1_score score: 0.6107075374364824
Generation:  52%|█████▏    | 13/25 [51:31<40:33, 202.76s/it]Generation:  14
Best f1_score score: 0.6107075374364824
Generation:  56%|█████▌    | 14/25 [55:41<39:46, 216.92s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678e65f0> 

Generation:  15
Best f1_score score: 0.6107075374364824
Generation:  60%|██████    | 15/25 [1:05:49<55:48, 334.86s/it]Generation:  16
Best f1_score score: 0.6107075374364824
Generation:  64%|██████▍   | 16/25 [1:08:42<42:56, 286.27s/it]Generation:  17
Best f1_score score: 0.6107075374364824
Generation:  68%|██████▊   | 17/25 [1:11:22<33:04, 248.09s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f558d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.6107075374364824
Generation:  72%|███████▏  | 18/25 [1:14:21<26:32, 227.47s/it]Generation:  19
Best f1_score score: 0.6107075374364824
Generation:  76%|███████▌  | 19/25 [1:17:02<20:43, 207.32s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe3550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.6107075374364824
Generation:  80%|████████  | 20/25 [1:19:20<15:33, 186.65s/it]Generation:  21
Best f1_score score: 0.6109964678271823
Generation:  84%|████████▍ | 21/25 [1:22:10<12:06, 181.66s/it]Generation:  22
Best f1_score score: 0.6109964678271823
Generation:  88%|████████▊ | 22/25 [1:22:40<06:48, 136.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464557eb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.6109964678271823
Generation:  92%|█████████▏| 23/25 [1:23:04<03:25, 102.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554677705e0> 

Generation:  24
Best f1_score score: 0.611149211078767
Generation:  96%|█████████▌| 24/25 [1:33:19<04:16, 256.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714130> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.611149211078767
Generation: 100%|██████████| 25/25 [1:38:47<00:00, 277.93s/it]Generation: 100%|██████████| 25/25 [1:38:51<00:00, 237.27s/it]
2024-11-01 23:31:08,304 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41801' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-16205b9c29c2cbd81f55a3a14ad321d1', 'ndarray-54442c5fd3df5c7f6b782e1da5265b1c'} (stimulus_id='handle-worker-cleanup-1730529068.3040147')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      criterion='entropy',
                                      max_features=0.5925366523131,
                                      min_samples_leaf=15, min_samples_split=12,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.7350267249945623, 'accuracy': 0.6597473477647636, 'balanced_accuracy': 0.669759889255036, 'logloss': 0.6266970941471446, 'f1': 0.6576890399187714}
original test score: {'auroc': 0.5457955477123659, 'accuracy': 0.5419426048565121, 'balanced_accuracy': 0.5165171697528396, 'logloss': 0.6814354980406317, 'f1': 0.5160230799056563}
imputed test score: {'auroc': 0.4796328212486002, 'accuracy': 0.480990924699534, 'balanced_accuracy': 0.4819027080667093, 'logloss': 0.715250422958336, 'f1': 0.47691244820546574}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469d120> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469cee0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.8308612791087867
Generation:   4%|▍         | 1/25 [07:42<3:04:55, 462.32s/it]Generation:  2
Best f1_score score: 0.8308612791087867
Generation:   8%|▊         | 2/25 [15:44<3:01:41, 473.98s/it]Generation:  3
Best f1_score score: 0.8354970151953299
Generation:  12%|█▏        | 3/25 [24:36<3:03:26, 500.31s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467653220> 

Generation:  4
Best f1_score score: 0.8432803353404331
Generation:  16%|█▌        | 4/25 [34:40<3:09:29, 541.43s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464d27520> 

Generation:  5
Best f1_score score: 0.8432803353404331
Generation:  20%|██        | 5/25 [44:45<3:08:03, 564.15s/it]Generation:  6
Best f1_score score: 0.8432803353404331
Generation:  24%|██▍       | 6/25 [52:30<2:48:01, 530.61s/it]Generation:  7
Best f1_score score: 0.8432803353404331
Generation:  28%|██▊       | 7/25 [1:00:12<2:32:26, 508.13s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747036a0> 

Generation:  8
Best f1_score score: 0.8438129236786184
Generation:  32%|███▏      | 8/25 [1:10:18<2:32:49, 539.38s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465256890> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f591b0> 

Generation:  9
Best f1_score score: 0.8438129236786184
Generation:  36%|███▌      | 9/25 [1:20:24<2:29:21, 560.07s/it]Generation:  10
Best f1_score score: 0.8438129236786184
Generation:  40%|████      | 10/25 [1:28:13<2:13:00, 532.05s/it]Generation:  11
Best f1_score score: 0.8458247536105976
Generation:  44%|████▍     | 11/25 [1:35:57<1:59:15, 511.12s/it]Generation:  12
Best f1_score score: 0.8458247536105976
Generation:  48%|████▊     | 12/25 [1:44:03<1:49:08, 503.71s/it]Generation:  13
Best f1_score score: 0.8458247536105976
Generation:  52%|█████▏    | 13/25 [1:51:35<1:37:34, 487.88s/it]Generation:  14
Best f1_score score: 0.8458247536105976
Generation:  56%|█████▌    | 14/25 [1:59:19<1:28:09, 480.82s/it]Generation:  15
Best f1_score score: 0.8458247536105976
Generation:  60%|██████    | 15/25 [2:02:20<1:05:02, 390.28s/it]Generation:  16
Best f1_score score: 0.8458247536105976
Generation:  64%|██████▍   | 16/25 [2:09:08<59:22, 395.80s/it]  Generation:  17
Best f1_score score: 0.8458247536105976
Generation:  68%|██████▊   | 17/25 [2:16:37<54:52, 411.51s/it]Generation:  18
Best f1_score score: 0.8458247536105976
Generation:  72%|███████▏  | 18/25 [2:24:10<49:28, 424.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467734f10> 

Generation:  19
Best f1_score score: 0.8458247536105976
Generation:  76%|███████▌  | 19/25 [2:34:18<47:56, 479.35s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546729c430> 

Generation:  20
Best f1_score score: 0.8458247536105976
Generation:  80%|████████  | 20/25 [2:44:26<43:10, 518.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451d495d0> 

Generation:  21
Best f1_score score: 0.8458247536105976
Generation:  84%|████████▍ | 21/25 [2:54:32<36:17, 544.37s/it]Generation:  22
Best f1_score score: 0.8458247536105976
Generation:  88%|████████▊ | 22/25 [3:02:11<25:56, 518.91s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546457fb50> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d1f850> 

Generation:  23
Best f1_score score: 0.8458247536105976
Generation:  92%|█████████▏| 23/25 [3:12:18<18:10, 545.11s/it]Generation:  24
Best f1_score score: 0.8458247536105976
Generation:  96%|█████████▌| 24/25 [3:19:51<08:37, 517.51s/it]Generation:  25
Best f1_score score: 0.8464530004497967
Generation: 100%|██████████| 25/25 [3:27:26<00:00, 498.67s/it]Generation: 100%|██████████| 25/25 [3:27:26<00:00, 497.84s/it]
2024-11-02 02:58:49,785 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36407' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-63b0e14d17c7ce7a82e285c5ba421aac', 'ndarray-16205b9c29c2cbd81f55a3a14ad321d1'} (stimulus_id='handle-worker-cleanup-1730541529.7854354')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(max_depth=9, n_estimators=74, n_jobs=1,
                                num_leaves=78, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9538745797689007, 'accuracy': 0.868308088550929, 'balanced_accuracy': 0.8694729985535814, 'logloss': 0.25748829448724614, 'f1': 0.8647622233335543}
test score: {'auroc': 0.91193046612542, 'accuracy': 0.8057395143487859, 'balanced_accuracy': 0.8018108977563589, 'logloss': 0.3352676485181841, 'f1': 0.7995930147796074}
original test score: {'auroc': 0.9997010478323468, 'accuracy': 0.9917831739023792, 'balanced_accuracy': 0.9923749700047992, 'logloss': 0.03087479203872853, 'f1': 0.9914804671544312}
score end
881
lvl
0.5
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
15.339304262863266
hours
DONE
