Run: 2
/cm/local/apps/slurm/var/spool/job1040043/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/923/923.pkl
working on 
../data/c/923/class_full_MCAR_0.1_1
4.229414701461792
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-04 14:55:43,722] A new study created in memory with name: no-name-38be5557-da35-4448-b136-1fff11c94f24
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-04 14:55:43,770] Trial 1 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 654, 'learning_rate': 0.004842711140534174, 'p_miss': 0.2962667539153136}. Best is trial 1 with value: inf.
[I 2024-11-04 14:55:43,893] Trial 0 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0016777724116536935, 'p_miss': 0.01818394794356943}. Best is trial 1 with value: inf.
running
[I 2024-11-04 14:55:44,028] Trial 2 finished with value: 0.48009630027539957 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 2 with value: 0.48009630027539957.
running
running
running
running
[I 2024-11-04 14:55:44,152] Trial 6 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 5751, 'learning_rate': 0.06423094023765905, 'p_miss': 0.261330462332722}. Best is trial 2 with value: 0.48009630027539957.
running
running
running
running
[I 2024-11-04 14:55:44,363] Trial 11 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 612, 'learning_rate': 0.004060498176284089, 'p_miss': 0.022258032168257322}. Best is trial 2 with value: 0.48009630027539957.
[I 2024-11-04 14:55:44,490] Trial 9 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.028166021307413233, 'p_miss': 0.2644615267784809}. Best is trial 2 with value: 0.48009630027539957.
running
[I 2024-11-04 14:55:44,644] Trial 3 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 255, 'iterations': 10, 'learning_rate': 0.0001023522654104099, 'p_miss': 0.014320196565933196}. Best is trial 2 with value: 0.48009630027539957.
[I 2024-11-04 14:55:44,815] Trial 10 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 933, 'iterations': 1533, 'learning_rate': 0.006562362459032295, 'p_miss': 0.10784805996207351}. Best is trial 2 with value: 0.48009630027539957.
running
running
running
[I 2024-11-04 14:55:45,101] Trial 18 finished with value: 0.29517975779255323 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 18 with value: 0.29517975779255323.
[I 2024-11-04 14:55:45,107] Trial 16 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 81, 'learning_rate': 0.0014838846248089634, 'p_miss': 0.0761393173132965}. Best is trial 18 with value: 0.29517975779255323.
running
running
[I 2024-11-04 14:55:45,684] Trial 19 finished with value: 0.3242024920637173 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 18 with value: 0.29517975779255323.
running
[I 2024-11-04 14:55:45,914] Trial 25 finished with value: 0.29517975779255323 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 18 with value: 0.29517975779255323.
running
[I 2024-11-04 14:55:46,129] Trial 26 finished with value: 0.29517975779255323 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 18 with value: 0.29517975779255323.
running
[I 2024-11-04 14:55:48,268] Trial 5 finished with value: 0.29517975779255323 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6554, 'weights': 'uniform'}. Best is trial 18 with value: 0.29517975779255323.
running
[I 2024-11-04 14:55:48,585] Trial 8 finished with value: 0.3054357008279842 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 351, 'weights': 'distance'}. Best is trial 18 with value: 0.29517975779255323.
running
[I 2024-11-04 14:55:48,974] Trial 7 finished with value: 0.2937339339718571 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3149, 'weights': 'uniform'}. Best is trial 7 with value: 0.2937339339718571.
running
[I 2024-11-04 14:55:49,426] Trial 15 finished with value: 0.28779498900851025 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1095, 'weights': 'uniform'}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:49,776] Trial 23 finished with value: 0.3105959273971637 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2188, 'weights': 'distance'}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:50,061] Trial 20 finished with value: 0.3117189062027007 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3563, 'weights': 'distance'}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:51,439] Trial 21 finished with value: 0.2908607945500719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:51,681] Trial 29 finished with value: 0.29517975779255323 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6827, 'weights': 'uniform'}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:51,933] Trial 31 finished with value: 0.29517975779255323 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6197, 'weights': 'uniform'}. Best is trial 15 with value: 0.28779498900851025.
[I 2024-11-04 14:55:52,137] Trial 34 finished with value: 0.2907384090797182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 15 with value: 0.28779498900851025.
running
running
[I 2024-11-04 14:55:54,226] Trial 37 finished with value: 0.29086086888499896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:54,743] Trial 35 finished with value: 0.2908607945500719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:55,110] Trial 14 finished with value: 0.3036985953982674 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:55,414] Trial 36 finished with value: 0.2908607945500719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 15 with value: 0.28779498900851025.
running
[I 2024-11-04 14:55:55,586] Trial 13 finished with value: 0.26028077020574225 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:55:55,846] Trial 38 finished with value: 0.2908607945500719 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:55:56,992] Trial 39 finished with value: 0.2907383365781708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:55:58,369] Trial 32 finished with value: 0.28463403162778644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:55:58,735] Trial 4 finished with value: 0.4775930850716252 and parameters: {'model_name': 'GAIN', 'batch_size': 196, 'hint_rate': 0.31996560726171996, 'alpha': 33, 'iterations': 3, 'learning_rate': 0.025373555117086787, 'p_miss': 0.01948842618314711}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:01,977] Trial 22 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.34606642904311374, 'alpha': 40, 'iterations': 45, 'learning_rate': 0.0021119391276267956, 'p_miss': 0.07199782685141436}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:02,732] Trial 43 finished with value: 0.29056467566747457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:11,604] Trial 49 finished with value: 0.28463403162778644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:13,006] Trial 48 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:21,814] Trial 50 finished with value: 0.28463403162778644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:22,315] Trial 51 finished with value: 0.28463403162778644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:31,839] Trial 52 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:43,770] Trial 42 finished with value: 0.4571110239404178 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.2960705016190026, 'alpha': 55, 'iterations': 31, 'learning_rate': 0.00011367866596602356, 'p_miss': 0.203615958143834}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:44,664] Trial 44 finished with value: 0.46152881855278904 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.8821094555775468, 'alpha': 42, 'iterations': 31, 'learning_rate': 0.00010815199241510275, 'p_miss': 0.19027379487481444}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:51,132] Trial 46 finished with value: 0.4718787120774176 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.4780709928073338, 'alpha': 31, 'iterations': 32, 'learning_rate': 0.0001020878697092619, 'p_miss': 0.19162761841063924}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:53,388] Trial 40 finished with value: 0.4619125285706728 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.4105528979510904, 'alpha': 76, 'iterations': 37, 'learning_rate': 0.00011513508585856637, 'p_miss': 0.18976465926130337}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:55,381] Trial 56 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:56:58,478] Trial 33 finished with value: 0.4695859616636998 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.21625376534892327, 'alpha': 56, 'iterations': 37, 'learning_rate': 0.00011155832427480436, 'p_miss': 0.1758563791706632}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:04,729] Trial 24 finished with value: 0.4688050704969628 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.15596646601262654, 'alpha': 90, 'iterations': 39, 'learning_rate': 0.00010260791532172745, 'p_miss': 0.18507939680109212}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:05,056] Trial 57 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:05,365] Trial 58 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:09,418] Trial 59 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:10,340] Trial 60 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:16,298] Trial 61 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:17,620] Trial 30 finished with value: 0.4567805577500971 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.2733909096915761, 'alpha': 49, 'iterations': 43, 'learning_rate': 0.00011428879938646323, 'p_miss': 0.18725137980168796}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:18,423] Trial 45 finished with value: 0.46689436831818343 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.6422535382066882, 'alpha': 75, 'iterations': 45, 'learning_rate': 0.00010560363076096382, 'p_miss': 0.1832773393991341}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:18,740] Trial 62 finished with value: 0.2779854710516947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:29,888] Trial 41 finished with value: 0.463507435873628 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.31539251266411, 'alpha': 86, 'iterations': 50, 'learning_rate': 0.00015003336780700322, 'p_miss': 0.18370482047564937}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:57:39,029] Trial 47 finished with value: 0.45846887519013224 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.9538556141443758, 'alpha': 99, 'iterations': 50, 'learning_rate': 0.00012059904834781879, 'p_miss': 0.19189808226192184}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 14:58:50,728] Trial 53 finished with value: 0.46846943591270296 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.8854066971777412, 'alpha': 98, 'iterations': 68, 'learning_rate': 0.00010524684068341117, 'p_miss': 0.18982184176408917}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:00:28,471] Trial 54 finished with value: 0.45443994561266077 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.9496473050397027, 'alpha': 100, 'iterations': 111, 'learning_rate': 0.00010775777819603633, 'p_miss': 0.18534497174626618}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:02:45,899] Trial 17 finished with value: 0.47215256348698775 and parameters: {'model_name': 'GAIN', 'batch_size': 827, 'hint_rate': 0.9566795700410685, 'alpha': 40, 'iterations': 173, 'learning_rate': 0.003304462826891726, 'p_miss': 0.26512518983400607}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:06:44,778] Trial 27 finished with value: 0.32041729817266623 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:06:45,281] Trial 75 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 8436, 'learning_rate': 0.00036634539716576216, 'p_miss': 0.11602211235193871}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:06:56,123] Trial 76 finished with value: 0.26442604908393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:07:05,760] Trial 77 finished with value: 0.2609955992934653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:07:12,992] Trial 78 finished with value: 0.2609955992934653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:07:24,649] Trial 79 finished with value: 0.2609955992934653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:07:35,823] Trial 80 finished with value: 0.2609955992934653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 13 with value: 0.26028077020574225.
running
[I 2024-11-04 15:07:45,622] Trial 28 finished with value: 0.2578243889292998 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.2578243889292998.
running
[I 2024-11-04 15:07:46,840] Trial 81 finished with value: 0.2609955992934653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 28 with value: 0.2578243889292998.
running
[I 2024-11-04 15:07:47,761] Trial 83 finished with value: 0.48009630027539957 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 28 with value: 0.2578243889292998.
running
[I 2024-11-04 15:09:43,827] Trial 55 finished with value: 0.2600132429735106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 28 with value: 0.2578243889292998.
running
[I 2024-11-04 15:09:48,583] Trial 63 finished with value: 0.26370416576788186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 28 with value: 0.2578243889292998.
running
[I 2024-11-04 15:10:16,369] Trial 64 finished with value: 0.21373579652300587 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 64 with value: 0.21373579652300587.
running
[I 2024-11-04 15:10:38,916] Trial 68 finished with value: 0.2138219006756455 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 64 with value: 0.21373579652300587.
running
[I 2024-11-04 15:10:45,011] Trial 65 finished with value: 0.21489954301447475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 64 with value: 0.21373579652300587.
running
[I 2024-11-04 15:10:45,390] Trial 89 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 403, 'iterations': 10, 'learning_rate': 0.0006049351172076979, 'p_miss': 0.23467265167102164}. Best is trial 64 with value: 0.21373579652300587.
running
[I 2024-11-04 15:11:00,269] Trial 71 finished with value: 0.21319548912137173 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.21319548912137173.
running
[I 2024-11-04 15:11:01,518] Trial 66 finished with value: 0.215522208921361 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.21319548912137173.
running
[I 2024-11-04 15:11:02,182] Trial 69 finished with value: 0.21284820354246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 69 with value: 0.21284820354246.
running
[I 2024-11-04 15:11:02,895] Trial 70 finished with value: 0.21340177188203296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 69 with value: 0.21284820354246.
running
[I 2024-11-04 15:11:09,315] Trial 67 finished with value: 0.21360706126502213 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 69 with value: 0.21284820354246.
running
[I 2024-11-04 15:11:09,759] Trial 95 finished with value: 0.48009630027539957 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 69 with value: 0.21284820354246.
running
[I 2024-11-04 15:12:18,326] Trial 72 finished with value: 0.21458649761031534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 69 with value: 0.21284820354246.
running
[I 2024-11-04 15:13:51,053] Trial 73 finished with value: 0.21091515463610774 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 73 with value: 0.21091515463610774.
running
[I 2024-11-04 15:16:09,360] Trial 74 finished with value: 0.2119969224862052 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 73 with value: 0.21091515463610774.
running
[I 2024-11-04 15:20:56,745] Trial 82 finished with value: 0.21022045440436318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:21:02,505] Trial 100 finished with value: 0.3125273790441481 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4964, 'weights': 'distance'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:21:25,330] Trial 84 finished with value: 0.21331676245725667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:10,721] Trial 85 finished with value: 0.2126997255076101 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:12,253] Trial 88 finished with value: 0.21273406163529068 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:19,046] Trial 87 finished with value: 0.21370213727876664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:22,625] Trial 86 finished with value: 0.21453391245220804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:38,657] Trial 90 finished with value: 0.2137661709575014 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:49,990] Trial 91 finished with value: 0.21236154702501295 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:52,628] Trial 94 finished with value: 0.21388704499900352 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:53,001] Trial 109 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2286, 'learning_rate': 0.00946240148001719, 'p_miss': 0.14704207407746334}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:23:59,106] Trial 93 finished with value: 0.21234688723483747 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:24:03,113] Trial 92 finished with value: 0.21346224415737067 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:24:12,655] Trial 96 finished with value: 0.2127125635056321 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:25:41,470] Trial 97 finished with value: 0.2119932203738061 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:25:46,960] Trial 114 finished with value: 0.31236432910399003 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4680, 'weights': 'distance'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:26:30,642] Trial 98 finished with value: 0.21395264502816985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:29:02,946] Trial 99 finished with value: 0.21360766723817023 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:34:08,994] Trial 101 finished with value: 0.21201720695989051 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:34:54,597] Trial 102 finished with value: 0.21222812277507938 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:11,341] Trial 104 finished with value: 0.2118464297687043 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:35,559] Trial 108 finished with value: 0.21503015323559937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:36,190] Trial 121 finished with value: 0.48009630027539957 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:38,856] Trial 103 finished with value: 0.21207449464995953 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:39,710] Trial 110 finished with value: 0.21578127236902858 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:41,341] Trial 122 finished with value: 0.2907384492514503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:41,749] Trial 107 finished with value: 0.2128970431291281 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:42,940] Trial 105 finished with value: 0.21178793570073232 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:43,990] Trial 124 finished with value: 0.2907384090797182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 82 with value: 0.21022045440436318.
running
[I 2024-11-04 15:36:44,695] Trial 106 finished with value: 0.2097567048271638 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 106 with value: 0.2097567048271638.
running
[I 2024-11-04 15:36:48,773] Trial 111 finished with value: 0.20939569625064106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:36:59,220] Trial 112 finished with value: 0.2122950179551415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:07,480] Trial 125 finished with value: 0.4189499996374793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:07,646] Trial 128 finished with value: 0.42350273248592796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:08,142] Trial 129 finished with value: 0.4121946961282606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:08,600] Trial 127 finished with value: 0.4189499996374793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:08,923] Trial 134 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0005882435879006452, 'p_miss': 0.05350669857693835}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:09,159] Trial 135 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.09353743308457535, 'p_miss': 0.04575925026199687}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:15,062] Trial 130 finished with value: 0.42155423086145827 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:37:29,812] Trial 131 finished with value: 0.4147849207368252 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:38:07,952] Trial 113 finished with value: 0.21287155432646246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:39:35,044] Trial 116 finished with value: 0.2116980661687816 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:39:35,302] Trial 115 finished with value: 0.21530017374038118 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:42:21,316] Trial 117 finished with value: 0.2119577408973959 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:42:24,468] Trial 143 finished with value: 0.2906721297383824 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1922, 'weights': 'uniform'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:47:23,289] Trial 118 finished with value: 0.2094762340270171 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:48:55,003] Trial 119 finished with value: 0.21531446723316164 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:49:29,742] Trial 120 finished with value: 0.21326436024070902 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:50:00,674] Trial 133 finished with value: 0.21152421992762188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:50:08,454] Trial 138 finished with value: 0.21319226955119336 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:50:12,234] Trial 126 finished with value: 0.21102854568584895 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:50:18,070] Trial 132 finished with value: 0.20994855285376207 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 111 with value: 0.20939569625064106.
running
[I 2024-11-04 15:50:27,451] Trial 136 finished with value: 0.2083466827252083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:50:28,405] Trial 139 finished with value: 0.2100177423986218 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:50:28,912] Trial 153 finished with value: 0.3242024920637173 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:50:31,717] Trial 137 finished with value: 0.2123344737501093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:50:33,430] Trial 123 finished with value: 0.21039684908662673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:51:04,923] Trial 140 finished with value: 0.21266946492488575 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.2083466827252083.
running
[I 2024-11-04 15:52:28,783] Trial 141 finished with value: 0.20588827933368373 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 15:52:56,138] Trial 142 finished with value: 0.21447768279681606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 15:55:15,544] Trial 144 finished with value: 0.2068699875941987 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 15:59:53,141] Trial 145 finished with value: 0.21189446631910788 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:01:24,609] Trial 146 finished with value: 0.21415422065540873 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:01:41,390] Trial 147 finished with value: 0.21300392776352642 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:08,384] Trial 148 finished with value: 0.2144717969784069 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:11,678] Trial 150 finished with value: 0.21299296887510594 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:12,564] Trial 149 finished with value: 0.2132274416118088 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:31,943] Trial 151 finished with value: 0.20910937327444934 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:32,941] Trial 154 finished with value: 0.20923002055073323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:41,796] Trial 156 finished with value: 0.21162424701503363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:42,529] Trial 152 finished with value: 0.2121054564852379 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:02:47,088] Trial 155 finished with value: 0.21407757774197966 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:03:26,392] Trial 157 finished with value: 0.21354760306543646 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:04:10,044] Trial 158 finished with value: 0.21248033068596897 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:04:44,849] Trial 159 finished with value: 0.2135355459572225 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:07:13,084] Trial 160 finished with value: 0.21460362241233186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:07:16,035] Trial 175 finished with value: 0.29660354891776464 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16, 'weights': 'distance'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:11:28,962] Trial 161 finished with value: 0.21529084649691432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:12:55,560] Trial 162 finished with value: 0.21240507349622778 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:13:29,156] Trial 163 finished with value: 0.21512669920160593 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:13:54,091] Trial 165 finished with value: 0.21207481719130813 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:13:55,916] Trial 164 finished with value: 0.20884836673721008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:13:58,609] Trial 166 finished with value: 0.21319864643762204 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:13:59,122] Trial 180 finished with value: 0.2907384065888592 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:00,994] Trial 181 finished with value: 0.2907384277326251 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:03,143] Trial 182 finished with value: 0.2907384065888592 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:07,318] Trial 168 finished with value: 0.21076647520642186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:24,456] Trial 169 finished with value: 0.2110500169593414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:25,764] Trial 167 finished with value: 0.21111752109335186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:28,769] Trial 170 finished with value: 0.2166782281239678 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:34,832] Trial 171 finished with value: 0.2152583952383759 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:14:35,148] Trial 190 finished with value: 0.48009630027539957 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:15:20,413] Trial 172 finished with value: 0.21015170255790183 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:15:47,277] Trial 173 finished with value: 0.2172025245696036 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:16:15,739] Trial 174 finished with value: 0.21426576858140423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:18:39,884] Trial 176 finished with value: 0.21039536790214894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:22:17,091] Trial 177 finished with value: 0.21650942879207205 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:23:39,739] Trial 178 finished with value: 0.21164463783167933 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:23:46,270] Trial 192 finished with value: 0.3076102331497522 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:24:07,869] Trial 193 finished with value: 0.32524813082798526 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 141 with value: 0.20588827933368373.
running
[I 2024-11-04 16:24:30,893] Trial 179 finished with value: 0.2102900608787337 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:01,548] Trial 187 finished with value: 0.2138657380765591 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:02,060] Trial 189 finished with value: 0.21342443055658955 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:11,197] Trial 186 finished with value: 0.21165295645828514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:14,618] Trial 184 finished with value: 0.21079219449736408 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:14,904] Trial 183 finished with value: 0.21501396926230515 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:17,495] Trial 185 finished with value: 0.20988198689091236 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:24,189] Trial 191 finished with value: 0.21548149764923438 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:30,898] Trial 188 finished with value: 0.21467011105344777 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:34,837] Trial 194 finished with value: 0.4758585885970373 and parameters: {'model_name': 'GAIN', 'batch_size': 85, 'hint_rate': 0.7031107973629986, 'alpha': 3, 'iterations': 318, 'learning_rate': 0.01650794688143839, 'p_miss': 0.1398229420031119}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:25:50,204] Trial 199 finished with value: 0.48630274239483995 and parameters: {'model_name': 'GAIN', 'batch_size': 101, 'hint_rate': 0.046716095547176706, 'alpha': 8, 'iterations': 263, 'learning_rate': 0.014973795932965267, 'p_miss': 0.138656354468215}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:26:14,022] Trial 12 finished with value: 0.49811833876110556 and parameters: {'model_name': 'GAIN', 'batch_size': 226, 'hint_rate': 0.3377906310325121, 'alpha': 38, 'iterations': 3300, 'learning_rate': 0.0019878227619624495, 'p_miss': 0.2629961607105324}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:26:57,060] Trial 195 finished with value: 0.2115090711131793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:27:03,360] Trial 197 finished with value: 0.32078391533574757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:28:10,354] Trial 196 finished with value: 0.21449888534450734 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 141 with value: 0.20588827933368373.
[I 2024-11-04 16:28:42,107] Trial 198 finished with value: 0.20934044071977795 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 141 with value: 0.20588827933368373.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
dtype: int64
0    0
1    0
2    0
3    0
dtype: int64
0.20588827933368373
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9724395333051333
Generation:   4%|▍         | 1/25 [01:29<35:56, 89.84s/it]Generation:  2
Best f1_score score: 0.9724395333051333
Generation:   8%|▊         | 2/25 [03:11<37:01, 96.58s/it]Generation:  3
Best f1_score score: 0.9724395333051333
Generation:  12%|█▏        | 3/25 [03:29<22:17, 60.81s/it]Generation:  4
Best f1_score score: 0.9725844474230552
Generation:  16%|█▌        | 4/25 [03:38<14:06, 40.32s/it]Generation:  5
Best f1_score score: 0.9727310252930683
Generation:  20%|██        | 5/25 [03:46<09:37, 28.89s/it]Generation:  6
Best f1_score score: 0.9730149323692958
Generation:  24%|██▍       | 6/25 [03:57<07:12, 22.77s/it]Generation:  7
Best f1_score score: 0.9730149323692958
Generation:  28%|██▊       | 7/25 [04:13<06:10, 20.56s/it]Generation:  8
Best f1_score score: 0.9730149323692958
Generation:  32%|███▏      | 8/25 [04:24<04:56, 17.43s/it]Generation:  9
Best f1_score score: 0.973311927968911
Generation:  36%|███▌      | 9/25 [04:37<04:18, 16.14s/it]Generation:  10
Best f1_score score: 0.973311927968911
Generation:  40%|████      | 10/25 [04:46<03:28, 13.91s/it]Generation:  11
Best f1_score score: 0.973311927968911
Generation:  44%|████▍     | 11/25 [04:54<02:49, 12.10s/it]Generation:  12
Best f1_score score: 0.973311927968911
Generation:  48%|████▊     | 12/25 [05:17<03:19, 15.35s/it]Generation:  13
Best f1_score score: 0.9734581887236138
Generation:  52%|█████▏    | 13/25 [05:26<02:41, 13.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a834c0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  14
Best f1_score score: 0.9734581887236138
Generation:  56%|█████▌    | 14/25 [05:36<02:14, 12.26s/it]Generation:  15
Best f1_score score: 0.9734581887236138
Generation:  60%|██████    | 15/25 [06:23<03:48, 22.88s/it]Generation:  16
Best f1_score score: 0.9734581887236138
Generation:  64%|██████▍   | 16/25 [06:36<02:58, 19.83s/it]Generation:  17
Best f1_score score: 0.9734581887236138
Generation:  68%|██████▊   | 17/25 [07:43<04:32, 34.00s/it]Generation:  18
Best f1_score score: 0.9734581887236138
Generation:  72%|███████▏  | 18/25 [07:58<03:17, 28.24s/it]Generation:  19
Best f1_score score: 0.9734581887236138
Generation:  76%|███████▌  | 19/25 [08:14<02:27, 24.50s/it]Generation:  20
Best f1_score score: 0.9734581887236138
Generation:  80%|████████  | 20/25 [08:27<01:45, 21.14s/it]Generation:  21
Best f1_score score: 0.9734581887236138
Generation:  84%|████████▍ | 21/25 [08:52<01:29, 22.36s/it]Generation:  22
Best f1_score score: 0.9734581887236138
Generation:  88%|████████▊ | 22/25 [09:16<01:08, 22.92s/it]Generation:  23
Best f1_score score: 0.9734581887236138
Generation:  92%|█████████▏| 23/25 [09:37<00:44, 22.16s/it]Generation:  24
Best f1_score score: 0.9734581887236138
Generation:  96%|█████████▌| 24/25 [10:13<00:26, 26.29s/it]Generation:  25
Best f1_score score: 0.9734581887236138
Generation: 100%|██████████| 25/25 [11:48<00:00, 47.15s/it]Generation: 100%|██████████| 25/25 [11:52<00:00, 28.50s/it]
2024-11-04 16:41:37,211 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:39947' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-782bc5f56dfe6ad3c3952dbb6d6329f9', 'ndarray-9e35e5ed863f58dea9a816f3cc6e5767'} (stimulus_id='handle-worker-cleanup-1730767297.2114584')
Fitted
Pipeline(steps=[('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.0069325593152,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0231400133993, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=11,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
score start
train score: {'auroc': 0.9972549563523005, 'accuracy': 0.9774305555555556, 'balanced_accuracy': 0.9782554790083404, 'logloss': 0.10483144725277721, 'f1': 0.977247490596595}
original test score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 0.06862735896471793, 'f1': 1.0}
imputed test score: {'auroc': 0.9922858903765216, 'accuracy': 0.9728166570271833, 'balanced_accuracy': 0.974120057631123, 'logloss': 0.12504598785252197, 'f1': 0.9726214360918088}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd52a0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d60> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4df0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4eb0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.9633203703488494
Generation:   4%|▍         | 1/25 [00:11<04:36, 11.53s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1c610> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  2
Best f1_score score: 0.9664797779932149
Generation:   8%|▊         | 2/25 [00:25<04:58, 12.99s/it]Generation:  3
Best f1_score score: 0.9681976406720334
Generation:  12%|█▏        | 3/25 [04:04<39:18, 107.21s/it]Generation:  4
Best f1_score score: 0.9681976406720334
Generation:  16%|█▌        | 4/25 [07:44<53:06, 151.73s/it]Generation:  5
Best f1_score score: 0.9703895651507375
Generation:  20%|██        | 5/25 [11:29<59:18, 177.91s/it]Generation:  6
Best f1_score score: 0.9703895651507375
Generation:  24%|██▍       | 6/25 [15:13<1:01:18, 193.60s/it]Generation:  7
Best f1_score score: 0.9715617540443884
Generation:  28%|██▊       | 7/25 [18:55<1:00:51, 202.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547457c220> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  8
Best f1_score score: 0.9715617540443884
Generation:  32%|███▏      | 8/25 [22:37<59:14, 209.08s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc93970> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  9
Best f1_score score: 0.9722887424315385
Generation:  36%|███▌      | 9/25 [26:23<57:11, 214.49s/it]Generation:  10
Best f1_score score: 0.9730117938157079
Generation:  40%|████      | 10/25 [30:09<54:29, 217.95s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fffa7a0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  11
Best f1_score score: 0.9730117938157079
Generation:  44%|████▍     | 11/25 [33:55<51:26, 220.45s/it]Generation:  12
Best f1_score score: 0.9730117938157079
Generation:  48%|████▊     | 12/25 [37:42<48:12, 222.47s/it]Generation:  13
Best f1_score score: 0.9733060693164429
Generation:  52%|█████▏    | 13/25 [41:29<44:43, 223.60s/it]Generation:  14
Best f1_score score: 0.9733060693164429
Generation:  56%|█████▌    | 14/25 [45:11<40:56, 223.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554096aed40> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  15
Best f1_score score: 0.9733060693164429
Generation:  60%|██████    | 15/25 [49:04<37:41, 226.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459fcfbe0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545dc51600> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15541bbe5de0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  16
Best f1_score score: 0.9733060693164429
Generation:  64%|██████▍   | 16/25 [52:50<33:55, 226.18s/it]Generation:  17
Best f1_score score: 0.9733060693164429
Generation:  68%|██████▊   | 17/25 [56:47<30:34, 229.33s/it]Generation:  18
Best f1_score score: 0.9733060693164429
Generation:  72%|███████▏  | 18/25 [1:00:33<26:37, 228.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f655720> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545450eec0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  19
Best f1_score score: 0.9733060693164429
Generation:  76%|███████▌  | 19/25 [1:04:18<22:44, 227.36s/it]Generation:  20
Best f1_score score: 0.9733060693164429
Generation:  80%|████████  | 20/25 [1:08:09<19:02, 228.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547428b250> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474194760> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  21
Best f1_score score: 0.9733060693164429
Generation:  84%|████████▍ | 21/25 [1:11:55<15:10, 227.61s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745729b0> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  22
Best f1_score score: 0.9733060693164429
Generation:  88%|████████▊ | 22/25 [1:16:33<12:08, 242.91s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554742dca30> 
 float division by zero 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 682, in fit_transform
    self.fit(X)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 617, in fit
    self.model = self.VAE(VAEImputer=self, input_size=features.shape[1])
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 568, in __init__
    self.encoder = VAEImputer.Encoder(VAEImputer, input_size)
  File "/common/ketrong/tpotexp/tpot2/tpot2/builtin_modules/imputer.py", line 499, in __init__
    self.E_W4 = torch.nn.init.xavier_normal_(torch.empty((VAEImputer.split_size, VAEImputer.code_size),requires_grad=True, device=VAEImputer.device))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/torch/nn/init.py", line 392, in xavier_normal_
    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))
ZeroDivisionError: float division by zero

Generation:  23
Best f1_score score: 0.9733060693164429
Generation:  92%|█████████▏| 23/25 [1:20:21<07:56, 238.42s/it]Generation:  24
Best f1_score score: 0.9733060693164429
Generation:  96%|█████████▌| 24/25 [1:24:04<03:53, 233.89s/it]Generation:  25
Best f1_score score: 0.9733060693164429
Generation: 100%|██████████| 25/25 [1:28:00<00:00, 234.45s/it]Generation: 100%|██████████| 25/25 [1:28:00<00:00, 211.23s/it]
2024-11-04 18:10:39,747 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38075' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-675040abea98de36d54975dfff631c67', 'ndarray-782bc5f56dfe6ad3c3952dbb6d6329f9'} (stimulus_id='handle-worker-cleanup-1730772639.7472348')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=RandomForestRegressor(),
                                  imputation_order='random',
                                  initial_strategy='median',
                                  n_nearest_features=28)),
                ('lgbmclassifier',
                 LGBMClassifier(boosting_type='goss', class_weight='balanced',
                                max_depth=8, n_estimators=84, n_jobs=1,
                                num_leaves=178, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9988536241714041, 'accuracy': 0.9827835648148148, 'balanced_accuracy': 0.9836187926138045, 'logloss': 0.048265245403731345, 'f1': 0.9826425533338194}
test score: {'auroc': 0.9902031145675368, 'accuracy': 0.9739733950260266, 'balanced_accuracy': 0.9752884935083892, 'logloss': 0.09512538125576436, 'f1': 0.9737864813644979}
original test score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 0.015400718076815903, 'f1': 1.0}
score end
923
lvl
0.1
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
3.2588977648152246
hours
DONE
