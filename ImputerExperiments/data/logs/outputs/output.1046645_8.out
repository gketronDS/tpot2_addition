Run: 8
/cm/local/apps/slurm/var/spool/job1046645/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1481/1481.pkl
working on 
../data/c/1481/class_full_MAR_0.5_1
4.659625053405762
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-12 16:31:03,174] A new study created in memory with name: no-name-6cf538be-bb7c-40a9-a6a1-e42f02ac0810
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-12 16:31:03,443] Trial 14 finished with value: 0.5200424478060762 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 14 with value: 0.5200424478060762.
running
[I 2024-11-12 16:31:03,658] Trial 1 finished with value: 0.3074496025709649 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 1 with value: 0.3074496025709649.
running
[I 2024-11-12 16:31:03,829] Trial 12 finished with value: 0.43680206886101675 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.3074496025709649.
running
[I 2024-11-12 16:31:03,983] Trial 7 finished with value: 0.43680206886101675 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.3074496025709649.
running
[I 2024-11-12 16:31:04,147] Trial 8 finished with value: 0.43680206886101675 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 1 with value: 0.3074496025709649.
running
[I 2024-11-12 16:31:09,895] Trial 20 finished with value: 0.300384343469292 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2533, 'weights': 'uniform'}. Best is trial 20 with value: 0.300384343469292.
running
[I 2024-11-12 16:31:10,681] Trial 19 finished with value: 0.3022646578400759 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 20 with value: 0.300384343469292.
running
[I 2024-11-12 16:31:11,335] Trial 6 finished with value: 0.30421291202584594 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11833, 'weights': 'uniform'}. Best is trial 20 with value: 0.300384343469292.
running
[I 2024-11-12 16:31:11,719] Trial 3 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 21, 'hint_rate': 0.21680593353461544, 'alpha': 34, 'iterations': 4, 'learning_rate': 0.0003341963655003174, 'p_miss': 0.02023667347459858}. Best is trial 20 with value: 0.300384343469292.
running
[I 2024-11-12 16:31:15,309] Trial 2 finished with value: 0.5202472046310507 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.777528001178115, 'alpha': 58, 'iterations': 1, 'learning_rate': 0.034120241208156495, 'p_miss': 0.12914928896556974}. Best is trial 20 with value: 0.300384343469292.
running
[I 2024-11-12 16:31:16,947] Trial 24 finished with value: 0.2698662996495597 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.014498011985070152, 'p_miss': 0.20037085320419568}. Best is trial 24 with value: 0.2698662996495597.
running
[I 2024-11-12 16:31:18,164] Trial 4 finished with value: 0.5171020406791949 and parameters: {'model_name': 'GAIN', 'batch_size': 227, 'hint_rate': 0.6053954399883719, 'alpha': 55, 'iterations': 2, 'learning_rate': 0.021553066314546978, 'p_miss': 0.2619404817677875}. Best is trial 24 with value: 0.2698662996495597.
running
[I 2024-11-12 16:31:19,555] Trial 21 finished with value: 0.3371757452758132 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14732, 'weights': 'distance'}. Best is trial 24 with value: 0.2698662996495597.
running
[I 2024-11-12 16:31:21,186] Trial 10 finished with value: 0.2701722255912083 and parameters: {'model_name': 'VAE', 'batch_size': 585, 'iterations': 1, 'learning_rate': 0.0015798983118415772, 'p_miss': 0.06206971933967792}. Best is trial 24 with value: 0.2698662996495597.
running
[I 2024-11-12 16:31:22,933] Trial 9 finished with value: 0.2695972430625951 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 3, 'learning_rate': 0.0061565190926573836, 'p_miss': 0.06400198455457407}. Best is trial 9 with value: 0.2695972430625951.
running
[I 2024-11-12 16:31:27,001] Trial 5 finished with value: 0.33059341452169827 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 9 with value: 0.2695972430625951.
running
[I 2024-11-12 16:31:36,145] Trial 0 finished with value: 0.5199139980738593 and parameters: {'model_name': 'GAIN', 'batch_size': 48, 'hint_rate': 0.7141037680670198, 'alpha': 10, 'iterations': 15, 'learning_rate': 0.0024071572885884136, 'p_miss': 0.05193364221164306}. Best is trial 9 with value: 0.2695972430625951.
running
[I 2024-11-12 16:31:40,943] Trial 18 finished with value: 0.5165670797751256 and parameters: {'model_name': 'GAIN', 'batch_size': 123, 'hint_rate': 0.7685992190409707, 'alpha': 7, 'iterations': 17, 'learning_rate': 0.0009071553864671996, 'p_miss': 0.2614049215586408}. Best is trial 9 with value: 0.2695972430625951.
running
[I 2024-11-12 16:33:53,012] Trial 17 finished with value: 0.2666803977634743 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 48, 'learning_rate': 0.0002205486170178534, 'p_miss': 0.0454166938316677}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:35:12,764] Trial 23 finished with value: 0.5175691897244247 and parameters: {'model_name': 'GAIN', 'batch_size': 30, 'hint_rate': 0.5273933282441872, 'alpha': 57, 'iterations': 162, 'learning_rate': 0.08731913147484797, 'p_miss': 0.06578121424457134}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:35:27,470] Trial 22 finished with value: 0.2698872667507987 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 67, 'learning_rate': 0.00024081512709042663, 'p_miss': 0.055267081599359794}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:39:03,812] Trial 11 finished with value: 0.5170772085788273 and parameters: {'model_name': 'GAIN', 'batch_size': 54, 'hint_rate': 0.03334814358959499, 'alpha': 53, 'iterations': 315, 'learning_rate': 0.0006827121084304165, 'p_miss': 0.13656260995650385}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:42:53,923] Trial 30 finished with value: 0.38485142692124663 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 277, 'learning_rate': 0.006339108866326499, 'p_miss': 0.21447414779365298}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:46:00,102] Trial 13 finished with value: 0.3020050008795475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:53:52,555] Trial 15 finished with value: 0.32170802875357224 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 16:54:12,140] Trial 40 finished with value: 0.26734551818586605 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.008062405536172065, 'p_miss': 0.18743094149917733}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:25:43,802] Trial 31 finished with value: 0.38350093882234026 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1311, 'learning_rate': 0.00571688682723007, 'p_miss': 0.21501384809442503}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:26:16,024] Trial 42 finished with value: 0.266952731015626 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9, 'learning_rate': 0.00013428848663505323, 'p_miss': 0.10092937247046724}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:26:55,995] Trial 43 finished with value: 0.27298176574495986 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 11, 'learning_rate': 0.00010178576649754086, 'p_miss': 0.10894269082984763}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:29:30,194] Trial 44 finished with value: 0.271133658578323 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 50, 'learning_rate': 0.00011638493756075637, 'p_miss': 0.17216899453298995}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:29:58,137] Trial 45 finished with value: 0.26845884904734646 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 10, 'learning_rate': 0.0002924408688968129, 'p_miss': 0.10185611523946805}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:30:22,212] Trial 46 finished with value: 0.2706674507611015 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8, 'learning_rate': 0.0003164690597512315, 'p_miss': 0.11146312058247007}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:32:24,376] Trial 47 finished with value: 0.2738282945916569 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 30, 'learning_rate': 0.0001873562931932156, 'p_miss': 0.09313638584257944}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:32:42,870] Trial 48 finished with value: 0.26988301342419885 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6, 'learning_rate': 0.0006056182618184995, 'p_miss': 0.17777768241321557}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:34:16,798] Trial 49 finished with value: 0.2715764357496469 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 25, 'learning_rate': 0.0001726931318290298, 'p_miss': 0.08837518327898522}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:42:23,946] Trial 32 finished with value: 0.3886083570945692 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1623, 'learning_rate': 0.012000186353811735, 'p_miss': 0.22595684422939705}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:43:19,009] Trial 50 finished with value: 0.27640061142314976 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 126, 'learning_rate': 0.00041660806416742496, 'p_miss': 0.01681172492005717}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:43:35,164] Trial 52 finished with value: 0.26836837199161384 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.0013645283498615664, 'p_miss': 0.15317874065557124}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:43:45,075] Trial 53 finished with value: 0.2699620959680321 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 2, 'learning_rate': 0.0017840539281598021, 'p_miss': 0.1490388619388533}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:43:53,145] Trial 54 finished with value: 0.3371572951132532 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21713, 'weights': 'distance'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:44:15,646] Trial 55 finished with value: 0.2673642673114716 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 5, 'learning_rate': 0.0010605750435437487, 'p_miss': 0.1817835533933832}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:44:32,844] Trial 56 finished with value: 0.27519455742976767 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.0011441708935680042, 'p_miss': 0.1773454456341354}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:44:47,846] Trial 57 finished with value: 0.27101049301957864 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 3, 'learning_rate': 0.0032217461052994473, 'p_miss': 0.1623596130605024}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:47:28,306] Trial 58 finished with value: 0.2717310220676994 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 44, 'learning_rate': 0.000518760415362973, 'p_miss': 0.19782785989611795}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:48:13,537] Trial 59 finished with value: 0.2695664759531615 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 18, 'learning_rate': 0.0031644795315069903, 'p_miss': 0.24094909708895648}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:48:45,420] Trial 51 finished with value: 0.27868920647548306 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 123, 'learning_rate': 0.0004202395154124615, 'p_miss': 0.027344789314739337}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:48:46,765] Trial 61 finished with value: 0.4534658413503617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:48:48,860] Trial 60 finished with value: 0.27248615581356883 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 9, 'learning_rate': 0.001982176666355771, 'p_miss': 0.0389998276468177}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:49:10,746] Trial 62 finished with value: 0.40647476946677596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:49:13,115] Trial 63 finished with value: 0.4064747694665324 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:49:15,055] Trial 64 finished with value: 0.518601707898344 and parameters: {'model_name': 'GAIN', 'batch_size': 33, 'hint_rate': 0.9425722732283455, 'alpha': 100, 'iterations': 2, 'learning_rate': 0.0010481938377248177, 'p_miss': 0.134434052693283}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:49:20,445] Trial 65 finished with value: 0.5140090028531142 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.9784661297530275, 'alpha': 92, 'iterations': 2, 'learning_rate': 0.00016721055766367258, 'p_miss': 0.14212027183944265}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:49:45,160] Trial 66 finished with value: 0.26969500002561775 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 10, 'learning_rate': 0.00016708048533116388, 'p_miss': 0.08709193004564986}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:01,250] Trial 68 finished with value: 0.26723048083446166 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 5, 'learning_rate': 0.0003480623216222395, 'p_miss': 0.18646364299163398}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:06,821] Trial 67 finished with value: 0.2668899563682673 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 12, 'learning_rate': 0.0002618026300577716, 'p_miss': 0.10673003299205627}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:07,429] Trial 70 finished with value: 0.5200424478060762 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:14,238] Trial 71 finished with value: 0.3370013086070704 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3242, 'weights': 'distance'}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:14,884] Trial 69 finished with value: 0.2694633135061358 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.0002448279949864127, 'p_miss': 0.1951543311306331}. Best is trial 17 with value: 0.2666803977634743.
running
[I 2024-11-12 17:50:27,606] Trial 72 finished with value: 0.2657390610089454 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.00023249852664418, 'p_miss': 0.18310501645348912}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:51:08,180] Trial 73 finished with value: 0.27847690975949824 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 14, 'learning_rate': 0.00012879301772600254, 'p_miss': 0.12013281773199758}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:51:12,857] Trial 74 finished with value: 0.26596156414641475 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 17, 'learning_rate': 0.00012300411653584604, 'p_miss': 0.07929801749155181}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:51:13,606] Trial 75 finished with value: 0.26725257601197094 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.0002605227661411899, 'p_miss': 0.07814872028888022}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:51:18,490] Trial 77 finished with value: 0.2679603994424563 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 1, 'learning_rate': 0.0002251583028748896, 'p_miss': 0.08166721115062597}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:52:27,594] Trial 76 finished with value: 0.2690974308180289 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 22, 'learning_rate': 0.00023143875611068254, 'p_miss': 0.07710613273358799}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:52:58,882] Trial 78 finished with value: 0.26959368457336697 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 31, 'learning_rate': 0.00014696071606869966, 'p_miss': 0.0728797361473702}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:53:54,810] Trial 80 finished with value: 0.26989791662715834 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 16, 'learning_rate': 0.0004055694670105295, 'p_miss': 0.04208397176499466}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:00,804] Trial 81 finished with value: 0.3074496025709649 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22279, 'weights': 'uniform'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:01,439] Trial 82 finished with value: 0.3074496025709649 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:16,538] Trial 83 finished with value: 0.27105143016137123 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.0007221298901453608, 'p_miss': 0.05094378309811933}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:16,906] Trial 79 finished with value: 0.2681125111288414 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 33, 'learning_rate': 0.00013522307443401092, 'p_miss': 0.038240566539171}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:23,166] Trial 84 finished with value: 0.266566007900241 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 1, 'learning_rate': 0.00010013680706494817, 'p_miss': 0.29753544896041967}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:30,244] Trial 86 finished with value: 0.2673502469219581 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 1, 'learning_rate': 0.00010685599983450464, 'p_miss': 0.2984961887858874}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:39,922] Trial 87 finished with value: 0.2661343884740113 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 2, 'learning_rate': 0.00028579669302159844, 'p_miss': 0.2859295022187264}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:41,187] Trial 85 finished with value: 0.3202289240757893 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:51,475] Trial 88 finished with value: 0.27302351450611145 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 3, 'learning_rate': 0.00033383616432365853, 'p_miss': 0.2515925777800945}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:54:57,020] Trial 89 finished with value: 0.26866754040774166 and parameters: {'model_name': 'VAE', 'batch_size': 169, 'iterations': 3, 'learning_rate': 0.00034709757052624066, 'p_miss': 0.2625751111099576}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:55:02,354] Trial 90 finished with value: 0.27398555697309945 and parameters: {'model_name': 'VAE', 'batch_size': 294, 'iterations': 2, 'learning_rate': 0.00021537145402083325, 'p_miss': 0.2900205294621819}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:55:25,036] Trial 92 finished with value: 0.271332565539266 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 7, 'learning_rate': 0.00010283595851705133, 'p_miss': 0.2772425672956586}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:58:02,322] Trial 91 finished with value: 0.2695165748799434 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 72, 'learning_rate': 0.00017626567066995145, 'p_miss': 0.29543613897405757}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 17:58:26,514] Trial 94 finished with value: 0.5207398113045828 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.32443430261707273, 'alpha': 77, 'iterations': 14, 'learning_rate': 0.04864171509909569, 'p_miss': 0.12688377400652842}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:00:28,531] Trial 93 finished with value: 0.2735867632925949 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 86, 'learning_rate': 0.00014312138678520777, 'p_miss': 0.12023963209306998}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:00:34,323] Trial 96 finished with value: 0.2663521129586708 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 1, 'learning_rate': 0.00026445643853233614, 'p_miss': 0.09626711521957267}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:02:28,423] Trial 37 finished with value: 0.3930478476108088 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2047, 'learning_rate': 0.007629377737839734, 'p_miss': 0.20203361870560416}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:02:29,161] Trial 29 finished with value: 0.36611026701718913 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2047, 'learning_rate': 0.0019860005924994244, 'p_miss': 0.17983230097829223}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:02:52,974] Trial 98 finished with value: 0.2694783276099366 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 7, 'learning_rate': 0.0002875836033887444, 'p_miss': 0.10733163091363619}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:03:01,111] Trial 100 finished with value: 0.26985004117092953 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 2, 'learning_rate': 0.0005462431635679674, 'p_miss': 0.05872405371426726}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:03:14,641] Trial 101 finished with value: 0.2685326220747356 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 4, 'learning_rate': 0.00019035893225367046, 'p_miss': 0.1004631625992333}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:14:28,913] Trial 38 finished with value: 0.3169755142523868 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1423, 'learning_rate': 0.008126002983822296, 'p_miss': 0.19248039578554085}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:18:14,744] Trial 16 finished with value: 0.3098328557601101 and parameters: {'model_name': 'VAE', 'batch_size': 505, 'iterations': 1552, 'learning_rate': 0.00012403793568704962, 'p_miss': 0.15822951591936857}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:19:15,077] Trial 102 finished with value: 0.2711127098595703 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 279, 'learning_rate': 0.00012283738365337975, 'p_miss': 0.28028185127838556}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:19:21,083] Trial 105 finished with value: 0.3021884624925792 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6412, 'weights': 'uniform'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:19:27,300] Trial 106 finished with value: 0.2696251293446223 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 1, 'learning_rate': 0.0002909024634546361, 'p_miss': 0.06855436670731847}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:25:20,769] Trial 27 finished with value: 0.37455686405380384 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2553, 'learning_rate': 0.0019513803289222477, 'p_miss': 0.2229711852375061}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:25:26,126] Trial 108 finished with value: 0.2678424894902316 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.0002584238555460986, 'p_miss': 0.08744557308771193}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:32:05,465] Trial 33 finished with value: 0.37004805145298997 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2141, 'learning_rate': 0.010680149686590536, 'p_miss': 0.18228485172906142}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:35:35,008] Trial 110 finished with value: 0.2744139942654112 and parameters: {'model_name': 'VAE', 'batch_size': 930, 'iterations': 43, 'learning_rate': 0.00020547808450272598, 'p_miss': 0.09367648397610051}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:38:12,200] Trial 34 finished with value: 0.31053480676825995 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2132, 'learning_rate': 0.00011831725996215395, 'p_miss': 0.1108941715719984}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:38:13,112] Trial 112 finished with value: 0.4534658413503617 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:40:44,941] Trial 97 finished with value: 0.31328700928929964 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 712, 'learning_rate': 0.00028285496567058313, 'p_miss': 0.10219508288858574}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:40:54,522] Trial 114 finished with value: 0.30615622612009347 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:42:22,671] Trial 95 finished with value: 0.2993588363086295 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 808, 'learning_rate': 0.00013780997732727268, 'p_miss': 0.27755810631901406}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:43:04,637] Trial 116 finished with value: 0.32068961318943295 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 11, 'learning_rate': 0.026819850972808187, 'p_miss': 0.16510293522312233}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:43:24,588] Trial 117 finished with value: 0.2725255615385951 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 5, 'learning_rate': 0.005155980400475836, 'p_miss': 0.21318393849031886}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:43:40,716] Trial 118 finished with value: 0.2767929364883507 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.01696100845791729, 'p_miss': 0.06332896396363466}. Best is trial 72 with value: 0.2657390610089454.
running
[I 2024-11-12 18:44:15,623] Trial 119 finished with value: 0.26562367975085893 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 7, 'learning_rate': 0.0003950559514012067, 'p_miss': 0.1877365788364845}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 18:44:46,866] Trial 120 finished with value: 0.2706437142674312 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 7, 'learning_rate': 0.0003962820204099403, 'p_miss': 0.20883816820264467}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 18:45:12,041] Trial 121 finished with value: 0.5150730675699933 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.33872649179812586, 'alpha': 27, 'iterations': 12, 'learning_rate': 0.0004828353715917142, 'p_miss': 0.2315401850434765}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 18:45:49,385] Trial 122 finished with value: 0.26680371572814476 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 9, 'learning_rate': 0.00015884503833511187, 'p_miss': 0.07795672387226998}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:08:41,202] Trial 103 finished with value: 0.2929010963637356 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 932, 'learning_rate': 0.00013197766543336816, 'p_miss': 0.21063760149008925}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:18:42,451] Trial 111 finished with value: 0.3121549387704464 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 803, 'learning_rate': 0.00036951898021741727, 'p_miss': 0.20818935996831367}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:19:07,335] Trial 125 finished with value: 0.27964139201352756 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 9, 'learning_rate': 0.0001662303292990627, 'p_miss': 0.04876870316167872}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:54:58,621] Trial 26 finished with value: 0.365838780195461 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3649, 'learning_rate': 0.019252430998547055, 'p_miss': 0.29790132544629283}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:56:25,827] Trial 127 finished with value: 0.2683153379487517 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 20, 'learning_rate': 0.0002176445136482894, 'p_miss': 0.07344723875340167}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:56:55,681] Trial 128 finished with value: 0.26985072654418596 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 6, 'learning_rate': 0.00025521409378807065, 'p_miss': 0.08052345769539453}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:57:41,116] Trial 129 finished with value: 0.26673859931955646 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 12, 'learning_rate': 0.0001598598459049349, 'p_miss': 0.024383770971860973}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:58:29,241] Trial 130 finished with value: 0.2715540330918371 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 12, 'learning_rate': 0.00015925085762239508, 'p_miss': 0.025142879929652237}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 19:59:13,780] Trial 131 finished with value: 0.26858165601329553 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 8, 'learning_rate': 0.00019132896652316556, 'p_miss': 0.015521960676078514}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:40:51,751] Trial 41 finished with value: 0.31391162777945825 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3610, 'learning_rate': 0.005120316636213764, 'p_miss': 0.10594500405896182}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:41:57,150] Trial 133 finished with value: 0.26677041718330563 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 18, 'learning_rate': 0.00011060751025650347, 'p_miss': 0.18634637483055885}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:42:04,854] Trial 134 finished with value: 0.3371846806105774 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15514, 'weights': 'distance'}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:43:13,219] Trial 135 finished with value: 0.2704289825954101 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 23, 'learning_rate': 0.00011406054450654821, 'p_miss': 0.171044039348069}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:44:08,081] Trial 136 finished with value: 0.26728445651461075 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 17, 'learning_rate': 0.00015383947506678378, 'p_miss': 0.18540365953943994}. Best is trial 119 with value: 0.26562367975085893.
running
[I 2024-11-12 20:44:49,591] Trial 137 finished with value: 0.26476167126766886 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 12, 'learning_rate': 0.00010097489579080331, 'p_miss': 0.19020998323077606}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:45:32,673] Trial 138 finished with value: 0.26686296626038125 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 14, 'learning_rate': 0.00011717004717561371, 'p_miss': 0.09328835294628834}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:46:26,969] Trial 139 finished with value: 0.268700356723647 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 15, 'learning_rate': 0.00011353365423465603, 'p_miss': 0.19203694053997322}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:48:00,623] Trial 140 finished with value: 0.2698386589162274 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 25, 'learning_rate': 0.00010030914841342267, 'p_miss': 0.0918165923328131}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:48:01,276] Trial 141 finished with value: 0.5200424478060762 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:48:49,354] Trial 142 finished with value: 0.265884889440712 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 13, 'learning_rate': 0.00018576925306646838, 'p_miss': 0.010930922464434162}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:50:51,853] Trial 143 finished with value: 0.27799049859614267 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 38, 'learning_rate': 0.0001249151633637168, 'p_miss': 0.011813895826003055}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:50:54,094] Trial 28 finished with value: 0.3555456013217868 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4917, 'learning_rate': 0.0020716865534096615, 'p_miss': 0.23573448237006295}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:51:06,110] Trial 144 finished with value: 0.2994259086051268 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:51:08,679] Trial 145 finished with value: 0.3038298152988947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:51:49,481] Trial 147 finished with value: 0.26808139673574916 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 13, 'learning_rate': 0.00019390260353034807, 'p_miss': 0.02945687617354892}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:52:40,978] Trial 39 finished with value: 0.330401835350116 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4338, 'learning_rate': 0.008187570618735828, 'p_miss': 0.19472025754656894}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:52:47,226] Trial 148 finished with value: 0.271421772972037 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 19, 'learning_rate': 0.0001571397019893354, 'p_miss': 0.0211954312821951}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:53:58,742] Trial 149 finished with value: 0.2686263131540882 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 26, 'learning_rate': 0.00015735602320106993, 'p_miss': 0.021530194532873793}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:54:50,990] Trial 151 finished with value: 0.26555263787532724 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 10, 'learning_rate': 0.00010043954707486915, 'p_miss': 0.03158426758953968}. Best is trial 137 with value: 0.26476167126766886.
running
[I 2024-11-12 20:55:25,037] Trial 152 finished with value: 0.26460726112316235 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 11, 'learning_rate': 0.0001166683912521255, 'p_miss': 0.03447558794308665}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 20:55:52,486] Trial 153 finished with value: 0.2659488015861794 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 9, 'learning_rate': 0.0001018179278696824, 'p_miss': 0.03668149146556672}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 20:56:11,175] Trial 154 finished with value: 0.5187396318244604 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.03890898941154747, 'alpha': 79, 'iterations': 10, 'learning_rate': 0.00010113222718460474, 'p_miss': 0.029186766802284846}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 20:59:51,962] Trial 155 finished with value: 0.2724391407405593 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 57, 'learning_rate': 0.00012995399169510338, 'p_miss': 0.034411345992703075}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:00:17,113] Trial 156 finished with value: 0.27051578476513416 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 8, 'learning_rate': 0.00014275270541237923, 'p_miss': 0.04493866778469868}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:00:39,977] Trial 157 finished with value: 0.2659285821593815 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 6, 'learning_rate': 0.00018130949562564135, 'p_miss': 0.05406675698834339}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:01:00,898] Trial 158 finished with value: 0.2684938536392069 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 6, 'learning_rate': 0.00011381971623266861, 'p_miss': 0.03423960735884062}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:01:21,842] Trial 159 finished with value: 0.2774192651617471 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 6, 'learning_rate': 0.00019695462273273102, 'p_miss': 0.05116903533905688}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:02:25,824] Trial 160 finished with value: 0.273249890238873 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 16, 'learning_rate': 0.00022105676024097604, 'p_miss': 0.04494602532290946}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:02:59,990] Trial 161 finished with value: 0.2667338908025519 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 10, 'learning_rate': 0.00010037577417345459, 'p_miss': 0.010216157736711542}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:03:34,194] Trial 162 finished with value: 0.2686226039635685 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 11, 'learning_rate': 0.00017659434953047222, 'p_miss': 0.014317117781716321}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:31:38,987] Trial 35 finished with value: 0.3138248731463902 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5094, 'learning_rate': 0.0001052789865519938, 'p_miss': 0.11518406276380498}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:31:54,996] Trial 164 finished with value: 0.2667451213816166 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 4, 'learning_rate': 0.00013700981552228659, 'p_miss': 0.03367455346252614}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:32:20,233] Trial 165 finished with value: 0.2678906027299265 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 8, 'learning_rate': 0.0001014826303038809, 'p_miss': 0.05619349376057234}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:32:35,245] Trial 166 finished with value: 0.27353564716826934 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 4, 'learning_rate': 0.0001367702367096509, 'p_miss': 0.03591320257165431}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:32:58,359] Trial 167 finished with value: 0.26512780958283705 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 6, 'learning_rate': 0.0001253732663642548, 'p_miss': 0.023179717497002893}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:33:20,643] Trial 168 finished with value: 0.2680124138727503 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 7, 'learning_rate': 0.00012185463070581969, 'p_miss': 0.02268016832914871}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:33:52,428] Trial 169 finished with value: 0.27309815068859283 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 10, 'learning_rate': 0.0001763213357947135, 'p_miss': 0.010589680476436401}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:34:04,395] Trial 170 finished with value: 0.2714505515186096 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.00023763596342728013, 'p_miss': 0.02939092798522338}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:34:25,443] Trial 171 finished with value: 0.2688300431139861 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 6, 'learning_rate': 0.0003127534096271304, 'p_miss': 0.016820521062623883}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:34:41,994] Trial 172 finished with value: 0.2662767368457108 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 5, 'learning_rate': 0.00012501894516919154, 'p_miss': 0.04209398207400014}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:34:48,433] Trial 173 finished with value: 0.33709483083961816 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8051, 'weights': 'distance'}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:35:05,266] Trial 174 finished with value: 0.2677895675534723 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.00012741994741170454, 'p_miss': 0.039422169891703884}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:35:31,190] Trial 175 finished with value: 0.2663055985675256 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7, 'learning_rate': 0.00010001269076658852, 'p_miss': 0.29014415825815115}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:35:53,212] Trial 176 finished with value: 0.26911035765315205 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7, 'learning_rate': 0.00010121633733150157, 'p_miss': 0.2948066348359284}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:36:21,190] Trial 177 finished with value: 0.2667607171821649 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 9, 'learning_rate': 0.00011507992351543551, 'p_miss': 0.04549920382467027}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:36:42,583] Trial 178 finished with value: 0.27051028027468094 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 5, 'learning_rate': 0.00013171316534457526, 'p_miss': 0.05306734913349234}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:37:14,834] Trial 179 finished with value: 0.27062908737027913 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 7, 'learning_rate': 0.00014848450597324065, 'p_miss': 0.28612209627844887}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:37:37,633] Trial 180 finished with value: 0.2706366415913851 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 6, 'learning_rate': 0.00010110975340759157, 'p_miss': 0.2859326473847489}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:37:38,369] Trial 181 finished with value: 0.3074496025709649 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 21:37:46,562] Trial 182 finished with value: 0.2702541047736796 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 2, 'learning_rate': 0.00012105296239985988, 'p_miss': 0.20122947012345757}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:13:22,115] Trial 25 finished with value: 0.38251240415759813 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7356, 'learning_rate': 0.070350936788902, 'p_miss': 0.2802647722748892}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:13:39,810] Trial 184 finished with value: 0.27353836054322167 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 4, 'learning_rate': 0.00019193001920340686, 'p_miss': 0.05964596971224371}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:14:04,767] Trial 185 finished with value: 0.2671601288527121 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 8, 'learning_rate': 0.00014345141875905646, 'p_miss': 0.03954623322214437}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:14:51,804] Trial 186 finished with value: 0.2661062953134419 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 12, 'learning_rate': 0.00016751443397472007, 'p_miss': 0.2659278497740812}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:15:44,443] Trial 187 finished with value: 0.2717633161958076 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 13, 'learning_rate': 0.00022501695637159536, 'p_miss': 0.2901850667828748}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:16:31,237] Trial 188 finished with value: 0.27381461059813583 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 10, 'learning_rate': 0.00011663198170860975, 'p_miss': 0.272560162036838}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:27:04,742] Trial 189 finished with value: 0.27437592069443417 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 199, 'learning_rate': 0.00017378946376146056, 'p_miss': 0.26835639065917827}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:27:21,290] Trial 190 finished with value: 0.2659758956779332 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.00020520161710694726, 'p_miss': 0.25100950745608247}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:27:36,513] Trial 191 finished with value: 0.26604696069796663 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4, 'learning_rate': 0.0002511372952276595, 'p_miss': 0.2990107861786626}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:27:49,907] Trial 192 finished with value: 0.2685291802589783 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.00031330599999982215, 'p_miss': 0.2956108324367775}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:28:00,206] Trial 193 finished with value: 0.5177759457026878 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.36943668506245364, 'alpha': 32, 'iterations': 3, 'learning_rate': 0.00026374577028121985, 'p_miss': 0.240218647796603}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:28:20,371] Trial 194 finished with value: 0.2648535009318402 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 5, 'learning_rate': 0.00019558766471334697, 'p_miss': 0.25554711698740223}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:28:34,667] Trial 195 finished with value: 0.26920739397895305 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 4, 'learning_rate': 0.00020901265114840067, 'p_miss': 0.26350049701082023}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:28:54,358] Trial 196 finished with value: 0.2715544325245517 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 5, 'learning_rate': 0.00024079129645074377, 'p_miss': 0.28343009883746506}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:29:18,330] Trial 197 finished with value: 0.26884876325572804 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 5, 'learning_rate': 0.0001533879564562601, 'p_miss': 0.2991729407180444}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:29:34,631] Trial 198 finished with value: 0.2666144888316826 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.00018979484517006473, 'p_miss': 0.2550344467231517}. Best is trial 152 with value: 0.26460726112316235.
running
[I 2024-11-12 22:29:45,153] Trial 199 finished with value: 0.26615984173182133 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 3, 'learning_rate': 0.00014034050920377588, 'p_miss': 0.25088155297196024}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 22:47:44,082] Trial 113 finished with value: 0.3158539108773972 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 4214, 'learning_rate': 0.0004560972320984691, 'p_miss': 0.050010114901179376}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:00:24,469] Trial 123 finished with value: 0.31370470750808954 and parameters: {'model_name': 'VAE', 'batch_size': 107, 'iterations': 4624, 'learning_rate': 0.00015409128782018896, 'p_miss': 0.09522285296945676}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:02:29,722] Trial 36 finished with value: 0.36834444163346347 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8622, 'learning_rate': 0.007898176745547617, 'p_miss': 0.18534657602211757}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:04:00,751] Trial 99 finished with value: 0.3133493452289333 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 5552, 'learning_rate': 0.0002044980072374844, 'p_miss': 0.1034784072870168}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:09:32,113] Trial 115 finished with value: 0.3168798001482818 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 4094, 'learning_rate': 0.0004121289225708955, 'p_miss': 0.064809559535038}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:21:26,990] Trial 104 finished with value: 0.32099722734057107 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 6039, 'learning_rate': 0.000123281302702778, 'p_miss': 0.2757318616653644}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-12 23:30:13,292] Trial 124 finished with value: 0.31360458299731386 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 5540, 'learning_rate': 0.00015334428223666479, 'p_miss': 0.027809936097543366}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:21:51,563] Trial 109 finished with value: 0.3193271246195172 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 6878, 'learning_rate': 0.0003789008307747351, 'p_miss': 0.09647367385356813}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:22:01,611] Trial 132 finished with value: 0.32173054960045466 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 5563, 'learning_rate': 0.0007320307666016708, 'p_miss': 0.18667367769208706}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:28:33,554] Trial 107 finished with value: 0.32033964569011614 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 9709, 'learning_rate': 0.0002656738180405093, 'p_miss': 0.09428590096746986}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:30:25,773] Trial 126 finished with value: 0.32056506612215285 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 7788, 'learning_rate': 0.0001976336079667087, 'p_miss': 0.07649703758872993}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:31:11,304] Trial 150 finished with value: 0.3197808286423528 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 6705, 'learning_rate': 0.00014479498423945882, 'p_miss': 0.03366283196498001}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:36:09,621] Trial 183 finished with value: 0.3193322316299624 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 7906, 'learning_rate': 0.0038485900235750822, 'p_miss': 0.06718963430531118}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:37:02,692] Trial 146 finished with value: 0.3216845193682475 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 8676, 'learning_rate': 0.00019223546964287265, 'p_miss': 0.01850978970476287}. Best is trial 152 with value: 0.26460726112316235.
[I 2024-11-13 00:37:13,469] Trial 163 finished with value: 0.315902071576826 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 9040, 'learning_rate': 0.00013949507427857987, 'p_miss': 0.036303394724000265}. Best is trial 152 with value: 0.26460726112316235.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.26460726112316235
{'model_name': 'VAE', 'batch_size': 32, 'iterations': 11, 'learning_rate': 0.0001166683912521255, 'p_miss': 0.03447558794308665}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a54b0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.05938572291422668
Generation:   4%|▍         | 1/25 [08:10<3:16:02, 490.11s/it]Generation:  2
Best f1_score score: 0.05938572291422668
Generation:   8%|▊         | 2/25 [10:21<1:46:54, 278.88s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474737340> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474736a10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f80a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.05938572291422668
Generation:  12%|█▏        | 3/25 [20:19<2:35:48, 424.93s/it]Generation:  4
Best f1_score score: 0.06148380245615106
Generation:  16%|█▌        | 4/25 [28:53<2:40:54, 459.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f08430> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747166e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.06148380245615106
Generation:  20%|██        | 5/25 [37:17<2:38:36, 475.82s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546592b580> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.06148380245615106
Generation:  24%|██▍       | 6/25 [45:26<2:32:08, 480.46s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f091e0> 

Generation:  7
Best f1_score score: 0.06148380245615106
Generation:  28%|██▊       | 7/25 [55:34<2:36:37, 522.08s/it]Generation:  8
Best f1_score score: 0.062499795512400994
Generation:  32%|███▏      | 8/25 [1:05:33<2:34:52, 546.61s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4f10> 

Generation:  9
Best f1_score score: 0.062499795512400994
Generation:  36%|███▌      | 9/25 [1:15:42<2:30:56, 566.01s/it]Generation:  10
Best f1_score score: 0.062499795512400994
Generation:  40%|████      | 10/25 [1:23:38<2:14:34, 538.32s/it]Generation:  11
Best f1_score score: 0.062499795512400994
Generation:  44%|████▍     | 11/25 [1:26:14<1:38:15, 421.13s/it]Generation:  12
Best f1_score score: 0.06308661280777364
Generation:  48%|████▊     | 12/25 [1:35:17<1:39:18, 458.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a7310> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  13
Best f1_score score: 0.06308661280777364
Generation:  52%|█████▏    | 13/25 [1:45:08<1:39:42, 498.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465014a60> 

Generation:  14
Best f1_score score: 0.06308661280777364
Generation:  56%|█████▌    | 14/25 [1:55:20<1:37:40, 532.81s/it]Generation:  15
Best f1_score score: 0.06308661280777364
Generation:  60%|██████    | 15/25 [2:02:12<1:22:44, 496.41s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b6bbe0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747356c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.06308661280777364
Generation:  64%|██████▍   | 16/25 [2:03:00<54:12, 361.35s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29db0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465980580> 

Generation:  17
Best f1_score score: 0.06308661280777364
Generation:  68%|██████▊   | 17/25 [2:13:13<58:15, 436.99s/it]Generation:  18
Best f1_score score: 0.06358130263718562
Generation:  72%|███████▏  | 18/25 [2:19:47<49:28, 424.05s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b19c00> 

Generation:  19
Best f1_score score: 0.06358130263718562
Generation:  76%|███████▌  | 19/25 [2:30:00<48:05, 480.91s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455b9d9f0> 

Generation:  20
Best f1_score score: 0.06358130263718562
Generation:  80%|████████  | 20/25 [2:40:15<43:25, 521.08s/it]Generation:  21
Best f1_score score: 0.06358130263718562
Generation:  84%|████████▍ | 21/25 [2:50:12<36:16, 544.05s/it]Generation:  22
Best f1_score score: 0.06358130263718562
Generation:  88%|████████▊ | 22/25 [2:57:43<25:47, 515.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546785c610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  23
Best f1_score score: 0.06358130263718562
Generation:  92%|█████████▏| 23/25 [3:01:18<14:11, 425.56s/it]Generation:  24
Best f1_score score: 0.06358130263718562
Generation:  96%|█████████▌| 24/25 [3:02:36<05:21, 321.31s/it]Generation:  25
Best f1_score score: 0.06358130263718562
Generation: 100%|██████████| 25/25 [3:09:39<00:00, 351.87s/it]Generation: 100%|██████████| 25/25 [3:09:42<00:00, 455.32s/it]
2024-11-13 03:47:23,512 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41855' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-04ef1e3a7246aa787bf6714e77e9803f', 'ndarray-65b17e71b1ef73bab3bdacc1f8094c6d'} (stimulus_id='handle-worker-cleanup-1731498443.5119472')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        max_features=0.7481363427544,
                                        min_samples_split=18,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9932689829010886, 'accuracy': 0.8944929602566387, 'balanced_accuracy': 0.9556993834824312, 'logloss': 1.617679458157714, 'f1': 0.8550917162781713}
original test score: {'auroc': 0.5234961767620653, 'accuracy': 0.10869565217391304, 'balanced_accuracy': 0.052829179819692214, 'logloss': 2.6687841353129826, 'f1': 0.04996299863967893}
imputed test score: {'auroc': 0.5178131073689849, 'accuracy': 0.08660014255167499, 'balanced_accuracy': 0.052424285845366986, 'logloss': 2.7613879524378206, 'f1': 0.05113118150197415}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4dc0> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4f10> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4c40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ca0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5120> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

malloc(): invalid next size (unsorted)
2024-11-13 03:49:38,714 - distributed.nanny - WARNING - Restarting worker
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
malloc(): invalid next size (unsorted)
2024-11-13 03:51:38,860 - distributed.scheduler - ERROR - Task eval_objective_list-b4af8aaf6c6c93205bd4c6cee6b67cd0 marked as failed because 2 workers died while trying to run it
Exception in future
Attempted to run task 'eval_objective_list-b4af8aaf6c6c93205bd4c6cee6b67cd0' on 2 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:35259. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.
2024-11-13 03:51:38,871 - distributed.nanny - WARNING - Restarting worker
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ca0> 

Generation:  1
Best f1_score score: 0.24519148205148386
Generation:   4%|▍         | 1/25 [10:04<4:01:44, 604.34s/it]Generation:  2
Best f1_score score: 0.24519148205148386
Generation:   8%|▊         | 2/25 [15:08<2:43:55, 427.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e111e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.25580754198823963
Generation:  12%|█▏        | 3/25 [24:57<3:03:48, 501.30s/it]Generation:  4
Best f1_score score: 0.2585600140471628
Generation:  16%|█▌        | 4/25 [34:48<3:07:50, 536.68s/it]Generation:  5
Best f1_score score: 0.2585600140471628
Generation:  20%|██        | 5/25 [39:54<2:31:11, 453.57s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659dc430> 

Generation:  6
Best f1_score score: 0.25890241138118925
Generation:  24%|██▍       | 6/25 [49:58<2:39:51, 504.80s/it]Generation:  7
Best f1_score score: 0.2694464419363627
Generation:  28%|██▊       | 7/25 [51:34<1:51:22, 371.27s/it]Generation:  8
Best f1_score score: 0.2867007207381001
Generation:  32%|███▏      | 8/25 [53:57<1:24:32, 298.38s/it]Generation:  9
Best f1_score score: 0.2867007207381001
Generation:  36%|███▌      | 9/25 [56:53<1:09:21, 260.10s/it]Generation:  10
Best f1_score score: 0.2908328522505272
Generation:  40%|████      | 10/25 [1:06:44<1:30:36, 362.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467b76ce0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657e9ed0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a43d0> 

Generation:  11
Best f1_score score: 0.2908328522505272
Generation:  44%|████▍     | 11/25 [1:16:53<1:42:10, 437.91s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650cebc0> 

Generation:  12
Best f1_score score: 0.30302013623048485
Generation:  48%|████▊     | 12/25 [1:27:02<1:46:08, 489.87s/it]Generation:  13
Best f1_score score: 0.30302013623048485
Generation:  52%|█████▏    | 13/25 [1:29:06<1:15:47, 378.95s/it]Generation:  14
Best f1_score score: 0.30302013623048485
Generation:  56%|█████▌    | 14/25 [1:33:18<1:02:29, 340.84s/it]Generation:  15
Best f1_score score: 0.30302013623048485
Generation:  60%|██████    | 15/25 [1:37:40<52:50, 317.06s/it]  Generation:  16
Best f1_score score: 0.3097485002039892
Generation:  64%|██████▍   | 16/25 [1:41:20<43:09, 287.75s/it]Generation:  17
Best f1_score score: 0.3131632997874078
Generation:  68%|██████▊   | 17/25 [1:46:10<38:26, 288.37s/it]Generation:  18
Best f1_score score: 0.3131632997874078
Generation:  72%|███████▏  | 18/25 [1:48:27<28:19, 242.83s/it]Generation:  19
Best f1_score score: 0.3131632997874078
Generation:  76%|███████▌  | 19/25 [1:49:57<19:42, 197.04s/it]Generation:  20
Best f1_score score: 0.3131632997874078
Generation:  80%|████████  | 20/25 [1:52:01<14:35, 175.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b6de10> 

Generation:  21
Best f1_score score: 0.3131632997874078
Generation:  84%|████████▍ | 21/25 [2:02:10<20:21, 305.30s/it]Generation:  22
Best f1_score score: 0.3131632997874078
Generation:  88%|████████▊ | 22/25 [2:04:49<13:04, 261.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554505a16f0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  23
Best f1_score score: 0.3131632997874078
Generation:  92%|█████████▏| 23/25 [2:06:13<06:56, 208.09s/it]Generation:  24
Best f1_score score: 0.3131632997874078
Generation:  96%|█████████▌| 24/25 [2:12:08<04:12, 252.12s/it]Generation:  25
Best f1_score score: 0.31320519074315206
Generation: 100%|██████████| 25/25 [2:17:18<00:00, 269.59s/it]Generation: 100%|██████████| 25/25 [2:17:18<00:00, 329.54s/it]
2024-11-13 06:05:22,971 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33331' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-d7652410fb22ae07744ec1be32c840fb', 'ndarray-04ef1e3a7246aa787bf6714e77e9803f'} (stimulus_id='handle-worker-cleanup-1731506722.971634')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=True,
                                                l2_regularization=0.0825086979719,
                                                learning_rate=0.0488878314443,
                                                max_features=0.772502612657,
                                                max_leaf_nodes=828,
                                                min_samples_leaf=69, tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9613658698107473, 'accuracy': 0.5753430761005168, 'balanced_accuracy': 0.5170282043196495, 'logloss': 1.163960820163965, 'f1': 0.5557234639035061}
test score: {'auroc': 0.8766583201314511, 'accuracy': 0.34515324305060585, 'balanced_accuracy': 0.2576548702001641, 'logloss': 1.8442958320720597, 'f1': 0.281196259818812}
original test score: {'auroc': 0.9714838276383269, 'accuracy': 0.6699928724162509, 'balanced_accuracy': 0.6296973504371477, 'logloss': 0.9516438195718637, 'f1': 0.6245362860920058}
score end
1481
lvl
0.5
type
MAR
num_run
1
class_full
finished
all finished
full run takes
13.577575383252567
hours
DONE
