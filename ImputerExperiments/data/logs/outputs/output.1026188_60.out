Run: 60
/cm/local/apps/slurm/var/spool/job1026188/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/737/737.pkl
working on 
../data/c/737/class_full_MNAR_0.5_3
0.40441107749938965
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-26 18:04:59,784] A new study created in memory with name: no-name-c7c3a38c-4813-4dd9-a74b-f6329c548e57
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-26 18:05:00,013] Trial 11 finished with value: 0.22264149207531317 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.22264149207531317.
running
[I 2024-10-26 18:05:00,238] Trial 14 finished with value: 0.4050542579098228 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 11 with value: 0.22264149207531317.
running
[I 2024-10-26 18:05:00,617] Trial 5 finished with value: 0.22264149207531317 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2231, 'weights': 'uniform'}. Best is trial 11 with value: 0.22264149207531317.
[I 2024-10-26 18:05:00,721] Trial 0 finished with value: 0.26262365839765495 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2049, 'weights': 'distance'}. Best is trial 11 with value: 0.22264149207531317.
running
running
[I 2024-10-26 18:05:00,887] Trial 18 finished with value: 0.22264149207531317 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.22264149207531317.
running
[I 2024-10-26 18:05:01,055] Trial 2 finished with value: 0.26262365839765495 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2313, 'weights': 'distance'}. Best is trial 11 with value: 0.22264149207531317.
running
[I 2024-10-26 18:05:01,342] Trial 19 finished with value: 0.4050542579098228 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 11 with value: 0.22264149207531317.
running
[I 2024-10-26 18:05:01,479] Trial 7 finished with value: 0.22298695889817374 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1753, 'weights': 'uniform'}. Best is trial 11 with value: 0.22264149207531317.
[I 2024-10-26 18:05:01,583] Trial 17 finished with value: 0.2196606300348692 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 258, 'weights': 'uniform'}. Best is trial 17 with value: 0.2196606300348692.
running
running
[I 2024-10-26 18:05:01,696] Trial 10 finished with value: 0.26262365839765495 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2019, 'weights': 'distance'}. Best is trial 17 with value: 0.2196606300348692.
running
[I 2024-10-26 18:05:02,068] Trial 22 finished with value: 0.22264149207531317 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2019, 'weights': 'uniform'}. Best is trial 17 with value: 0.2196606300348692.
running
[I 2024-10-26 18:05:03,684] Trial 26 finished with value: 0.2138742764591426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 26 with value: 0.2138742764591426.
[I 2024-10-26 18:05:03,687] Trial 9 finished with value: 0.23216659231289238 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.2138742764591426.
running
running
[I 2024-10-26 18:05:07,169] Trial 8 finished with value: 0.3603068292572247 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.6527679072458515, 'alpha': 38, 'iterations': 1, 'learning_rate': 0.0006575756282994463, 'p_miss': 0.2908494512761652}. Best is trial 26 with value: 0.2138742764591426.
running
[I 2024-10-26 18:05:07,849] Trial 25 finished with value: 0.1472128589299476 and parameters: {'model_name': 'VAE', 'batch_size': 298, 'iterations': 1, 'learning_rate': 0.08842902766802953, 'p_miss': 0.18221436208983888}. Best is trial 25 with value: 0.1472128589299476.
running
[I 2024-10-26 18:05:08,748] Trial 23 finished with value: 0.38754676165842855 and parameters: {'model_name': 'GAIN', 'batch_size': 31, 'hint_rate': 0.13270292266271988, 'alpha': 58, 'iterations': 2, 'learning_rate': 0.03918703617271774, 'p_miss': 0.12980267434817536}. Best is trial 25 with value: 0.1472128589299476.
running
[I 2024-10-26 18:05:30,336] Trial 20 finished with value: 0.2593947243976251 and parameters: {'model_name': 'VAE', 'batch_size': 367, 'iterations': 4, 'learning_rate': 0.046779020662431295, 'p_miss': 0.06460542447784412}. Best is trial 25 with value: 0.1472128589299476.
running
[I 2024-10-26 18:05:30,756] Trial 6 finished with value: 0.14502346296690688 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.005396879690886742, 'p_miss': 0.19555997022696464}. Best is trial 6 with value: 0.14502346296690688.
running
[I 2024-10-26 18:05:44,237] Trial 27 finished with value: 0.1438271434672626 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 9, 'learning_rate': 0.00027688677820971044, 'p_miss': 0.019743761500556845}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:06:37,242] Trial 3 finished with value: 0.38119920443810107 and parameters: {'model_name': 'GAIN', 'batch_size': 373, 'hint_rate': 0.3342208410419049, 'alpha': 70, 'iterations': 48, 'learning_rate': 0.0001713744900639507, 'p_miss': 0.16789257035552912}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:10:49,674] Trial 35 finished with value: 0.2191498214440753 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 73, 'learning_rate': 0.002827230732566435, 'p_miss': 0.01502142534511347}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:11:10,021] Trial 12 finished with value: 0.22637931665749284 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 106, 'learning_rate': 0.02060703095680634, 'p_miss': 0.2980430317873341}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:11:39,917] Trial 37 finished with value: 0.14677958110927009 and parameters: {'model_name': 'VAE', 'batch_size': 127, 'iterations': 7, 'learning_rate': 0.005081396630739976, 'p_miss': 0.19233754645075582}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:11:43,761] Trial 36 finished with value: 0.16610538319510193 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 10, 'learning_rate': 0.0064583349938403325, 'p_miss': 0.20568655938717118}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:12:19,784] Trial 13 finished with value: 0.3965917385955184 and parameters: {'model_name': 'GAIN', 'batch_size': 91, 'hint_rate': 0.31858769524794245, 'alpha': 1, 'iterations': 247, 'learning_rate': 0.001415228122523595, 'p_miss': 0.1020734301505371}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:12:33,658] Trial 38 finished with value: 0.15044057277124814 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 13, 'learning_rate': 0.004391953511003509, 'p_miss': 0.2202315907335477}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:15:09,795] Trial 21 finished with value: 0.2275571055274289 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 27 with value: 0.1438271434672626.
running
[I 2024-10-26 18:15:52,539] Trial 34 finished with value: 0.13632243960542464 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 174, 'learning_rate': 0.00013340625298305126, 'p_miss': 0.0264612380701036}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 18:15:55,809] Trial 4 finished with value: 0.22632744394556292 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 18:19:18,921] Trial 15 finished with value: 0.14145293279936114 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 227, 'learning_rate': 0.00017339665805076525, 'p_miss': 0.2985255444873198}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 18:21:20,045] Trial 16 finished with value: 0.2180961992769806 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 274, 'learning_rate': 0.0008700994231642719, 'p_miss': 0.2128462970607856}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 18:22:16,226] Trial 30 finished with value: 0.2313249864707625 and parameters: {'model_name': 'VAE', 'batch_size': 981, 'iterations': 246, 'learning_rate': 0.09681158857244927, 'p_miss': 0.1077425642085917}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 18:27:37,437] Trial 33 finished with value: 0.262882034197563 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 399, 'learning_rate': 0.004599130606777768, 'p_miss': 0.21935654823745293}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 19:34:28,123] Trial 28 finished with value: 0.24143718389511717 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 1691, 'learning_rate': 0.01002198002061807, 'p_miss': 0.04455447542872727}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 19:35:47,032] Trial 49 finished with value: 0.15279601492126382 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 21, 'learning_rate': 0.00010146899012205032, 'p_miss': 0.03641091085068546}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 19:58:28,094] Trial 41 finished with value: 0.21347236616662602 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1833, 'learning_rate': 0.00010482146699843598, 'p_miss': 0.23516888318873458}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:00:32,576] Trial 51 finished with value: 0.14651914263779536 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 42, 'learning_rate': 0.00027907966778820413, 'p_miss': 0.2533673020528786}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:12:40,077] Trial 42 finished with value: 0.24724821358953247 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2032, 'learning_rate': 0.009669538351284304, 'p_miss': 0.2405063595283462}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:12:50,898] Trial 53 finished with value: 0.1406911403407337 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 3, 'learning_rate': 0.00033135594034445495, 'p_miss': 0.07546804237181218}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:18:16,061] Trial 39 finished with value: 0.24355656936092332 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2106, 'learning_rate': 0.0034239831545391976, 'p_miss': 0.2307048609668271}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:20:33,545] Trial 46 finished with value: 0.23453148507125815 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1878, 'learning_rate': 0.00014296189378347303, 'p_miss': 0.01348696613804548}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:20:44,196] Trial 56 finished with value: 0.13996034500165364 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 3, 'learning_rate': 0.00033312145853607643, 'p_miss': 0.07134807432557999}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:20:54,675] Trial 57 finished with value: 0.14688241167207355 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 3, 'learning_rate': 0.00030669678506186563, 'p_miss': 0.0717411816749512}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:24:47,281] Trial 43 finished with value: 0.2405518602321884 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2297, 'learning_rate': 0.0001529856399924662, 'p_miss': 0.0109091850474228}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:24:48,356] Trial 55 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.9870049092032538, 'alpha': 98, 'iterations': 660, 'learning_rate': 0.00033546218779308877, 'p_miss': 0.06867095258016019}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:24:52,866] Trial 60 finished with value: 0.21834931214773506 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:04,475] Trial 61 finished with value: 0.1366817210322671 and parameters: {'model_name': 'VAE', 'batch_size': 148, 'iterations': 2, 'learning_rate': 0.0006216201482774384, 'p_miss': 0.039347451101434186}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:10,761] Trial 62 finished with value: 0.13727374571570208 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.000500848983741141, 'p_miss': 0.15264704246568642}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:16,984] Trial 63 finished with value: 0.1440350457227113 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.000540757857890638, 'p_miss': 0.14477514841709346}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:18,189] Trial 64 finished with value: 0.26167060710841283 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 700, 'weights': 'distance'}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:18,515] Trial 65 finished with value: 0.29030997297167777 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:22,295] Trial 66 finished with value: 0.13738429822247009 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00045350039720285456, 'p_miss': 0.08709514976304548}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:26,675] Trial 67 finished with value: 0.14167250475610838 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0011968263820335595, 'p_miss': 0.09177982528016927}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:34,102] Trial 68 finished with value: 0.13714530938329372 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.00048249673596055125, 'p_miss': 0.0463355514590414}. Best is trial 34 with value: 0.13632243960542464.
running
[I 2024-10-26 20:25:37,871] Trial 69 finished with value: 0.13357523691112141 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0005748188827870552, 'p_miss': 0.046041975863090306}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:38,611] Trial 70 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7629411966716848, 'alpha': 0, 'iterations': 1, 'learning_rate': 0.0004773098085300425, 'p_miss': 0.044898396795750924}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:45,160] Trial 71 finished with value: 0.14498670617794313 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.0008827401955007832, 'p_miss': 0.03928366371175305}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:48,672] Trial 72 finished with value: 0.2122259798833336 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:48,907] Trial 73 finished with value: 0.4050542579098228 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:49,819] Trial 74 finished with value: 0.22239304666211943 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1241, 'weights': 'uniform'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:25:54,217] Trial 75 finished with value: 0.13672343667224846 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0018278609636314426, 'p_miss': 0.05269041978610445}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:31:12,965] Trial 50 finished with value: 0.17852032068525897 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1235, 'learning_rate': 0.00027090476606370204, 'p_miss': 0.25320403415020637}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:32:42,840] Trial 47 finished with value: 0.23845108551838337 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2288, 'learning_rate': 0.00012105743828632035, 'p_miss': 0.020472125087242683}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:32:47,913] Trial 78 finished with value: 0.14334611265867564 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0016499209886540105, 'p_miss': 0.052361644164070756}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:32:54,383] Trial 79 finished with value: 0.14037605172386708 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0007887680430716733, 'p_miss': 0.030408325001218664}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:33:17,788] Trial 52 finished with value: 0.19803045208315634 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 673, 'learning_rate': 0.00025459717372766595, 'p_miss': 0.07452281595825638}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:33:37,376] Trial 32 finished with value: 0.23125916916030365 and parameters: {'model_name': 'VAE', 'batch_size': 994, 'iterations': 2347, 'learning_rate': 0.004345651498692454, 'p_miss': 0.23576912728627625}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:34:17,457] Trial 82 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.014951489915059735, 'alpha': 35, 'iterations': 142, 'learning_rate': 0.0005031909495490359, 'p_miss': 0.05321144921640952}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:34:32,205] Trial 83 finished with value: 0.13686212942885403 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4, 'learning_rate': 0.0016270591970027025, 'p_miss': 0.10297211779106483}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:34:47,638] Trial 84 finished with value: 0.13859717361166202 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0016524170982249742, 'p_miss': 0.118999639750266}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:34:59,810] Trial 85 finished with value: 0.13940029780392443 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0021418467841943364, 'p_miss': 0.16341093685525696}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:35:04,040] Trial 86 finished with value: 0.13638322554765225 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.001136813005791946, 'p_miss': 0.055064439584543434}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:35:10,991] Trial 87 finished with value: 0.1380517372434752 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0010972791419208386, 'p_miss': 0.05376409059549862}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:35:16,597] Trial 88 finished with value: 0.14169622303232365 and parameters: {'model_name': 'VAE', 'batch_size': 205, 'iterations': 1, 'learning_rate': 0.0007585136163397208, 'p_miss': 0.027371511929478655}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:35:23,817] Trial 89 finished with value: 0.1377099267846255 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.002285870193533332, 'p_miss': 0.1403032730701625}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:35:31,165] Trial 90 finished with value: 0.21958662975983181 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:39:15,493] Trial 81 finished with value: 0.21586452393434702 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 110, 'learning_rate': 0.001928811759161465, 'p_miss': 0.05606132061598772}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:39:15,898] Trial 92 finished with value: 0.29030997297167777 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:39:38,983] Trial 93 finished with value: 0.13767375817125083 and parameters: {'model_name': 'VAE', 'batch_size': 492, 'iterations': 4, 'learning_rate': 0.0006443498210794039, 'p_miss': 0.1016361769243909}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:39:39,671] Trial 94 finished with value: 0.2826450032054379 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3, 'weights': 'distance'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:40:32,848] Trial 80 finished with value: 0.23747495826870554 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 141, 'learning_rate': 0.00210613955210951, 'p_miss': 0.05917633770207155}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:40:37,556] Trial 96 finished with value: 0.1401259042312974 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00121779856019734, 'p_miss': 0.08766096449881645}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:40:41,892] Trial 97 finished with value: 0.14381060970638315 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00042002640512597914, 'p_miss': 0.0873418896624133}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:42:33,819] Trial 95 finished with value: 0.14244030539054997 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 42, 'learning_rate': 0.0011200333046371244, 'p_miss': 0.031866247374760306}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:42:40,527] Trial 99 finished with value: 0.13804271464023551 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.00018895688414911517, 'p_miss': 0.0449511022331857}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:42:54,367] Trial 100 finished with value: 0.13829255420556713 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0006792794667097918, 'p_miss': 0.1133847282623884}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:42:58,868] Trial 101 finished with value: 0.13870998379866684 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0009175329898396537, 'p_miss': 0.0249857432017547}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:43:19,158] Trial 102 finished with value: 0.13653019194009283 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0004073309874660459, 'p_miss': 0.1817312568293351}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:43:53,492] Trial 103 finished with value: 0.1365410607074209 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8, 'learning_rate': 0.0002114327128002504, 'p_miss': 0.18132707877219367}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:44:23,855] Trial 104 finished with value: 0.13886085408016713 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 7, 'learning_rate': 0.00020475225567915842, 'p_miss': 0.1784005511404535}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:44:51,531] Trial 91 finished with value: 0.19423222105523325 and parameters: {'model_name': 'VAE', 'batch_size': 642, 'iterations': 117, 'learning_rate': 0.0010375466720459069, 'p_miss': 0.06022186552700121}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:44:55,399] Trial 105 finished with value: 0.37600592339836264 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.925594882678302, 'alpha': 97, 'iterations': 17, 'learning_rate': 0.0002168149175011865, 'p_miss': 0.20193497248006853}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:45:16,987] Trial 107 finished with value: 0.14117884650803708 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 5, 'learning_rate': 0.000588040036873433, 'p_miss': 0.17586000689863412}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:45:51,083] Trial 106 finished with value: 0.13771381163417046 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 13, 'learning_rate': 0.0005556082086809776, 'p_miss': 0.18348040743517785}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:45:54,709] Trial 108 finished with value: 0.13969932607633323 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 9, 'learning_rate': 0.0003897779676427831, 'p_miss': 0.16115847907145142}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:46:10,784] Trial 110 finished with value: 0.13894233533751627 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 3, 'learning_rate': 0.002832629703419835, 'p_miss': 0.04150955028307196}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:46:19,088] Trial 59 finished with value: 0.3952516806866774 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.9138202727086837, 'alpha': 100, 'iterations': 871, 'learning_rate': 0.0003396763000126102, 'p_miss': 0.0667402311036322}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:46:30,424] Trial 109 finished with value: 0.1353284879389353 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 9, 'learning_rate': 0.00039275331693103494, 'p_miss': 0.1611299475527382}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:49:15,617] Trial 45 finished with value: 0.23945857341898721 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 2797, 'learning_rate': 0.00010407098009293748, 'p_miss': 0.029276440620314037}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:49:36,764] Trial 114 finished with value: 0.1381884540967496 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 6, 'learning_rate': 0.00015676297206422934, 'p_miss': 0.1954487016746111}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:49:50,235] Trial 115 finished with value: 0.2958572339315006 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:50:09,740] Trial 116 finished with value: 0.13493864415537948 and parameters: {'model_name': 'VAE', 'batch_size': 199, 'iterations': 4, 'learning_rate': 0.0013964147185672455, 'p_miss': 0.15651973073482983}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:51:06,799] Trial 117 finished with value: 0.13991101065685052 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 10, 'learning_rate': 0.0015814839621263131, 'p_miss': 0.13112453293637313}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:51:17,041] Trial 112 finished with value: 0.16917107227422842 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 72, 'learning_rate': 0.001317284645584415, 'p_miss': 0.13348371377521473}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:51:38,084] Trial 119 finished with value: 0.1379874402229134 and parameters: {'model_name': 'VAE', 'batch_size': 212, 'iterations': 4, 'learning_rate': 0.00012854128419107017, 'p_miss': 0.1527302452897545}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:52:01,044] Trial 120 finished with value: 0.14277975248534389 and parameters: {'model_name': 'VAE', 'batch_size': 159, 'iterations': 6, 'learning_rate': 0.0003973994619170856, 'p_miss': 0.17089431743854583}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:52:01,386] Trial 121 finished with value: 0.4050542579098228 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:52:02,467] Trial 122 finished with value: 0.22250496234806488 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1270, 'weights': 'uniform'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:53:42,236] Trial 123 finished with value: 0.13600504641230035 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 29, 'learning_rate': 0.00023472743066476075, 'p_miss': 0.19011924237490074}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:55:50,841] Trial 58 finished with value: 0.2014629483185424 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 634, 'learning_rate': 0.00033501206069616206, 'p_miss': 0.06276359427645861}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:57:23,983] Trial 54 finished with value: 0.2234729949922738 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 751, 'learning_rate': 0.00033960687738730674, 'p_miss': 0.0693199108406708}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:58:32,256] Trial 1 finished with value: 0.2287953113427707 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 3373, 'learning_rate': 0.05851035662899659, 'p_miss': 0.010368303234134632}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 20:59:22,506] Trial 126 finished with value: 0.14073092712256158 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 28, 'learning_rate': 0.00024116570131656577, 'p_miss': 0.18729086350212965}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:00:13,894] Trial 128 finished with value: 0.14642801028676447 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 13, 'learning_rate': 0.003430123586493608, 'p_miss': 0.20326672827659656}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:00:23,912] Trial 127 finished with value: 0.1378496255086898 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 26, 'learning_rate': 0.00021326833603213573, 'p_miss': 0.1867512362521235}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:00:57,290] Trial 130 finished with value: 0.13680227544577814 and parameters: {'model_name': 'VAE', 'batch_size': 263, 'iterations': 7, 'learning_rate': 0.00017927181533194332, 'p_miss': 0.166751286162884}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:01:30,582] Trial 131 finished with value: 0.1439882433159581 and parameters: {'model_name': 'VAE', 'batch_size': 309, 'iterations': 7, 'learning_rate': 0.0001701974989093804, 'p_miss': 0.1691471430145574}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:02:13,362] Trial 129 finished with value: 0.13749031205803844 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 32, 'learning_rate': 0.00017478658196204666, 'p_miss': 0.16957148951815834}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:06:08,471] Trial 48 finished with value: 0.2426660507017666 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 3085, 'learning_rate': 0.00011632842465837574, 'p_miss': 0.018597574689658336}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:07:59,686] Trial 31 finished with value: 0.23061316162367404 and parameters: {'model_name': 'VAE', 'batch_size': 991, 'iterations': 2749, 'learning_rate': 0.0947280961451742, 'p_miss': 0.22268071176057658}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:15:52,260] Trial 133 finished with value: 0.14711437762128216 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 200, 'learning_rate': 0.00012424244799661276, 'p_miss': 0.14723826563466433}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:16:12,920] Trial 136 finished with value: 0.14032390166085912 and parameters: {'model_name': 'VAE', 'batch_size': 92, 'iterations': 5, 'learning_rate': 0.0002603450768511287, 'p_miss': 0.1622745451216429}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:17:43,017] Trial 137 finished with value: 0.1459830720933088 and parameters: {'model_name': 'VAE', 'batch_size': 393, 'iterations': 16, 'learning_rate': 0.0014467480221788483, 'p_miss': 0.04949001510830617}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:17:55,239] Trial 138 finished with value: 0.13537043596357456 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 3, 'learning_rate': 0.0007683298968152736, 'p_miss': 0.03702785560617421}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:18:35,560] Trial 139 finished with value: 0.14179022834866895 and parameters: {'model_name': 'VAE', 'batch_size': 267, 'iterations': 10, 'learning_rate': 0.0009675241384745021, 'p_miss': 0.035235425832397985}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:19:30,081] Trial 134 finished with value: 0.15302852053442736 and parameters: {'model_name': 'VAE', 'batch_size': 148, 'iterations': 199, 'learning_rate': 0.0002588508900401953, 'p_miss': 0.2121838331827942}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:19:48,732] Trial 125 finished with value: 0.16622841103129588 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 337, 'learning_rate': 0.00023862089250428447, 'p_miss': 0.20877337506237406}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:19:54,672] Trial 141 finished with value: 0.13876174790270618 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 8, 'learning_rate': 0.0007398740283535923, 'p_miss': 0.02130269630607322}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:20:07,267] Trial 143 finished with value: 0.139881169000232 and parameters: {'model_name': 'VAE', 'batch_size': 176, 'iterations': 3, 'learning_rate': 0.0006256762216535143, 'p_miss': 0.17626642192545017}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:20:30,366] Trial 144 finished with value: 0.14384437248669418 and parameters: {'model_name': 'VAE', 'batch_size': 272, 'iterations': 5, 'learning_rate': 0.0018969522665210148, 'p_miss': 0.1586944063334083}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:20:47,265] Trial 145 finished with value: 0.14282983444875344 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 4, 'learning_rate': 0.00014218799697559846, 'p_miss': 0.010135514550210195}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:20:58,396] Trial 146 finished with value: 0.14417502153411438 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 3, 'learning_rate': 0.0008411118018164193, 'p_miss': 0.04888681441558416}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:21:13,602] Trial 147 finished with value: 0.1811706738682811 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.031155510607524865, 'p_miss': 0.04064443178385111}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:22:40,264] Trial 142 finished with value: 0.14422267314622705 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 56, 'learning_rate': 0.0007147633316511083, 'p_miss': 0.15774048768092852}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:22:50,364] Trial 149 finished with value: 0.2836319770563076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:23:36,789] Trial 150 finished with value: 0.1372874455394371 and parameters: {'model_name': 'VAE', 'batch_size': 118, 'iterations': 13, 'learning_rate': 0.0004569788199789985, 'p_miss': 0.02649626242709813}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:23:37,280] Trial 151 finished with value: 0.29030997297167777 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:26:19,516] Trial 132 finished with value: 0.15303984486485953 and parameters: {'model_name': 'VAE', 'batch_size': 148, 'iterations': 357, 'learning_rate': 0.00013519247341956949, 'p_miss': 0.1607012590618026}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:26:20,858] Trial 153 finished with value: 0.2618351253000606 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 805, 'weights': 'distance'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:26:46,705] Trial 154 finished with value: 0.1420112802052687 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 7, 'learning_rate': 0.0005810622563859264, 'p_miss': 0.03503251241777035}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:26:48,507] Trial 155 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.5184832789036075, 'alpha': 22, 'iterations': 5, 'learning_rate': 0.00039740735640015116, 'p_miss': 0.01755816917452066}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:26:58,851] Trial 156 finished with value: 0.13697348204644672 and parameters: {'model_name': 'VAE', 'batch_size': 353, 'iterations': 2, 'learning_rate': 0.0005145060333644839, 'p_miss': 0.15393855826587313}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:30:32,550] Trial 135 finished with value: 0.2314104640773759 and parameters: {'model_name': 'VAE', 'batch_size': 254, 'iterations': 389, 'learning_rate': 0.026155081536543365, 'p_miss': 0.1602017219420889}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:35:12,274] Trial 158 finished with value: 0.14246464172184498 and parameters: {'model_name': 'VAE', 'batch_size': 392, 'iterations': 86, 'learning_rate': 0.0004948484643115921, 'p_miss': 0.195208466960408}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:35:29,563] Trial 159 finished with value: 0.14353359108300448 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.000997372158640944, 'p_miss': 0.07793213314396236}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:35:41,449] Trial 160 finished with value: 0.13640102468948404 and parameters: {'model_name': 'VAE', 'batch_size': 415, 'iterations': 3, 'learning_rate': 0.0012948251250065777, 'p_miss': 0.12476509983670248}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:35:56,756] Trial 161 finished with value: 0.138086281295759 and parameters: {'model_name': 'VAE', 'batch_size': 750, 'iterations': 3, 'learning_rate': 0.0012840724433550482, 'p_miss': 0.13808092175835562}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:36:30,781] Trial 162 finished with value: 0.14090576216054823 and parameters: {'model_name': 'VAE', 'batch_size': 500, 'iterations': 8, 'learning_rate': 0.0014254758525479093, 'p_miss': 0.1187310028312529}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:36:51,159] Trial 163 finished with value: 0.14561074237476201 and parameters: {'model_name': 'VAE', 'batch_size': 362, 'iterations': 4, 'learning_rate': 0.00029984737446401845, 'p_miss': 0.14743203757199638}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:37:19,391] Trial 164 finished with value: 0.13852806599324924 and parameters: {'model_name': 'VAE', 'batch_size': 525, 'iterations': 5, 'learning_rate': 0.0025174414275289164, 'p_miss': 0.19028336076457453}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:37:38,476] Trial 165 finished with value: 0.14152326258510742 and parameters: {'model_name': 'VAE', 'batch_size': 444, 'iterations': 3, 'learning_rate': 0.0008810120158666716, 'p_miss': 0.12547311262599686}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:37:47,053] Trial 166 finished with value: 0.13548655907849563 and parameters: {'model_name': 'VAE', 'batch_size': 336, 'iterations': 2, 'learning_rate': 0.0017195696101658907, 'p_miss': 0.06264389395101481}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:37:55,744] Trial 167 finished with value: 0.14205260215835155 and parameters: {'model_name': 'VAE', 'batch_size': 221, 'iterations': 2, 'learning_rate': 0.001817758837662668, 'p_miss': 0.100180673814855}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:39:07,759] Trial 140 finished with value: 0.23150962523894694 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 379, 'learning_rate': 0.0008236901876213073, 'p_miss': 0.21012454628850982}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:39:17,814] Trial 169 finished with value: 0.1400908171767155 and parameters: {'model_name': 'VAE', 'batch_size': 301, 'iterations': 2, 'learning_rate': 0.0016555741806538315, 'p_miss': 0.1831477603837513}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 21:39:49,663] Trial 170 finished with value: 0.13500041060012757 and parameters: {'model_name': 'VAE', 'batch_size': 340, 'iterations': 6, 'learning_rate': 0.0023812619839343224, 'p_miss': 0.17327351142825304}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:11:00,397] Trial 44 finished with value: 0.24431352059570735 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4350, 'learning_rate': 0.00010707264729932493, 'p_miss': 0.026247249906994872}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:12:18,324] Trial 172 finished with value: 0.15105845663628817 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 11, 'learning_rate': 0.0025871544255628544, 'p_miss': 0.17488894783065448}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:12:47,645] Trial 173 finished with value: 0.13823995928891625 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.003168958571090829, 'p_miss': 0.061067042281081306}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:13:32,639] Trial 174 finished with value: 0.1369275857125824 and parameters: {'model_name': 'VAE', 'batch_size': 442, 'iterations': 8, 'learning_rate': 0.0011832502953050314, 'p_miss': 0.1691371663411992}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:15:36,093] Trial 175 finished with value: 0.14423708729277843 and parameters: {'model_name': 'VAE', 'batch_size': 637, 'iterations': 19, 'learning_rate': 0.0014637065670876426, 'p_miss': 0.18257996524885953}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:16:25,414] Trial 176 finished with value: 0.1393322345099687 and parameters: {'model_name': 'VAE', 'batch_size': 188, 'iterations': 8, 'learning_rate': 0.0010951226383481946, 'p_miss': 0.1718167638367643}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:17:21,832] Trial 177 finished with value: 0.14288198322750473 and parameters: {'model_name': 'VAE', 'batch_size': 236, 'iterations': 11, 'learning_rate': 0.0020022544065334737, 'p_miss': 0.1777556075071236}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:17:41,456] Trial 178 finished with value: 0.1369382465861197 and parameters: {'model_name': 'VAE', 'batch_size': 413, 'iterations': 4, 'learning_rate': 0.0011517936142853655, 'p_miss': 0.05508537412827453}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:18:20,928] Trial 179 finished with value: 0.14068052562664285 and parameters: {'model_name': 'VAE', 'batch_size': 583, 'iterations': 6, 'learning_rate': 0.0016501954256829619, 'p_miss': 0.167485149817202}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:19:11,971] Trial 180 finished with value: 0.1493510632101548 and parameters: {'model_name': 'VAE', 'batch_size': 440, 'iterations': 9, 'learning_rate': 0.0013625064830847316, 'p_miss': 0.04323896363311376}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:19:15,516] Trial 181 finished with value: 0.21222589788798024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:19:38,323] Trial 182 finished with value: 0.14068787074333328 and parameters: {'model_name': 'VAE', 'batch_size': 341, 'iterations': 4, 'learning_rate': 0.002248282442949305, 'p_miss': 0.16552904218303516}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:19:50,124] Trial 183 finished with value: 0.14152485766880962 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0018280028789648738, 'p_miss': 0.14189183617922313}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:20:14,252] Trial 184 finished with value: 0.13927495997787384 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 7, 'learning_rate': 0.00016387126742745752, 'p_miss': 0.06475735477835076}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:20:14,836] Trial 185 finished with value: 0.4050542579098228 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:20:41,007] Trial 186 finished with value: 0.14063658251701874 and parameters: {'model_name': 'VAE', 'batch_size': 742, 'iterations': 5, 'learning_rate': 0.0011968314413208683, 'p_miss': 0.056326795677867525}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:21:05,289] Trial 187 finished with value: 0.14156967308761575 and parameters: {'model_name': 'VAE', 'batch_size': 271, 'iterations': 4, 'learning_rate': 0.0011917516499977865, 'p_miss': 0.07985907619988744}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:21:32,045] Trial 188 finished with value: 0.13572435023762044 and parameters: {'model_name': 'VAE', 'batch_size': 442, 'iterations': 4, 'learning_rate': 0.0006689499737495436, 'p_miss': 0.04882422805100711}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:22:01,539] Trial 189 finished with value: 0.1395021587480929 and parameters: {'model_name': 'VAE', 'batch_size': 476, 'iterations': 5, 'learning_rate': 0.000687627894251426, 'p_miss': 0.0364583439659933}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:22:28,405] Trial 190 finished with value: 0.13569438875591472 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 7, 'learning_rate': 0.0009849015408947895, 'p_miss': 0.19907718087117046}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:22:29,639] Trial 191 finished with value: 0.2227466101648606 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1550, 'weights': 'uniform'}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:22:42,364] Trial 192 finished with value: 0.3988844074324556 and parameters: {'model_name': 'GAIN', 'batch_size': 41, 'hint_rate': 0.32822072560160565, 'alpha': 75, 'iterations': 6, 'learning_rate': 0.0006324422038232807, 'p_miss': 0.04636352941575177}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:22:56,763] Trial 193 finished with value: 0.1379768637439005 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 3, 'learning_rate': 0.00019669719978932676, 'p_miss': 0.20281722965948953}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:26:02,483] Trial 194 finished with value: 0.15072405013757328 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 54, 'learning_rate': 0.000985455301822948, 'p_miss': 0.031071934925565127}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:27:02,574] Trial 195 finished with value: 0.23418246517176922 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 14, 'learning_rate': 0.07468382619864498, 'p_miss': 0.1914517496618158}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:27:47,507] Trial 196 finished with value: 0.13856689649046183 and parameters: {'model_name': 'VAE', 'batch_size': 366, 'iterations': 8, 'learning_rate': 0.0007827761539242552, 'p_miss': 0.05004414021563639}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:28:16,836] Trial 197 finished with value: 0.139237531093799 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 7, 'learning_rate': 0.0015672180958583887, 'p_miss': 0.18644917786459467}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:29:03,648] Trial 198 finished with value: 0.13956872150844632 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 9, 'learning_rate': 0.001046306061494611, 'p_miss': 0.1997962366228522}. Best is trial 69 with value: 0.13357523691112141.
running
[I 2024-10-26 22:29:23,854] Trial 199 finished with value: 0.15066011458559667 and parameters: {'model_name': 'VAE', 'batch_size': 243, 'iterations': 5, 'learning_rate': 0.001348671139883272, 'p_miss': 0.03804914886122332}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 01:01:39,041] Trial 111 finished with value: 0.22984443163282903 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 4150, 'learning_rate': 0.00013675856344784538, 'p_miss': 0.19247271756108975}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 01:53:23,093] Trial 29 finished with value: 0.2308318866392026 and parameters: {'model_name': 'VAE', 'batch_size': 958, 'iterations': 7111, 'learning_rate': 0.09534350786783091, 'p_miss': 0.026420261486686997}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 02:26:17,319] Trial 98 finished with value: 0.22761379726735384 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6100, 'learning_rate': 0.00020284357303767436, 'p_miss': 0.04305106346740223}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 02:49:31,086] Trial 24 finished with value: 0.24264613898629417 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9506, 'learning_rate': 0.038323742430613796, 'p_miss': 0.04656849698821763}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 02:52:02,390] Trial 40 finished with value: 0.23636151654843346 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7871, 'learning_rate': 0.008249296778257396, 'p_miss': 0.2244009797863051}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:01:32,911] Trial 113 finished with value: 0.23025557590419504 and parameters: {'model_name': 'VAE', 'batch_size': 169, 'iterations': 6424, 'learning_rate': 0.0014722799627385815, 'p_miss': 0.19152998863283308}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:13:35,915] Trial 124 finished with value: 0.2285297686219429 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 7877, 'learning_rate': 0.00022250671518188659, 'p_miss': 0.18522619241579727}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:20:09,742] Trial 118 finished with value: 0.2298244720633363 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 6566, 'learning_rate': 0.0002383223565382537, 'p_miss': 0.17222787687261232}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:23:05,191] Trial 77 finished with value: 0.26226664366279745 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6678, 'learning_rate': 0.0018111920226079404, 'p_miss': 0.053634335482981035}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:25:56,681] Trial 148 finished with value: 0.23128971538348903 and parameters: {'model_name': 'VAE', 'batch_size': 373, 'iterations': 6591, 'learning_rate': 0.00043736457760470683, 'p_miss': 0.19033519882640532}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:31:26,609] Trial 152 finished with value: 0.23089686359018927 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 6825, 'learning_rate': 0.00028799826133010635, 'p_miss': 0.03504693877395286}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:37:28,387] Trial 171 finished with value: 0.23129126443971781 and parameters: {'model_name': 'VAE', 'batch_size': 301, 'iterations': 7336, 'learning_rate': 0.002367274147286882, 'p_miss': 0.17351092320364195}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:38:16,261] Trial 168 finished with value: 0.23024833310246176 and parameters: {'model_name': 'VAE', 'batch_size': 698, 'iterations': 7539, 'learning_rate': 0.0015653729568357012, 'p_miss': 0.18208136590200377}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:39:22,577] Trial 157 finished with value: 0.2295403466082253 and parameters: {'model_name': 'VAE', 'batch_size': 379, 'iterations': 9606, 'learning_rate': 0.0005118728149935947, 'p_miss': 0.14808305801108737}. Best is trial 69 with value: 0.13357523691112141.
[I 2024-10-27 03:39:23,924] Trial 76 finished with value: 0.24425353306070505 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9375, 'learning_rate': 0.0016957340784099887, 'p_miss': 0.05365606188044337}. Best is trial 69 with value: 0.13357523691112141.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.13357523691112141
{'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0005748188827870552, 'p_miss': 0.046041975863090306}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5836538715678676
Generation:   4%|▍         | 1/25 [00:05<02:19,  5.79s/it]Generation:  2
Best f1_score score: 0.5836538715678676
Generation:   8%|▊         | 2/25 [00:22<04:41, 12.25s/it]Generation:  3
Best f1_score score: 0.5836538715678676
Generation:  12%|█▏        | 3/25 [00:52<07:28, 20.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465856bc0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465be2320> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.5836538715678676
Generation:  16%|█▌        | 4/25 [01:04<05:57, 17.03s/it]Generation:  5
Best f1_score score: 0.5836538715678676
Generation:  20%|██        | 5/25 [01:32<06:57, 20.87s/it]Generation:  6
Best f1_score score: 0.5836538715678676
Generation:  24%|██▍       | 6/25 [03:38<17:56, 56.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465b82d40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.5836538715678676
Generation:  28%|██▊       | 7/25 [03:50<12:40, 42.25s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469e500> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5836538715678676
Generation:  32%|███▏      | 8/25 [04:03<09:17, 32.78s/it]Generation:  9
Best f1_score score: 0.5836538715678676
Generation:  36%|███▌      | 9/25 [04:16<07:04, 26.53s/it]Generation:  10
Best f1_score score: 0.5836538715678676
Generation:  40%|████      | 10/25 [04:29<05:37, 22.48s/it]Generation:  11
Best f1_score score: 0.5836538715678676
Generation:  44%|████▍     | 11/25 [05:43<08:56, 38.30s/it]Generation:  12
Best f1_score score: 0.5836538715678676
Generation:  48%|████▊     | 12/25 [05:58<06:45, 31.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e26bc0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.5836538715678676
Generation:  52%|█████▏    | 13/25 [06:17<05:30, 27.51s/it]Generation:  14
Best f1_score score: 0.5836538715678676
Generation:  56%|█████▌    | 14/25 [06:33<04:24, 24.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650a5060> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546551e230> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5836538715678676
Generation:  60%|██████    | 15/25 [06:53<03:48, 22.82s/it]Generation:  16
Best f1_score score: 0.5836538715678676
Generation:  64%|██████▍   | 16/25 [07:11<03:10, 21.22s/it]Generation:  17
Best f1_score score: 0.5836538715678676
Generation:  68%|██████▊   | 17/25 [07:28<02:39, 19.92s/it]Generation:  18
Best f1_score score: 0.5836538715678676
Generation:  72%|███████▏  | 18/25 [07:49<02:23, 20.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2ec20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.5836538715678676
Generation:  76%|███████▌  | 19/25 [08:07<01:57, 19.56s/it]Generation:  20
Best f1_score score: 0.5836538715678676
Generation:  80%|████████  | 20/25 [08:25<01:36, 19.29s/it]Generation:  21
Best f1_score score: 0.5836538715678676
Generation:  84%|████████▍ | 21/25 [08:48<01:21, 20.38s/it]Generation:  22
Best f1_score score: 0.5836538715678676
Generation:  88%|████████▊ | 22/25 [09:09<01:01, 20.41s/it]Generation:  23
Best f1_score score: 0.5836538715678676
Generation:  92%|█████████▏| 23/25 [09:30<00:41, 20.55s/it]Generation:  24
Best f1_score score: 0.5836538715678676
Generation:  96%|█████████▌| 24/25 [09:50<00:20, 20.46s/it]Generation:  25
Best f1_score score: 0.5836538715678676
Generation: 100%|██████████| 25/25 [10:12<00:00, 20.83s/it]Generation: 100%|██████████| 25/25 [10:15<00:00, 24.63s/it]
2024-10-27 03:49:51,992 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35977' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-a4318f9d2006b2541ea4dbf20f98ea3a', 'ndarray-bc1ee22df90b340c13f4c4b70d48b351'} (stimulus_id='handle-worker-cleanup-1730026191.992124')
Fitted
Pipeline(steps=[('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=8.0602838876986,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0071401880606, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=13,
                               max_leaves=None, min_child_weight=12,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100, n_jobs=1,
                               nthread=1, num_parallel_tree=None, ...))])
score start
train score: {'auroc': 0.6218818746453363, 'accuracy': 0.5899396378269618, 'balanced_accuracy': 0.5898756636583413, 'logloss': 0.680591925485414, 'f1': 0.5898716287338233}
original test score: {'auroc': 0.49820601373149137, 'accuracy': 0.5096463022508039, 'balanced_accuracy': 0.5096471999338241, 'logloss': 0.6951429646821944, 'f1': 0.5096348949919225}
imputed test score: {'auroc': 0.5178416328894035, 'accuracy': 0.5096463022508039, 'balanced_accuracy': 0.5095851600628671, 'logloss': 0.6938144368995044, 'f1': 0.5095841896415785}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014670>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd0d30> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd0bb0> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd1060> 
 Input X contains NaN.
MultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 101, in predict
    X = self._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 574, in _check_X
    return self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.7002311633562194
Generation:   4%|▍         | 1/25 [00:18<07:17, 18.23s/it]Generation:  2
Best f1_score score: 0.7255807200672765
Generation:   8%|▊         | 2/25 [02:20<30:33, 79.72s/it]Generation:  3
Best f1_score score: 0.7255807200672765
Generation:  12%|█▏        | 3/25 [04:21<36:01, 98.27s/it]Generation:  4
Best f1_score score: 0.7255807200672765
Generation:  16%|█▌        | 4/25 [07:59<50:58, 145.62s/it]Generation:  5
Best f1_score score: 0.726351577063939
Generation:  20%|██        | 5/25 [09:59<45:28, 136.42s/it]Generation:  6
Best f1_score score: 0.726351577063939
Generation:  24%|██▍       | 6/25 [12:05<42:06, 132.98s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745222f0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.726351577063939
Generation:  28%|██▊       | 7/25 [15:52<49:05, 163.64s/it]Generation:  8
Best f1_score score: 0.7275178375753484
Generation:  32%|███▏      | 8/25 [17:52<42:27, 149.83s/it]Generation:  9
Best f1_score score: 0.7275178375753484
Generation:  36%|███▌      | 9/25 [19:54<37:34, 140.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457216290> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  10
Best f1_score score: 0.7275178375753484
Generation:  40%|████      | 10/25 [22:15<35:16, 141.11s/it]Generation:  11
Best f1_score score: 0.7275178375753484
Generation:  44%|████▍     | 11/25 [25:55<38:31, 165.07s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452fa7f70> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  12
Best f1_score score: 0.7275178375753484
Generation:  48%|████▊     | 12/25 [27:58<32:58, 152.22s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452f0c280> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457305a50> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  13
Best f1_score score: 0.7275178375753484
Generation:  52%|█████▏    | 13/25 [31:19<33:26, 167.19s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554575de7d0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.7275178375753484
Generation:  56%|█████▌    | 14/25 [35:04<33:49, 184.53s/it]Generation:  15
Best f1_score score: 0.7275178375753484
Generation:  60%|██████    | 15/25 [44:06<48:42, 292.27s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd3880> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457321f30> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  16
Best f1_score score: 0.7275178375753484
Generation:  64%|██████▍   | 16/25 [46:14<36:25, 242.86s/it]Generation:  17
Best f1_score score: 0.7275178375753484
Generation:  68%|██████▊   | 17/25 [48:16<27:31, 206.43s/it]Generation:  18
Best f1_score score: 0.7275178375753484
Generation:  72%|███████▏  | 18/25 [50:18<21:08, 181.20s/it]Generation:  19
Best f1_score score: 0.7275178375753484
Generation:  76%|███████▌  | 19/25 [52:18<16:17, 162.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545a066410> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.7275178375753484
Generation:  80%|████████  | 20/25 [54:20<12:32, 150.47s/it]Generation:  21
Best f1_score score: 0.7275178375753484
Generation:  84%|████████▍ | 21/25 [56:27<09:34, 143.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459d840a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.7275178375753484
Generation:  88%|████████▊ | 22/25 [58:45<07:05, 141.87s/it]Generation:  23
Best f1_score score: 0.7318539033675273
Generation:  92%|█████████▏| 23/25 [1:00:49<04:32, 136.47s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545967c610> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  24
Best f1_score score: 0.7318539033675273
Generation:  96%|█████████▌| 24/25 [1:03:22<02:21, 141.47s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554741aea70> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  25
Best f1_score score: 0.7318539033675273
Generation: 100%|██████████| 25/25 [1:05:21<00:00, 134.75s/it]Generation: 100%|██████████| 25/25 [1:05:21<00:00, 156.87s/it]
2024-10-27 04:55:50,225 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44985' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-4cd93f7aee8e2d853f7c30554dc3b7e1', 'ndarray-bc1ee22df90b340c13f4c4b70d48b351'} (stimulus_id='handle-worker-cleanup-1730030150.2255502')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=RandomForestRegressor(),
                                  imputation_order='roman',
                                  initial_strategy='constant',
                                  n_nearest_features=60)),
                ('logisticregression',
                 LogisticRegression(C=37032.26594417065,
                                    l1_ratio=0.2447360934963, max_iter=1000,
                                    n_jobs=1, penalty='elasticnet',
                                    solver='saga'))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.7978896377312925, 'accuracy': 0.7307847082494969, 'balanced_accuracy': 0.7305258868859298, 'logloss': 0.550462624289265, 'f1': 0.7303653597910089}
test score: {'auroc': 0.7854195963272395, 'accuracy': 0.7186495176848875, 'balanced_accuracy': 0.7180494664571098, 'logloss': 0.5600336960690865, 'f1': 0.7172984274156895}
original test score: {'auroc': 0.9047687980809, 'accuracy': 0.8344051446945338, 'balanced_accuracy': 0.8338158656629995, 'logloss': 0.41673045594370833, 'f1': 0.833609931564663}
score end
737
lvl
0.5
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
10.856188145014976
hours
DONE
