Run: 56
/cm/local/apps/slurm/var/spool/job945231/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
starting loops
../data/r/189/189.pkl
working on 
../data/r/189/reg_full_MAR_0.5_3
0.4225473403930664
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-09-05 18:00:11,228] A new study created in memory with name: no-name-a40006d7-3e2f-44f6-bab5-4d32b2c3591d
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-09-05 18:00:11,432] Trial 4 finished with value: 0.5303851592688558 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.5303851592688558.
running
[I 2024-09-05 18:00:11,577] Trial 5 finished with value: 0.37243736557787044 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.37243736557787044.
running
[I 2024-09-05 18:00:13,459] Trial 17 finished with value: 0.2879896161246275 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4561, 'weights': 'distance'}. Best is trial 17 with value: 0.2879896161246275.
running
[I 2024-09-05 18:00:15,980] Trial 0 finished with value: 0.2704701462742126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:17,391] Trial 14 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.03028900628008334, 'alpha': 30, 'iterations': 2, 'learning_rate': 0.003366723149804819, 'p_miss': 0.10323480001474443}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:20,197] Trial 2 finished with value: 0.5115967077861617 and parameters: {'model_name': 'GAIN', 'batch_size': 170, 'hint_rate': 0.4676618388290718, 'alpha': 7, 'iterations': 4, 'learning_rate': 0.0006271646422428429, 'p_miss': 0.07136035915641335}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:20,502] Trial 20 finished with value: 0.28933920613568315 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6395, 'weights': 'distance'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:22,734] Trial 16 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.6626410563468579, 'alpha': 39, 'iterations': 68, 'learning_rate': 0.02245301395766133, 'p_miss': 0.028262087892494292}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:22,939] Trial 21 finished with value: 0.2789020384879984 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1241, 'weights': 'uniform'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:23,166] Trial 23 finished with value: 0.2929371206414412 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:23,360] Trial 7 finished with value: 0.4934594124188707 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.6202471332478772, 'alpha': 86, 'iterations': 10, 'learning_rate': 0.0022021061488565296, 'p_miss': 0.1725489992397732}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:24,083] Trial 3 finished with value: 0.2705806947990652 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:31,368] Trial 22 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.25357257163003843, 'alpha': 0, 'iterations': 101, 'learning_rate': 0.037526201216115246, 'p_miss': 0.1263397862394075}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:40,259] Trial 18 finished with value: 0.3757361659002544 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:41,624] Trial 25 finished with value: 0.2704701462742126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:43,185] Trial 26 finished with value: 0.2704701462742126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 0 with value: 0.2704701462742126.
running
[I 2024-09-05 18:00:49,470] Trial 29 finished with value: 0.26913610153409684 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:00:56,264] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.5934976505975357, 'alpha': 7, 'iterations': 310, 'learning_rate': 0.027159885103332098, 'p_miss': 0.22732041301450648}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:01:13,463] Trial 27 finished with value: 0.27050106600006496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:01:18,732] Trial 9 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.5406569011087677, 'alpha': 57, 'iterations': 191, 'learning_rate': 0.009292271968772635, 'p_miss': 0.17563858957045855}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:01:22,607] Trial 28 finished with value: 0.27050106600006496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:04:19,210] Trial 15 finished with value: 0.2781378718034254 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 2, 'learning_rate': 0.0007110642575129224, 'p_miss': 0.05180940065339073}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:04:26,050] Trial 37 finished with value: 0.2691361390951158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:04:29,471] Trial 10 finished with value: 0.49128576677819613 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.14150437074434022, 'alpha': 16, 'iterations': 248, 'learning_rate': 0.004282642417784507, 'p_miss': 0.1986786746225349}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:04:33,569] Trial 38 finished with value: 0.2691361390951158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:04:37,687] Trial 39 finished with value: 0.2691361390951158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:18:14,197] Trial 8 finished with value: 0.32323965499810053 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:23:30,918] Trial 6 finished with value: 0.28591720099420465 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:25:45,528] Trial 11 finished with value: 0.2740993520821552 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:31:02,378] Trial 12 finished with value: 0.26977587495222993 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 29 with value: 0.26913610153409684.
running
[I 2024-09-05 18:33:22,417] Trial 24 finished with value: 0.26609366646671095 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 07:21:09,204] Trial 36 finished with value: 0.2976806440304863 and parameters: {'model_name': 'VAE', 'batch_size': 940, 'iterations': 3759, 'learning_rate': 0.00011107832987998347, 'p_miss': 0.2434148928551192}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 07:21:27,409] Trial 47 finished with value: 0.28448432802059465 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 07:21:33,887] Trial 48 finished with value: 0.2691361390951158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:18:54,858] Trial 31 finished with value: 0.2978593345524626 and parameters: {'model_name': 'VAE', 'batch_size': 831, 'iterations': 3809, 'learning_rate': 0.00012010150176197304, 'p_miss': 0.29661407803057194}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:00,474] Trial 50 finished with value: 0.2691361390951158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:01,350] Trial 51 finished with value: 0.530362348109505 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:08,520] Trial 52 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:25,082] Trial 53 finished with value: 0.2853535079129035 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:31,574] Trial 54 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:32,461] Trial 55 finished with value: 0.530362348109505 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:38,564] Trial 56 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:44,714] Trial 57 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:51,908] Trial 58 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:19:58,659] Trial 59 finished with value: 0.26913607997169664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:20:09,761] Trial 60 finished with value: 0.27036243960450046 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 09:52:38,670] Trial 61 finished with value: 0.2667532203386114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 10:03:06,249] Trial 62 finished with value: 0.27675750090788787 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 13, 'learning_rate': 0.0005141119591948804, 'p_miss': 0.2964502123022947}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 10:03:07,974] Trial 63 finished with value: 0.27116575754691097 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 47, 'weights': 'uniform'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 10:35:46,103] Trial 64 finished with value: 0.26643708304577085 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 11:04:57,738] Trial 65 finished with value: 0.27308596630368553 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 11:38:01,074] Trial 66 finished with value: 0.2690003225334822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 12:10:38,202] Trial 67 finished with value: 0.266766306969472 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 12:43:58,699] Trial 68 finished with value: 0.26847132828902814 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:00:22,649] Trial 41 finished with value: 0.29804001418247855 and parameters: {'model_name': 'VAE', 'batch_size': 806, 'iterations': 4845, 'learning_rate': 0.00014759629680994953, 'p_miss': 0.27138671223063415}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:16:54,288] Trial 69 finished with value: 0.267236620481054 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:32:26,493] Trial 70 finished with value: 0.2680271929330006 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:32:26,904] Trial 72 finished with value: 0.5303851592688558 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:32:30,263] Trial 73 finished with value: 0.28467160124016627 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2806, 'weights': 'uniform'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:49:38,148] Trial 71 finished with value: 0.2682743620287545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 13:55:46,037] Trial 75 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9672595323545118, 'alpha': 100, 'iterations': 1256, 'learning_rate': 0.094201765729351, 'p_miss': 0.13444202569904753}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 14:04:34,513] Trial 74 finished with value: 0.2670351319530153 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 14:28:09,712] Trial 76 finished with value: 0.26783042452776906 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 14:33:33,939] Trial 1 finished with value: 0.29409087307719306 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 24, 'learning_rate': 0.040213687914213724, 'p_miss': 0.03742992455462147}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 14:37:00,099] Trial 77 finished with value: 0.2686662349941894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:01:15,499] Trial 78 finished with value: 0.2674200163230897 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:06:08,806] Trial 79 finished with value: 0.2671542140802841 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:09:26,548] Trial 80 finished with value: 0.2685395154990099 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:31:58,818] Trial 82 finished with value: 0.27920612094860303 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:33:36,990] Trial 83 finished with value: 0.28625480919694263 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:33:40,664] Trial 85 finished with value: 0.28933920613568315 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6053, 'weights': 'distance'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 15:34:21,822] Trial 81 finished with value: 0.2677506056105363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:01:43,747] Trial 84 finished with value: 0.26911564948746297 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:05:50,957] Trial 86 finished with value: 0.2670542741346604 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:06:47,357] Trial 87 finished with value: 0.2689244997815456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:24:55,677] Trial 34 finished with value: 0.2980521003641391 and parameters: {'model_name': 'VAE', 'batch_size': 807, 'iterations': 6317, 'learning_rate': 0.00019484034241401378, 'p_miss': 0.29603429329691855}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:28:53,486] Trial 45 finished with value: 0.29801711562117184 and parameters: {'model_name': 'VAE', 'batch_size': 975, 'iterations': 6862, 'learning_rate': 0.00012237291589099132, 'p_miss': 0.2570643230819793}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:33:37,498] Trial 88 finished with value: 0.26659129314998514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:33:42,083] Trial 93 finished with value: 0.5107280901655706 and parameters: {'model_name': 'GAIN', 'batch_size': 93, 'hint_rate': 0.968986655959369, 'alpha': 65, 'iterations': 1, 'learning_rate': 0.0014071402716075753, 'p_miss': 0.08356080544287055}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:35:23,180] Trial 89 finished with value: 0.26971446047243763 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:36:37,188] Trial 90 finished with value: 0.2691361962128114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:53:59,886] Trial 91 finished with value: 0.2703988642148923 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 16:57:34,102] Trial 92 finished with value: 0.2687277558323752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:02:38,937] Trial 94 finished with value: 0.26969893041650994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:03:19,630] Trial 99 finished with value: 0.36619358953323033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:03:20,281] Trial 100 finished with value: 0.37243736557787044 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:07:01,807] Trial 95 finished with value: 0.2680855225711981 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:07:16,839] Trial 102 finished with value: 0.284863667451785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:08:23,976] Trial 96 finished with value: 0.26642986060714374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:25:30,526] Trial 97 finished with value: 0.2675868515317109 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:28:43,001] Trial 98 finished with value: 0.26859402211737854 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:34:29,230] Trial 101 finished with value: 0.26817555137117255 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:38:35,933] Trial 103 finished with value: 0.2674898191026886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:39:55,801] Trial 104 finished with value: 0.2670610176489861 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:42:54,780] Trial 33 finished with value: 0.29797834131950385 and parameters: {'model_name': 'VAE', 'batch_size': 696, 'iterations': 5540, 'learning_rate': 0.00019679498139891903, 'p_miss': 0.28959549116564004}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:46:13,971] Trial 106 finished with value: 0.3262560632952657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:47:02,636] Trial 111 finished with value: 0.3729580009658887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 24 with value: 0.26609366646671095.
running
[I 2024-09-06 17:57:05,793] Trial 105 finished with value: 0.26595410880639964 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:05:44,657] Trial 107 finished with value: 0.267759453486553 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:07:42,636] Trial 112 finished with value: 0.49663906650393363 and parameters: {'model_name': 'GAIN', 'batch_size': 55, 'hint_rate': 0.7985800301946537, 'alpha': 72, 'iterations': 941, 'learning_rate': 0.011866952140119603, 'p_miss': 0.22326502679821203}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:07:42,989] Trial 115 finished with value: 0.2929371206414412 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:09:46,776] Trial 108 finished with value: 0.26729982497073623 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:11:20,116] Trial 109 finished with value: 0.2679412291269391 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:14:10,846] Trial 110 finished with value: 0.26728033892801906 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:14:26,618] Trial 119 finished with value: 0.2851067512701605 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:15:22,380] Trial 113 finished with value: 0.5061299410107074 and parameters: {'model_name': 'GAIN', 'batch_size': 63, 'hint_rate': 0.7928382927975853, 'alpha': 77, 'iterations': 818, 'learning_rate': 0.008731183285102603, 'p_miss': 0.21689018045715464}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:15:26,268] Trial 121 finished with value: 0.2837277886390649 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3111, 'weights': 'distance'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:20:15,468] Trial 114 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 74, 'hint_rate': 0.798115286562237, 'alpha': 81, 'iterations': 1113, 'learning_rate': 0.00800028912310908, 'p_miss': 0.013290224969824821}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:27:01,440] Trial 35 finished with value: 0.297754647520942 and parameters: {'model_name': 'VAE', 'batch_size': 737, 'iterations': 6236, 'learning_rate': 0.00013801403821051304, 'p_miss': 0.2841081988771034}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:37:49,375] Trial 116 finished with value: 0.2681654008586386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:40:08,925] Trial 117 finished with value: 0.26781107512215946 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 105 with value: 0.26595410880639964.
running
[I 2024-09-06 18:41:54,260] Trial 118 finished with value: 0.26579700830797665 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 18:44:41,589] Trial 120 finished with value: 0.2675596891237203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 18:45:35,061] Trial 122 finished with value: 0.267282158376725 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 18:50:11,207] Trial 123 finished with value: 0.2683512161475329 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 18:56:38,619] Trial 124 finished with value: 0.26748582107767116 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:07:27,114] Trial 125 finished with value: 0.2671779423545269 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:09:55,683] Trial 126 finished with value: 0.26730165773726666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:12:01,883] Trial 127 finished with value: 0.2673324078282517 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:14:41,657] Trial 128 finished with value: 0.2673914575262101 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:15:33,020] Trial 129 finished with value: 0.26757481010741596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:19:59,393] Trial 130 finished with value: 0.26827867158708957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:22:06,022] Trial 134 finished with value: 0.29978502082248826 and parameters: {'model_name': 'VAE', 'batch_size': 355, 'iterations': 32, 'learning_rate': 0.07962032233996896, 'p_miss': 0.1482609897042302}. Best is trial 118 with value: 0.26579700830797665.
running
[I 2024-09-06 19:26:26,639] Trial 131 finished with value: 0.26575495803311944 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:37:20,315] Trial 132 finished with value: 0.26815167772286774 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:40:00,746] Trial 133 finished with value: 0.26646588686430517 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:44:51,671] Trial 135 finished with value: 0.26731432650883924 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:45:19,430] Trial 142 finished with value: 0.2691819561699845 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:45:22,806] Trial 143 finished with value: 0.2909456454994263 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4540, 'weights': 'uniform'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:45:40,305] Trial 139 finished with value: 0.3066553415682095 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:45:59,241] Trial 136 finished with value: 0.26799046157562045 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:50:10,382] Trial 137 finished with value: 0.26798121337123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 19:52:41,067] Trial 138 finished with value: 0.26702176012354395 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:07:10,773] Trial 140 finished with value: 0.2665239420354374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:10:06,873] Trial 141 finished with value: 0.26637705360416963 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:10:21,787] Trial 150 finished with value: 0.28448432802059465 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:15:23,716] Trial 145 finished with value: 0.2665711792736262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:15:24,103] Trial 152 finished with value: 0.2929371206414412 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-06 20:15:24,224] Trial 144 finished with value: 0.2695898350680256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
running
[I 2024-09-06 20:15:44,895] Trial 146 finished with value: 0.26687880545732445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:16:36,453] Trial 44 finished with value: 0.2982358181346911 and parameters: {'model_name': 'VAE', 'batch_size': 688, 'iterations': 7288, 'learning_rate': 0.00011450853194217402, 'p_miss': 0.2891955070957771}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:19:57,597] Trial 147 finished with value: 0.2676347159497966 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:22:51,122] Trial 148 finished with value: 0.2674099787754667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:36:32,894] Trial 149 finished with value: 0.2680379683698881 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:40:02,549] Trial 151 finished with value: 0.2672148818170003 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:40:09,480] Trial 153 finished with value: 0.2765985982599064 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:44:52,738] Trial 154 finished with value: 0.2667274882666807 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:45:03,740] Trial 156 finished with value: 0.2685485283403718 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:45:16,768] Trial 155 finished with value: 0.26732502294932614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:49:22,901] Trial 157 finished with value: 0.2661654965220308 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 20:52:32,185] Trial 158 finished with value: 0.2663244943696985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:05:41,308] Trial 159 finished with value: 0.2662273204746467 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:06:09,219] Trial 30 finished with value: 0.2981251771640471 and parameters: {'model_name': 'VAE', 'batch_size': 691, 'iterations': 6616, 'learning_rate': 0.00015943584160283845, 'p_miss': 0.2908748664230897}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:09:11,455] Trial 161 finished with value: 0.2667200782134155 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:09:25,693] Trial 160 finished with value: 0.2664783046070078 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:13:12,874] Trial 163 finished with value: 0.26713718723953794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:14:03,604] Trial 162 finished with value: 0.2672341597123764 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:14:24,921] Trial 164 finished with value: 0.26649910429920937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:18:31,685] Trial 165 finished with value: 0.26735490214273955 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:19:31,615] Trial 174 finished with value: 0.3566866226662346 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:22:11,539] Trial 166 finished with value: 0.2676229602865653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:34:44,314] Trial 167 finished with value: 0.26823727511347234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:35:24,189] Trial 168 finished with value: 0.2666826898168495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:38:25,806] Trial 169 finished with value: 0.2674862125813672 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:38:43,799] Trial 170 finished with value: 0.26754009394102063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:41:30,248] Trial 171 finished with value: 0.2661201583770181 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:41:41,831] Trial 181 finished with value: 0.2855704483413323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:41:44,669] Trial 182 finished with value: 0.27961519470964397 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1800, 'weights': 'distance'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:43:15,590] Trial 172 finished with value: 0.2677035591396625 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:43:38,513] Trial 173 finished with value: 0.26759625191801495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:48:17,625] Trial 175 finished with value: 0.26914915125858696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 21:51:17,168] Trial 176 finished with value: 0.267066381228824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:03:34,622] Trial 177 finished with value: 0.2663359068257448 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:04:35,274] Trial 178 finished with value: 0.2670425764037838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:07:27,415] Trial 179 finished with value: 0.267078149061176 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:07:58,430] Trial 180 finished with value: 0.2670468922748502 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:10:07,138] Trial 183 finished with value: 0.26741244811402093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:10:07,904] Trial 192 finished with value: 0.530362348109505 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:17:47,778] Trial 186 finished with value: 0.26911495571909844 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:21:06,982] Trial 187 finished with value: 0.26879770032247896 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:28:26,229] Trial 42 finished with value: 0.2979696018218376 and parameters: {'model_name': 'VAE', 'batch_size': 613, 'iterations': 7568, 'learning_rate': 0.00015121078391204087, 'p_miss': 0.28464568263272616}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:28:31,348] Trial 196 finished with value: 0.2691364205546475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:34:42,991] Trial 189 finished with value: 0.26801731307166554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:38:19,177] Trial 40 finished with value: 0.2984787202131002 and parameters: {'model_name': 'VAE', 'batch_size': 642, 'iterations': 7216, 'learning_rate': 0.09594580605944525, 'p_miss': 0.2972268308298408}. Best is trial 131 with value: 0.26575495803311944.
running
[I 2024-09-06 22:56:55,318] Trial 197 finished with value: 0.2671375616439412 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-06 22:58:34,820] Trial 198 finished with value: 0.2750802519979232 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-06 23:07:52,230] Trial 199 finished with value: 0.2680997793486256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-06 23:30:42,729] Trial 46 finished with value: 0.29792078275791817 and parameters: {'model_name': 'VAE', 'batch_size': 610, 'iterations': 6669, 'learning_rate': 0.00019968812732403112, 'p_miss': 0.2773140200120408}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 00:40:24,000] Trial 191 finished with value: 0.29792069253496883 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 25, 'learning_rate': 0.0003555106305856106, 'p_miss': 0.11129086514707764}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 00:41:32,213] Trial 43 finished with value: 0.29756577413036467 and parameters: {'model_name': 'VAE', 'batch_size': 648, 'iterations': 8233, 'learning_rate': 0.00011274488096629114, 'p_miss': 0.29855540608724596}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 00:58:30,271] Trial 194 finished with value: 0.2980266761404923 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 26, 'learning_rate': 0.00032800200412095936, 'p_miss': 0.10755563566615212}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 01:12:06,787] Trial 184 finished with value: 0.2979496129759063 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 36, 'learning_rate': 0.0003823305264437946, 'p_miss': 0.1088009389086404}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 01:13:04,399] Trial 188 finished with value: 0.29776149379654165 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 31, 'learning_rate': 0.00036139264534889963, 'p_miss': 0.10308122872350106}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 01:16:43,339] Trial 190 finished with value: 0.2979059147632418 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 34, 'learning_rate': 0.0003447749180833791, 'p_miss': 0.10782117484290282}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 01:25:13,509] Trial 185 finished with value: 0.29780535823745335 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 44, 'learning_rate': 0.0003297846053214121, 'p_miss': 0.11318223879062533}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 02:54:43,626] Trial 32 finished with value: 0.29780499405015376 and parameters: {'model_name': 'VAE', 'batch_size': 285, 'iterations': 6563, 'learning_rate': 0.00015047938970959892, 'p_miss': 0.2988934196721871}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 03:41:38,446] Trial 195 finished with value: 0.2986751428408425 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 28, 'learning_rate': 0.0003419590756617473, 'p_miss': 0.10951559787168116}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 03:45:01,290] Trial 193 finished with value: 0.2980087124207401 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 27, 'learning_rate': 0.0004132636439101445, 'p_miss': 0.10467724219328714}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 04:26:01,969] Trial 49 finished with value: 0.2979023820889696 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 6105, 'learning_rate': 0.0001554963528049709, 'p_miss': 0.2959805996460414}. Best is trial 131 with value: 0.26575495803311944.
[I 2024-09-07 05:29:50,115] Trial 13 finished with value: 0.2977208321374323 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 314, 'learning_rate': 0.0006713009731221626, 'p_miss': 0.1265835572302093}. Best is trial 131 with value: 0.26575495803311944.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0.26575495803311944
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746e46d0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  1
Best root_mean_squared_error score: -0.21152433416009514
Generation:   4%|▍         | 1/25 [00:07<03:11,  7.98s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746e2800> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746950f0> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  2
Best root_mean_squared_error score: -0.20839139817434016
Generation:   8%|▊         | 2/25 [00:24<04:54, 12.79s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474702a10> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  3
Best root_mean_squared_error score: -0.20669216857417974
Generation:  12%|█▏        | 3/25 [00:30<03:38,  9.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747002e0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747259f0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  4
Best root_mean_squared_error score: -0.19754570736356653
Generation:  16%|█▌        | 4/25 [01:35<11:04, 31.64s/it]Generation:  5
Best root_mean_squared_error score: -0.1964863383036136
Generation:  20%|██        | 5/25 [01:50<08:32, 25.63s/it]Generation:  6
Best root_mean_squared_error score: -0.1964863383036136
Generation:  24%|██▍       | 6/25 [03:23<15:21, 48.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472a860> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  7
Best root_mean_squared_error score: -0.19536814892892782
Generation:  28%|██▊       | 7/25 [07:26<33:36, 112.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474697250> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  8
Best root_mean_squared_error score: -0.19536814892892782
Generation:  32%|███▏      | 8/25 [08:15<26:02, 91.91s/it] Generation:  9
Best root_mean_squared_error score: -0.19536814892892782
Generation:  36%|███▌      | 9/25 [13:46<44:28, 166.77s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659ba9b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155486487700> 

Generation:  10
Best root_mean_squared_error score: -0.19536814892892782
Generation:  40%|████      | 10/25 [23:52<1:15:33, 302.23s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746961d0> 

Generation:  11
Best root_mean_squared_error score: -0.19536814892892782
Generation:  44%|████▍     | 11/25 [33:57<1:32:11, 395.08s/it]Generation:  12
Best root_mean_squared_error score: -0.19536814892892782
Generation:  48%|████▊     | 12/25 [36:57<1:11:26, 329.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465a1b6d0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  13
Best root_mean_squared_error score: -0.19536814892892782
Generation:  52%|█████▏    | 13/25 [45:56<1:18:35, 392.94s/it]Generation:  14
Best root_mean_squared_error score: -0.19536814892892782
Generation:  56%|█████▌    | 14/25 [51:39<1:09:17, 377.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659248b0> 

Generation:  15
Best root_mean_squared_error score: -0.19536814892892782
Generation:  60%|██████    | 15/25 [1:01:46<1:14:29, 446.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474741750> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  16
Best root_mean_squared_error score: -0.19536814892892782
Generation:  64%|██████▍   | 16/25 [1:05:12<56:09, 374.34s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474695540> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  17
Best root_mean_squared_error score: -0.19536814892892782
Generation:  68%|██████▊   | 17/25 [1:08:31<42:54, 321.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa4250> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  18
Best root_mean_squared_error score: -0.19536814892892782
Generation:  72%|███████▏  | 18/25 [1:14:58<39:49, 341.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465537ac0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  19
Best root_mean_squared_error score: -0.19536814892892782
Generation:  76%|███████▌  | 19/25 [1:24:12<40:30, 405.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472b910> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  20
Best root_mean_squared_error score: -0.19536814892892782
Generation:  80%|████████  | 20/25 [1:34:17<38:45, 465.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474696860> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  21
Best root_mean_squared_error score: -0.19536814892892782
Generation:  84%|████████▍ | 21/25 [1:41:30<30:22, 455.53s/it]Generation:  22
Best root_mean_squared_error score: -0.19536814892892782
Generation:  88%|████████▊ | 22/25 [1:46:00<19:59, 399.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658a9750> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  23
Best root_mean_squared_error score: -0.19536814892892782
Generation:  92%|█████████▏| 23/25 [1:48:04<10:34, 317.01s/it]Generation:  24
Best root_mean_squared_error score: -0.19536814892892782
Generation:  96%|█████████▌| 24/25 [1:51:11<04:38, 278.23s/it]Generation:  25
Best root_mean_squared_error score: -0.19536814892892782
Generation: 100%|██████████| 25/25 [1:57:15<00:00, 303.97s/it]Generation: 100%|██████████| 25/25 [1:57:18<00:00, 281.53s/it]
2024-09-07 07:31:30,089 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37481' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-87dcf99fa6fd6be8e5d90766da857929', 'ndarray-205f4c4589270e18d3317408cd6d4b16'} (stimulus_id='handle-worker-cleanup-1725719490.089706')
Fitted
Pipeline(steps=[('mlpregressor',
                 MLPRegressor(alpha=0.0060145105561, early_stopping=True,
                              hidden_layer_sizes=[291, 291, 291],
                              learning_rate='invscaling',
                              learning_rate_init=0.0036943377332,
                              n_iter_no_change=32))])
score start
train score: {'explained_var': 0.49929839281179844, 'r2': 0.4896551215204451, 'rmse': 0.18804526792468104}
original test score: {'explained_var': 0.7694627306655085, 'r2': 0.7653636742654287, 'rmse': 0.1283789102387691}
imputed test score: {'explained_var': 0.34980393032532875, 'r2': 0.33250251442501, 'rmse': 0.21653139668631827}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155317bdda20>
Start tpot fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474695270> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747080a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474695270> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746944f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474694640> 

Generation:  1
Best root_mean_squared_error score: -0.20551878072745788
Generation:   4%|▍         | 1/25 [10:02<4:01:05, 602.74s/it]malloc(): invalid next size (unsorted)
2024-09-07 07:45:03,795 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42347' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-87dcf99fa6fd6be8e5d90766da857929', 'DataFrame-96ffdb3431880bc7b2a5cf8417bdf95d'} (stimulus_id='handle-worker-cleanup-1725720303.7948503')
Cancelled future (likely memory related)
Generation:  2
Best root_mean_squared_error score: -0.20346270435840408
Generation:   8%|▊         | 2/25 [13:17<2:18:59, 362.58s/it]2024-09-07 07:45:06,065 - distributed.nanny - WARNING - Restarting worker
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  3
Best root_mean_squared_error score: -0.20346270435840408
Generation:  12%|█▏        | 3/25 [13:20<1:12:44, 198.37s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  4
Best root_mean_squared_error score: -0.20346270435840408
Generation:  16%|█▌        | 4/25 [13:23<42:26, 121.27s/it]  Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  5
Best root_mean_squared_error score: -0.20346270435840408
Generation:  20%|██        | 5/25 [13:26<26:15, 78.79s/it] Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  6
Best root_mean_squared_error score: -0.20346270435840408
Generation:  24%|██▍       | 6/25 [13:29<16:44, 52.88s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  7
Best root_mean_squared_error score: -0.20346270435840408
Generation:  28%|██▊       | 7/25 [13:32<10:59, 36.61s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  8
Best root_mean_squared_error score: -0.20346270435840408
Generation:  32%|███▏      | 8/25 [13:34<07:16, 25.68s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  9
Best root_mean_squared_error score: -0.20346270435840408
Generation:  36%|███▌      | 9/25 [13:38<04:59, 18.73s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  10
Best root_mean_squared_error score: -0.20346270435840408
Generation:  40%|████      | 10/25 [13:41<03:28, 13.87s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  11
Best root_mean_squared_error score: -0.20346270435840408
Generation:  44%|████▍     | 11/25 [13:44<02:28, 10.61s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  12
Best root_mean_squared_error score: -0.20346270435840408
Generation:  48%|████▊     | 12/25 [13:48<01:50,  8.52s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  13
Best root_mean_squared_error score: -0.20346270435840408
Generation:  52%|█████▏    | 13/25 [13:50<01:21,  6.78s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  14
Best root_mean_squared_error score: -0.20346270435840408
Generation:  56%|█████▌    | 14/25 [13:54<01:03,  5.73s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  15
Best root_mean_squared_error score: -0.20346270435840408
Generation:  60%|██████    | 15/25 [13:56<00:47,  4.77s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  16
Best root_mean_squared_error score: -0.20346270435840408
Generation:  64%|██████▍   | 16/25 [14:00<00:39,  4.38s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  17
Best root_mean_squared_error score: -0.20346270435840408
Generation:  68%|██████▊   | 17/25 [14:02<00:30,  3.83s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  18
Best root_mean_squared_error score: -0.20346270435840408
Generation:  72%|███████▏  | 18/25 [14:06<00:26,  3.74s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  19
Best root_mean_squared_error score: -0.20346270435840408
Generation:  76%|███████▌  | 19/25 [14:09<00:21,  3.53s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  20
Best root_mean_squared_error score: -0.20346270435840408
Generation:  80%|████████  | 20/25 [14:13<00:18,  3.60s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  21
Best root_mean_squared_error score: -0.20346270435840408
Generation:  84%|████████▍ | 21/25 [14:15<00:13,  3.30s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  22
Best root_mean_squared_error score: -0.20346270435840408
Generation:  88%|████████▊ | 22/25 [14:19<00:10,  3.40s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  23
Best root_mean_squared_error score: -0.20346270435840408
Generation:  92%|█████████▏| 23/25 [14:21<00:06,  3.14s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  24
Best root_mean_squared_error score: -0.20346270435840408
Generation:  96%|█████████▌| 24/25 [14:24<00:02,  2.97s/it]Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Cancelled future (likely memory related)
Generation:  25
Best root_mean_squared_error score: -0.20346270435840408
Generation: 100%|██████████| 25/25 [14:27<00:00,  3.12s/it]Generation: 100%|██████████| 25/25 [14:27<00:00, 34.72s/it]
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmregressor',
                 LGBMRegressor(max_depth=6, n_estimators=64, n_jobs=1,
                               num_leaves=253, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'explained_var': 0.5743705851845822, 'r2': 0.5743705851845822, 'rmse': 0.17173006948834518}
test score: {'explained_var': 0.3542691014167565, 'r2': 0.3519566292021522, 'rmse': 0.21335267694899188}
original test score: {'explained_var': 0.665634739196137, 'r2': 0.6656303332125615, 'rmse': 0.15325318052883927}
score end
189
lvl
0.5
type
MAR
num_run
3
reg_full
finished
all finished
full run takes
37.770076008968886
hours
DONE
