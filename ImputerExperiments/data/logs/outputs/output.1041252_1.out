Run: 1
/cm/local/apps/slurm/var/spool/job1041252/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1120/1120.pkl
Could not download file from http://openml1.win.tue.nl/dataset1120/dataset_1120.pq: Bucket does not exist or is private.
Failed to download parquet, fallback on ARFF.
       fLength:   fWidth:  fSize:  fConc:  fConc1:    fAsym:  fM3Long:  \
0       28.7967   16.0021  2.6449  0.3918   0.1982   27.7004   22.0110   
1       31.6036   11.7235  2.5185  0.5303   0.3773   26.2722   23.8238   
2      162.0520  136.0310  4.0612  0.0374   0.0187  116.7410  -64.8580   
3       23.8172    9.5728  2.3385  0.6147   0.3922   27.2107   -6.4633   
4       75.1362   30.9205  3.1611  0.3168   0.1832   -5.5277   28.5525   
...         ...       ...     ...     ...      ...       ...       ...   
19015   21.3846   10.9170  2.6161  0.5857   0.3934   15.2618   11.5245   
19016   28.9452    6.7020  2.2672  0.5351   0.2784   37.0816   13.1853   
19017   75.4455   47.5305  3.4483  0.1417   0.0549   -9.3561   41.0562   
19018  120.5135   76.9018  3.9939  0.0944   0.0683    5.8043  -93.5224   
19019  187.1814   53.0014  3.2093  0.2876   0.1539 -167.3125 -168.4558   

       fM3Trans:  fAlpha:    fDist:  
0        -8.2027  40.0920   81.8828  
1        -9.9574   6.3609  205.2610  
2       -45.2160  76.9600  256.7880  
3        -7.1513  10.4490  116.7370  
4        21.8393   4.6480  356.4620  
...          ...      ...       ...  
19015     2.8766   2.4229  106.8258  
19016    -2.9632  86.7975  247.4560  
19017    -9.4662  30.2987  256.5166  
19018   -63.8389  84.6874  408.3166  
19019    31.4755  52.7310  272.3174  

[19020 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
       fLength:  fWidth:  fSize:  fConc:  fConc1:    fAsym:  fM3Long:  \
14127   84.2891  58.8586  3.1847  0.1203   0.0605   63.6605   89.6350   
5870    65.9566  20.7513  2.7455  0.3019   0.1518   62.2307   56.0095   
7563   128.7360  31.6330  2.7952  0.5064   0.3309  -92.6210 -110.6300   
17354   17.1868  11.1893  2.3284  0.5587   0.3028   -1.6795    6.9433   
8801    68.6177  25.6677  3.2476  0.1956   0.0992  -22.9812   62.5800   
...         ...      ...     ...     ...      ...       ...       ...   
7660    40.1099  23.8657  3.2044  0.2142   0.1096    7.6748   26.4934   
18753  140.4164  39.9692  3.4607  0.1482   0.0909 -154.5634   62.0818   
3296    17.5738  10.9547  2.2765  0.5608   0.2831    2.4225   -8.4245   
10107   52.5503  17.4617  2.6547  0.2547   0.1318  -45.7927   23.5980   
18511   91.2356  24.8769  2.6258  0.4402   0.2497  -39.2618  -95.4027   

       fM3Trans:  fAlpha:    fDist:  
14127    37.7878  39.6411  294.5760  
5870    -16.9916   4.1510  257.0170  
7563     16.7206  43.5130  256.5890  
17354     4.7963  19.7790  219.7140  
8801    -12.1541   0.3340  215.0150  
...          ...      ...       ...  
7660    -13.9909   4.0619  109.9970  
18753    31.1722  42.7430  182.9054  
3296     -4.1089  23.8960  145.0200  
10107    16.0060  13.0019  143.3630  
18511   -14.1885  13.5704  169.3060  

[15216 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
              0         1         2         3         4         5         6  \
0      0.235745  0.229574  0.367652  0.121832  0.089198  0.504838  0.755047   
1      0.179677  0.080939  0.237788  0.328219  0.224478  0.503454  0.694801   
2      0.371681  0.123382  0.252484  0.560632  0.489850  0.353572  0.396233   
3      0.030519  0.043643  0.114459  0.620070  0.448215  0.441595  0.606889   
4      0.187815  0.100115  0.386251  0.207410  0.146540  0.420977  0.706573   
...         ...       ...       ...       ...       ...       ...       ...   
15211  0.100627  0.093086  0.373477  0.228549  0.161950  0.450649  0.641917   
15212  0.407404  0.155897  0.449261  0.153540  0.134242  0.293617  0.705680   
15213  0.031703  0.042728  0.099113  0.622457  0.419025  0.445565  0.579355   
15214  0.138675  0.068108  0.210940  0.274577  0.194844  0.398897  0.636729   
15215  0.256990  0.097031  0.202395  0.485396  0.369536  0.405219  0.423516   

              7         8         9  
0      0.631718  0.440457  0.593377  
1      0.489709  0.046122  0.517389  
2      0.577104  0.483478  0.516523  
3      0.546191  0.219767  0.441920  
4      0.502250  0.003711  0.432413  
...         ...       ...       ...  
15211  0.497488  0.045132  0.219946  
15212  0.614568  0.474922  0.367450  
15213  0.523106  0.265511  0.290803  
15214  0.575251  0.144466  0.287450  
15215  0.496976  0.150782  0.339937  

[15216 rows x 10 columns]
<class 'numpy.ndarray'>
             0         1         2         3         4         5         6  \
0     0.144405  0.105968  0.440035  0.218434  0.175582  0.476568  0.664745   
1     0.117410  0.073869  0.274719  0.286851  0.204178  0.400794  0.662656   
2     0.641280  0.366404  0.493140  0.114331  0.076456  0.228015  0.321424   
3     0.094938  0.078890  0.217978  0.371065  0.314861  0.448943  0.651571   
4     0.018107  0.040991  0.083590  0.873963  0.720551  0.430427  0.585302   
...        ...       ...       ...       ...       ...       ...       ...   
3799  0.229336  0.062571  0.270668  0.329697  0.249963  0.355623  0.688621   
3800  0.520498  0.330940  0.414045  0.181157  0.145948  0.140343  0.365417   
3801  0.015982  0.046984  0.029007  0.763496  0.520522  0.458973  0.577941   
3802  0.241127  0.111761  0.321200  0.203773  0.171285  0.353759  0.724513   
3803  0.066652  0.071444  0.332555  0.358109  0.270114  0.456536  0.561229   

             7         8         9  
0     0.563713  0.076867  0.439134  
1     0.577911  0.138211  0.337252  
2     0.243432  0.319662  0.333784  
3     0.580972  0.231767  0.431917  
4     0.560617  0.487956  0.244820  
...        ...       ...       ...  
3799  0.564589  0.005917  0.545853  
3800  0.743064  0.935202  0.608821  
3801  0.507455  0.685667  0.401863  
3802  0.490674  0.244267  0.543009  
3803  0.563249  0.012667  0.389221  

[3804 rows x 10 columns]
<class 'numpy.ndarray'>
working on 
../data/c/1120/class_full_MCAR_0.01_1
4.607126951217651
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-05 12:18:53,920] A new study created in memory with name: no-name-4dd4417a-e491-4dd2-9fad-6e4e2321301f
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-05 12:18:54,573] Trial 9 finished with value: 0.41081088391887804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 9 with value: 0.41081088391887804.
running
[I 2024-11-05 12:18:54,904] Trial 13 finished with value: 0.41081088391887804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 9 with value: 0.41081088391887804.
running
[I 2024-11-05 12:19:06,728] Trial 3 finished with value: 0.1053283847321262 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 404, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:08,431] Trial 7 finished with value: 0.26708034301816663 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0016261279956981275, 'p_miss': 0.16403550236859668}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:09,008] Trial 8 finished with value: 0.1133856794615066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1992, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:09,218] Trial 19 finished with value: 0.41081088391887804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:10,377] Trial 2 finished with value: 0.22725376922141405 and parameters: {'model_name': 'VAE', 'batch_size': 119, 'iterations': 1, 'learning_rate': 0.015209008832249658, 'p_miss': 0.04375674039132514}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:14,342] Trial 10 finished with value: 0.12002169048361629 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4353, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:14,928] Trial 14 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:15,545] Trial 0 finished with value: 0.12383138027469945 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6058, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:16,535] Trial 4 finished with value: 0.13605417356324637 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12177, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:17,585] Trial 6 finished with value: 0.1293122968176516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8522, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:17,816] Trial 17 finished with value: 0.2741815587248037 and parameters: {'model_name': 'VAE', 'batch_size': 260, 'iterations': 6, 'learning_rate': 0.000112213974049906, 'p_miss': 0.2257062071093275}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:28,478] Trial 18 finished with value: 0.13605417356324637 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12383, 'weights': 'distance'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:29,977] Trial 11 finished with value: 0.26669191685105187 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 24, 'learning_rate': 0.0005231179186791303, 'p_miss': 0.2268155022214181}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:34,457] Trial 24 finished with value: 0.13738726931647113 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8221, 'weights': 'uniform'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:38,402] Trial 21 finished with value: 0.11361214701251246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:44,104] Trial 27 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:44,592] Trial 28 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:44,797] Trial 26 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:54,844] Trial 29 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:55,548] Trial 30 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:57,166] Trial 31 finished with value: 0.10564074271436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:19:59,294] Trial 16 finished with value: 0.16050037304436798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:20:00,538] Trial 12 finished with value: 0.24083814362457034 and parameters: {'model_name': 'VAE', 'batch_size': 398, 'iterations': 31, 'learning_rate': 0.0009866045734297855, 'p_miss': 0.19877415170313698}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:20:32,260] Trial 22 finished with value: 0.3481339772664297 and parameters: {'model_name': 'GAIN', 'batch_size': 812, 'hint_rate': 0.9474299156474998, 'alpha': 89, 'iterations': 85, 'learning_rate': 0.0014582827916930384, 'p_miss': 0.25713835092263576}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:29:01,013] Trial 1 finished with value: 0.15323841810085198 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 225, 'learning_rate': 0.052713722321784104, 'p_miss': 0.11500993131909297}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:37:46,034] Trial 38 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.554307115949536, 'alpha': 98, 'iterations': 3558, 'learning_rate': 0.031518117183943546, 'p_miss': 0.012096360074015655}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:38:05,670] Trial 37 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.6685521586787923, 'alpha': 70, 'iterations': 3544, 'learning_rate': 0.09267623323846945, 'p_miss': 0.02017906870131675}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:38:31,998] Trial 43 finished with value: 0.10687781227473658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:38:52,409] Trial 44 finished with value: 0.10687781227473658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:41:23,110] Trial 40 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.6296906659629352, 'alpha': 47, 'iterations': 4362, 'learning_rate': 0.09728941943742116, 'p_miss': 0.019669895069236804}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:49:54,028] Trial 39 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.658244707542986, 'alpha': 50, 'iterations': 6123, 'learning_rate': 0.09958090770049073, 'p_miss': 0.02776810662666951}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:57:28,371] Trial 36 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.13551113770213818, 'alpha': 70, 'iterations': 8025, 'learning_rate': 0.08894212377358499, 'p_miss': 0.01951078491549263}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 12:57:49,813] Trial 49 finished with value: 0.10926496191367283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:00:35,914] Trial 34 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.038452675504492106, 'alpha': 95, 'iterations': 9235, 'learning_rate': 0.09552850787793418, 'p_miss': 0.030298310198049114}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:00:43,470] Trial 33 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.7957888294211489, 'alpha': 5, 'iterations': 9290, 'learning_rate': 0.09956527274909283, 'p_miss': 0.04644988559648408}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:01:14,812] Trial 42 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.044434954314302166, 'alpha': 0, 'iterations': 7737, 'learning_rate': 0.009601560753190573, 'p_miss': 0.010986923315808639}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:01:39,070] Trial 32 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.16467674261167053, 'alpha': 0, 'iterations': 9724, 'learning_rate': 0.09577459130246953, 'p_miss': 0.01983175718542396}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:01:47,720] Trial 35 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.24737728275786397, 'alpha': 91, 'iterations': 9661, 'learning_rate': 0.060136912168193404, 'p_miss': 0.014846328287346222}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:01:54,996] Trial 55 finished with value: 0.11038677717334167 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 927, 'weights': 'uniform'}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:24:03,508] Trial 23 finished with value: 0.15575946947226704 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 2090, 'learning_rate': 0.00011917887010773082, 'p_miss': 0.09144748621051708}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:26:51,549] Trial 5 finished with value: 0.152805617011388 and parameters: {'model_name': 'VAE', 'batch_size': 459, 'iterations': 1522, 'learning_rate': 0.0003265527547834268, 'p_miss': 0.041386204626032555}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:37:27,138] Trial 20 finished with value: 0.1526224982698527 and parameters: {'model_name': 'VAE', 'batch_size': 436, 'iterations': 2464, 'learning_rate': 0.0007337500201241295, 'p_miss': 0.09036895277532228}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:39:10,310] Trial 15 finished with value: 0.1698882805943181 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4079, 'learning_rate': 0.0005097320085986867, 'p_miss': 0.0880197252328844}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:39:47,428] Trial 41 finished with value: 0.36933335739763146 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.02232502916292839, 'alpha': 8, 'iterations': 8392, 'learning_rate': 0.07442059194191285, 'p_miss': 0.0586159656616399}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:40:43,189] Trial 25 finished with value: 0.39008175335588813 and parameters: {'model_name': 'GAIN', 'batch_size': 845, 'hint_rate': 0.11125300621314482, 'alpha': 76, 'iterations': 8817, 'learning_rate': 0.00015394123060089918, 'p_miss': 0.29681012402251866}. Best is trial 3 with value: 0.1053283847321262.
running
[I 2024-11-05 13:49:55,510] Trial 46 finished with value: 0.1020260940886573 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 46 with value: 0.1020260940886573.
running
[I 2024-11-05 13:51:40,976] Trial 47 finished with value: 0.10187617503472621 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 47 with value: 0.10187617503472621.
running
[I 2024-11-05 13:59:23,253] Trial 48 finished with value: 0.10196527427568816 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 47 with value: 0.10187617503472621.
running
[I 2024-11-05 14:30:34,872] Trial 45 finished with value: 0.09402864231997851 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 45 with value: 0.09402864231997851.
running
[I 2024-11-05 14:37:05,111] Trial 50 finished with value: 0.0944855935488912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 45 with value: 0.09402864231997851.
running
[I 2024-11-05 14:38:35,521] Trial 52 finished with value: 0.09368561994488138 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:39:02,327] Trial 51 finished with value: 0.09389387462459162 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:39:34,601] Trial 54 finished with value: 0.09500412202821547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:40:02,104] Trial 53 finished with value: 0.09448428084312141 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:40:33,701] Trial 56 finished with value: 0.09391219809071802 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:40:34,016] Trial 72 finished with value: 0.15724196584902667 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:41:04,401] Trial 64 finished with value: 0.10369853527571889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:48:57,776] Trial 65 finished with value: 0.10310723391483265 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 14:59:49,931] Trial 57 finished with value: 0.09406427464257326 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:02:07,230] Trial 58 finished with value: 0.09392232958314664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:12:01,726] Trial 59 finished with value: 0.09480571066122179 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:13:47,230] Trial 60 finished with value: 0.09405929428729401 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:15:05,051] Trial 61 finished with value: 0.09410275371143531 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:15:51,053] Trial 62 finished with value: 0.09432157039391298 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:19:59,639] Trial 66 finished with value: 0.10471401580086737 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:19:59,937] Trial 82 finished with value: 0.15083901498306013 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:24:24,576] Trial 63 finished with value: 0.0946469154269572 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:26:19,186] Trial 67 finished with value: 0.10533799858172226 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 15:28:06,210] Trial 68 finished with value: 0.10505184607817522 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:26:07,850] Trial 69 finished with value: 0.09372099452679382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:26:19,966] Trial 70 finished with value: 0.09414194242317366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:26:43,838] Trial 88 finished with value: 0.1047014863718951 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:27:36,931] Trial 71 finished with value: 0.09451950941420825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:27:58,979] Trial 90 finished with value: 0.1519025101659895 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:28:16,640] Trial 73 finished with value: 0.09371291660537034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:28:31,183] Trial 74 finished with value: 0.0938054274472323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:29:00,259] Trial 92 finished with value: 0.19904375363525068 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 579, 'learning_rate': 0.005956711465643514, 'p_miss': 0.1490173813111664}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:29:05,583] Trial 94 finished with value: 0.15083901498306013 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14616, 'weights': 'uniform'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:29:22,124] Trial 93 finished with value: 0.20114230011398368 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 674, 'learning_rate': 0.004373596545611766, 'p_miss': 0.15172670317619447}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:37:10,311] Trial 75 finished with value: 0.09419720607103924 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:47:32,100] Trial 76 finished with value: 0.09384851047990372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 52 with value: 0.09368561994488138.
running
[I 2024-11-05 16:49:58,297] Trial 77 finished with value: 0.09347229989386885 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:00:06,776] Trial 78 finished with value: 0.0939296698473873 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:00:06,991] Trial 100 finished with value: 0.15083901498306013 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:01:40,687] Trial 79 finished with value: 0.09381665447538062 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:01:57,744] Trial 102 finished with value: 0.10750338059217227 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:02:24,338] Trial 98 finished with value: 0.14531789244895998 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:03:01,569] Trial 80 finished with value: 0.09358854829668774 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 77 with value: 0.09347229989386885.
running
[I 2024-11-05 17:03:44,339] Trial 81 finished with value: 0.09331669251788162 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:07:21,869] Trial 83 finished with value: 0.09378506412574392 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:11:53,052] Trial 84 finished with value: 0.09429782854271473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:13:51,912] Trial 85 finished with value: 0.0945968497211716 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:14:28,320] Trial 86 finished with value: 0.09363580725140111 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:14:44,523] Trial 110 finished with value: 0.10734025304332535 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:15:11,304] Trial 111 finished with value: 0.10470989853143461 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:15:17,496] Trial 112 finished with value: 0.14860869463795098 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11108, 'weights': 'uniform'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 17:15:23,389] Trial 101 finished with value: 0.14440678353390898 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:12:40,207] Trial 87 finished with value: 0.093878554599923 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:12:59,852] Trial 89 finished with value: 0.09359398053512184 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:15:20,078] Trial 91 finished with value: 0.09397028879133659 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:15:33,334] Trial 96 finished with value: 0.09378730263923325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:16:24,700] Trial 95 finished with value: 0.09344490366015361 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:23:33,931] Trial 97 finished with value: 0.09376799423232447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:23:42,608] Trial 120 finished with value: 0.10473512782525048 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:36:07,191] Trial 99 finished with value: 0.09373497989065378 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:48:10,818] Trial 103 finished with value: 0.0936148183671159 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:48:55,881] Trial 104 finished with value: 0.09393703184113464 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:49:36,976] Trial 105 finished with value: 0.09404542747278699 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:50:11,674] Trial 106 finished with value: 0.09387252949392763 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:52:30,389] Trial 107 finished with value: 0.09377719679212179 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 18:57:32,580] Trial 108 finished with value: 0.09413042130258761 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:00:19,002] Trial 109 finished with value: 0.09392084024821758 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:00:19,400] Trial 129 finished with value: 0.41081088391887804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:00:32,388] Trial 113 finished with value: 0.09334839438955453 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:00:32,893] Trial 131 finished with value: 0.26694316098717963 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 1, 'learning_rate': 0.002552221290106576, 'p_miss': 0.18397216595194935}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:01:52,837] Trial 114 finished with value: 0.09365629120397137 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:57:41,700] Trial 116 finished with value: 0.0938776308524703 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:57:43,713] Trial 115 finished with value: 0.09385488989751103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:57:49,023] Trial 134 finished with value: 0.12147971679480599 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3477, 'weights': 'uniform'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 19:57:50,849] Trial 135 finished with value: 0.12197019142317242 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3622, 'weights': 'uniform'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:00:22,128] Trial 118 finished with value: 0.0937061002645679 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:01:22,127] Trial 117 finished with value: 0.09366352136653353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:01:28,897] Trial 139 finished with value: 0.10473512782525048 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:02:32,723] Trial 119 finished with value: 0.09427609630518448 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:08:26,359] Trial 128 finished with value: 0.09889716519057022 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:09:58,274] Trial 121 finished with value: 0.09395439633088058 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:10:14,309] Trial 143 finished with value: 0.10687781227473658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:11:53,108] Trial 130 finished with value: 0.0984129150591386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:22:31,276] Trial 122 finished with value: 0.09405946690232132 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:24:56,933] Trial 133 finished with value: 0.09542713639009677 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:34:12,574] Trial 123 finished with value: 0.09343652628587065 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:35:13,394] Trial 124 finished with value: 0.09340527173583976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:35:26,743] Trial 125 finished with value: 0.09376458806549871 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 81 with value: 0.09331669251788162.
running
[I 2024-11-05 20:36:07,536] Trial 126 finished with value: 0.09321991288973475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 20:37:39,129] Trial 127 finished with value: 0.09340919911474144 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 20:45:43,435] Trial 132 finished with value: 0.09419468087989635 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:09:44,259] Trial 136 finished with value: 0.0987057827865505 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:24:58,802] Trial 140 finished with value: 0.09606312990281461 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:43:42,097] Trial 137 finished with value: 0.09405771865505996 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:46:46,423] Trial 138 finished with value: 0.09342873469223809 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:47:00,597] Trial 145 finished with value: 0.09400320634490139 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:49:52,221] Trial 141 finished with value: 0.09384424908444082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:54:20,963] Trial 142 finished with value: 0.09420775717758405 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:54:33,871] Trial 160 finished with value: 0.10470758965872844 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:54:34,191] Trial 161 finished with value: 0.15724196584902667 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:57:37,518] Trial 144 finished with value: 0.09393474259212173 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 21:57:50,241] Trial 163 finished with value: 0.15361444581710126 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 215, 'learning_rate': 0.027918766765602336, 'p_miss': 0.2865695339546641}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:09:40,921] Trial 146 finished with value: 0.09327557925479626 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:12:36,882] Trial 147 finished with value: 0.09413419698096137 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:21:40,726] Trial 149 finished with value: 0.09426686197914617 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:21:50,388] Trial 148 finished with value: 0.09357583647571033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:22:26,122] Trial 150 finished with value: 0.09387950538572108 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:23:06,866] Trial 151 finished with value: 0.09371979479335288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:24:46,282] Trial 152 finished with value: 0.09363381970135351 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:31:54,673] Trial 153 finished with value: 0.09397715068086891 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 22:55:37,122] Trial 154 finished with value: 0.09358575183826508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:11:35,064] Trial 155 finished with value: 0.09370248448074989 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:11:42,320] Trial 174 finished with value: 0.10472606507085432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:11:42,991] Trial 175 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.36556946937212953, 'alpha': 29, 'iterations': 10, 'learning_rate': 0.0319221025958312, 'p_miss': 0.12534073506916338}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:29:45,070] Trial 156 finished with value: 0.09331969089940008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:32:47,506] Trial 157 finished with value: 0.09414287967527721 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:33:37,936] Trial 158 finished with value: 0.09410904466330461 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:36:10,160] Trial 159 finished with value: 0.09341758024338458 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:40:52,283] Trial 162 finished with value: 0.09417030208342533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:44:25,757] Trial 164 finished with value: 0.09402091132704093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:56:23,957] Trial 165 finished with value: 0.09414395545359495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:58:20,953] Trial 170 finished with value: 0.09414907287236365 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:58:36,040] Trial 184 finished with value: 0.10665178501362949 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:58:50,710] Trial 166 finished with value: 0.09422398294181301 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-05 23:59:31,162] Trial 171 finished with value: 0.0937463091242512 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:06:58,314] Trial 172 finished with value: 0.09388694382446447 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:08:05,968] Trial 167 finished with value: 0.09388457935697585 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:08:33,441] Trial 168 finished with value: 0.09334286238054511 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:09:08,790] Trial 169 finished with value: 0.09362373289233551 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:26:09,862] Trial 185 finished with value: 0.12011673047871203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:30:18,650] Trial 173 finished with value: 0.09466579412527817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:58:31,950] Trial 176 finished with value: 0.09390419020521393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:58:32,288] Trial 194 finished with value: 0.15724196584902667 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 00:58:45,276] Trial 195 finished with value: 0.1579073518592676 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 01:16:08,781] Trial 177 finished with value: 0.09377931007064366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 01:18:48,110] Trial 178 finished with value: 0.09430396298995505 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 01:20:32,253] Trial 179 finished with value: 0.09363859384947353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
running
[I 2024-11-06 01:22:36,533] Trial 180 finished with value: 0.0935176770205099 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:26:48,553] Trial 181 finished with value: 0.0940967784366838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:31:11,953] Trial 182 finished with value: 0.09399002913439015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:42:38,250] Trial 183 finished with value: 0.09409566738365371 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:45:26,238] Trial 186 finished with value: 0.09367794389407322 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:46:21,664] Trial 187 finished with value: 0.09378173903218626 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:53:23,563] Trial 188 finished with value: 0.0937539544658576 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:55:12,959] Trial 189 finished with value: 0.09400640887684451 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:55:20,944] Trial 190 finished with value: 0.09408112281934385 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 01:55:47,932] Trial 191 finished with value: 0.09359111822821944 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 02:12:15,482] Trial 192 finished with value: 0.09331922646977082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 02:17:09,961] Trial 193 finished with value: 0.09355628323481799 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 02:45:26,516] Trial 196 finished with value: 0.09420037580173322 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 03:02:06,616] Trial 197 finished with value: 0.09376007158686747 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 03:04:20,635] Trial 198 finished with value: 0.09388013426036423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
[I 2024-11-06 03:06:19,296] Trial 199 finished with value: 0.09396091791130248 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 126 with value: 0.09321991288973475.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.09321991288973475
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.8578627513419473
Generation:   4%|         | 1/25 [01:43<41:26, 103.60s/it]Generation:  2
Best f1_score score: 0.8643486112763868
Generation:   8%|         | 2/25 [03:07<35:21, 92.24s/it] WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b2e0> 

Generation:  3
Best f1_score score: 0.8643486112763868
Generation:  12%|        | 3/25 [13:14<1:59:54, 327.01s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f150c0> 

Generation:  4
Best f1_score score: 0.8643486112763868
Generation:  16%|        | 4/25 [23:20<2:33:00, 437.17s/it]Generation:  5
Best f1_score score: 0.8643486112763868
Generation:  20%|        | 5/25 [24:51<1:44:11, 312.57s/it]Generation:  6
Best f1_score score: 0.8643486112763868
Generation:  24%|       | 6/25 [33:13<1:59:17, 376.69s/it]Generation:  7
Best f1_score score: 0.8643486112763868
Generation:  28%|       | 7/25 [34:37<1:24:18, 281.04s/it]Generation:  8
Best f1_score score: 0.8643596421714073
Generation:  32%|      | 8/25 [35:56<1:01:23, 216.67s/it]Generation:  9
Best f1_score score: 0.8643596421714073
Generation:  36%|      | 9/25 [37:37<48:09, 180.57s/it]  Generation:  10
Best f1_score score: 0.8658151462002476
Generation:  40%|      | 10/25 [38:53<37:04, 148.32s/it]Generation:  11
Best f1_score score: 0.8658151462002476
Generation:  44%|     | 11/25 [39:44<27:39, 118.55s/it]Generation:  12
Best f1_score score: 0.8658151462002476
Generation:  48%|     | 12/25 [44:52<38:11, 176.29s/it]Generation:  13
Best f1_score score: 0.8658151462002476
Generation:  52%|    | 13/25 [46:00<28:42, 143.55s/it]Generation:  14
Best f1_score score: 0.8658151462002476
Generation:  56%|    | 14/25 [46:42<20:41, 112.86s/it]Generation:  15
Best f1_score score: 0.8658151462002476
Generation:  60%|    | 15/25 [48:33<18:41, 112.10s/it]Generation:  16
Best f1_score score: 0.8671558279311418
Generation:  64%|   | 16/25 [49:40<14:46, 98.52s/it] Generation:  17
Best f1_score score: 0.8671558279311418
Generation:  68%|   | 17/25 [50:31<11:14, 84.33s/it]Generation:  18
Best f1_score score: 0.8671558279311418
Generation:  72%|  | 18/25 [51:37<09:10, 78.65s/it]Generation:  19
Best f1_score score: 0.8671558279311418
Generation:  76%|  | 19/25 [52:29<07:04, 70.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f4f850> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  20
Best f1_score score: 0.8671558279311418
Generation:  80%|  | 20/25 [54:13<06:43, 80.65s/it]Generation:  21
Best f1_score score: 0.8671558279311418
Generation:  84%| | 21/25 [55:36<05:25, 81.42s/it]Generation:  22
Best f1_score score: 0.8671558279311418
Generation:  88%| | 22/25 [56:22<03:32, 70.99s/it]Generation:  23
Best f1_score score: 0.8671558279311418
Generation:  92%|| 23/25 [57:05<02:05, 62.56s/it]Generation:  24
Best f1_score score: 0.8671558279311418
Generation:  96%|| 24/25 [58:20<01:06, 66.21s/it]Generation:  25
Best f1_score score: 0.8671558279311418
Generation: 100%|| 25/25 [58:44<00:00, 53.66s/it]Generation: 100%|| 25/25 [58:49<00:00, 141.19s/it]
2024-11-06 04:34:19,318 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42015' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-1f7d326cd04e4dc0db2a9196295439a3', 'ndarray-353219245c525f417771924f3306f34c'} (stimulus_id='handle-worker-cleanup-1730896459.3180447')
Fitted
Pipeline(steps=[('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=2.13712e-08,
                                                learning_rate=0.1229163003035,
                                                max_features=0.6824491939775,
                                                max_leaf_nodes=87,
                                                min_samples_leaf=2, tol=0.0001,
                                                validation_fraction=None))])
score start
train score: {'auroc': 0.9997070463841647, 'accuracy': 0.989419032597266, 'balanced_accuracy': 0.9852099440919537, 'logloss': 0.08544661036136562, 'f1': 0.9883212993341088}
original test score: {'auroc': 0.9294500877100464, 'accuracy': 0.8738170347003155, 'balanced_accuracy': 0.8495157459839466, 'logloss': 0.3144435816349998, 'f1': 0.857988121500296}
imputed test score: {'auroc': 0.9283378006660388, 'accuracy': 0.8722397476340694, 'balanced_accuracy': 0.8477863972446802, 'logloss': 0.3171060801239595, 'f1': 0.8562129730190498}
score end
Could not download file from http://openml1.win.tue.nl/dataset1120/dataset_1120.pq: Bucket does not exist or is private.
Failed to download parquet, fallback on ARFF.
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d60> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d21660> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4a00> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.7861423887788753
Generation:   4%|         | 1/25 [02:26<58:44, 146.87s/it]Generation:  2
Best f1_score score: 0.8257584744902571
Generation:   8%|         | 2/25 [04:24<49:47, 129.87s/it]Generation:  3
Best f1_score score: 0.8315993480439177
Generation:  12%|        | 3/25 [05:02<32:15, 87.98s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456e5f550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.8572759181935805
Generation:  16%|        | 4/25 [06:28<30:23, 86.85s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f97a7d0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  5
Best f1_score score: 0.8610665302850979
Generation:  20%|        | 5/25 [07:59<29:30, 88.55s/it]Generation:  6
Best f1_score score: 0.8639631825013308
Generation:  24%|       | 6/25 [10:07<32:14, 101.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474520940> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ef195d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d5dc90> 

Generation:  7
Best f1_score score: 0.8639631825013308
Generation:  28%|       | 7/25 [20:12<1:19:56, 266.48s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f2341c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456e58a30> 
 KNeighborsRegressor.predict() got an unexpected keyword argument 'return_std' 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 469, in fit
    Xt = self._fit(X, y, routed_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 406, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/joblib/memory.py", line 312, in __call__
    return self.func(*args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 1310, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 313, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/impute/_iterative.py", line 789, in fit_transform
    Xt, estimator = self._impute_one_feature(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/impute/_iterative.py", line 431, in _impute_one_feature
    mus, sigmas = estimator.predict(X_test, return_std=True)
TypeError: KNeighborsRegressor.predict() got an unexpected keyword argument 'return_std'

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547457a740> 

Generation:  8
Best f1_score score: 0.8639631825013308
Generation:  32%|      | 8/25 [30:19<1:46:12, 374.85s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474037760> 

Generation:  9
Best f1_score score: 0.8639631825013308
Generation:  36%|      | 9/25 [40:25<1:59:15, 447.21s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f53a680> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ebf0400> 

Generation:  10
Best f1_score score: 0.8660198133462244
Generation:  40%|      | 10/25 [50:32<2:04:07, 496.48s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458974310> 

Generation:  11
Best f1_score score: 0.8669136204573749
Generation:  44%|     | 11/25 [1:00:38<2:03:37, 529.80s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fd17bb0> 

Generation:  12
Best f1_score score: 0.8669136204573749
Generation:  48%|     | 12/25 [1:10:46<1:59:56, 553.60s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f863100> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547507ffa0> 

Generation:  13
Best f1_score score: 0.8669136204573749
Generation:  52%|    | 13/25 [1:20:53<1:53:57, 569.80s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456f06bf0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545dc3c7c0> 

Generation:  14
Best f1_score score: 0.8669136204573749
Generation:  56%|    | 14/25 [1:30:58<1:46:24, 580.44s/it]Generation:  15
Best f1_score score: 0.8669136204573749
Generation:  60%|    | 15/25 [1:37:15<1:26:31, 519.13s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456a20580> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f26dcf0> 

Generation:  16
Best f1_score score: 0.8669136204573749
Generation:  64%|   | 16/25 [1:47:20<1:21:46, 545.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554570c8280> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.8669136204573749
Generation:  68%|   | 17/25 [1:48:42<54:06, 405.85s/it]  Generation:  18
Best f1_score score: 0.8669136204573749
Generation:  72%|  | 18/25 [1:49:36<35:00, 300.06s/it]Generation:  19
Best f1_score score: 0.8671276882895109
Generation:  76%|  | 19/25 [1:50:05<21:51, 218.57s/it]Generation:  20
Best f1_score score: 0.8671276882895109
Generation:  80%|  | 20/25 [1:50:20<13:08, 157.67s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f233250> 

Generation:  21
Best f1_score score: 0.8671276882895109
Generation:  84%| | 21/25 [2:00:26<19:28, 292.07s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554744d84f0> 

Generation:  22
Best f1_score score: 0.8674901125002636
Generation:  88%| | 22/25 [2:10:31<19:17, 385.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545be248b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547459fdc0> 

Generation:  23
Best f1_score score: 0.8674901125002636
Generation:  92%|| 23/25 [2:20:36<15:03, 451.65s/it]Generation:  24
Best f1_score score: 0.8674901125002636
Generation:  96%|| 24/25 [2:20:55<05:21, 321.89s/it]Generation:  25
Best f1_score score: 0.8674901125002636
Generation: 100%|| 25/25 [2:23:02<00:00, 263.36s/it]Generation: 100%|| 25/25 [2:23:02<00:00, 343.29s/it]
2024-11-06 06:57:35,006 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44851' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-b3ba9bdc3c70fcd33472f2d6fed66e24', 'ndarray-353219245c525f417771924f3306f34c'} (stimulus_id='handle-worker-cleanup-1730905055.0069075')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=KNeighborsRegressor(),
                                  initial_strategy='most_frequent',
                                  n_nearest_features=22)),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=True,
                                                l2_regularization=1.6684e-09,
                                                learning_rate=0.1158961627831,
                                                max_features=0.1445866214729,
                                                max_leaf_nodes=647,
                                                min_samples_leaf=59,
                                                n_iter_no_change=1, tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9994824669259668, 'accuracy': 0.98784174553102, 'balanced_accuracy': 0.9839080880054412, 'logloss': 0.08753735524795332, 'f1': 0.9865922765433366}
test score: {'auroc': 0.9267466543496787, 'accuracy': 0.8727655099894848, 'balanced_accuracy': 0.8487047159758364, 'logloss': 0.32360582774277813, 'f1': 0.856917574757182}
original test score: {'auroc': 0.9274388787661675, 'accuracy': 0.8738170347003155, 'balanced_accuracy': 0.8495157459839466, 'logloss': 0.3219266749956365, 'f1': 0.857988121500296}
score end
Could not download file from http://openml1.win.tue.nl/dataset1120/dataset_1120.pq: Bucket does not exist or is private.
Failed to download parquet, fallback on ARFF.
1120
lvl
0.01
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
18.651140918400554
hours
DONE
