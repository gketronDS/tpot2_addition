Run: 8
/cm/local/apps/slurm/var/spool/job1029089/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/803/803.pkl
working on 
../data/c/803/class_full_MAR_0.5_1
1.2537908554077148
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-28 16:39:44,608] A new study created in memory with name: no-name-cd243fcd-e938-4dc9-8186-a04ce8cc40ea
running
[I 2024-10-28 16:39:44,622] Trial 0 finished with value: 0.524179962050778 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.524179962050778.
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-28 16:39:44,941] Trial 2 finished with value: 0.12436287305619001 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.12436287305619001.
running
[I 2024-10-28 16:39:45,082] Trial 13 finished with value: 0.524179962050778 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 2 with value: 0.12436287305619001.
running
[I 2024-10-28 16:39:45,197] Trial 15 finished with value: 0.12436287305619001 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.12436287305619001.
running
[I 2024-10-28 16:39:45,434] Trial 10 finished with value: 0.15338985386999407 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.12436287305619001.
running
[I 2024-10-28 16:39:45,572] Trial 17 finished with value: 0.15338985386999407 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.12436287305619001.
running
[I 2024-10-28 16:39:46,510] Trial 11 finished with value: 0.11112728461532324 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 433, 'weights': 'uniform'}. Best is trial 11 with value: 0.11112728461532324.
running
[I 2024-10-28 16:39:46,999] Trial 6 finished with value: 0.12286238674460379 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2931, 'weights': 'distance'}. Best is trial 11 with value: 0.11112728461532324.
running
[I 2024-10-28 16:39:47,331] Trial 18 finished with value: 0.1229127359810698 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3020, 'weights': 'distance'}. Best is trial 11 with value: 0.11112728461532324.
running
[I 2024-10-28 16:39:48,227] Trial 23 finished with value: 0.114924074284199 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 898, 'weights': 'uniform'}. Best is trial 11 with value: 0.11112728461532324.
running
[I 2024-10-28 16:39:48,983] Trial 21 finished with value: 0.11920154552294164 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 11 with value: 0.11112728461532324.
running
[I 2024-10-28 16:39:49,906] Trial 25 finished with value: 0.1074065211997556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 25 with value: 0.1074065211997556.
running
[I 2024-10-28 16:39:50,905] Trial 1 finished with value: 0.12239189627236276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 25 with value: 0.1074065211997556.
running
[I 2024-10-28 16:39:51,071] Trial 20 finished with value: 0.1276900674392159 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 25 with value: 0.1074065211997556.
[I 2024-10-28 16:39:51,222] Trial 16 finished with value: 0.11871500944909055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 25 with value: 0.1074065211997556.
running
running
[I 2024-10-28 16:39:52,231] Trial 28 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.14910130091908647, 'alpha': 91, 'iterations': 9, 'learning_rate': 0.077354960666076, 'p_miss': 0.19292704075131312}. Best is trial 25 with value: 0.1074065211997556.
running
[I 2024-10-28 16:39:52,448] Trial 27 finished with value: 0.1073609647127366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 27 with value: 0.1073609647127366.
running
[I 2024-10-28 16:39:55,638] Trial 7 finished with value: 0.12679998408015788 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 1, 'learning_rate': 0.07597306906405138, 'p_miss': 0.2754575186391895}. Best is trial 27 with value: 0.1073609647127366.
running
[I 2024-10-28 16:39:56,438] Trial 24 finished with value: 0.15568405082748857 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 1, 'learning_rate': 0.0031977283807488035, 'p_miss': 0.15003359143247585}. Best is trial 27 with value: 0.1073609647127366.
running
[I 2024-10-28 16:39:58,499] Trial 14 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6800917195801464, 'alpha': 94, 'iterations': 53, 'learning_rate': 0.004315894798706848, 'p_miss': 0.276831928261475}. Best is trial 27 with value: 0.1073609647127366.
running
[I 2024-10-28 16:40:03,146] Trial 33 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:04,148] Trial 34 finished with value: 0.1073609647127366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:04,903] Trial 29 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.14605378424187082, 'alpha': 62, 'iterations': 157, 'learning_rate': 0.005999001490540466, 'p_miss': 0.19242785874775892}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:05,617] Trial 35 finished with value: 0.1073609647127366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:08,979] Trial 36 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:10,138] Trial 37 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:11,721] Trial 38 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:12,652] Trial 39 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:17,471] Trial 8 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9149161476081926, 'alpha': 66, 'iterations': 159, 'learning_rate': 0.07006958626135461, 'p_miss': 0.1575903699682146}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:20,288] Trial 40 finished with value: 0.10736096380269569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:40:59,210] Trial 22 finished with value: 0.4768682973854732 and parameters: {'model_name': 'GAIN', 'batch_size': 170, 'hint_rate': 0.8743081140408043, 'alpha': 6, 'iterations': 86, 'learning_rate': 0.001000967289509059, 'p_miss': 0.20417950535548166}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:44:20,470] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.48821276975522093, 'alpha': 9, 'iterations': 1106, 'learning_rate': 0.00018589651787860695, 'p_miss': 0.2792967508194787}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:49:33,432] Trial 26 finished with value: 0.14819825073062243 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 212, 'learning_rate': 0.016114912499308156, 'p_miss': 0.2804581274617183}. Best is trial 33 with value: 0.10736096380269569.
running
[I 2024-10-28 16:51:05,364] Trial 19 finished with value: 0.10448384515560907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 19 with value: 0.10448384515560907.
running
[I 2024-10-28 16:51:10,070] Trial 4 finished with value: 0.11452414884419956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 19 with value: 0.10448384515560907.
running
[I 2024-10-28 16:51:59,309] Trial 43 finished with value: 0.10425249216171087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 16:52:01,573] Trial 41 finished with value: 0.10549624662965762 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 16:52:18,678] Trial 42 finished with value: 0.10483636802235752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 16:52:55,169] Trial 46 finished with value: 0.10488585898541021 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 16:56:07,226] Trial 47 finished with value: 0.10505408769985494 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:01:20,397] Trial 48 finished with value: 0.10470455729886397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:01:41,162] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.36970956148330575, 'alpha': 50, 'iterations': 4017, 'learning_rate': 0.00808499132858978, 'p_miss': 0.10076451478187486}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:02:14,748] Trial 49 finished with value: 0.10472737849777429 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:03:13,695] Trial 50 finished with value: 0.10575855590968852 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:03:47,312] Trial 59 finished with value: 0.1533056410208753 and parameters: {'model_name': 'VAE', 'batch_size': 353, 'iterations': 8, 'learning_rate': 0.0001079286442376179, 'p_miss': 0.020562368157599736}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:03:51,513] Trial 52 finished with value: 0.10459318203925638 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 43 with value: 0.10425249216171087.
running
[I 2024-10-28 17:03:56,047] Trial 51 finished with value: 0.10349716477083329 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:04:33,557] Trial 53 finished with value: 0.10535840037479657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:04:35,947] Trial 63 finished with value: 0.12436287305619001 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5143, 'weights': 'uniform'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:04:36,630] Trial 64 finished with value: 0.168251356477405 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:05:04,077] Trial 54 finished with value: 0.10461517806393325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:13:09,390] Trial 56 finished with value: 0.11272263689628648 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:13:10,122] Trial 58 finished with value: 0.11180957490640511 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:13:31,323] Trial 57 finished with value: 0.11324154040524262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:16:01,446] Trial 62 finished with value: 0.11245060588329128 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:16:04,601] Trial 61 finished with value: 0.11249372572213923 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:16:23,425] Trial 60 finished with value: 0.11396040745407084 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:17:17,882] Trial 65 finished with value: 0.11319522496924576 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:17:52,463] Trial 66 finished with value: 0.11319724494945109 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:25:54,761] Trial 68 finished with value: 0.11328327707096449 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:26:51,080] Trial 67 finished with value: 0.11208590486079646 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:28:07,647] Trial 69 finished with value: 0.1048789942334087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 17:30:43,238] Trial 70 finished with value: 0.10364187522614657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 19:51:57,579] Trial 30 finished with value: 0.13041774014695584 and parameters: {'model_name': 'VAE', 'batch_size': 186, 'iterations': 2682, 'learning_rate': 0.0006849599195567211, 'p_miss': 0.2649582185395301}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 19:52:00,356] Trial 79 finished with value: 0.12354690610271099 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5685, 'weights': 'distance'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 19:52:01,093] Trial 80 finished with value: 0.168251356477405 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 19:52:19,798] Trial 81 finished with value: 0.5097731496523166 and parameters: {'model_name': 'GAIN', 'batch_size': 840, 'hint_rate': 0.6534920496508299, 'alpha': 28, 'iterations': 7, 'learning_rate': 0.018855835163647347, 'p_miss': 0.023088785271026646}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 21:58:41,767] Trial 32 finished with value: 0.1302873211513123 and parameters: {'model_name': 'VAE', 'batch_size': 694, 'iterations': 4187, 'learning_rate': 0.0001354888956817876, 'p_miss': 0.02953330329743989}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 21:58:53,222] Trial 83 finished with value: 0.10733196849983968 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 21:58:55,540] Trial 84 finished with value: 0.12334346070026245 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3945, 'weights': 'distance'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 21:58:55,909] Trial 85 finished with value: 0.12436287305619001 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 21:59:00,959] Trial 86 finished with value: 0.1074064532622574 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:12:54,457] Trial 87 finished with value: 0.1048298813240753 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:26:42,648] Trial 88 finished with value: 0.10496345705150474 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:26:51,557] Trial 89 finished with value: 0.11666222992158952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:40:50,999] Trial 90 finished with value: 0.10523672717089742 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:54:42,477] Trial 91 finished with value: 0.10375898904455157 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:54:47,445] Trial 92 finished with value: 0.1074064813935192 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 22:58:58,130] Trial 93 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.014261346745623682, 'alpha': 32, 'iterations': 642, 'learning_rate': 0.0011663766332158086, 'p_miss': 0.07444924251103359}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:04:06,692] Trial 74 finished with value: 0.13043108298643408 and parameters: {'model_name': 'VAE', 'batch_size': 697, 'iterations': 4348, 'learning_rate': 0.0007944679961184004, 'p_miss': 0.010864268432283691}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:12:51,730] Trial 94 finished with value: 0.1053018393879209 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:18:24,848] Trial 95 finished with value: 0.10535878634239601 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:26:45,629] Trial 96 finished with value: 0.1036812971066533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:30:07,700] Trial 3 finished with value: 0.12845902239397836 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 4968, 'learning_rate': 0.05595712862343897, 'p_miss': 0.12548963615819236}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:33:00,716] Trial 97 finished with value: 0.10436278722325446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:40:43,798] Trial 98 finished with value: 0.10402560807997843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:44:50,732] Trial 99 finished with value: 0.10454779086568285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:47:35,084] Trial 100 finished with value: 0.10426611271455188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:54:32,550] Trial 101 finished with value: 0.10515561407611815 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:54:43,896] Trial 104 finished with value: 0.10717678464415163 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-28 23:59:40,622] Trial 102 finished with value: 0.10416483581780496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:02:08,244] Trial 103 finished with value: 0.10606693775677822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:08:50,154] Trial 105 finished with value: 0.1040408933563584 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:14:27,634] Trial 106 finished with value: 0.10530122796915002 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:14:39,550] Trial 107 finished with value: 0.11678790028964361 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:22:45,358] Trial 108 finished with value: 0.10542736278073231 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:29:08,019] Trial 109 finished with value: 0.1050519614688891 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:29:10,655] Trial 110 finished with value: 0.10675234157230491 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:29:12,875] Trial 112 finished with value: 0.10740594159359233 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:29:14,473] Trial 113 finished with value: 0.10740646941087387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:30:48,095] Trial 115 finished with value: 0.1590050899732872 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 20, 'learning_rate': 0.00032071308948847233, 'p_miss': 0.2445853255586159}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:31:06,425] Trial 114 finished with value: 0.14730657633376992 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 23, 'learning_rate': 0.00028653293371675337, 'p_miss': 0.06391107780174304}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:36:36,942] Trial 111 finished with value: 0.10371661232874878 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:45:19,734] Trial 116 finished with value: 0.10386156505095381 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:45:51,528] Trial 117 finished with value: 0.10400822431755175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:50:35,228] Trial 118 finished with value: 0.10490451567640766 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:50:37,474] Trial 121 finished with value: 0.11563274881370131 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1145, 'weights': 'uniform'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:50:38,040] Trial 122 finished with value: 0.15338985386999407 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 00:59:52,346] Trial 119 finished with value: 0.105775322559526 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:00:01,306] Trial 124 finished with value: 0.47491679721546254 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.28811280409207707, 'alpha': 74, 'iterations': 3, 'learning_rate': 0.0018300622585659683, 'p_miss': 0.22733489086008246}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:00:35,905] Trial 120 finished with value: 0.10427154401623881 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:04:27,904] Trial 123 finished with value: 0.10515831166731274 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:14:35,489] Trial 125 finished with value: 0.10415314725876165 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:15:27,523] Trial 126 finished with value: 0.10673572894807362 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:18:27,076] Trial 127 finished with value: 0.10422211354743993 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:29:11,691] Trial 128 finished with value: 0.10384699846810874 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:30:21,707] Trial 129 finished with value: 0.1050315945405123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:30:43,217] Trial 132 finished with value: 0.15409991896545056 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:32:32,145] Trial 130 finished with value: 0.10520860393542479 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:33:22,906] Trial 78 finished with value: 0.13065817593156107 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6399, 'learning_rate': 0.0006478693627748083, 'p_miss': 0.011532606116293337}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:43:51,955] Trial 131 finished with value: 0.10601832665492017 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:45:30,012] Trial 133 finished with value: 0.10567516593133912 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:46:34,854] Trial 134 finished with value: 0.10581367092302767 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:47:36,126] Trial 135 finished with value: 0.1050408760843388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 01:58:38,965] Trial 136 finished with value: 0.10395881366750659 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:00:33,093] Trial 137 finished with value: 0.10481593238128091 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:00:42,432] Trial 138 finished with value: 0.10483390700684134 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:01:50,961] Trial 139 finished with value: 0.10501367968563055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:05:28,106] Trial 75 finished with value: 0.13069802361595714 and parameters: {'model_name': 'VAE', 'batch_size': 811, 'iterations': 7029, 'learning_rate': 0.0006182592251771934, 'p_miss': 0.05526875858236881}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:11:52,896] Trial 55 finished with value: 0.13048985585186212 and parameters: {'model_name': 'VAE', 'batch_size': 785, 'iterations': 6174, 'learning_rate': 0.00011777183370808466, 'p_miss': 0.014953690429613448}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:13:20,858] Trial 140 finished with value: 0.10488154515561439 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:14:46,079] Trial 142 finished with value: 0.1053366254700943 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:15:01,874] Trial 144 finished with value: 0.11722356663573134 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:15:27,963] Trial 141 finished with value: 0.10512467277860271 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:16:09,195] Trial 143 finished with value: 0.10520579833089116 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:16:20,812] Trial 150 finished with value: 0.10717678464415163 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:16:23,511] Trial 151 finished with value: 0.11751322807609646 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1903, 'weights': 'uniform'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:16:24,489] Trial 152 finished with value: 0.168251356477405 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:26:05,600] Trial 145 finished with value: 0.10529558660910858 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:27:57,731] Trial 146 finished with value: 0.10373766981371683 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:28:05,332] Trial 148 finished with value: 0.10479092856807859 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:28:34,485] Trial 147 finished with value: 0.1050274076072922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:30:18,597] Trial 149 finished with value: 0.104091214602595 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:30:31,482] Trial 153 finished with value: 0.10452480345579733 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:33:57,955] Trial 159 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.7292610929802688, 'alpha': 33, 'iterations': 521, 'learning_rate': 0.025046501380914188, 'p_miss': 0.09537875610123839}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:39:53,051] Trial 154 finished with value: 0.10375275046841645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:40:58,141] Trial 156 finished with value: 0.10493324086201519 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:42:06,320] Trial 157 finished with value: 0.10529319608538323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:42:14,335] Trial 9 finished with value: 0.1453903770436578 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7851, 'learning_rate': 0.0007903313752680974, 'p_miss': 0.18833281421909437}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:42:38,459] Trial 164 finished with value: 0.1484870941715311 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:44:45,315] Trial 155 finished with value: 0.5052000720928519 and parameters: {'model_name': 'GAIN', 'batch_size': 143, 'hint_rate': 0.6656459091988456, 'alpha': 32, 'iterations': 469, 'learning_rate': 0.037361600616562275, 'p_miss': 0.09811006023780319}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:44:59,915] Trial 158 finished with value: 0.10450222846925887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:46:50,719] Trial 72 finished with value: 0.1302633667778176 and parameters: {'model_name': 'VAE', 'batch_size': 949, 'iterations': 6543, 'learning_rate': 0.0006687664512199605, 'p_miss': 0.020212035026853065}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:48:04,436] Trial 160 finished with value: 0.10537156649128407 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:54:01,585] Trial 161 finished with value: 0.10484422007475838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:54:09,185] Trial 162 finished with value: 0.10456677797054799 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 51 with value: 0.10349716477083329.
running
[I 2024-10-29 02:56:07,863] Trial 163 finished with value: 0.1033674981065229 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 02:57:18,905] Trial 165 finished with value: 0.10494266450253578 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 02:59:16,798] Trial 166 finished with value: 0.10565572111679149 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 02:59:45,126] Trial 167 finished with value: 0.10466613966976143 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:01:22,141] Trial 168 finished with value: 0.10506610989533369 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:02:01,963] Trial 169 finished with value: 0.10463750338489519 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:07:05,529] Trial 171 finished with value: 0.1043696801423113 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:07:58,864] Trial 170 finished with value: 0.10590217548487868 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:09:48,820] Trial 172 finished with value: 0.10451972798990453 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:10:00,306] Trial 180 finished with value: 0.10828770006812641 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:10:05,648] Trial 181 finished with value: 0.10740632213724118 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:12:04,565] Trial 173 finished with value: 0.10443014966680439 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:13:40,616] Trial 174 finished with value: 0.10488608782505722 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:14:31,046] Trial 175 finished with value: 0.1046368837062652 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:14:35,262] Trial 185 finished with value: 0.12354690610271099 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4498, 'weights': 'distance'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:15:51,217] Trial 176 finished with value: 0.10450970049577327 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:16:08,061] Trial 177 finished with value: 0.10379540945202019 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:20:04,895] Trial 178 finished with value: 0.10593318051765015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:22:02,631] Trial 179 finished with value: 0.10579754997103481 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:23:51,214] Trial 182 finished with value: 0.10467373077050304 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:23:51,726] Trial 191 finished with value: 0.524179962050778 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:26:54,114] Trial 183 finished with value: 0.10419985707460713 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:28:01,854] Trial 184 finished with value: 0.10524760542490197 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:29:27,490] Trial 186 finished with value: 0.1058461470733432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:29:44,417] Trial 195 finished with value: 0.15716881831261462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:30:13,923] Trial 188 finished with value: 0.10432032636527618 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:30:22,086] Trial 187 finished with value: 0.10526021331557558 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:33:07,832] Trial 189 finished with value: 0.10446861596134707 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
running
[I 2024-10-29 03:36:04,316] Trial 190 finished with value: 0.10531734006570599 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:37:36,942] Trial 192 finished with value: 0.10654518350818201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:41:01,117] Trial 193 finished with value: 0.10549984877970753 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:41:44,422] Trial 194 finished with value: 0.10547303204190048 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:43:10,232] Trial 196 finished with value: 0.10397236693546616 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:43:12,227] Trial 197 finished with value: 0.10504770169308415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:43:28,030] Trial 198 finished with value: 0.10539318759068542 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:44:23,734] Trial 199 finished with value: 0.10487003097067657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 03:56:09,781] Trial 77 finished with value: 0.1286457651093493 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 8601, 'learning_rate': 0.0006668084095471848, 'p_miss': 0.010374867680957717}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:10:43,777] Trial 71 finished with value: 0.13054242533068378 and parameters: {'model_name': 'VAE', 'batch_size': 973, 'iterations': 8243, 'learning_rate': 0.0008718934243278347, 'p_miss': 0.024024271649257717}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:14:29,932] Trial 76 finished with value: 0.1303904291698516 and parameters: {'model_name': 'VAE', 'batch_size': 601, 'iterations': 9387, 'learning_rate': 0.0011342879728376185, 'p_miss': 0.019445123676309017}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:18:27,495] Trial 45 finished with value: 0.130340683439423 and parameters: {'model_name': 'VAE', 'batch_size': 637, 'iterations': 9597, 'learning_rate': 0.00012570630351786588, 'p_miss': 0.04056748718610895}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:20:21,448] Trial 31 finished with value: 0.130401913490054 and parameters: {'model_name': 'VAE', 'batch_size': 642, 'iterations': 9938, 'learning_rate': 0.00021824133799689156, 'p_miss': 0.013086092659816279}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:21:03,769] Trial 44 finished with value: 0.13047682419895232 and parameters: {'model_name': 'VAE', 'batch_size': 712, 'iterations': 9894, 'learning_rate': 0.0002152681207225548, 'p_miss': 0.02958495669291819}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:21:15,987] Trial 82 finished with value: 0.13008206453210983 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 7627, 'learning_rate': 0.000847930953140479, 'p_miss': 0.061558293508171325}. Best is trial 163 with value: 0.1033674981065229.
[I 2024-10-29 04:21:46,754] Trial 73 finished with value: 0.13014302969536248 and parameters: {'model_name': 'VAE', 'batch_size': 686, 'iterations': 8725, 'learning_rate': 0.0006543544241353104, 'p_miss': 0.01850840024164066}. Best is trial 163 with value: 0.1033674981065229.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.1033674981065229
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.940036065892911
Generation:   4%|         | 1/25 [00:12<05:07, 12.82s/it]Generation:  2
Best f1_score score: 0.9418377514559897
Generation:   8%|         | 2/25 [00:22<04:11, 10.95s/it]Generation:  3
Best f1_score score: 0.9418377514559897
Generation:  12%|        | 3/25 [00:33<04:06, 11.19s/it]Generation:  4
Best f1_score score: 0.9418377514559897
Generation:  16%|        | 4/25 [00:56<05:27, 15.59s/it]Generation:  5
Best f1_score score: 0.9418377514559897
Generation:  20%|        | 5/25 [01:05<04:27, 13.36s/it]Generation:  6
Best f1_score score: 0.9418377514559897
Generation:  24%|       | 6/25 [01:18<04:11, 13.23s/it]Generation:  7
Best f1_score score: 0.9418377514559897
Generation:  28%|       | 7/25 [01:35<04:19, 14.43s/it]Generation:  8
Best f1_score score: 0.9423762048991973
Generation:  32%|      | 8/25 [01:52<04:16, 15.09s/it]Generation:  9
Best f1_score score: 0.9423762048991973
Generation:  36%|      | 9/25 [02:07<04:04, 15.26s/it]Generation:  10
Best f1_score score: 0.9423762048991973
Generation:  40%|      | 10/25 [02:20<03:38, 14.59s/it]Generation:  11
Best f1_score score: 0.9423762048991973
Generation:  44%|     | 11/25 [02:53<04:40, 20.04s/it]Generation:  12
Best f1_score score: 0.9423762048991973
Generation:  48%|     | 12/25 [03:07<03:57, 18.25s/it]Generation:  13
Best f1_score score: 0.9423762048991973
Generation:  52%|    | 13/25 [03:26<03:43, 18.64s/it]Generation:  14
Best f1_score score: 0.9423762048991973
Generation:  56%|    | 14/25 [04:02<04:20, 23.69s/it]Generation:  15
Best f1_score score: 0.9423762048991973
Generation:  60%|    | 15/25 [04:20<03:40, 22.08s/it]Generation:  16
Best f1_score score: 0.9423762048991973
Generation:  64%|   | 16/25 [04:37<03:04, 20.50s/it]Generation:  17
Best f1_score score: 0.9423762048991973
Generation:  68%|   | 17/25 [05:05<03:02, 22.78s/it]Generation:  18
Best f1_score score: 0.9423762048991973
Generation:  72%|  | 18/25 [05:20<02:23, 20.52s/it]Generation:  19
Best f1_score score: 0.9423762048991973
Generation:  76%|  | 19/25 [07:55<06:04, 60.71s/it]Generation:  20
Best f1_score score: 0.9423762048991973
Generation:  80%|  | 20/25 [09:39<06:09, 73.82s/it]Generation:  21
Best f1_score score: 0.9423762048991973
Generation:  84%| | 21/25 [10:21<04:17, 64.42s/it]Generation:  22
Best f1_score score: 0.9423762048991973
Generation:  88%| | 22/25 [10:43<02:34, 51.42s/it]Generation:  23
Best f1_score score: 0.9423762048991973
Generation:  92%|| 23/25 [11:11<01:29, 44.61s/it]Generation:  24
Best f1_score score: 0.9423762048991973
Generation:  96%|| 24/25 [11:44<00:40, 40.97s/it]Generation:  25
Best f1_score score: 0.9425391726633665
Generation: 100%|| 25/25 [12:05<00:00, 35.19s/it]Generation: 100%|| 25/25 [12:10<00:00, 29.21s/it]
2024-10-29 04:35:03,202 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41387' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-582d7d183af8cedc419ecc82f5b1ea53', 'ndarray-5ecf64e7be59a7a388fc24d66042e6d2'} (stimulus_id='handle-worker-cleanup-1730201703.2018392')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.5820616678939,
                                        min_samples_leaf=3,
                                        min_samples_split=14,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.9957709315924915, 'accuracy': 0.9523058039628266, 'balanced_accuracy': 0.9517818552250807, 'logloss': 0.10768165313773503, 'f1': 0.9520919824449441}
original test score: {'auroc': 0.9750213749893866, 'accuracy': 0.9431977559607293, 'balanced_accuracy': 0.9421552308005205, 'logloss': 0.1834915210596148, 'f1': 0.9428761337014787}
imputed test score: {'auroc': 0.8737177474611646, 'accuracy': 0.8225806451612904, 'balanced_accuracy': 0.8260293069369492, 'logloss': 0.5869370054833334, 'f1': 0.8225763698426352}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d2a980> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.9407542531806762
Generation:   4%|         | 1/25 [00:51<20:38, 51.61s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547459ad70> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  2
Best f1_score score: 0.9407542531806762
Generation:   8%|         | 2/25 [04:26<56:36, 147.69s/it]Generation:  3
Best f1_score score: 0.9416428117670048
Generation:  12%|        | 3/25 [08:01<1:05:25, 178.44s/it]Generation:  4
Best f1_score score: 0.9416428117670048
Generation:  16%|        | 4/25 [11:44<1:08:36, 196.02s/it]Generation:  5
Best f1_score score: 0.9416428117670048
Generation:  20%|        | 5/25 [15:24<1:08:16, 204.81s/it]Generation:  6
Best f1_score score: 0.9416428117670048
Generation:  24%|       | 6/25 [21:22<1:21:16, 256.67s/it]Generation:  7
Best f1_score score: 0.9416428117670048
Generation:  28%|       | 7/25 [28:43<1:35:06, 317.01s/it]Generation:  8
Best f1_score score: 0.9416428117670048
Generation:  32%|      | 8/25 [32:20<1:20:49, 285.28s/it]Generation:  9
Best f1_score score: 0.941814296886801
Generation:  36%|      | 9/25 [35:58<1:10:24, 264.02s/it]Generation:  10
Best f1_score score: 0.941814296886801
Generation:  40%|      | 10/25 [39:34<1:02:17, 249.18s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455284970> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  11
Best f1_score score: 0.941814296886801
Generation:  44%|     | 11/25 [39:56<41:55, 179.67s/it]  Generation:  12
Best f1_score score: 0.9427144631455411
Generation:  48%|     | 12/25 [43:32<41:20, 190.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d5e0b0> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  13
Best f1_score score: 0.9427144631455411
Generation:  52%|    | 13/25 [44:17<29:19, 146.63s/it]Generation:  14
Best f1_score score: 0.9427144631455411
Generation:  56%|    | 14/25 [47:51<30:38, 167.13s/it]Generation:  15
Best f1_score score: 0.9427144631455411
Generation:  60%|    | 15/25 [48:18<20:48, 124.85s/it]Generation:  16
Best f1_score score: 0.9428811487636428
Generation:  64%|   | 16/25 [51:56<22:53, 152.64s/it]Generation:  17
Best f1_score score: 0.9428916858240903
Generation:  68%|   | 17/25 [54:05<19:26, 145.75s/it]Generation:  18
Best f1_score score: 0.9428916858240903
Generation:  72%|  | 18/25 [54:15<12:15, 105.00s/it]Generation:  19
Best f1_score score: 0.9428916858240903
Generation:  76%|  | 19/25 [57:49<13:44, 137.48s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474631a20> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.9428916858240903
Generation:  80%|  | 20/25 [57:56<08:11, 98.38s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bfdf5e0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  21
Best f1_score score: 0.9428916858240903
Generation:  84%| | 21/25 [1:01:28<08:50, 132.56s/it]Generation:  22
Best f1_score score: 0.9434261446798254
Generation:  88%| | 22/25 [1:01:49<04:57, 99.10s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fc8eb60> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  23
Best f1_score score: 0.9434261446798254
Generation:  92%|| 23/25 [1:05:21<04:26, 133.10s/it]Generation:  24
Best f1_score score: 0.9434261446798254
Generation:  96%|| 24/25 [1:05:36<01:37, 97.44s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15542fb28430> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  25
Best f1_score score: 0.9434261446798254
Generation: 100%|| 25/25 [1:05:48<00:00, 71.96s/it]Generation: 100%|| 25/25 [1:05:48<00:00, 157.95s/it]
2024-10-29 05:41:01,543 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38927' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-582d7d183af8cedc419ecc82f5b1ea53', 'DataFrame-328517ad01ff7f6adeffae92a0fdc334'} (stimulus_id='handle-worker-cleanup-1730205661.5430863')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('kneighborsclassifier',
                 KNeighborsClassifier(metric='euclidean', n_jobs=1,
                                      n_neighbors=19, p=3,
                                      weights='distance'))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 2.2204460492503136e-16, 'f1': 1.0}
test score: {'auroc': 0.808105909370045, 'accuracy': 0.7538569424964937, 'balanced_accuracy': 0.7477464936131729, 'logloss': 2.0192063626960675, 'f1': 0.7485586199725012}
original test score: {'auroc': 0.9692012566321706, 'accuracy': 0.9424964936886395, 'balanced_accuracy': 0.9414947288190145, 'logloss': 0.45395387046472846, 'f1': 0.9421769918506211}
score end
803
lvl
0.5
type
MAR
num_run
1
class_full
finished
all finished
full run takes
13.023803306619326
hours
DONE
