Run: 32
/cm/local/apps/slurm/var/spool/job1011344/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/310/310.pkl
working on 
../data/c/310/class_full_MAR_0.5_2
4.93442702293396
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-22 19:23:06,903] A new study created in memory with name: no-name-6e32af44-e7da-4614-931f-7cc594100ee8
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-22 19:23:07,139] Trial 2 finished with value: 0.2225019899264462 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:07,334] Trial 14 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:07,473] Trial 8 finished with value: 0.2225019899264462 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:07,595] Trial 13 finished with value: 0.2225019899264462 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:07,770] Trial 15 finished with value: 0.2225019899264462 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:08,016] Trial 18 finished with value: 0.3463991369118173 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:08,199] Trial 19 finished with value: 0.3463991369118173 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.2225019899264462.
running
[I 2024-10-22 19:23:10,063] Trial 5 finished with value: 0.12700518869063507 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4034, 'weights': 'distance'}. Best is trial 5 with value: 0.12700518869063507.
running
[I 2024-10-22 19:23:13,860] Trial 16 finished with value: 0.17577075757327648 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 5 with value: 0.12700518869063507.
running
[I 2024-10-22 19:23:16,759] Trial 23 finished with value: 0.34641339983816255 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.6388136233202492, 'alpha': 62, 'iterations': 1, 'learning_rate': 0.007029560188328263, 'p_miss': 0.185523016794932}. Best is trial 5 with value: 0.12700518869063507.
running
[I 2024-10-22 19:23:16,989] Trial 24 finished with value: 0.08523362850017241 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1675, 'weights': 'distance'}. Best is trial 24 with value: 0.08523362850017241.
running
[I 2024-10-22 19:23:17,441] Trial 11 finished with value: 0.34200318190396023 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.0898200796181786, 'alpha': 32, 'iterations': 1, 'learning_rate': 0.0001497860235386701, 'p_miss': 0.17253940325375422}. Best is trial 24 with value: 0.08523362850017241.
running
[I 2024-10-22 19:23:19,587] Trial 4 finished with value: 0.08192583934871503 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 4 with value: 0.08192583934871503.
running
[I 2024-10-22 19:23:19,981] Trial 6 finished with value: 0.06338660082335516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:20,323] Trial 22 finished with value: 0.07198496150355013 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:20,612] Trial 7 finished with value: 0.4030768486249441 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.004903616815121977, 'p_miss': 0.06857596888377243}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:20,931] Trial 26 finished with value: 0.09206581443448662 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2552, 'weights': 'distance'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:21,465] Trial 25 finished with value: 0.13532000419524987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4348, 'weights': 'distance'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:21,909] Trial 27 finished with value: 0.09055522512903326 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2401, 'weights': 'distance'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:35,663] Trial 12 finished with value: 0.4088663665400401 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 4, 'learning_rate': 0.0007511288918079887, 'p_miss': 0.19334070728838193}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:36,117] Trial 1 finished with value: 0.4093111982225218 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 5, 'learning_rate': 0.00047133472367772827, 'p_miss': 0.026585666523537874}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:36,496] Trial 29 finished with value: 0.06438117130266188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:36,810] Trial 32 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:37,029] Trial 20 finished with value: 0.3464279367556987 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 2, 'learning_rate': 0.01360110726852697, 'p_miss': 0.292242471397859}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:39,997] Trial 31 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
[I 2024-10-22 19:23:40,183] Trial 34 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
running
[I 2024-10-22 19:23:41,746] Trial 33 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:57,011] Trial 38 finished with value: 0.06436955794667448 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:57,628] Trial 35 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:57,955] Trial 36 finished with value: 0.07124524533087177 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:58,307] Trial 37 finished with value: 0.06932921533380262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:23:58,958] Trial 39 finished with value: 0.06933895723367012 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:24:13,377] Trial 9 finished with value: 0.23574152658488617 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 47, 'learning_rate': 0.06501000088606503, 'p_miss': 0.10463352136715501}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:24:14,571] Trial 40 finished with value: 0.16117135924993167 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:24:16,965] Trial 42 finished with value: 0.16117135924993148 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:24:35,530] Trial 43 finished with value: 0.16117082330313554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:24:40,099] Trial 47 finished with value: 0.1988377205861535 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:27:06,143] Trial 17 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9194823773749435, 'alpha': 13, 'iterations': 1082, 'learning_rate': 0.00013892373050751046, 'p_miss': 0.16499124690548642}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:27:28,370] Trial 3 finished with value: 0.2279505361850283 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 58, 'learning_rate': 0.010710951812732707, 'p_miss': 0.13085537902999028}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:31:58,578] Trial 0 finished with value: 0.33253738250854215 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.3576355257063087, 'alpha': 70, 'iterations': 364, 'learning_rate': 0.002632282221158993, 'p_miss': 0.19034053764037995}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:39:25,302] Trial 21 finished with value: 0.07117409635625493 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 6 with value: 0.06338660082335516.
running
[I 2024-10-22 19:39:39,435] Trial 56 finished with value: 0.06338564991329751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 56 with value: 0.06338564991329751.
running
[I 2024-10-22 19:39:53,248] Trial 57 finished with value: 0.06338564991329751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 56 with value: 0.06338564991329751.
running
[I 2024-10-22 19:40:06,759] Trial 58 finished with value: 0.06338564991329751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 56 with value: 0.06338564991329751.
running
[I 2024-10-22 19:40:25,104] Trial 59 finished with value: 0.14582081462864716 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 56 with value: 0.06338564991329751.
running
[I 2024-10-22 19:41:05,478] Trial 49 finished with value: 0.0559464776527676 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 49 with value: 0.0559464776527676.
running
[I 2024-10-22 19:41:13,404] Trial 41 finished with value: 0.054494704167478224 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:41:24,974] Trial 45 finished with value: 0.05501290427130225 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:41:33,291] Trial 44 finished with value: 0.05516375954246892 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:41:33,856] Trial 46 finished with value: 0.05549279276111628 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:42:04,875] Trial 50 finished with value: 0.05533291445875536 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:42:29,987] Trial 48 finished with value: 0.055829521680237394 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:43:40,716] Trial 53 finished with value: 0.055915632301061766 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:44:32,512] Trial 54 finished with value: 0.05587651196006412 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:48:58,135] Trial 55 finished with value: 0.055859336621284596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:53:40,783] Trial 52 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9542548655154398, 'alpha': 100, 'iterations': 5675, 'learning_rate': 0.03695121478151154, 'p_miss': 0.2816758436553517}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 19:55:21,720] Trial 60 finished with value: 0.06001141873912932 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:12:59,793] Trial 51 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8721133046022824, 'alpha': 98, 'iterations': 9700, 'learning_rate': 0.07688524559431925, 'p_miss': 0.2865288926925367}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:14:38,154] Trial 69 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.025088982511103197, 'alpha': 100, 'iterations': 6595, 'learning_rate': 0.0762728954138643, 'p_miss': 0.2766627301130306}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:15:57,806] Trial 74 finished with value: 0.3858763852893094 and parameters: {'model_name': 'VAE', 'batch_size': 943, 'iterations': 15, 'learning_rate': 0.0017171383228375052, 'p_miss': 0.23136592486592572}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:36:15,808] Trial 73 finished with value: 0.22830558209100293 and parameters: {'model_name': 'VAE', 'batch_size': 693, 'iterations': 273, 'learning_rate': 0.001434226598671567, 'p_miss': 0.2449531350033501}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:40:04,893] Trial 75 finished with value: 0.24324868165194072 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 432, 'learning_rate': 0.00045309431634540703, 'p_miss': 0.052417018742399346}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:45:56,419] Trial 10 finished with value: 0.3718409399388019 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.43554285870969944, 'alpha': 6, 'iterations': 3318, 'learning_rate': 0.01611155142561163, 'p_miss': 0.24392817692783086}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:51:25,783] Trial 76 finished with value: 0.057340600349912695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:55:23,768] Trial 77 finished with value: 0.05731931774735849 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 20:55:24,563] Trial 80 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:01:26,140] Trial 78 finished with value: 0.0573450100227242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:06:58,897] Trial 79 finished with value: 0.05636202166066982 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:07:01,699] Trial 83 finished with value: 0.2225019899264462 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8668, 'weights': 'uniform'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:11:02,004] Trial 81 finished with value: 0.0559476141783393 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:18:08,164] Trial 82 finished with value: 0.05748491482606053 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:22:15,130] Trial 85 finished with value: 0.1169808826838196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:23:40,672] Trial 84 finished with value: 0.0566920181511751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:27:58,606] Trial 61 finished with value: 0.36880688671634454 and parameters: {'model_name': 'GAIN', 'batch_size': 783, 'hint_rate': 0.01994313525407193, 'alpha': 100, 'iterations': 3569, 'learning_rate': 0.0800471240328378, 'p_miss': 0.2973583399546946}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:34:47,982] Trial 86 finished with value: 0.056213863056897316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:38:47,049] Trial 87 finished with value: 0.05662646109789412 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:40:08,650] Trial 88 finished with value: 0.05600128291015692 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:40:09,486] Trial 92 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:44:35,384] Trial 89 finished with value: 0.05617619979553692 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:52:10,469] Trial 90 finished with value: 0.05653028775283937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:52:13,765] Trial 95 finished with value: 0.2225019899264462 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8039, 'weights': 'uniform'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:54:00,365] Trial 93 finished with value: 0.08670905767863109 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 41 with value: 0.054494704167478224.
running
[I 2024-10-22 21:56:09,520] Trial 91 finished with value: 0.053344127399440236 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 21:58:16,322] Trial 94 finished with value: 0.07941077524417453 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 21:58:25,914] Trial 68 finished with value: 0.3497433878430176 and parameters: {'model_name': 'GAIN', 'batch_size': 822, 'hint_rate': 0.9810725503964485, 'alpha': 98, 'iterations': 4441, 'learning_rate': 0.09030631091421167, 'p_miss': 0.2948615144712355}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 21:58:29,271] Trial 99 finished with value: 0.14569485601250695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 21:58:41,013] Trial 100 finished with value: 0.14569485601250695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:09:52,253] Trial 96 finished with value: 0.053433367006928 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:11:31,275] Trial 97 finished with value: 0.0560872571589076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:13:33,851] Trial 98 finished with value: 0.0551001618880711 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:15:34,904] Trial 101 finished with value: 0.05487947426151922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:15:56,416] Trial 102 finished with value: 0.05569334357373821 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:27:15,493] Trial 103 finished with value: 0.05633469836016418 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:28:51,389] Trial 104 finished with value: 0.0556616778563452 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:30:56,342] Trial 105 finished with value: 0.05584847934201721 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:32:55,730] Trial 106 finished with value: 0.0558961073472911 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:33:27,703] Trial 107 finished with value: 0.05458372857370066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:33:28,123] Trial 112 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:44:26,135] Trial 108 finished with value: 0.05487597885422372 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:45:56,371] Trial 109 finished with value: 0.05520405393103759 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:46:28,344] Trial 63 finished with value: 0.37538820621790975 and parameters: {'model_name': 'GAIN', 'batch_size': 806, 'hint_rate': 0.050342365341895734, 'alpha': 95, 'iterations': 6148, 'learning_rate': 0.08248757914396716, 'p_miss': 0.27996332114723443}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:48:21,312] Trial 110 finished with value: 0.05516719466427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:49:56,923] Trial 111 finished with value: 0.05503135095204781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 22:50:53,618] Trial 113 finished with value: 0.05494957081724834 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:01:51,535] Trial 114 finished with value: 0.05491171337562952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:03:40,334] Trial 115 finished with value: 0.05547476067149813 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:03:42,668] Trial 116 finished with value: 0.054912629342058004 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:04:03,077] Trial 122 finished with value: 0.23188221914368007 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 17, 'learning_rate': 0.02508553784132282, 'p_miss': 0.012345909009656236}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:04:16,153] Trial 121 finished with value: 0.19717572549226123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:04:20,770] Trial 124 finished with value: 0.2217242693143838 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6154, 'weights': 'uniform'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:04:42,429] Trial 123 finished with value: 0.19717572549226123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:06:24,408] Trial 117 finished with value: 0.055195489525999966 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:07:55,175] Trial 118 finished with value: 0.05491377349314084 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:09:07,011] Trial 119 finished with value: 0.05521504447285952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:12:41,153] Trial 65 finished with value: 0.36281235110009274 and parameters: {'model_name': 'GAIN', 'batch_size': 788, 'hint_rate': 0.9627091567459334, 'alpha': 99, 'iterations': 6979, 'learning_rate': 0.05091261204709733, 'p_miss': 0.2882521896434456}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:14:36,440] Trial 62 finished with value: 0.3440552935743595 and parameters: {'model_name': 'GAIN', 'batch_size': 972, 'hint_rate': 0.018927548711667075, 'alpha': 89, 'iterations': 6935, 'learning_rate': 0.09104958485105036, 'p_miss': 0.29786745947213267}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:20:10,742] Trial 120 finished with value: 0.05531936284779117 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:22:05,894] Trial 126 finished with value: 0.054740439296164456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:22:18,190] Trial 125 finished with value: 0.05474451587979177 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:24:12,166] Trial 127 finished with value: 0.055135930181305734 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:25:30,049] Trial 128 finished with value: 0.055041879245393666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:26:55,823] Trial 129 finished with value: 0.05523777339111321 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:30:25,254] Trial 130 finished with value: 0.05497013395388782 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:32:11,229] Trial 131 finished with value: 0.05531214845965029 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:35:54,852] Trial 64 finished with value: 0.3766499536459428 and parameters: {'model_name': 'GAIN', 'batch_size': 973, 'hint_rate': 0.011730974696835872, 'alpha': 100, 'iterations': 7490, 'learning_rate': 0.08997470351176999, 'p_miss': 0.2979808762390954}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:37:58,890] Trial 132 finished with value: 0.05499011317251758 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:39:37,159] Trial 133 finished with value: 0.05530027972420344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:40:18,299] Trial 134 finished with value: 0.056866215226981466 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:42:14,483] Trial 135 finished with value: 0.054670590642158255 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:43:12,222] Trial 70 finished with value: 0.3682697015032711 and parameters: {'model_name': 'GAIN', 'batch_size': 806, 'hint_rate': 0.021074396467021472, 'alpha': 96, 'iterations': 7665, 'learning_rate': 0.09203660813019626, 'p_miss': 0.2963388917114587}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:43:21,679] Trial 136 finished with value: 0.05571122627824352 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:44:51,028] Trial 137 finished with value: 0.0561296295248432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:48:12,976] Trial 138 finished with value: 0.05626586928631969 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:49:56,297] Trial 139 finished with value: 0.05430931103862259 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:53:53,916] Trial 140 finished with value: 0.059883353905332205 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:54:13,618] Trial 150 finished with value: 0.14578184671294264 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:54:14,439] Trial 151 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:56:15,390] Trial 141 finished with value: 0.0567242868837182 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:57:26,982] Trial 142 finished with value: 0.05611763060068581 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-22 23:58:30,047] Trial 143 finished with value: 0.056392584473775806 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:00:31,346] Trial 144 finished with value: 0.05954978832395298 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:01:15,176] Trial 145 finished with value: 0.056256544260330624 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:01:23,244] Trial 146 finished with value: 0.05488666031208396 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:03:01,000] Trial 153 finished with value: 0.3958788507085145 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 115, 'learning_rate': 0.00018230760833731153, 'p_miss': 0.1376951994623944}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:03:05,701] Trial 147 finished with value: 0.05478589985674476 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:03:08,626] Trial 160 finished with value: 0.07739757787463616 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 610, 'weights': 'uniform'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:06:17,118] Trial 148 finished with value: 0.05631010482388686 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:07:39,819] Trial 149 finished with value: 0.05688480559203033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:09:55,816] Trial 157 finished with value: 0.37442258071077655 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 137, 'learning_rate': 0.0003214923887946799, 'p_miss': 0.12535600628622212}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:12:10,539] Trial 152 finished with value: 0.05694822923672962 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:18:32,618] Trial 156 finished with value: 0.05511912228297711 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:21:13,660] Trial 161 finished with value: 0.0554136690292097 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:21:23,439] Trial 159 finished with value: 0.05443835916922487 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:24:11,925] Trial 162 finished with value: 0.055198305560559525 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:25:43,044] Trial 163 finished with value: 0.05494738985482668 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:25:51,777] Trial 164 finished with value: 0.06967064014982964 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:28:13,350] Trial 165 finished with value: 0.0685751957823694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:36:36,307] Trial 166 finished with value: 0.054771911693006804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:36:50,087] Trial 173 finished with value: 0.06447014832048875 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:37:31,966] Trial 167 finished with value: 0.07045114685363485 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:38:15,421] Trial 175 finished with value: 0.16117135924993167 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:40:08,389] Trial 168 finished with value: 0.055476991394724416 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:42:37,768] Trial 169 finished with value: 0.05462409001799886 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:43:55,358] Trial 170 finished with value: 0.0554706735001288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:44:25,168] Trial 171 finished with value: 0.054889126857047735 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:44:39,609] Trial 180 finished with value: 0.1456954665183254 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:46:56,114] Trial 172 finished with value: 0.05484226853163217 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:46:56,685] Trial 182 finished with value: 0.34779019637341835 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:49:00,103] Trial 30 finished with value: 0.22820747435131264 and parameters: {'model_name': 'VAE', 'batch_size': 536, 'iterations': 5405, 'learning_rate': 0.08706770231066814, 'p_miss': 0.04143507733045691}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:55:18,140] Trial 174 finished with value: 0.05533485905927131 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:56:19,434] Trial 176 finished with value: 0.054727272662120276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 00:58:18,553] Trial 177 finished with value: 0.05511646640986888 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:00:28,726] Trial 178 finished with value: 0.054793869859674806 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:01:42,226] Trial 179 finished with value: 0.05512063764498626 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:02:26,574] Trial 181 finished with value: 0.055045523673331875 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:04:53,049] Trial 183 finished with value: 0.05461867030291105 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:06:54,445] Trial 184 finished with value: 0.05550971619323355 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:13:13,601] Trial 185 finished with value: 0.054893240803367306 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:14:18,555] Trial 186 finished with value: 0.054812163634977075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:14:22,002] Trial 194 finished with value: 0.22299090421895373 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6531, 'weights': 'uniform'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:16:04,858] Trial 155 finished with value: 0.22702303252753214 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1409, 'learning_rate': 0.00020598252447721554, 'p_miss': 0.13225960079921026}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:16:16,105] Trial 187 finished with value: 0.05714057552104833 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:18:03,106] Trial 188 finished with value: 0.05475098961233429 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:19:13,558] Trial 189 finished with value: 0.05537068693600998 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
running
[I 2024-10-23 01:20:09,236] Trial 190 finished with value: 0.05489776215432918 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 91 with value: 0.053344127399440236.
[I 2024-10-23 01:21:20,595] Trial 154 finished with value: 0.29995406382765877 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1459, 'learning_rate': 0.00010057359840180776, 'p_miss': 0.1331428953206023}. Best is trial 91 with value: 0.053344127399440236.
[I 2024-10-23 01:22:28,501] Trial 191 finished with value: 0.05355365033166791 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 91 with value: 0.053344127399440236.
[I 2024-10-23 01:24:16,935] Trial 192 finished with value: 0.05312800049049223 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:29:28,329] Trial 193 finished with value: 0.05599427815928722 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:30:22,907] Trial 195 finished with value: 0.05538553171460801 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:31:42,822] Trial 196 finished with value: 0.05603755359179907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:31:47,724] Trial 197 finished with value: 0.05600476337273835 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:32:05,301] Trial 158 finished with value: 0.22817323168432896 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1837, 'learning_rate': 0.0002179564487027807, 'p_miss': 0.0995708020160429}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:32:45,614] Trial 198 finished with value: 0.05607036339073681 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:33:35,735] Trial 199 finished with value: 0.056005929673308974 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:37:56,476] Trial 67 finished with value: 0.2267548836491134 and parameters: {'model_name': 'VAE', 'batch_size': 862, 'iterations': 5970, 'learning_rate': 0.07882126865914431, 'p_miss': 0.282643564386129}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:46:50,160] Trial 28 finished with value: 0.22650556410817724 and parameters: {'model_name': 'VAE', 'batch_size': 892, 'iterations': 7059, 'learning_rate': 0.08865633353523443, 'p_miss': 0.05602289335733371}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:51:36,622] Trial 66 finished with value: 0.23541068696937054 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8659, 'learning_rate': 0.05578216745549453, 'p_miss': 0.28485759227948637}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:53:15,585] Trial 72 finished with value: 0.22696167957502272 and parameters: {'model_name': 'VAE', 'batch_size': 918, 'iterations': 8133, 'learning_rate': 0.0014897611329383904, 'p_miss': 0.24704576289882602}. Best is trial 192 with value: 0.05312800049049223.
[I 2024-10-23 01:53:52,051] Trial 71 finished with value: 0.2305861084862754 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 8379, 'learning_rate': 0.001745005291235868, 'p_miss': 0.24295719743848787}. Best is trial 192 with value: 0.05312800049049223.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.05312800049049223
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.7997807956557118
Generation:   4%|         | 1/25 [00:38<15:26, 38.59s/it]Generation:  2
Best f1_score score: 0.7997807956557118
Generation:   8%|         | 2/25 [07:51<1:43:39, 270.42s/it]Generation:  3
Best f1_score score: 0.8225446593833377
Generation:  12%|        | 3/25 [11:07<1:26:48, 236.73s/it]Generation:  4
Best f1_score score: 0.8225446593833377
Generation:  16%|        | 4/25 [11:21<52:03, 148.75s/it]  Generation:  5
Best f1_score score: 0.8225446593833377
Generation:  20%|        | 5/25 [11:38<33:41, 101.09s/it]Generation:  6
Best f1_score score: 0.8225446593833377
Generation:  24%|       | 6/25 [13:19<31:59, 101.03s/it]Generation:  7
Best f1_score score: 0.8225446593833377
Generation:  28%|       | 7/25 [13:37<22:13, 74.07s/it] Generation:  8
Best f1_score score: 0.8225446593833377
Generation:  32%|      | 8/25 [15:11<22:45, 80.31s/it]Generation:  9
Best f1_score score: 0.8225446593833377
Generation:  36%|      | 9/25 [15:44<17:26, 65.39s/it]Generation:  10
Best f1_score score: 0.8225446593833377
Generation:  40%|      | 10/25 [16:07<13:06, 52.46s/it]Generation:  11
Best f1_score score: 0.8225446593833377
Generation:  44%|     | 11/25 [16:24<09:42, 41.58s/it]Generation:  12
Best f1_score score: 0.8225446593833377
Generation:  48%|     | 12/25 [18:24<14:12, 65.54s/it]Generation:  13
Best f1_score score: 0.8225446593833377
Generation:  52%|    | 13/25 [18:40<10:03, 50.32s/it]Generation:  14
Best f1_score score: 0.8250341904601874
Generation:  56%|    | 14/25 [19:01<07:38, 41.69s/it]Generation:  15
Best f1_score score: 0.8250341904601874
Generation:  60%|    | 15/25 [19:20<05:48, 34.84s/it]Generation:  16
Best f1_score score: 0.8250341904601874
Generation:  64%|   | 16/25 [20:23<06:28, 43.18s/it]Generation:  17
Best f1_score score: 0.8250341904601874
Generation:  68%|   | 17/25 [20:35<04:31, 33.91s/it]Generation:  18
Best f1_score score: 0.8250341904601874
Generation:  72%|  | 18/25 [20:51<03:19, 28.57s/it]Generation:  19
Best f1_score score: 0.8250341904601874
Generation:  76%|  | 19/25 [21:08<02:30, 25.02s/it]Generation:  20
Best f1_score score: 0.8250341904601874
Generation:  80%|  | 20/25 [21:21<01:47, 21.42s/it]Generation:  21
Best f1_score score: 0.8250341904601874
Generation:  84%| | 21/25 [21:35<01:16, 19.18s/it]Generation:  22
Best f1_score score: 0.8250341904601874
Generation:  88%| | 22/25 [21:52<00:55, 18.38s/it]Generation:  23
Best f1_score score: 0.8250341904601874
Generation:  92%|| 23/25 [26:11<03:01, 90.68s/it]Generation:  24
Best f1_score score: 0.8250341904601874
Generation:  96%|| 24/25 [26:33<01:10, 70.14s/it]Generation:  25
Best f1_score score: 0.8250341904601874
Generation: 100%|| 25/25 [26:57<00:00, 56.11s/it]Generation: 100%|| 25/25 [27:00<00:00, 64.83s/it]
2024-10-23 02:22:40,407 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44227' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-b5f468972b7ffa9aa2eaa92c4caed8b0', 'ndarray-9e1de1552c42d282edf2f63e27ef1a61'} (stimulus_id='handle-worker-cleanup-1729675360.4073238')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(boosting_type='dart', max_depth=8,
                                n_estimators=61, n_jobs=1, num_leaves=61,
                                verbose=-1))])
score start
train score: {'auroc': 0.9911769107523284, 'accuracy': 0.9984350547730829, 'balanced_accuracy': 0.9710394034896209, 'logloss': 0.022258679289353125, 'f1': 0.9823583004334502}
original test score: {'auroc': 0.9373965851082555, 'accuracy': 0.9852481001341081, 'balanced_accuracy': 0.8234905826439007, 'logloss': 0.05533195364288531, 'f1': 0.8328605099247633}
imputed test score: {'auroc': 0.8746039429677874, 'accuracy': 0.9812248547161377, 'balanced_accuracy': 0.7557252244323183, 'logloss': 0.06316813445427664, 'f1': 0.7764532891731384}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd08b0> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d60> 
 Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1223, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.794610777967659
Generation:   4%|         | 1/25 [01:13<29:14, 73.09s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d19cf0> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1ffd0> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 589, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.8235927640439961
Generation:   8%|         | 2/25 [07:54<1:42:02, 266.20s/it]Generation:  3
Best f1_score score: 0.8235927640439961
Generation:  12%|        | 3/25 [14:39<2:00:51, 329.61s/it]Generation:  4
Best f1_score score: 0.8235927640439961
Generation:  16%|        | 4/25 [21:22<2:05:33, 358.75s/it]Generation:  5
Best f1_score score: 0.8237092971648506
Generation:  20%|        | 5/25 [28:07<2:05:08, 375.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b144a90> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.8237092971648506
Generation:  24%|       | 6/25 [34:51<2:01:54, 384.97s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d33400> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.824325777659762
Generation:  28%|       | 7/25 [41:33<1:57:10, 390.57s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545735fc10> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  8
Best f1_score score: 0.824325777659762
Generation:  32%|      | 8/25 [48:21<1:52:11, 395.99s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452f27700> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15540a073910> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  9
Best f1_score score: 0.8262889071077357
Generation:  36%|      | 9/25 [55:04<1:46:14, 398.39s/it]Generation:  10
Best f1_score score: 0.8262889071077357
Generation:  40%|      | 10/25 [55:50<1:12:24, 289.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553e7529f00> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  11
Best f1_score score: 0.8262889071077357
Generation:  44%|     | 11/25 [56:14<48:37, 208.36s/it]  Generation:  12
Best f1_score score: 0.8262889071077357
Generation:  48%|     | 12/25 [1:03:00<58:10, 268.46s/it]Generation:  13
Best f1_score score: 0.8262889071077357
Generation:  52%|    | 13/25 [1:04:13<41:49, 209.09s/it]Generation:  14
Best f1_score score: 0.8262889071077357
Generation:  56%|    | 14/25 [1:10:50<48:45, 265.92s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454d004f0> 

Generation:  15
Best f1_score score: 0.8262889071077357
Generation:  60%|    | 15/25 [1:20:58<1:01:31, 369.14s/it]Generation:  16
Best f1_score score: 0.827346752915821
Generation:  64%|   | 16/25 [1:21:22<39:46, 265.21s/it]  Generation:  17
Best f1_score score: 0.827346752915821
Generation:  68%|   | 17/25 [1:21:55<26:01, 195.18s/it]Generation:  18
Best f1_score score: 0.827346752915821
Generation:  72%|  | 18/25 [1:30:30<33:59, 291.43s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f5dd000> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.827346752915821
Generation:  76%|  | 19/25 [1:31:47<22:42, 227.00s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b9db670> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.827346752915821
Generation:  80%|  | 20/25 [1:38:37<23:29, 281.91s/it]Generation:  21
Best f1_score score: 0.8328241857074973
Generation:  84%| | 21/25 [1:45:22<21:15, 318.96s/it]Generation:  22
Best f1_score score: 0.8328241857074973
Generation:  88%| | 22/25 [1:45:54<11:37, 232.66s/it]Generation:  23
Best f1_score score: 0.8328241857074973
Generation:  92%|| 23/25 [1:46:18<05:40, 170.24s/it]Generation:  24
Best f1_score score: 0.8328241857074973
Generation:  96%|| 24/25 [1:53:02<04:00, 240.29s/it]Generation:  25
Best f1_score score: 0.8328241857074973
Generation: 100%|| 25/25 [1:59:47<00:00, 289.61s/it]Generation: 100%|| 25/25 [1:59:47<00:00, 287.49s/it]
2024-10-23 04:22:38,528 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37647' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-787be2d1e81f99eccafa71cb9569fbbd', 'ndarray-b5f468972b7ffa9aa2eaa92c4caed8b0'} (stimulus_id='handle-worker-cleanup-1729682558.5287323')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=34)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      criterion='entropy',
                                      max_features=0.4029367454936,
                                      min_samples_leaf=2, min_samples_split=9,
                                      n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9877130944416078, 'accuracy': 0.9881511289961994, 'balanced_accuracy': 0.9563885416483265, 'logloss': 0.12184052515415637, 'f1': 0.8887911077544453}
test score: {'auroc': 0.847165991902834, 'accuracy': 0.9749664729548503, 'balanced_accuracy': 0.6304963914803732, 'logloss': 0.13557655215514564, 'f1': 0.6602885345482157}
original test score: {'auroc': 0.9491638795986622, 'accuracy': 0.9772016092981672, 'balanced_accuracy': 0.8475312444992079, 'logloss': 0.14532040519080708, 'f1': 0.7901365831225569}
score end
310
lvl
0.5
type
MAR
num_run
2
class_full
finished
all finished
full run takes
9.003061882853508
hours
DONE
