Run: 36
/cm/local/apps/slurm/var/spool/job1025220/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/737/737.pkl
working on 
../data/c/737/class_full_MNAR_0.5_2
1.9412050247192383
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-26 08:12:11,060] A new study created in memory with name: no-name-743a8a05-1b93-4a30-8c4c-9450fe9ebe02
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-26 08:12:11,180] Trial 1 finished with value: 0.22115566152444804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 1 with value: 0.22115566152444804.
running
[I 2024-10-26 08:12:11,314] Trial 5 finished with value: 0.22115566152444804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 1 with value: 0.22115566152444804.
running
[I 2024-10-26 08:12:12,002] Trial 4 finished with value: 0.22115566152444804 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1973, 'weights': 'uniform'}. Best is trial 1 with value: 0.22115566152444804.
running
[I 2024-10-26 08:12:12,203] Trial 16 finished with value: 0.2662520413543335 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 614, 'weights': 'distance'}. Best is trial 1 with value: 0.22115566152444804.
[I 2024-10-26 08:12:12,204] Trial 11 finished with value: 0.22115566152444804 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2174, 'weights': 'uniform'}. Best is trial 1 with value: 0.22115566152444804.
[I 2024-10-26 08:12:12,208] Trial 12 finished with value: 0.22823625948104906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 921, 'weights': 'uniform'}. Best is trial 1 with value: 0.22115566152444804.
[I 2024-10-26 08:12:12,211] Trial 2 finished with value: 0.26727495158548165 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1063, 'weights': 'distance'}. Best is trial 1 with value: 0.22115566152444804.
running
running
running
running
[I 2024-10-26 08:12:13,322] Trial 17 finished with value: 0.22065920516364726 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 17 with value: 0.22065920516364726.
running
[I 2024-10-26 08:12:14,170] Trial 23 finished with value: 0.2662153235797865 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 564, 'weights': 'distance'}. Best is trial 17 with value: 0.22065920516364726.
running
[I 2024-10-26 08:12:17,825] Trial 6 finished with value: 0.22490982083009925 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 17 with value: 0.22065920516364726.
running
[I 2024-10-26 08:12:20,067] Trial 21 finished with value: 0.23047599807882033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 17 with value: 0.22065920516364726.
running
[I 2024-10-26 08:12:21,298] Trial 0 finished with value: 0.1361173313217202 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.0009242349648735765, 'p_miss': 0.12186158322054878}. Best is trial 0 with value: 0.1361173313217202.
running
[I 2024-10-26 08:12:23,375] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.933903697116417, 'alpha': 61, 'iterations': 16, 'learning_rate': 0.00020561851046896736, 'p_miss': 0.07001937401127448}. Best is trial 0 with value: 0.1361173313217202.
running
[I 2024-10-26 08:12:23,799] Trial 24 finished with value: 0.22124543554453932 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 0 with value: 0.1361173313217202.
running
[I 2024-10-26 08:12:26,410] Trial 27 finished with value: 0.13000883357310639 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0007979022150360282, 'p_miss': 0.11783455559617831}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:29,995] Trial 22 finished with value: 0.3839080694412712 and parameters: {'model_name': 'GAIN', 'batch_size': 288, 'hint_rate': 0.5404132938670567, 'alpha': 84, 'iterations': 6, 'learning_rate': 0.0068779215812953655, 'p_miss': 0.19237340948686243}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:30,983] Trial 10 finished with value: 0.13599554424241952 and parameters: {'model_name': 'VAE', 'batch_size': 179, 'iterations': 2, 'learning_rate': 0.0023796235928894797, 'p_miss': 0.06091318197914732}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:31,188] Trial 30 finished with value: 0.13559271198833173 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.0014302181290251638, 'p_miss': 0.15703764259767894}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:31,796] Trial 28 finished with value: 0.1431693962615294 and parameters: {'model_name': 'VAE', 'batch_size': 177, 'iterations': 1, 'learning_rate': 0.009353361713149213, 'p_miss': 0.23433837747822425}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:36,688] Trial 31 finished with value: 0.13008255028759838 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0006144048085639934, 'p_miss': 0.10992681151556628}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:37,219] Trial 29 finished with value: 0.14615029543976568 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 1, 'learning_rate': 0.008434913570314973, 'p_miss': 0.24567761728302295}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:44,411] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.06058149631192802, 'alpha': 75, 'iterations': 79, 'learning_rate': 0.00017095566877903785, 'p_miss': 0.15780660314105793}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:12:45,848] Trial 26 finished with value: 0.1523023549356848 and parameters: {'model_name': 'VAE', 'batch_size': 193, 'iterations': 2, 'learning_rate': 0.008506683575035747, 'p_miss': 0.09937165499085165}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:14:57,427] Trial 3 finished with value: 0.23390816073060966 and parameters: {'model_name': 'VAE', 'batch_size': 257, 'iterations': 37, 'learning_rate': 0.006983631768238951, 'p_miss': 0.18645729980671163}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:17:32,372] Trial 7 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9666556367913036, 'alpha': 97, 'iterations': 1023, 'learning_rate': 0.00017836476022001062, 'p_miss': 0.17336934350528055}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:17:58,788] Trial 40 finished with value: 0.1441582635238837 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7, 'learning_rate': 0.0008295221624852792, 'p_miss': 0.021628195372813103}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:21:16,807] Trial 14 finished with value: 0.22737911595959331 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:21:22,529] Trial 8 finished with value: 0.22982448675919298 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:21:37,754] Trial 43 finished with value: 0.1378282829669181 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.0006928456846035067, 'p_miss': 0.12192227922546214}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:22:18,084] Trial 13 finished with value: 0.22756886933702755 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:20,871] Trial 42 finished with value: 0.21528183055445135 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 196, 'learning_rate': 0.000978133422582945, 'p_miss': 0.12051497983015856}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:30,450] Trial 46 finished with value: 0.17844205449870593 and parameters: {'model_name': 'VAE', 'batch_size': 982, 'iterations': 2, 'learning_rate': 0.05566724554329269, 'p_miss': 0.07410104137249644}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:34,209] Trial 47 finished with value: 0.14429755513705086 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.002092716553391851, 'p_miss': 0.037231917270997686}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:43,530] Trial 48 finished with value: 0.14075470888786842 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 3, 'learning_rate': 0.0025175412287325844, 'p_miss': 0.07670578741486173}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:44,101] Trial 49 finished with value: 0.41106939266515746 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:30:47,430] Trial 50 finished with value: 0.1407999135813291 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.00038877227746264494, 'p_miss': 0.14249859074240886}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:31:22,382] Trial 51 finished with value: 0.136215289143416 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 12, 'learning_rate': 0.0017293062822027543, 'p_miss': 0.04961463257799226}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:32:53,248] Trial 20 finished with value: 0.23126068512510875 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 320, 'learning_rate': 0.06221643519704472, 'p_miss': 0.04165798348144668}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:32:53,457] Trial 53 finished with value: 0.41106939266515746 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:33:36,608] Trial 44 finished with value: 0.23687073080067073 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 240, 'learning_rate': 0.002210737579274615, 'p_miss': 0.11810325762214968}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:33:46,523] Trial 55 finished with value: 0.13668722738134298 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0003300463447321222, 'p_miss': 0.21992400770416853}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:33:50,483] Trial 56 finished with value: 0.13557700657685973 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.0010810172177574474, 'p_miss': 0.13925001259487546}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:33:53,888] Trial 37 finished with value: 0.2349609857914814 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 389, 'learning_rate': 0.0009293852820220704, 'p_miss': 0.11411507617567052}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:33:58,326] Trial 57 finished with value: 0.1388771580184139 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0004974262538076197, 'p_miss': 0.29779123423982}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:34:01,548] Trial 58 finished with value: 0.14069860951106472 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.00045796828047272534, 'p_miss': 0.28474943834914257}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:35:10,463] Trial 45 finished with value: 0.2399532037046479 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 238, 'learning_rate': 0.0021240644994139444, 'p_miss': 0.12393372280023253}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:35:10,741] Trial 61 finished with value: 0.3084386522872819 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:35:15,033] Trial 62 finished with value: 0.13803011767166734 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 1, 'learning_rate': 0.0012640119783176862, 'p_miss': 0.15435584290762297}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:35:21,408] Trial 63 finished with value: 0.13916798872833921 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2, 'learning_rate': 0.00402452446582817, 'p_miss': 0.09317126248589282}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:36:13,575] Trial 18 finished with value: 0.3644958873488878 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.5141454757196964, 'alpha': 81, 'iterations': 1031, 'learning_rate': 0.00030087129171899073, 'p_miss': 0.29543300957734137}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:38:50,910] Trial 35 finished with value: 0.25649217877810376 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 637, 'learning_rate': 0.06799956781120374, 'p_miss': 0.11646775765209301}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:46:02,342] Trial 36 finished with value: 0.20465438483838297 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 631, 'learning_rate': 0.0004404350023298948, 'p_miss': 0.1304996103715748}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:46:03,123] Trial 67 finished with value: 0.21569487600963705 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 34, 'weights': 'uniform'}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 08:46:06,852] Trial 68 finished with value: 0.13441161749283276 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.001182902741150539, 'p_miss': 0.17947326630050012}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 09:02:11,418] Trial 64 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.04610248343219486, 'alpha': 5, 'iterations': 6003, 'learning_rate': 0.003503170517168906, 'p_miss': 0.14938643743662705}. Best is trial 27 with value: 0.13000883357310639.
running
[I 2024-10-26 09:02:15,464] Trial 70 finished with value: 0.12996966242038444 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.0013374566239187334, 'p_miss': 0.17638976800177447}. Best is trial 70 with value: 0.12996966242038444.
running
[I 2024-10-26 09:02:19,812] Trial 71 finished with value: 0.12947776437595865 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0013672808119718244, 'p_miss': 0.18016628507231142}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:02:32,945] Trial 72 finished with value: 0.135757707118148 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.0007281364207109523, 'p_miss': 0.19705183158324568}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:03:10,637] Trial 73 finished with value: 0.13668783145067492 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 10, 'learning_rate': 0.00010275660627309175, 'p_miss': 0.17753005463084637}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:03:10,968] Trial 74 finished with value: 0.3084386522872819 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:12,365] Trial 75 finished with value: 0.13647022963468286 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 29, 'learning_rate': 0.001220233535459569, 'p_miss': 0.1702533623779939}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:16,744] Trial 76 finished with value: 0.13890228913802552 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.0014648410023588385, 'p_miss': 0.20462199309561463}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:20,318] Trial 77 finished with value: 0.13320758489430617 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0006032287858427353, 'p_miss': 0.1681950161405887}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:26,809] Trial 78 finished with value: 0.1389819422815588 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0006433591634188541, 'p_miss': 0.173031088001788}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:27,814] Trial 79 finished with value: 0.2680647233349084 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1624, 'weights': 'distance'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:34,384] Trial 80 finished with value: 0.31238583989058155 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:45,593] Trial 81 finished with value: 0.14156388586250704 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.00024594603243401016, 'p_miss': 0.14039735980110218}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:49,086] Trial 82 finished with value: 0.13806977980052015 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.000582329174478279, 'p_miss': 0.1820377908646106}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:51,814] Trial 83 finished with value: 0.38795840608940163 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.35568384976303924, 'alpha': 25, 'iterations': 1, 'learning_rate': 0.0010658420222760501, 'p_miss': 0.1652178240594916}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:05:59,078] Trial 84 finished with value: 0.13723109724684573 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.000849454433794405, 'p_miss': 0.09829589186373434}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:06:11,968] Trial 85 finished with value: 0.14226306215031875 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.0015010248620100754, 'p_miss': 0.20722364939311952}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:06:17,282] Trial 86 finished with value: 0.14056184796116591 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.004830607939805119, 'p_miss': 0.1601438793013682}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:10:37,259] Trial 87 finished with value: 0.14708314605831782 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 86, 'learning_rate': 0.0011641531632000518, 'p_miss': 0.1377869285163522}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:10:41,665] Trial 88 finished with value: 0.13460142854445972 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.001726550384510194, 'p_miss': 0.15529882529739567}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:10:48,973] Trial 89 finished with value: 0.13497929212739512 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.002817394840404423, 'p_miss': 0.19303288524429518}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:10:55,501] Trial 90 finished with value: 0.13759493147399554 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.0028289227633160165, 'p_miss': 0.1889729035404818}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:11:07,318] Trial 91 finished with value: 0.13639538118435002 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0017732844432505033, 'p_miss': 0.18310747983592}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:11:14,454] Trial 92 finished with value: 0.21918430785356596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:04,819] Trial 34 finished with value: 0.24994907165391425 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1041, 'learning_rate': 0.00043772907331337966, 'p_miss': 0.14799244828642488}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:09,354] Trial 94 finished with value: 0.13467593379377357 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.006043322775075739, 'p_miss': 0.21028878125600992}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:09,986] Trial 95 finished with value: 0.22115566152444804 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2406, 'weights': 'uniform'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:14,807] Trial 96 finished with value: 0.13909246148393664 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.012322747048157008, 'p_miss': 0.2224850507715003}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:18,855] Trial 97 finished with value: 0.13114356424402623 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00571524761813864, 'p_miss': 0.20000363141882962}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:24,916] Trial 98 finished with value: 0.1346079119997064 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.013357676509912791, 'p_miss': 0.2104952805910326}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:36,038] Trial 99 finished with value: 0.1322993316471865 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.01633029406860445, 'p_miss': 0.2305665540834387}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:12:49,133] Trial 100 finished with value: 0.15773648196925802 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.03732323811386312, 'p_miss': 0.24037372429744064}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:13:08,735] Trial 101 finished with value: 0.16837709523453098 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5, 'learning_rate': 0.01942428630249784, 'p_miss': 0.10896691988702067}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:13:13,422] Trial 102 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7750623475097772, 'alpha': 40, 'iterations': 7, 'learning_rate': 0.023527396447078245, 'p_miss': 0.2586514414842304}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:14:15,527] Trial 103 finished with value: 0.13826767209765972 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 22, 'learning_rate': 0.0008262044914980128, 'p_miss': 0.15987555011704255}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:14:25,023] Trial 104 finished with value: 0.14029028699309137 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.0005470613632693835, 'p_miss': 0.17221824118311305}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:14:25,275] Trial 105 finished with value: 0.41106939266515746 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:14:29,850] Trial 106 finished with value: 0.13465830809855056 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.014434710365218798, 'p_miss': 0.19669580968375341}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:17:21,819] Trial 107 finished with value: 0.23215805913097548 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 55, 'learning_rate': 0.012375776357147502, 'p_miss': 0.21329559640090726}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:17:26,218] Trial 108 finished with value: 0.13385558979398365 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.001769711868224175, 'p_miss': 0.22499333787301695}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:17:30,481] Trial 109 finished with value: 0.13369616976826557 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.001711102127169804, 'p_miss': 0.22294508329865187}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:17:37,207] Trial 110 finished with value: 0.1350549755725224 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0020024426840440646, 'p_miss': 0.2311328838791543}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:17:45,175] Trial 111 finished with value: 0.13352307950370426 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.0007154341215458721, 'p_miss': 0.25417089862955056}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:09,357] Trial 39 finished with value: 0.24844559282381598 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1314, 'learning_rate': 0.0008309231322303462, 'p_miss': 0.12542916628887185}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:16,586] Trial 113 finished with value: 0.13988248457603866 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.00039378274288316256, 'p_miss': 0.25673826263772204}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:23,977] Trial 114 finished with value: 0.2216910230434018 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:35,049] Trial 115 finished with value: 0.1387099631090116 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0007241327946227439, 'p_miss': 0.25278313686276493}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:43,062] Trial 116 finished with value: 0.13922292197004205 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.001477563843805354, 'p_miss': 0.22652721054944902}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:19:46,728] Trial 117 finished with value: 0.14031788588926328 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.09309676006568147, 'p_miss': 0.2639623636667865}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:20:09,595] Trial 33 finished with value: 0.22729903233503568 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1324, 'learning_rate': 0.000568661364706979, 'p_miss': 0.2676210961465373}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:52:02,921] Trial 38 finished with value: 0.23515832601086156 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1793, 'learning_rate': 0.0008507405873544978, 'p_miss': 0.15144003170948417}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 09:52:18,897] Trial 120 finished with value: 0.1354015126648446 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 4, 'learning_rate': 0.0009591326759678702, 'p_miss': 0.2419631930456063}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 10:55:22,127] Trial 32 finished with value: 0.23310679514251986 and parameters: {'model_name': 'VAE', 'batch_size': 202, 'iterations': 2666, 'learning_rate': 0.09312690845165732, 'p_miss': 0.0493465411923034}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 10:55:27,125] Trial 122 finished with value: 0.1361727931001268 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.0012068066326848283, 'p_miss': 0.08582846413072417}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 10:55:27,872] Trial 123 finished with value: 0.2680250620818181 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1525, 'weights': 'distance'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 10:55:34,894] Trial 124 finished with value: 0.13761089391856018 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0006336049994128049, 'p_miss': 0.185072626286711}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 10:58:08,288] Trial 66 finished with value: 0.21823577525797289 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2876, 'learning_rate': 0.0012756886530459499, 'p_miss': 0.14852919634533163}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:16,409] Trial 125 finished with value: 0.1838434163596105 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 127, 'learning_rate': 0.0013252359265263412, 'p_miss': 0.23589525548404133}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:20,130] Trial 127 finished with value: 0.1343332620810502 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.001752051211561743, 'p_miss': 0.1981073621014675}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:20,503] Trial 126 finished with value: 0.16619897402941636 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 114, 'learning_rate': 0.001677513216196777, 'p_miss': 0.23625589155200682}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:23,936] Trial 129 finished with value: 0.14669971498291923 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.000965704353650262, 'p_miss': 0.1997029745643045}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:25,919] Trial 128 finished with value: 0.13574561867334078 and parameters: {'model_name': 'VAE', 'batch_size': 822, 'iterations': 1, 'learning_rate': 0.0023918588496799906, 'p_miss': 0.19897040676804087}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:28,003] Trial 130 finished with value: 0.3722335800815968 and parameters: {'model_name': 'GAIN', 'batch_size': 813, 'hint_rate': 0.28696974143524345, 'alpha': 0, 'iterations': 2, 'learning_rate': 0.002338131016905013, 'p_miss': 0.281938530896733}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:30,091] Trial 131 finished with value: 0.38301531429887437 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.233544209162027, 'alpha': 2, 'iterations': 2, 'learning_rate': 0.0036188493385677033, 'p_miss': 0.24824625384613583}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:31,435] Trial 132 finished with value: 0.13615068914922115 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1, 'learning_rate': 0.0007400541414684202, 'p_miss': 0.24805186026147508}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:31,885] Trial 134 finished with value: 0.41106939266515746 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:35,430] Trial 133 finished with value: 0.13599235609338667 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1, 'learning_rate': 0.0007438786571120781, 'p_miss': 0.21615692918737403}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:39,634] Trial 136 finished with value: 0.1325639234497599 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.001040082018273754, 'p_miss': 0.16557153495655771}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:41,663] Trial 135 finished with value: 0.13743129791400957 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.0005121676853069931, 'p_miss': 0.2182246879910558}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:43,573] Trial 137 finished with value: 0.14229039873431998 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.0019184309426286857, 'p_miss': 0.16535343696825572}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:45,065] Trial 138 finished with value: 0.1436191894136647 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.0010397254838718439, 'p_miss': 0.1671037650412826}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:47,458] Trial 139 finished with value: 0.1428583001824884 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.0010711112695527293, 'p_miss': 0.17846130152516793}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:02:57,220] Trial 140 finished with value: 0.13823472308242218 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 4, 'learning_rate': 0.0014964881541816909, 'p_miss': 0.18852519194191916}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:03:03,898] Trial 141 finished with value: 0.13851038938710283 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.0013721507094312559, 'p_miss': 0.11196560936617078}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:03:10,219] Trial 143 finished with value: 0.13525613776849107 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0028105985200870794, 'p_miss': 0.17759974414103966}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:03:19,199] Trial 144 finished with value: 0.22167038481988163 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:03:22,301] Trial 142 finished with value: 0.13280130224680559 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 9, 'learning_rate': 0.0008936058363816332, 'p_miss': 0.17661509881191298}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:03:47,739] Trial 145 finished with value: 0.13985772009327238 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8, 'learning_rate': 0.0008290024671782543, 'p_miss': 0.19166171981968902}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:01,210] Trial 146 finished with value: 0.1375995107143123 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 15, 'learning_rate': 0.0008687143558635921, 'p_miss': 0.20391498888347792}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:09,347] Trial 147 finished with value: 0.13176545814482724 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.0006192372965837887, 'p_miss': 0.1757253658327675}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:23,329] Trial 69 finished with value: 0.23603440015649824 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2515, 'learning_rate': 0.004188732226976315, 'p_miss': 0.18213180541346197}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:29,335] Trial 149 finished with value: 0.13733342078000296 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0005955236222260847, 'p_miss': 0.22663157331268913}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:36,364] Trial 148 finished with value: 0.13393068365831953 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.0016590007538899597, 'p_miss': 0.1327015741976018}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:04:47,519] Trial 150 finished with value: 0.1388816113481211 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.00034457112280701744, 'p_miss': 0.22539077932323162}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:05:20,316] Trial 152 finished with value: 0.13364585942192733 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 13, 'learning_rate': 0.00032410544495481105, 'p_miss': 0.12639172385180145}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:05:20,942] Trial 154 finished with value: 0.21551504329475413 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28, 'weights': 'uniform'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:05:23,527] Trial 153 finished with value: 0.13624904350066763 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 10, 'learning_rate': 0.0003973497190430583, 'p_miss': 0.1042155602671668}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:06:11,367] Trial 155 finished with value: 0.13764381986184385 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 16, 'learning_rate': 0.0002784806373405099, 'p_miss': 0.10218789189521196}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:06:17,253] Trial 151 finished with value: 0.14160202027210295 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 37, 'learning_rate': 0.000318165850425287, 'p_miss': 0.1711250531395061}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:06:35,065] Trial 156 finished with value: 0.13304198053523283 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 17, 'learning_rate': 0.0002016129583844632, 'p_miss': 0.13726077549390325}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:06:51,055] Trial 157 finished with value: 0.1400830856417703 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 12, 'learning_rate': 0.00017367446536384107, 'p_miss': 0.13701072451082758}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:06:56,809] Trial 158 finished with value: 0.1351147308689736 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9, 'learning_rate': 0.00048745258808030015, 'p_miss': 0.12440795651984511}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:00,783] Trial 160 finished with value: 0.21218635146882875 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 23, 'learning_rate': 0.007143066197794541, 'p_miss': 0.12470261436786653}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:04,118] Trial 161 finished with value: 0.13966824995230875 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 21, 'learning_rate': 0.00013275290438706747, 'p_miss': 0.1445272331059548}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:05,435] Trial 159 finished with value: 0.13982143102801717 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 21, 'learning_rate': 0.00013778940542983633, 'p_miss': 0.12796808597940226}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:05,752] Trial 164 finished with value: 0.3084386522872819 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:20,659] Trial 162 finished with value: 0.13416440829817447 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.0001008873999454151, 'p_miss': 0.16507334127490236}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:22,831] Trial 165 finished with value: 0.14473943413463586 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.00023760936519406835, 'p_miss': 0.1179935468722324}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:42,578] Trial 163 finished with value: 0.13308754184565924 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 13, 'learning_rate': 0.00015212515738190612, 'p_miss': 0.15141932080907047}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:08:59,998] Trial 166 finished with value: 0.13727518522547968 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 13, 'learning_rate': 0.00022232770866334375, 'p_miss': 0.13290986336838595}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:09:02,349] Trial 167 finished with value: 0.13837164826094212 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 13, 'learning_rate': 0.0006561750830053255, 'p_miss': 0.15108954130495295}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:09:22,068] Trial 169 finished with value: 0.13870895051679197 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 8, 'learning_rate': 0.00013939373335687428, 'p_miss': 0.1519006869464188}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:09:22,918] Trial 168 finished with value: 0.1353691828229265 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 14, 'learning_rate': 0.00019166673340120923, 'p_miss': 0.1584280053226055}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:09:41,614] Trial 171 finished with value: 0.1391344478975924 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.00020081056711833658, 'p_miss': 0.15749361743875065}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:09:53,625] Trial 170 finished with value: 0.13923030930752847 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 18, 'learning_rate': 0.00015740750867075667, 'p_miss': 0.16047978972925542}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:10:02,783] Trial 174 finished with value: 0.23047599807882033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:10:26,339] Trial 175 finished with value: 0.1386211661470287 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6, 'learning_rate': 0.00044002474804838757, 'p_miss': 0.27160591018588964}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:11:08,969] Trial 176 finished with value: 0.14087756677613833 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.0011310433669744376, 'p_miss': 0.13437619324310274}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:11:39,341] Trial 173 finished with value: 0.13729742748488122 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 35, 'learning_rate': 0.00027042619551572973, 'p_miss': 0.14265752676566829}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:11:45,367] Trial 177 finished with value: 0.13930030060781964 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 10, 'learning_rate': 0.0009400623750178753, 'p_miss': 0.17538272057998983}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:08,988] Trial 179 finished with value: 0.13362908106872412 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.00055564934957932, 'p_miss': 0.11014480786045336}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:14,234] Trial 178 finished with value: 0.1328870127541613 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 10, 'learning_rate': 0.0009279475838527209, 'p_miss': 0.17439558272597802}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:38,134] Trial 180 finished with value: 0.13346419128797843 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9, 'learning_rate': 0.000553224237865383, 'p_miss': 0.1090378104804839}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:38,852] Trial 181 finished with value: 0.13671495468640665 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.0005665702733844927, 'p_miss': 0.18349708470678158}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:58,777] Trial 182 finished with value: 0.1401554304724902 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6, 'learning_rate': 0.0005553901027597298, 'p_miss': 0.08903739385420821}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:12:59,009] Trial 183 finished with value: 0.1358451169096252 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8, 'learning_rate': 0.0006957889332780953, 'p_miss': 0.09360065204640011}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:13:00,203] Trial 184 finished with value: 0.268068442261396 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1609, 'weights': 'distance'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:13:00,570] Trial 185 finished with value: 0.2679660128850219 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1495, 'weights': 'distance'}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:13:35,621] Trial 25 finished with value: 0.23322800966828233 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 4108, 'learning_rate': 0.00345266993484626, 'p_miss': 0.22996369315146678}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:13:48,234] Trial 186 finished with value: 0.1378792394232462 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 17, 'learning_rate': 0.0006525978585710244, 'p_miss': 0.10521822151699615}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:02,949] Trial 187 finished with value: 0.14002434746058845 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 16, 'learning_rate': 0.0008585278362631762, 'p_miss': 0.10771425001251725}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:08,174] Trial 188 finished with value: 0.13159817193108017 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9, 'learning_rate': 0.0007436639112648744, 'p_miss': 0.11135460262092954}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:30,275] Trial 189 finished with value: 0.14032949459927554 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 12, 'learning_rate': 0.0007396340115929509, 'p_miss': 0.1102450304034357}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:35,735] Trial 190 finished with value: 0.13818103042152066 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 12, 'learning_rate': 0.0007879555889688914, 'p_miss': 0.11981786378245324}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:39,537] Trial 191 finished with value: 0.1387400527323423 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 9, 'learning_rate': 0.0007614637608941172, 'p_miss': 0.1155791769948}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:46,716] Trial 193 finished with value: 0.3904134107486539 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.7146056730181968, 'alpha': 44, 'iterations': 8, 'learning_rate': 0.00048316897493276084, 'p_miss': 0.1164863955268472}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:14:49,499] Trial 194 finished with value: 0.38488308035444263 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.7373097022030531, 'alpha': 46, 'iterations': 6, 'learning_rate': 0.0005099093844049986, 'p_miss': 0.16512513010574342}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:15:01,274] Trial 192 finished with value: 0.13267711256069245 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.00045381475162822545, 'p_miss': 0.11620171063626146}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:15:09,997] Trial 195 finished with value: 0.21132380129604708 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 6, 'learning_rate': 0.02853869655656416, 'p_miss': 0.17247652087929402}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:15:14,773] Trial 196 finished with value: 0.14121125896493486 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 10, 'learning_rate': 0.0009605117971932412, 'p_miss': 0.17161831177814932}. Best is trial 71 with value: 0.12947776437595865.
running
[I 2024-10-26 11:15:24,550] Trial 197 finished with value: 0.13344653942983736 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7, 'learning_rate': 0.0003873664936835257, 'p_miss': 0.1120144359256483}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:15:38,863] Trial 199 finished with value: 0.13837497543981683 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7, 'learning_rate': 0.0004309193256557937, 'p_miss': 0.12819557429830242}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:15:53,986] Trial 93 finished with value: 0.2303198511580317 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2419, 'learning_rate': 0.000599166663447327, 'p_miss': 0.2170375954696174}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:16:20,258] Trial 198 finished with value: 0.13595161855357346 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 27, 'learning_rate': 0.0003971596595031068, 'p_miss': 0.10107089190706921}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:26:50,995] Trial 118 finished with value: 0.22389055332536162 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2790, 'learning_rate': 0.0010408382977606765, 'p_miss': 0.24339704996372422}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:30:28,104] Trial 54 finished with value: 0.22693588891915364 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3543, 'learning_rate': 0.0003965112628270605, 'p_miss': 0.09537914665110746}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:38:03,441] Trial 60 finished with value: 0.237533539643628 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 4071, 'learning_rate': 0.0036659420898088224, 'p_miss': 0.14769510590812013}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:40:39,957] Trial 172 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.00027107454513434045, 'p_miss': 0.16145503240200115}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 11:49:56,247] Trial 41 finished with value: 0.23171316467016884 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 4185, 'learning_rate': 0.0008207249011340073, 'p_miss': 0.11615000902657209}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:05:38,179] Trial 9 finished with value: 0.22820705707166505 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6048, 'learning_rate': 0.00016122233196537656, 'p_miss': 0.18181813417124115}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:07:09,750] Trial 121 finished with value: 0.2248292509950866 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4486, 'learning_rate': 0.001310503660662348, 'p_miss': 0.2191423466653775}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:07:20,036] Trial 112 finished with value: 0.24673805208960595 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5098, 'learning_rate': 0.0916647334781752, 'p_miss': 0.25371994612104154}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:07:33,486] Trial 52 finished with value: 0.23799837188707113 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 5948, 'learning_rate': 0.00038167675011847765, 'p_miss': 0.09573686655297348}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:07:43,923] Trial 65 finished with value: 0.22307724968048462 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 6788, 'learning_rate': 0.004220466370280811, 'p_miss': 0.140839407954572}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:09:00,067] Trial 119 finished with value: 0.21186529531107148 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5136, 'learning_rate': 0.0011834808492973267, 'p_miss': 0.24189546493215383}. Best is trial 71 with value: 0.12947776437595865.
[I 2024-10-26 12:10:01,780] Trial 59 finished with value: 0.2301610055932637 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 8381, 'learning_rate': 0.0014350064350850153, 'p_miss': 0.1512347893839308}. Best is trial 71 with value: 0.12947776437595865.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.12947776437595865
{'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0013672808119718244, 'p_miss': 0.18016628507231142}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469d390> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547469d060> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.529024489330498
Generation:   4%|▍         | 1/25 [00:05<02:15,  5.63s/it]Generation:  2
Best f1_score score: 0.529024489330498
Generation:   8%|▊         | 2/25 [00:13<02:43,  7.09s/it]Generation:  3
Best f1_score score: 0.529024489330498
Generation:  12%|█▏        | 3/25 [00:23<03:07,  8.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474700250> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.529024489330498
Generation:  16%|█▌        | 4/25 [00:57<06:24, 18.31s/it]Generation:  5
Best f1_score score: 0.529024489330498
Generation:  20%|██        | 5/25 [01:08<05:12, 15.64s/it]Generation:  6
Best f1_score score: 0.529024489330498
Generation:  24%|██▍       | 6/25 [01:23<04:52, 15.41s/it]Generation:  7
Best f1_score score: 0.529024489330498
Generation:  28%|██▊       | 7/25 [01:33<04:07, 13.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714f70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.529024489330498
Generation:  32%|███▏      | 8/25 [02:02<05:18, 18.71s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c5ee60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.529024489330498
Generation:  36%|███▌      | 9/25 [02:17<04:41, 17.57s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f04fd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.529024489330498
Generation:  40%|████      | 10/25 [02:28<03:52, 15.51s/it]Generation:  11
Best f1_score score: 0.529024489330498
Generation:  44%|████▍     | 11/25 [02:43<03:34, 15.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659f0fd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe55a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.529024489330498
Generation:  48%|████▊     | 12/25 [03:00<03:24, 15.76s/it]Generation:  13
Best f1_score score: 0.5292781713145993
Generation:  52%|█████▏    | 13/25 [03:14<03:02, 15.22s/it]Generation:  14
Best f1_score score: 0.5292781713145993
Generation:  56%|█████▌    | 14/25 [03:33<03:00, 16.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c00340> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5292781713145993
Generation:  60%|██████    | 15/25 [03:50<02:46, 16.65s/it]Generation:  16
Best f1_score score: 0.5292781713145993
Generation:  64%|██████▍   | 16/25 [04:01<02:13, 14.79s/it]Generation:  17
Best f1_score score: 0.5292781713145993
Generation:  68%|██████▊   | 17/25 [04:16<01:59, 14.98s/it]Generation:  18
Best f1_score score: 0.5292781713145993
Generation:  72%|███████▏  | 18/25 [04:45<02:13, 19.12s/it]Generation:  19
Best f1_score score: 0.5292781713145993
Generation:  76%|███████▌  | 19/25 [05:01<01:48, 18.10s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554655b7fd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  20
Best f1_score score: 0.5292781713145993
Generation:  80%|████████  | 20/25 [05:16<01:25, 17.20s/it]Generation:  21
Best f1_score score: 0.5292781713145993
Generation:  84%|████████▍ | 21/25 [05:39<01:16, 19.09s/it]Generation:  22
Best f1_score score: 0.5292781713145993
Generation:  88%|████████▊ | 22/25 [05:55<00:54, 18.06s/it]Generation:  23
Best f1_score score: 0.5292781713145993
Generation:  92%|█████████▏| 23/25 [06:16<00:37, 18.95s/it]Generation:  24
Best f1_score score: 0.5292781713145993
Generation:  96%|█████████▌| 24/25 [06:35<00:19, 19.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546559b4c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659bca60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.5292781713145993
Generation: 100%|██████████| 25/25 [06:59<00:00, 20.38s/it]Generation: 100%|██████████| 25/25 [07:02<00:00, 16.91s/it]
2024-10-26 12:17:12,386 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42673' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bc1ee22df90b340c13f4c4b70d48b351', 'ndarray-dbf3b60a15f40ef9fa488f075341694a'} (stimulus_id='handle-worker-cleanup-1729970232.386655')
Fitted
Pipeline(steps=[('baggingclassifier',
                 BaggingClassifier(bootstrap=False, bootstrap_features=True,
                                   max_features=0.3419296771248,
                                   max_samples=0.9158822136876, n_estimators=61,
                                   n_jobs=1))])
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 0.06696915069400373, 'f1': 1.0}
original test score: {'auroc': 0.6013472991976176, 'accuracy': 0.5578778135048231, 'balanced_accuracy': 0.5561771031516254, 'logloss': 0.6834645925468168, 'f1': 0.5427876455100704}
imputed test score: {'auroc': 0.45783873769542555, 'accuracy': 0.4694533762057878, 'balanced_accuracy': 0.4692178840268012, 'logloss': 0.7719454664915699, 'f1': 0.4690086920529801}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014670>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554742975e0> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 589, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd09a0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.6928453701792188
Generation:   4%|▍         | 1/25 [01:14<29:53, 74.74s/it]Generation:  2
Best f1_score score: 0.6958343485039797
Generation:   8%|▊         | 2/25 [02:27<28:10, 73.49s/it]Generation:  3
Best f1_score score: 0.7141470643793122
Generation:  12%|█▏        | 3/25 [02:36<16:08, 44.01s/it]Generation:  4
Best f1_score score: 0.7205530471257657
Generation:  16%|█▌        | 4/25 [02:51<11:25, 32.65s/it]Generation:  5
Best f1_score score: 0.7258489156530084
Generation:  20%|██        | 5/25 [05:36<26:50, 80.54s/it]Generation:  6
Best f1_score score: 0.7258489156530084
Generation:  24%|██▍       | 6/25 [06:06<19:58, 63.06s/it]Generation:  7
Best f1_score score: 0.7293532670307122
Generation:  28%|██▊       | 7/25 [08:05<24:28, 81.56s/it]Generation:  8
Best f1_score score: 0.7293532670307122
Generation:  32%|███▏      | 8/25 [10:06<26:39, 94.06s/it]Generation:  9
Best f1_score score: 0.7321151174826415
Generation:  36%|███▌      | 9/25 [12:08<27:22, 102.64s/it]Generation:  10
Best f1_score score: 0.7346582919320681
Generation:  40%|████      | 10/25 [14:09<27:06, 108.44s/it]Generation:  11
Best f1_score score: 0.7346582919320681
Generation:  44%|████▍     | 11/25 [16:09<26:08, 112.04s/it]Generation:  12
Best f1_score score: 0.7346582919320681
Generation:  48%|████▊     | 12/25 [18:09<24:46, 114.35s/it]Generation:  13
Best f1_score score: 0.7346582919320681
Generation:  52%|█████▏    | 13/25 [18:18<16:29, 82.42s/it] Generation:  14
Best f1_score score: 0.737206866412868
Generation:  56%|█████▌    | 14/25 [20:20<17:19, 94.48s/it]Exception ignored in: <bound method GCDiagnosis._gc_callback of <distributed.gc.GCDiagnosis object at 0x155485ed6bc0>>
Traceback (most recent call last):
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/distributed/gc.py", line 198, in _gc_callback
    def _gc_callback(self, phase, info):
func_timeout.dafunc.FunctionTimedOut8685372336815747261: Function objective_function (args=[<tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545c18b970>]) (kwargs={'budget': None, 'X':              0  ...         5
0     0.805015  ...  0.699416
1          NaN  ...  0.839310
2     0.791402  ...  0.066838
3          NaN  ...       NaN
4     0.662536  ...  0.692366
...        ...  ...       ...
2480       NaN  ...  0.430328
2481  0.798677  ...       NaN
2482       NaN  ...  0.483023
2483  0.831078  ...       NaN
2484       NaN  ...  0.818269

[2485 rows x 6 columns], 'y': array([0, 0, 1, ..., 1, 0, 0])}) timed out after 600.000000 seconds.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545c18b970> 

Generation:  15
Best f1_score score: 0.737206866412868
Generation:  60%|██████    | 15/25 [30:27<41:29, 248.90s/it]Exception ignored in: <bound method GCDiagnosis._gc_callback of <distributed.gc.GCDiagnosis object at 0x155485ed6bc0>>
Traceback (most recent call last):
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/distributed/gc.py", line 205, in _gc_callback
    self._fractional_timer.start_timing()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/distributed/gc.py", line 132, in start_timing
    assert self._cur_start is None
AssertionError: 
Generation:  16
Best f1_score score: 0.737206866412868
Generation:  64%|██████▍   | 16/25 [32:37<31:58, 213.20s/it]Generation:  17
Best f1_score score: 0.737206866412868
Generation:  68%|██████▊   | 17/25 [33:54<22:56, 172.04s/it]Generation:  18
Best f1_score score: 0.737206866412868
Generation:  72%|███████▏  | 18/25 [35:53<18:14, 156.36s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545301eb90> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.737206866412868
Generation:  76%|███████▌  | 19/25 [37:55<14:35, 145.84s/it]Generation:  20
Best f1_score score: 0.737206866412868
Generation:  80%|████████  | 20/25 [39:57<11:33, 138.72s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155442b9c9d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.737206866412868
Generation:  84%|████████▍ | 21/25 [41:56<08:51, 132.76s/it]Generation:  22
Best f1_score score: 0.7390395826089329
Generation:  88%|████████▊ | 22/25 [43:56<06:26, 128.97s/it]Generation:  23
Best f1_score score: 0.7390395826089329
Generation:  92%|█████████▏| 23/25 [44:05<03:06, 93.10s/it] Generation:  24
Best f1_score score: 0.7390395826089329
Generation:  96%|█████████▌| 24/25 [46:32<01:49, 109.12s/it]Generation:  25
Best f1_score score: 0.7390395826089329
Generation: 100%|██████████| 25/25 [48:30<00:00, 111.88s/it]Generation: 100%|██████████| 25/25 [48:30<00:00, 116.42s/it]
2024-10-26 13:05:51,235 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44119' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-6eeb491b98441819e34f11328616d241', 'ndarray-bc1ee22df90b340c13f4c4b70d48b351'} (stimulus_id='handle-worker-cleanup-1729973151.2356017')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=Ridge(),
                                  imputation_order='descending',
                                  n_nearest_features=25)),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               fe...,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0596253253279, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=14,
                               max_leaves=None, min_child_weight=16,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100, n_jobs=1,
                               nthread=1, num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8833655283743902, 'accuracy': 0.8032193158953722, 'balanced_accuracy': 0.8031616566777827, 'logloss': 0.4399544718364616, 'f1': 0.8031824717216474}
test score: {'auroc': 0.7645483497394325, 'accuracy': 0.6897106109324759, 'balanced_accuracy': 0.6892629663330301, 'logloss': 0.577268197983102, 'f1': 0.6888347438406408}
original test score: {'auroc': 0.8781898833650426, 'accuracy': 0.7990353697749196, 'balanced_accuracy': 0.7985048391099347, 'logloss': 0.43589033603569194, 'f1': 0.7982421768566261}
score end
737
lvl
0.5
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
4.8978363149695925
hours
DONE
