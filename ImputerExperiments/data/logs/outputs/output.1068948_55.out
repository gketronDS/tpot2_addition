Run: 55
/cm/local/apps/slurm/var/spool/job1068948/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40983/40983.pkl
working on 
../data/c/40983/class_full_MAR_0.3_3
1.2977509498596191
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-21 22:18:47,566] A new study created in memory with name: no-name-3ca81078-92e6-4ee7-b6af-aa44ea53ff7b
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-21 22:18:47,811] Trial 5 finished with value: 0.06821247270949683 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.06821247270949683.
running
[I 2024-11-21 22:18:47,998] Trial 12 finished with value: 0.06821247270949683 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 5 with value: 0.06821247270949683.
running
[I 2024-11-21 22:18:48,679] Trial 10 finished with value: 0.06340695276273492 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 550, 'weights': 'uniform'}. Best is trial 10 with value: 0.06340695276273492.
running
[I 2024-11-21 22:18:48,828] Trial 14 finished with value: 0.07418804900825006 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2861, 'weights': 'uniform'}. Best is trial 10 with value: 0.06340695276273492.
running
[I 2024-11-21 22:18:48,992] Trial 15 finished with value: 0.06313790603531756 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1046, 'weights': 'distance'}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:49,390] Trial 2 finished with value: 0.0761164733449076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:50,148] Trial 1 finished with value: 0.0781681805366887 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:50,305] Trial 4 finished with value: 0.07536292621241457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:50,480] Trial 22 finished with value: 0.16232327817898806 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:50,636] Trial 24 finished with value: 0.06821247270949683 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:52,724] Trial 13 finished with value: 0.11163013559198379 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 15 with value: 0.06313790603531756.
running
[I 2024-11-21 22:18:53,834] Trial 26 finished with value: 0.061956065446314365 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 384, 'weights': 'distance'}. Best is trial 26 with value: 0.061956065446314365.
running
[I 2024-11-21 22:18:55,063] Trial 27 finished with value: 0.06214174108277486 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 538, 'weights': 'distance'}. Best is trial 26 with value: 0.061956065446314365.
running
[I 2024-11-21 22:18:55,443] Trial 23 finished with value: 0.1609141813092359 and parameters: {'model_name': 'GAIN', 'batch_size': 366, 'hint_rate': 0.9474806031680157, 'alpha': 76, 'iterations': 4, 'learning_rate': 0.019356353062057494, 'p_miss': 0.06893897571740858}. Best is trial 26 with value: 0.061956065446314365.
running
[I 2024-11-21 22:19:14,672] Trial 21 finished with value: 0.15853363878919433 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.02963784790392729, 'p_miss': 0.09075074328154485}. Best is trial 26 with value: 0.061956065446314365.
running
[I 2024-11-21 22:19:16,004] Trial 30 finished with value: 0.05927976677666306 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 100, 'weights': 'distance'}. Best is trial 30 with value: 0.05927976677666306.
running
[I 2024-11-21 22:19:17,283] Trial 31 finished with value: 0.057237425004354026 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31, 'weights': 'distance'}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:19:27,132] Trial 7 finished with value: 0.1568053698190451 and parameters: {'model_name': 'GAIN', 'batch_size': 45, 'hint_rate': 0.4042523271381225, 'alpha': 29, 'iterations': 25, 'learning_rate': 0.010439702195089088, 'p_miss': 0.16132483366538625}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:21:55,557] Trial 9 finished with value: 0.2337449108893471 and parameters: {'model_name': 'GAIN', 'batch_size': 846, 'hint_rate': 0.503982348131379, 'alpha': 28, 'iterations': 97, 'learning_rate': 0.02543901480941047, 'p_miss': 0.2400537418488548}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:22:02,536] Trial 28 finished with value: 0.157354386588281 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.955952098496931, 'alpha': 63, 'iterations': 107, 'learning_rate': 0.032694566590516165, 'p_miss': 0.2297081232109136}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:22:44,435] Trial 19 finished with value: 0.3530147606362285 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 76, 'learning_rate': 0.0001490306688423953, 'p_miss': 0.15814869624545586}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:22:45,988] Trial 36 finished with value: 0.061034614193324954 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 221, 'weights': 'distance'}. Best is trial 31 with value: 0.057237425004354026.
running
[I 2024-11-21 22:22:46,858] Trial 37 finished with value: 0.05675163077383497 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22, 'weights': 'distance'}. Best is trial 37 with value: 0.05675163077383497.
running
[I 2024-11-21 22:22:47,852] Trial 38 finished with value: 0.056848784526101 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14, 'weights': 'distance'}. Best is trial 37 with value: 0.05675163077383497.
running
[I 2024-11-21 22:22:49,540] Trial 39 finished with value: 0.0645703977067715 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1488, 'weights': 'distance'}. Best is trial 37 with value: 0.05675163077383497.
running
[I 2024-11-21 22:22:51,073] Trial 40 finished with value: 0.06739531586801098 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2405, 'weights': 'distance'}. Best is trial 37 with value: 0.05675163077383497.
running
[I 2024-11-21 22:22:52,170] Trial 41 finished with value: 0.0567167402699977 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:22:53,507] Trial 42 finished with value: 0.06425723932795238 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1409, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:12,742] Trial 20 finished with value: 0.08390724084251872 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 72, 'learning_rate': 0.04645631260619939, 'p_miss': 0.2910725648862904}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:13,628] Trial 44 finished with value: 0.06419149249408763 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 925, 'weights': 'uniform'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:14,668] Trial 45 finished with value: 0.056898330137024486 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:15,424] Trial 46 finished with value: 0.05705956400986023 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:16,274] Trial 47 finished with value: 0.06244246475443641 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 719, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:26,531] Trial 25 finished with value: 0.22411535239944103 and parameters: {'model_name': 'GAIN', 'batch_size': 719, 'hint_rate': 0.16083891968893138, 'alpha': 35, 'iterations': 143, 'learning_rate': 0.02064363561288967, 'p_miss': 0.19628141059918708}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:33,066] Trial 49 finished with value: 0.07584654974566991 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:23:34,736] Trial 50 finished with value: 0.06923056546081682 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3744, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:30:05,052] Trial 18 finished with value: 0.05950988217898484 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:30:06,248] Trial 52 finished with value: 0.05807845037765704 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:30:07,523] Trial 53 finished with value: 0.062151050613432644 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 559, 'weights': 'distance'}. Best is trial 41 with value: 0.0567167402699977.
running
[I 2024-11-21 22:31:13,608] Trial 3 finished with value: 0.0548265357616303 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:32:30,376] Trial 48 finished with value: 0.0806683159061391 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:34:00,294] Trial 51 finished with value: 0.06838954723940473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:34:03,676] Trial 57 finished with value: 0.076116580480413 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:34:12,128] Trial 58 finished with value: 0.05962013642794156 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:34:13,058] Trial 59 finished with value: 0.16232327817898806 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 3 with value: 0.0548265357616303.
running
[I 2024-11-21 22:43:21,798] Trial 55 finished with value: 0.05311393723613663 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 22:44:37,500] Trial 56 finished with value: 0.05490408812801541 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 22:53:06,210] Trial 16 finished with value: 0.09895175851557943 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 648, 'learning_rate': 0.0138098319467081, 'p_miss': 0.1471518575491999}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 22:55:23,280] Trial 61 finished with value: 0.055440627359288085 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 22:56:38,029] Trial 62 finished with value: 0.05567299544122008 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:05:01,305] Trial 63 finished with value: 0.05430450087599069 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:06:09,772] Trial 17 finished with value: 0.07631113021574057 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 895, 'learning_rate': 0.07890554094933018, 'p_miss': 0.1620323665830369}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:07:32,518] Trial 64 finished with value: 0.054021216054761935 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:08:35,757] Trial 65 finished with value: 0.05367005655634567 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:10:55,326] Trial 8 finished with value: 0.07824044933586648 and parameters: {'model_name': 'VAE', 'batch_size': 602, 'iterations': 858, 'learning_rate': 0.03247686610858483, 'p_miss': 0.1853184760295497}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:16:57,542] Trial 66 finished with value: 0.055176006075170626 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 55 with value: 0.05311393723613663.
running
[I 2024-11-21 23:18:13,742] Trial 67 finished with value: 0.05305531188472377 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:19:50,476] Trial 68 finished with value: 0.054261796509111525 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:20:37,243] Trial 69 finished with value: 0.056086430063449454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:23:05,983] Trial 70 finished with value: 0.05379250041743433 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:28:37,722] Trial 71 finished with value: 0.054611084050145184 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:30:06,084] Trial 72 finished with value: 0.055491526446903104 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:31:53,091] Trial 73 finished with value: 0.05560899149467572 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:32:38,268] Trial 74 finished with value: 0.05526628158431539 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:35:28,777] Trial 75 finished with value: 0.0539842843670423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:40:16,938] Trial 76 finished with value: 0.05357231176119319 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:42:09,234] Trial 77 finished with value: 0.054352746353544534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:43:43,607] Trial 78 finished with value: 0.054063437600582145 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:44:31,296] Trial 79 finished with value: 0.05381654032211208 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:47:47,634] Trial 80 finished with value: 0.05405574114415459 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:52:04,117] Trial 81 finished with value: 0.054186745031012694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:54:09,907] Trial 82 finished with value: 0.054588971314247316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:55:31,630] Trial 83 finished with value: 0.05534054321659002 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-21 23:56:13,312] Trial 84 finished with value: 0.053239044579387954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-22 00:03:13,998] Trial 86 finished with value: 0.054669195655835445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-22 00:03:15,031] Trial 90 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.06499158096410618, 'alpha': 1, 'iterations': 1, 'learning_rate': 0.000555679657064319, 'p_miss': 0.010893367242850671}. Best is trial 67 with value: 0.05305531188472377.
running
[I 2024-11-22 00:05:44,143] Trial 87 finished with value: 0.052549688078440945 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:05:44,496] Trial 92 finished with value: 0.07462973147020019 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:07:08,696] Trial 0 finished with value: 0.07744280192684136 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1700, 'learning_rate': 0.03169916915641752, 'p_miss': 0.12588933347050923}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:28:36,879] Trial 88 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.06959709607640113, 'alpha': 98, 'iterations': 6982, 'learning_rate': 0.0006591364905865796, 'p_miss': 0.014184270988378711}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:28:45,500] Trial 95 finished with value: 0.3570312414290914 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 1, 'learning_rate': 0.004122825276307174, 'p_miss': 0.2941385026936667}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:28:48,518] Trial 96 finished with value: 0.0761163588782785 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:29:04,837] Trial 97 finished with value: 0.10889363055694379 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:31:14,769] Trial 89 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6548631664951666, 'alpha': 2, 'iterations': 7588, 'learning_rate': 0.000623876010993612, 'p_miss': 0.022918496522716297}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:32:32,651] Trial 85 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.015074638051712885, 'alpha': 99, 'iterations': 9406, 'learning_rate': 0.0007790684079592111, 'p_miss': 0.10773075669441774}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:41:13,926] Trial 98 finished with value: 0.055477081991045965 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:43:15,992] Trial 99 finished with value: 0.05466068583373727 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:43:23,743] Trial 102 finished with value: 0.05969528406130577 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:43:35,349] Trial 103 finished with value: 0.11161941559103009 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:44:14,948] Trial 100 finished with value: 0.05401072450572462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:45:18,041] Trial 105 finished with value: 0.35564610833490246 and parameters: {'model_name': 'VAE', 'batch_size': 152, 'iterations': 14, 'learning_rate': 0.00010350546908391346, 'p_miss': 0.04749106624369914}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:53:28,442] Trial 101 finished with value: 0.055248576563017536 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:55:48,076] Trial 104 finished with value: 0.053909173232884154 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:55:59,985] Trial 6 finished with value: 0.07718162783704341 and parameters: {'model_name': 'VAE', 'batch_size': 294, 'iterations': 3038, 'learning_rate': 0.0005759819293261159, 'p_miss': 0.17751617415574367}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 00:56:39,245] Trial 106 finished with value: 0.05542076040796197 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 01:05:51,806] Trial 107 finished with value: 0.05374254758852285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 01:05:56,000] Trial 111 finished with value: 0.07611552758529846 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 01:07:39,928] Trial 108 finished with value: 0.055597032517648894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 01:07:40,355] Trial 113 finished with value: 0.16232327817898806 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 87 with value: 0.052549688078440945.
running
[I 2024-11-22 01:08:00,643] Trial 109 finished with value: 0.052420091534728555 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 109 with value: 0.052420091534728555.
running
[I 2024-11-22 01:08:03,736] Trial 110 finished with value: 0.054943552560328415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.052420091534728555.
running
[I 2024-11-22 01:18:08,991] Trial 112 finished with value: 0.05545524463018432 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 109 with value: 0.052420091534728555.
running
[I 2024-11-22 01:19:10,895] Trial 114 finished with value: 0.05370814793785148 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 109 with value: 0.052420091534728555.
running
[I 2024-11-22 01:19:41,471] Trial 115 finished with value: 0.05156212264243494 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:19:47,492] Trial 116 finished with value: 0.054089513253708546 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:19:49,168] Trial 119 finished with value: 0.059519663027351476 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:19:54,933] Trial 120 finished with value: 0.06569793668848695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:29:34,247] Trial 121 finished with value: 0.07371930798207563 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:30:41,130] Trial 117 finished with value: 0.05479208365387582 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:31:21,976] Trial 118 finished with value: 0.054966504237230894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:31:30,764] Trial 122 finished with value: 0.05276269240671063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:41:15,166] Trial 123 finished with value: 0.05448881690066386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:42:48,988] Trial 126 finished with value: 0.05361158140450571 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:43:12,402] Trial 124 finished with value: 0.05439858807636781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:43:17,157] Trial 125 finished with value: 0.05527674594910058 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:52:45,696] Trial 127 finished with value: 0.055776612980375784 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:54:35,166] Trial 128 finished with value: 0.05489950823068853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:54:58,507] Trial 130 finished with value: 0.0550556552735198 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:54:58,862] Trial 133 finished with value: 0.07462973147020019 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:55:06,041] Trial 134 finished with value: 0.07816842274794948 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 01:55:21,596] Trial 129 finished with value: 0.054822230673150715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:01:51,601] Trial 11 finished with value: 0.07762484498087094 and parameters: {'model_name': 'VAE', 'batch_size': 180, 'iterations': 4578, 'learning_rate': 0.04600331454559398, 'p_miss': 0.061809663873604224}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:04:20,460] Trial 131 finished with value: 0.05518541028659464 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:07:02,115] Trial 136 finished with value: 0.05169228808646796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:10:07,545] Trial 135 finished with value: 0.08484710418784965 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 261, 'learning_rate': 0.0020081843280332673, 'p_miss': 0.24539413489582246}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:13:35,804] Trial 137 finished with value: 0.05497714985556189 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:13:39,504] Trial 141 finished with value: 0.076116580480413 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:15:56,238] Trial 138 finished with value: 0.05431843349060874 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:18:46,458] Trial 139 finished with value: 0.053038510716498954 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:19:29,445] Trial 132 finished with value: 0.08091134359423698 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 457, 'learning_rate': 0.002229084311938298, 'p_miss': 0.25713395957245183}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:21:52,874] Trial 140 finished with value: 0.05473027779988728 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:25:42,005] Trial 142 finished with value: 0.05418577613840374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:27:52,902] Trial 143 finished with value: 0.0548873152309589 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:30:33,612] Trial 144 finished with value: 0.05635708375066363 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:31:15,820] Trial 145 finished with value: 0.05391318174004104 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:33:31,158] Trial 146 finished with value: 0.05370187772164399 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:37:47,942] Trial 147 finished with value: 0.05637087511223689 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:39:35,990] Trial 148 finished with value: 0.05404559592127335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:42:13,913] Trial 149 finished with value: 0.05470719135663983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:42:50,216] Trial 150 finished with value: 0.05587957566370475 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:45:40,193] Trial 151 finished with value: 0.053673390063610125 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:49:56,472] Trial 152 finished with value: 0.054642961129666066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:51:13,457] Trial 153 finished with value: 0.05430045435152679 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:54:05,028] Trial 154 finished with value: 0.053665212173006516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:54:19,064] Trial 155 finished with value: 0.05552121399999356 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:57:53,422] Trial 156 finished with value: 0.05450842519024547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:58:14,651] Trial 161 finished with value: 0.12010417410347833 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 02:58:22,060] Trial 162 finished with value: 0.1741024826861961 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.7669450021161568, 'alpha': 51, 'iterations': 3, 'learning_rate': 0.0052767646742677785, 'p_miss': 0.20937490566334255}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:02:07,551] Trial 157 finished with value: 0.055058519941595094 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:02:56,230] Trial 158 finished with value: 0.05446066832849271 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:02:57,035] Trial 165 finished with value: 0.16232327817898806 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:05:42,990] Trial 160 finished with value: 0.05472172257604964 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:06:08,666] Trial 159 finished with value: 0.05464217553098344 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:10:39,126] Trial 163 finished with value: 0.055964782710349034 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:13:48,472] Trial 164 finished with value: 0.053988995475089466 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:13:53,070] Trial 170 finished with value: 0.07611635389886967 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:15:02,115] Trial 166 finished with value: 0.05303521626342374 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:17:21,288] Trial 167 finished with value: 0.05289428590207148 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:17:29,079] Trial 173 finished with value: 0.06095257882790067 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:17:56,970] Trial 168 finished with value: 0.05576196306356709 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:22:29,129] Trial 169 finished with value: 0.05261655025850674 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:25:41,326] Trial 171 finished with value: 0.05351030603058425 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:26:50,780] Trial 172 finished with value: 0.05481681156056904 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:29:09,425] Trial 174 finished with value: 0.05503412607308942 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:29:35,263] Trial 175 finished with value: 0.054777380140000755 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:34:22,116] Trial 176 finished with value: 0.053332252526207456 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:37:26,722] Trial 177 finished with value: 0.05456809665686829 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:38:49,766] Trial 178 finished with value: 0.05287436087996685 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:40:06,454] Trial 179 finished with value: 0.061180251298223444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:41:25,105] Trial 180 finished with value: 0.05318402678643501 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:45:47,462] Trial 181 finished with value: 0.05522079555711366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:49:36,835] Trial 182 finished with value: 0.05356802439234708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:50:42,889] Trial 183 finished with value: 0.053568640002219614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:51:31,427] Trial 184 finished with value: 0.05503089821561934 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:53:03,318] Trial 185 finished with value: 0.055229837671867885 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 03:57:22,725] Trial 186 finished with value: 0.05278404459239512 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:00:32,055] Trial 189 finished with value: 0.07754423777630529 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:01:23,280] Trial 187 finished with value: 0.05258568635640931 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:01:35,058] Trial 192 finished with value: 0.3582252139658764 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 18, 'learning_rate': 0.00029633857393340644, 'p_miss': 0.2709474391771411}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:01:45,361] Trial 194 finished with value: 0.07816872910559838 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:01:50,379] Trial 195 finished with value: 0.16272912225478264 and parameters: {'model_name': 'GAIN', 'batch_size': 65, 'hint_rate': 0.29361330222451787, 'alpha': 77, 'iterations': 2, 'learning_rate': 0.09938898248982633, 'p_miss': 0.12591240319685174}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:02:14,950] Trial 193 finished with value: 0.35768753239735374 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 25, 'learning_rate': 0.0001869992183032181, 'p_miss': 0.13144742879419757}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:02:22,008] Trial 188 finished with value: 0.05397721356208882 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:04:53,651] Trial 190 finished with value: 0.05345567998341634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
running
[I 2024-11-22 04:09:17,019] Trial 191 finished with value: 0.05376460503706766 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:12:56,560] Trial 196 finished with value: 0.05355589858890157 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:13:26,803] Trial 198 finished with value: 0.053456572776975055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:13:28,733] Trial 197 finished with value: 0.05411862006800426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:15:40,233] Trial 199 finished with value: 0.05581257479984939 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:17:36,510] Trial 34 finished with value: 0.127031134128295 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7995, 'learning_rate': 0.0001502992754528774, 'p_miss': 0.29610878973308213}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:25:16,423] Trial 93 finished with value: 0.07792622750653537 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 5602, 'learning_rate': 0.0023691013305535175, 'p_miss': 0.29349303697906143}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:26:31,196] Trial 33 finished with value: 0.1270723695738086 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7269, 'learning_rate': 0.00023086609993202225, 'p_miss': 0.2772600509276244}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:44:24,684] Trial 60 finished with value: 0.0958883584371814 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8506, 'learning_rate': 0.0004907337417849905, 'p_miss': 0.016014981910634468}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 04:58:31,371] Trial 94 finished with value: 0.07731074516877154 and parameters: {'model_name': 'VAE', 'batch_size': 150, 'iterations': 7761, 'learning_rate': 0.0026106017246380906, 'p_miss': 0.022754922789026993}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 05:00:36,591] Trial 54 finished with value: 0.08689000901585833 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9667, 'learning_rate': 0.0006635130599607515, 'p_miss': 0.010310902383504045}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 05:01:05,164] Trial 35 finished with value: 0.09911302644049949 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8763, 'learning_rate': 0.00021616419538726144, 'p_miss': 0.29373481182354577}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 05:01:16,274] Trial 43 finished with value: 0.08681679146664585 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9955, 'learning_rate': 0.00045815701374557043, 'p_miss': 0.012937906138845656}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 05:02:05,843] Trial 32 finished with value: 0.07821370423714824 and parameters: {'model_name': 'VAE', 'batch_size': 626, 'iterations': 8031, 'learning_rate': 0.00012429127408053025, 'p_miss': 0.29537704043906987}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 05:02:34,617] Trial 91 finished with value: 0.07836634229991622 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 9230, 'learning_rate': 0.003278620002569072, 'p_miss': 0.2880424856157911}. Best is trial 115 with value: 0.05156212264243494.
[I 2024-11-22 23:15:02,811] Trial 29 finished with value: inf and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9001, 'learning_rate': 0.00014304025651266269, 'p_miss': 0.2916212125499389}. Best is trial 115 with value: 0.05156212264243494.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
dtype: int64
0.05156212264243494
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c51210> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  1
Best f1_score score: 0.7577535161861906
Generation:   4%|         | 1/25 [00:09<03:47,  9.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fdf00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  2
Best f1_score score: 0.7577535161861906
Generation:   8%|         | 2/25 [00:21<04:07, 10.78s/it]Generation:  3
Best f1_score score: 0.7577535161861906
Generation:  12%|        | 3/25 [00:46<06:25, 17.53s/it]Generation:  4
Best f1_score score: 0.7577535161861906
Generation:  16%|        | 4/25 [00:59<05:30, 15.71s/it]Generation:  5
Best f1_score score: 0.7610365762939898
Generation:  20%|        | 5/25 [01:13<05:01, 15.06s/it]Generation:  6
Best f1_score score: 0.7667397321890521
Generation:  24%|       | 6/25 [01:32<05:10, 16.34s/it]Generation:  7
Best f1_score score: 0.7667397321890521
Generation:  28%|       | 7/25 [01:45<04:35, 15.29s/it]Generation:  8
Best f1_score score: 0.7729722529823698
Generation:  32%|      | 8/25 [01:58<04:09, 14.66s/it]Generation:  9
Best f1_score score: 0.7729722529823698
Generation:  36%|      | 9/25 [02:16<04:11, 15.70s/it]Generation:  10
Best f1_score score: 0.7729722529823698
Generation:  40%|      | 10/25 [03:07<06:36, 26.43s/it]Generation:  11
Best f1_score score: 0.7729722529823698
Generation:  44%|     | 11/25 [03:23<05:25, 23.25s/it]Generation:  12
Best f1_score score: 0.7729722529823698
Generation:  48%|     | 12/25 [03:35<04:20, 20.02s/it]Generation:  13
Best f1_score score: 0.7729722529823698
Generation:  52%|    | 13/25 [04:49<07:14, 36.24s/it]Generation:  14
Best f1_score score: 0.7729722529823698
Generation:  56%|    | 14/25 [05:02<05:20, 29.10s/it]Generation:  15
Best f1_score score: 0.7729722529823698
Generation:  60%|    | 15/25 [05:18<04:13, 25.38s/it]Generation:  16
Best f1_score score: 0.7729722529823698
Generation:  64%|   | 16/25 [05:33<03:19, 22.12s/it]Generation:  17
Best f1_score score: 0.7756577641095159
Generation:  68%|   | 17/25 [07:44<07:18, 54.80s/it]Generation:  18
Best f1_score score: 0.7756577641095159
Generation:  72%|  | 18/25 [14:10<18:00, 154.38s/it]Generation:  19
Best f1_score score: 0.7756577641095159
Generation:  76%|  | 19/25 [14:24<11:14, 112.39s/it]Generation:  20
Best f1_score score: 0.7756577641095159
Generation:  80%|  | 20/25 [14:39<06:54, 82.91s/it] Generation:  21
Best f1_score score: 0.7756577641095159
Generation:  84%| | 21/25 [15:07<04:25, 66.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465c94a30> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  22
Best f1_score score: 0.7756577641095159
Generation:  88%| | 22/25 [15:27<02:37, 52.63s/it]Generation:  23
Best f1_score score: 0.7756577641095159
Generation:  92%|| 23/25 [15:44<01:23, 41.75s/it]Generation:  24
Best f1_score score: 0.7756577641095159
Generation:  96%|| 24/25 [16:05<00:35, 35.59s/it]Generation:  25
Best f1_score score: 0.7756577641095159
Generation: 100%|| 25/25 [16:19<00:00, 29.14s/it]Generation: 100%|| 25/25 [16:22<00:00, 39.30s/it]
2024-11-22 23:32:37,324 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34301' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-ebd5ec05bb0f66b412969f9be33321b3', 'ndarray-635d2ca863672089e970fe8516e1cd47'} (stimulus_id='handle-worker-cleanup-1732347157.3245077')
Fitted
Pipeline(steps=[('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.0005866512253,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0989898670686, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=13,
                               max_leaves=None, min_child_weight=7, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
score start
train score: {'auroc': 0.9788726321538418, 'accuracy': 0.974941875484371, 'balanced_accuracy': 0.7792216191638424, 'logloss': 0.07640814672620658, 'f1': 0.8469299942398028}
original test score: {'auroc': 0.9735262008733624, 'accuracy': 0.9793388429752066, 'balanced_accuracy': 0.843970440040309, 'logloss': 0.06052940619413351, 'f1': 0.8858813543336792}
imputed test score: {'auroc': 0.926205072220356, 'accuracy': 0.9597107438016529, 'balanced_accuracy': 0.6884867316090023, 'logloss': 0.11876252038343423, 'f1': 0.7426637492075827}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.747135866094186
Generation:   4%|         | 1/25 [04:12<1:41:00, 252.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d25a20> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d25540> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.747135866094186
Generation:   8%|         | 2/25 [08:31<1:38:09, 256.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd6530> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  3
Best f1_score score: 0.7635567501973753
Generation:  12%|        | 3/25 [12:50<1:34:30, 257.73s/it]Generation:  4
Best f1_score score: 0.7635567501973753
Generation:  16%|        | 4/25 [17:09<1:30:19, 258.05s/it]Generation:  5
Best f1_score score: 0.7684829557882497
Generation:  20%|        | 5/25 [21:28<1:26:07, 258.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545be4a3e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.7684829557882497
Generation:  24%|       | 6/25 [25:45<1:21:39, 257.88s/it]Generation:  7
Best f1_score score: 0.7718318152611456
Generation:  28%|       | 7/25 [30:09<1:17:57, 259.85s/it]Generation:  8
Best f1_score score: 0.7718318152611456
Generation:  32%|      | 8/25 [34:24<1:13:13, 258.42s/it]Generation:  9
Best f1_score score: 0.7754579419965376
Generation:  36%|      | 9/25 [38:40<1:08:45, 257.81s/it]Generation:  10
Best f1_score score: 0.7768344415637246
Generation:  40%|      | 10/25 [42:57<1:04:22, 257.49s/it]Generation:  11
Best f1_score score: 0.7768344415637246
Generation:  44%|     | 11/25 [47:15<1:00:07, 257.67s/it]Generation:  12
Best f1_score score: 0.7768344415637246
Generation:  48%|     | 12/25 [51:29<55:35, 256.55s/it]  Generation:  13
Best f1_score score: 0.7768344415637246
Generation:  52%|    | 13/25 [55:46<51:20, 256.67s/it]Generation:  14
Best f1_score score: 0.7768344415637246
Generation:  56%|    | 14/25 [1:00:06<47:14, 257.72s/it]Generation:  15
Best f1_score score: 0.7768344415637246
Generation:  60%|    | 15/25 [1:01:25<33:57, 203.79s/it]Generation:  16
Best f1_score score: 0.7768344415637246
Generation:  64%|   | 16/25 [1:05:45<33:06, 220.69s/it]Generation:  17
Best f1_score score: 0.7768344415637246
Generation:  68%|   | 17/25 [1:10:10<31:11, 234.00s/it]Generation:  18
Best f1_score score: 0.7768344415637246
Generation:  72%|  | 18/25 [1:14:29<28:11, 241.60s/it]Generation:  19
Best f1_score score: 0.7768344415637246
Generation:  76%|  | 19/25 [1:18:49<24:42, 247.08s/it]Generation:  20
Best f1_score score: 0.7768344415637246
Generation:  80%|  | 20/25 [1:19:21<15:12, 182.58s/it]Generation:  21
Best f1_score score: 0.7844906718416809
Generation:  84%| | 21/25 [1:21:13<10:45, 161.32s/it]Generation:  22
Best f1_score score: 0.7844906718416809
Generation:  88%| | 22/25 [1:25:29<09:28, 189.64s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554741e16c0> 

Generation:  23
Best f1_score score: 0.7844906718416809
Generation:  92%|| 23/25 [1:35:36<10:29, 314.84s/it]Generation:  24
Best f1_score score: 0.7844906718416809
Generation:  96%|| 24/25 [1:39:52<04:57, 297.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155411690df0> 

Generation:  25
Best f1_score score: 0.7844906718416809
Generation: 100%|| 25/25 [1:49:58<00:00, 389.97s/it]Generation: 100%|| 25/25 [1:49:58<00:00, 263.95s/it]
2024-11-23 01:23:08,461 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42253' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-3dca972fb7f6deb28215aa85947ece7a', 'ndarray-ebd5ec05bb0f66b412969f9be33321b3'} (stimulus_id='handle-worker-cleanup-1732353788.4615717')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=Ridge(), n_nearest_features=98)),
                ('mlpclassifier',
                 MLPClassifier(alpha=0.0001257614447,
                               hidden_layer_sizes=[456, 456],
                               learning_rate_init=0.0005068364359,
                               n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9567313597035636, 'accuracy': 0.9648669594420046, 'balanced_accuracy': 0.8077337664204203, 'logloss': 0.11760934977078728, 'f1': 0.820738218469082}
test score: {'auroc': 0.927065838092039, 'accuracy': 0.9597107438016529, 'balanced_accuracy': 0.733834397044004, 'logloss': 0.12818387786285756, 'f1': 0.7703412153324858}
original test score: {'auroc': 0.988705072220356, 'accuracy': 0.981404958677686, 'balanced_accuracy': 0.9448270070540813, 'logloss': 0.06244732691041113, 'f1': 0.9147086466165414}
score end
40983
lvl
0.3
type
MAR
num_run
3
class_full
finished
all finished
full run takes
27.0762914087375
hours
DONE
