Run: 28
/cm/local/apps/slurm/var/spool/job958009/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
starting loops
../data/c/6/6.pkl
working on 
../data/c/6/class_full_MCAR_0.5_2
2.520000457763672
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-09-20 07:10:25,631] A new study created in memory with name: no-name-3b4369cb-7380-4e12-9839-dfdbcd764396
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-09-20 07:10:26,843] Trial 6 finished with value: 0.30900904062158785 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 6 with value: 0.30900904062158785.
running
[I 2024-09-20 07:10:27,053] Trial 4 finished with value: 0.30900904062158785 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 6 with value: 0.30900904062158785.
running
[I 2024-09-20 07:10:27,266] Trial 15 finished with value: 0.2908217128133914 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 15 with value: 0.2908217128133914.
running
[I 2024-09-20 07:10:40,120] Trial 16 finished with value: 0.16643393256043465 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.00035565665502350347, 'p_miss': 0.27879314186636905}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:40,894] Trial 10 finished with value: 0.3100493897497465 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.833071687257041, 'alpha': 31, 'iterations': 1, 'learning_rate': 0.027160862261896613, 'p_miss': 0.18110854588501346}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:46,793] Trial 0 finished with value: 0.1815958169951736 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 49, 'weights': 'uniform'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:51,240] Trial 3 finished with value: 0.18002207304080892 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13653, 'weights': 'uniform'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:53,896] Trial 17 finished with value: 0.18002207304080892 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14497, 'weights': 'uniform'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:54,364] Trial 8 finished with value: 0.18141949530315854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3022, 'weights': 'distance'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:54,936] Trial 7 finished with value: 0.1801323949245893 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11540, 'weights': 'uniform'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:55,650] Trial 23 finished with value: 0.30900904062158785 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:56,277] Trial 12 finished with value: 0.18007679654491637 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11895, 'weights': 'uniform'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:10:57,379] Trial 11 finished with value: 0.18141392125828038 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3658, 'weights': 'distance'}. Best is trial 16 with value: 0.16643393256043465.
running
[I 2024-09-20 07:11:00,255] Trial 22 finished with value: 0.16412798494217423 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5, 'learning_rate': 0.03538300914171901, 'p_miss': 0.2720914906503277}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:08,105] Trial 19 finished with value: 0.18005511518111744 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12017, 'weights': 'uniform'}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:09,607] Trial 29 finished with value: 0.1686768520486875 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.0001635086443448069, 'p_miss': 0.2879171817437797}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:13,194] Trial 28 finished with value: 0.1687623817066667 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 12, 'learning_rate': 0.00012574143447882956, 'p_miss': 0.29095113675298434}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:14,625] Trial 27 finished with value: 0.16731767182091023 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 15, 'learning_rate': 0.00022370874464964564, 'p_miss': 0.2969013065454855}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:15,444] Trial 30 finished with value: 0.1687013927841295 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5, 'learning_rate': 0.00021663689466223547, 'p_miss': 0.28931941170167413}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:16,055] Trial 18 finished with value: 0.3112425622875049 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.010278650178108728, 'alpha': 3, 'iterations': 51, 'learning_rate': 0.0010308477562535258, 'p_miss': 0.2173953885708449}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:17,558] Trial 25 finished with value: 0.1685369228793971 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 17, 'learning_rate': 0.0001639735138135079, 'p_miss': 0.2971827244828521}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:11:17,745] Trial 26 finished with value: 0.16661031877157292 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 17, 'learning_rate': 0.00011076170751316258, 'p_miss': 0.28665620608780973}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:12:01,828] Trial 37 finished with value: 0.17939484658791827 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:12:12,978] Trial 32 finished with value: 0.17678426025810984 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:12:15,383] Trial 33 finished with value: 0.1768298222523742 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 22 with value: 0.16412798494217423.
running
[I 2024-09-20 07:12:18,095] Trial 21 finished with value: 0.16026852974120676 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 105, 'learning_rate': 0.00017836398290159905, 'p_miss': 0.07424848051231156}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:12:22,096] Trial 35 finished with value: 0.1767412669160201 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'random'}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:12:52,767] Trial 14 finished with value: 0.1891669153117947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:13:22,598] Trial 5 finished with value: 0.2392764475885308 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:14:51,483] Trial 20 finished with value: 0.3095330699240744 and parameters: {'model_name': 'GAIN', 'batch_size': 343, 'hint_rate': 0.12263488379606399, 'alpha': 50, 'iterations': 216, 'learning_rate': 0.0006101924136688381, 'p_miss': 0.038651836614190735}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:18:02,106] Trial 42 finished with value: 0.18502640170181497 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 141, 'learning_rate': 0.08830361854457736, 'p_miss': 0.03533236129740683}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:19:44,003] Trial 31 finished with value: 0.18594072556398114 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 282, 'learning_rate': 0.0009072735708598941, 'p_miss': 0.28591925899912174}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:26:29,974] Trial 13 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9832761457818535, 'alpha': 19, 'iterations': 3972, 'learning_rate': 0.0002108692772581341, 'p_miss': 0.055139553133453444}. Best is trial 21 with value: 0.16026852974120676.
running
[I 2024-09-20 07:26:38,341] Trial 48 finished with value: 0.15948133297720404 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.006281969251478428, 'p_miss': 0.10395660854070486}. Best is trial 48 with value: 0.15948133297720404.
running
[I 2024-09-20 07:26:46,218] Trial 49 finished with value: 0.16399733805775712 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.006374578118429007, 'p_miss': 0.09567391050406937}. Best is trial 48 with value: 0.15948133297720404.
running
[I 2024-09-20 07:26:53,458] Trial 50 finished with value: 0.16407815365101325 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.007416081801060714, 'p_miss': 0.09569813343134116}. Best is trial 48 with value: 0.15948133297720404.
running
[I 2024-09-20 07:27:00,684] Trial 51 finished with value: 0.16631260771422213 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.005093669002790813, 'p_miss': 0.09705857934336895}. Best is trial 48 with value: 0.15948133297720404.
running
[I 2024-09-20 07:27:12,307] Trial 52 finished with value: 0.15850522691345093 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 1, 'learning_rate': 0.0059440889808341476, 'p_miss': 0.10459128324280653}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:32:29,530] Trial 39 finished with value: 0.18524013790149002 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 473, 'learning_rate': 0.08508115145723716, 'p_miss': 0.08653042590689333}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:32:41,019] Trial 54 finished with value: 0.167344502201295 and parameters: {'model_name': 'VAE', 'batch_size': 84, 'iterations': 2, 'learning_rate': 0.0025738456772479074, 'p_miss': 0.1346347875977022}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:32:46,327] Trial 1 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.30963115800099067, 'alpha': 23, 'iterations': 5306, 'learning_rate': 0.002351862862978974, 'p_miss': 0.27405195217535794}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:32:55,579] Trial 56 finished with value: 0.15885375710404764 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 1, 'learning_rate': 0.007765582320939421, 'p_miss': 0.10281706432703554}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:33:05,722] Trial 57 finished with value: 0.1596915149804079 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 1, 'learning_rate': 0.009677009482613966, 'p_miss': 0.1274575820584083}. Best is trial 52 with value: 0.15850522691345093.
running
[I 2024-09-20 07:33:24,451] Trial 58 finished with value: 0.14333955954828811 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 2, 'learning_rate': 0.01172702472528666, 'p_miss': 0.13560640118373685}. Best is trial 58 with value: 0.14333955954828811.
running
[I 2024-09-20 07:33:48,175] Trial 59 finished with value: 0.1424537036155277 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 2, 'learning_rate': 0.013079514790830254, 'p_miss': 0.1279514261427493}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:34:04,957] Trial 60 finished with value: 0.1503161544969966 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 2, 'learning_rate': 0.013289873819014378, 'p_miss': 0.12702134901619427}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:34:05,759] Trial 61 finished with value: 0.18002207304080892 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:34:30,082] Trial 62 finished with value: 0.1561960308065437 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 2, 'learning_rate': 0.01660901806575048, 'p_miss': 0.164442029912595}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:35:02,339] Trial 63 finished with value: 0.17609747443368987 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 3, 'learning_rate': 0.013921231445006451, 'p_miss': 0.17092522015245626}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:35:27,312] Trial 64 finished with value: 0.17758935552741156 and parameters: {'model_name': 'VAE', 'batch_size': 202, 'iterations': 2, 'learning_rate': 0.018796848112171194, 'p_miss': 0.13897123366787467}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:35:37,060] Trial 65 finished with value: 0.3119554337157552 and parameters: {'model_name': 'GAIN', 'batch_size': 37, 'hint_rate': 0.6541067799644962, 'alpha': 98, 'iterations': 2, 'learning_rate': 0.0037680695539822895, 'p_miss': 0.15997888893550188}. Best is trial 59 with value: 0.1424537036155277.
running
[I 2024-09-20 07:35:59,448] Trial 66 finished with value: 0.1383875032959215 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 2, 'learning_rate': 0.012131575960690286, 'p_miss': 0.11803911832003963}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:36:29,106] Trial 67 finished with value: 0.18050994047420355 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 3, 'learning_rate': 0.015903029182855306, 'p_miss': 0.12019235288678869}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:37:13,254] Trial 68 finished with value: 0.18162081791026435 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 8, 'learning_rate': 0.03204982543366068, 'p_miss': 0.19299631864891556}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:37:34,044] Trial 69 finished with value: 0.14211387869754594 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 2, 'learning_rate': 0.011767497925509022, 'p_miss': 0.1473359666549917}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:37:34,649] Trial 70 finished with value: 0.30900904062158785 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:37:57,269] Trial 71 finished with value: 0.18116384172799477 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7652, 'weights': 'distance'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:38:22,181] Trial 72 finished with value: 0.19620356989997828 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 2, 'learning_rate': 0.02247751219646939, 'p_miss': 0.14858480342559166}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:39:28,482] Trial 73 finished with value: 0.30900904062158785 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.528897959914268, 'alpha': 94, 'iterations': 37, 'learning_rate': 0.04634987962598444, 'p_miss': 0.1871825252845904}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:55:42,143] Trial 24 finished with value: 0.1795604310739824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:58:32,201] Trial 40 finished with value: 0.18128552956656632 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 877, 'learning_rate': 0.03282907076769576, 'p_miss': 0.03754411131776045}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:58:55,824] Trial 76 finished with value: 0.14563357103137106 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 3, 'learning_rate': 0.011671749352770624, 'p_miss': 0.12234346438034326}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:59:18,111] Trial 77 finished with value: 0.14713268068699348 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 3, 'learning_rate': 0.011906957353023358, 'p_miss': 0.1171312737932795}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 07:59:54,659] Trial 78 finished with value: 0.16704168917244253 and parameters: {'model_name': 'VAE', 'batch_size': 102, 'iterations': 4, 'learning_rate': 0.011081717819349057, 'p_miss': 0.11923211757799082}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:00:37,660] Trial 9 finished with value: 0.18636788101964147 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 1288, 'learning_rate': 0.003026309774140751, 'p_miss': 0.1367281682838898}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:01:09,984] Trial 79 finished with value: 0.19890398936524928 and parameters: {'model_name': 'VAE', 'batch_size': 288, 'iterations': 8, 'learning_rate': 0.01141129478423257, 'p_miss': 0.14686178605256794}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:02:30,371] Trial 80 finished with value: 0.1888477045797064 and parameters: {'model_name': 'VAE', 'batch_size': 912, 'iterations': 8, 'learning_rate': 0.010473648247124321, 'p_miss': 0.14749456851678058}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:02:54,600] Trial 82 finished with value: 0.18113535631893113 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7978, 'weights': 'distance'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:06:25,120] Trial 44 finished with value: 0.19474298414804508 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 891, 'learning_rate': 0.08345749042435043, 'p_miss': 0.025600112630146332}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:06:26,881] Trial 84 finished with value: 0.2908217128133914 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:10:05,611] Trial 43 finished with value: 0.18191362555592577 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1013, 'learning_rate': 0.06040405807675812, 'p_miss': 0.02329166168968526}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:10:32,481] Trial 86 finished with value: 0.17938337617196004 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 3, 'learning_rate': 0.021551233957978644, 'p_miss': 0.16486102374034148}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:11:20,922] Trial 55 finished with value: 0.18622711701154215 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 761, 'learning_rate': 0.009411212178934798, 'p_miss': 0.13006946647137163}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:11:35,529] Trial 88 finished with value: 0.14536436927325808 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2, 'learning_rate': 0.01482324854246192, 'p_miss': 0.11786844751259308}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:11:56,403] Trial 89 finished with value: 0.14703412515859043 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 3, 'learning_rate': 0.013568495805110208, 'p_miss': 0.1182121700483097}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:12:18,888] Trial 90 finished with value: 0.16573538537039217 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 4, 'learning_rate': 0.023745208906946653, 'p_miss': 0.08338854275176244}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:12:33,659] Trial 91 finished with value: 0.15949151866970862 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 3, 'learning_rate': 0.004829586634273429, 'p_miss': 0.11433001006009844}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:15:16,695] Trial 38 finished with value: 0.18351538491988628 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1359, 'learning_rate': 0.040716019294658755, 'p_miss': 0.03868469193358398}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:15:33,619] Trial 93 finished with value: 0.3095192330954026 and parameters: {'model_name': 'GAIN', 'batch_size': 155, 'hint_rate': 0.3255113703954049, 'alpha': 69, 'iterations': 5, 'learning_rate': 0.014773425863569395, 'p_miss': 0.06619653479656327}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:17:59,742] Trial 94 finished with value: 0.18711896328323455 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 38, 'learning_rate': 0.008353877485059173, 'p_miss': 0.11251735006913369}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:19:01,140] Trial 95 finished with value: 0.19020073357501355 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 13, 'learning_rate': 0.026412660746289545, 'p_miss': 0.1417387110190951}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:19:14,156] Trial 96 finished with value: 0.1492230229298879 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 2, 'learning_rate': 0.013355947461641673, 'p_miss': 0.12835838089454182}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:19:31,043] Trial 97 finished with value: 0.15112745298505087 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 2, 'learning_rate': 0.01828024911843899, 'p_miss': 0.1149567476848439}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:19:56,337] Trial 98 finished with value: 0.1428435343226948 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.012435932918540747, 'p_miss': 0.12840882671659168}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:20:20,106] Trial 99 finished with value: 0.15216775184431577 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 4, 'learning_rate': 0.012231429044124035, 'p_miss': 0.13767544789285674}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:20:38,340] Trial 53 finished with value: 0.1876095623796361 and parameters: {'model_name': 'VAE', 'batch_size': 276, 'iterations': 994, 'learning_rate': 0.00221009239876753, 'p_miss': 0.10254559310530412}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:20:50,629] Trial 100 finished with value: 0.16238526581665497 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 6, 'learning_rate': 0.001555003562904041, 'p_miss': 0.15458497459249}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:21:00,484] Trial 101 finished with value: 0.18135709971129538 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5227, 'weights': 'distance'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:22:17,200] Trial 103 finished with value: 0.1768872788448858 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:22:39,390] Trial 104 finished with value: 0.1479726856744878 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 3, 'learning_rate': 0.007791096276111859, 'p_miss': 0.08743896513034637}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:39:19,116] Trial 36 finished with value: 0.17142856866385792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'arabic'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:39:34,926] Trial 106 finished with value: 0.15260238723169287 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 3, 'learning_rate': 0.009334554328997956, 'p_miss': 0.08351954693280807}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:40:06,813] Trial 107 finished with value: 0.21079526878069815 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 4, 'learning_rate': 0.01939066450592732, 'p_miss': 0.12128571609418429}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:40:22,971] Trial 108 finished with value: 0.15349594574623066 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.007588196352627688, 'p_miss': 0.11020828750112963}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:40:44,962] Trial 47 finished with value: 0.18575148540728534 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1436, 'learning_rate': 0.014829347529638062, 'p_miss': 0.10692118209973928}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:40:55,132] Trial 109 finished with value: 0.14890483400652918 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 7, 'learning_rate': 0.004334526673548335, 'p_miss': 0.07334672530363298}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:41:19,125] Trial 111 finished with value: 0.14784188183438027 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 4, 'learning_rate': 0.010051886199265116, 'p_miss': 0.08874059187322766}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:41:23,462] Trial 110 finished with value: 0.17057584479280546 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 6, 'learning_rate': 0.011204808996102045, 'p_miss': 0.09114144133687577}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:41:24,288] Trial 113 finished with value: 0.18002207304080892 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:41:36,504] Trial 41 finished with value: 0.1884099940616141 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1646, 'learning_rate': 0.09898615725911826, 'p_miss': 0.041835915784150246}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:42:04,200] Trial 115 finished with value: 0.14575928751390257 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 5, 'learning_rate': 0.0059014343413674, 'p_miss': 0.13335593983994173}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:42:05,367] Trial 112 finished with value: 0.19795844639537533 and parameters: {'model_name': 'VAE', 'batch_size': 98, 'iterations': 5, 'learning_rate': 0.011663178878623622, 'p_miss': 0.12339345412649481}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:42:19,226] Trial 114 finished with value: 0.16036524947590114 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 10, 'learning_rate': 0.005981811466019183, 'p_miss': 0.13326857519669358}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:42:29,302] Trial 117 finished with value: 0.15237645679414158 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 4, 'learning_rate': 0.0062620199022334995, 'p_miss': 0.1334771575333345}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:42:44,734] Trial 116 finished with value: 0.21672827393529426 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 4, 'learning_rate': 0.016720810464743215, 'p_miss': 0.12694373807433965}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:43:51,956] Trial 118 finished with value: 0.18697852787705269 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 19, 'learning_rate': 0.016478553733716313, 'p_miss': 0.14301282835534462}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:44:00,657] Trial 119 finished with value: 0.19275645403530356 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 18, 'learning_rate': 0.009355918477145876, 'p_miss': 0.10945617671211902}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:53:22,305] Trial 2 finished with value: 0.17025273211142988 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 13, 'imputation_order': 'arabic'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:59:01,905] Trial 34 finished with value: 0.16990940497528656 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 08:59:13,460] Trial 124 finished with value: 0.31087758185550224 and parameters: {'model_name': 'GAIN', 'batch_size': 37, 'hint_rate': 0.7147371089061823, 'alpha': 68, 'iterations': 2, 'learning_rate': 0.013540722515789175, 'p_miss': 0.15224007320105107}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:00:03,784] Trial 125 finished with value: 0.16409122150291774 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 10, 'learning_rate': 0.00884976822974849, 'p_miss': 0.1190012844351737}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:00:23,514] Trial 126 finished with value: 0.15175780465062733 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 3, 'learning_rate': 0.007480652417585067, 'p_miss': 0.2668311238076202}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:00:34,054] Trial 127 finished with value: 0.16071719168009152 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 2, 'learning_rate': 0.006891797864857131, 'p_miss': 0.07782473412028523}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:26:36,682] Trial 46 finished with value: 0.18974730082980612 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 2093, 'learning_rate': 0.005510733800208887, 'p_miss': 0.08916673502211096}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:31:19,592] Trial 74 finished with value: 0.18608245280107208 and parameters: {'model_name': 'VAE', 'batch_size': 900, 'iterations': 1471, 'learning_rate': 0.011610093212208442, 'p_miss': 0.15828373367833706}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:31:39,641] Trial 130 finished with value: 0.15080431535425215 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 3, 'learning_rate': 0.008840418203979756, 'p_miss': 0.0609638562613743}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:31:54,015] Trial 131 finished with value: 0.16427090378305462 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 3, 'learning_rate': 0.0004343482019155276, 'p_miss': 0.09646738520962267}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:32:27,169] Trial 132 finished with value: 0.19311568333828114 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 6, 'learning_rate': 0.019210889016050853, 'p_miss': 0.10519503671437266}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:32:58,192] Trial 133 finished with value: 0.16339306743365586 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 5, 'learning_rate': 0.014138351339890762, 'p_miss': 0.1371133634967033}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:33:14,960] Trial 134 finished with value: 0.18131331373626336 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1093, 'weights': 'distance'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:33:24,148] Trial 135 finished with value: 0.16478106835065276 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.003230787243433066, 'p_miss': 0.12394951900251991}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:33:49,828] Trial 136 finished with value: 0.15176957945053038 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 7, 'learning_rate': 0.004732944276895282, 'p_miss': 0.07755223793293096}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:34:17,503] Trial 137 finished with value: 0.14243552917339847 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 4, 'learning_rate': 0.0103563956864233, 'p_miss': 0.06812447852369792}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:48:59,722] Trial 122 finished with value: 0.31823489078839867 and parameters: {'model_name': 'GAIN', 'batch_size': 44, 'hint_rate': 0.7105297245141937, 'alpha': 68, 'iterations': 2420, 'learning_rate': 0.013401702611620126, 'p_miss': 0.1567706656514325}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:49:28,646] Trial 139 finished with value: 0.1494819749042279 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 4, 'learning_rate': 0.010127672334751328, 'p_miss': 0.10112688376850548}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:49:52,410] Trial 140 finished with value: 0.1450120639143586 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 3, 'learning_rate': 0.008168795103051853, 'p_miss': 0.05548133098544312}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:56:02,680] Trial 141 finished with value: 0.18685729228183962 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 93, 'learning_rate': 0.010759096472876324, 'p_miss': 0.054020610424924106}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:56:43,407] Trial 142 finished with value: 0.20749895105206786 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 5, 'learning_rate': 0.01575420450455139, 'p_miss': 0.05774613133607232}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 09:58:25,327] Trial 92 finished with value: 0.3136142364185987 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.24636968812002935, 'alpha': 70, 'iterations': 4166, 'learning_rate': 0.0016914078986708767, 'p_miss': 0.0652609092045106}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:11:47,856] Trial 102 finished with value: 0.1694715224177134 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:12:30,849] Trial 145 finished with value: 0.19993187352786768 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 4, 'learning_rate': 0.026567096230184554, 'p_miss': 0.1167243577129884}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:12:43,376] Trial 146 finished with value: 0.1556599647879618 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 2, 'learning_rate': 0.008079456934750725, 'p_miss': 0.05258010602724231}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:13:12,353] Trial 147 finished with value: 0.1507512803485561 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 3, 'learning_rate': 0.012369801546323007, 'p_miss': 0.13107929018906533}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:13:38,603] Trial 148 finished with value: 0.14719009687994436 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 5, 'learning_rate': 0.010075239600660474, 'p_miss': 0.06977288198357395}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:14:02,652] Trial 149 finished with value: 0.14112681253965206 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 5, 'learning_rate': 0.010004477582910176, 'p_miss': 0.0703242617045803}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:14:03,328] Trial 150 finished with value: 0.30900904062158785 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:33:47,800] Trial 151 finished with value: 0.18512501516912144 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 288, 'learning_rate': 0.021615855056531953, 'p_miss': 0.043707732453398165}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:34:16,207] Trial 152 finished with value: 0.1551453396800161 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 5, 'learning_rate': 0.012560213765988074, 'p_miss': 0.06829271052751527}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:35:23,733] Trial 153 finished with value: 0.1761655537249945 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 9, 'learning_rate': 0.006846679045369549, 'p_miss': 0.14490611155007832}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:36:10,601] Trial 154 finished with value: 0.2028068905201152 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 6, 'learning_rate': 0.01732173083704807, 'p_miss': 0.04527330307333891}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:38:01,003] Trial 155 finished with value: 0.18827954644542563 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 13, 'learning_rate': 0.014781210413870018, 'p_miss': 0.031733539551156466}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:38:34,365] Trial 156 finished with value: 0.14688084409505456 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 4, 'learning_rate': 0.009521755983775557, 'p_miss': 0.07098397851028944}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:39:12,351] Trial 157 finished with value: 0.14925415383836776 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 7, 'learning_rate': 0.01086054148426099, 'p_miss': 0.07182256025198362}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:39:42,972] Trial 158 finished with value: 0.13979338987320267 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 5, 'learning_rate': 0.00863389594258436, 'p_miss': 0.05158262099651263}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:39:51,461] Trial 159 finished with value: 0.16062248217288475 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 1, 'learning_rate': 0.008769359111451316, 'p_miss': 0.06196193210730477}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:40:21,358] Trial 160 finished with value: 0.14508288966954078 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 3, 'learning_rate': 0.0057162588857119735, 'p_miss': 0.1369132877525997}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:40:42,643] Trial 161 finished with value: 0.15371590662940032 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 3, 'learning_rate': 0.005419712975036209, 'p_miss': 0.1373189989785494}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:40:56,979] Trial 162 finished with value: 0.15953477510824599 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 2, 'learning_rate': 0.003776675575402845, 'p_miss': 0.0197479158279793}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:41:39,924] Trial 163 finished with value: 0.15397091712664693 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 4, 'learning_rate': 0.0065732618568877365, 'p_miss': 0.011482222253615872}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:41:55,909] Trial 164 finished with value: 0.18002207304080892 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15971, 'weights': 'uniform'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:42:29,619] Trial 165 finished with value: 0.14189319403972983 and parameters: {'model_name': 'VAE', 'batch_size': 72, 'iterations': 3, 'learning_rate': 0.008835957185962615, 'p_miss': 0.1497782203892306}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:43:00,652] Trial 166 finished with value: 0.14163918866500064 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 3, 'learning_rate': 0.007958040729194853, 'p_miss': 0.150231366746383}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:43:41,256] Trial 167 finished with value: 0.15237735809425776 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 6, 'learning_rate': 0.008155449675675532, 'p_miss': 0.16459797610660468}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:44:02,619] Trial 168 finished with value: 0.1512631142128038 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 4, 'learning_rate': 0.005746176414160539, 'p_miss': 0.14919882795732414}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:44:21,114] Trial 169 finished with value: 0.15298435254085146 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 2, 'learning_rate': 0.0075726284299593325, 'p_miss': 0.14485072432642623}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:44:45,023] Trial 170 finished with value: 0.14206457337535824 and parameters: {'model_name': 'VAE', 'batch_size': 96, 'iterations': 2, 'learning_rate': 0.009474750566618421, 'p_miss': 0.1727572080354504}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:44:58,382] Trial 171 finished with value: 0.15866273106077186 and parameters: {'model_name': 'VAE', 'batch_size': 161, 'iterations': 1, 'learning_rate': 0.004278563204756021, 'p_miss': 0.05008815112580019}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 10:46:05,053] Trial 172 finished with value: 0.18714263815893314 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:37:18,655] Trial 105 finished with value: 0.18730769068813638 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2890, 'learning_rate': 0.018751234118124693, 'p_miss': 0.24515917039314783}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:37:34,772] Trial 174 finished with value: 0.15247940089689288 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 2, 'learning_rate': 0.006796522369411925, 'p_miss': 0.17524213852983828}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:38:08,413] Trial 175 finished with value: 0.16052733550743253 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 3, 'learning_rate': 0.01166263385069479, 'p_miss': 0.16797538316889687}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:38:45,655] Trial 176 finished with value: 0.16202138902998192 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 4, 'learning_rate': 0.00917316911986046, 'p_miss': 0.1933443020005863}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:39:19,137] Trial 177 finished with value: 0.14240660548409673 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 3, 'learning_rate': 0.00980658371943968, 'p_miss': 0.1815722751851903}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:39:47,423] Trial 178 finished with value: 0.14292402980052993 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 3, 'learning_rate': 0.00856525162470223, 'p_miss': 0.1809130919453544}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:40:22,908] Trial 179 finished with value: 0.15041972279770097 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 3, 'learning_rate': 0.008607464866346289, 'p_miss': 0.1747340516625009}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:40:45,423] Trial 180 finished with value: 0.14369203084806234 and parameters: {'model_name': 'VAE', 'batch_size': 108, 'iterations': 2, 'learning_rate': 0.010455680194931576, 'p_miss': 0.2012028917335786}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:41:18,284] Trial 181 finished with value: 0.14712396765679933 and parameters: {'model_name': 'VAE', 'batch_size': 138, 'iterations': 2, 'learning_rate': 0.010174616958956308, 'p_miss': 0.20260734719192228}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 11:41:19,520] Trial 182 finished with value: 0.2908217128133914 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:09:16,338] Trial 121 finished with value: 0.1854843013525866 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 4055, 'learning_rate': 0.008891139970444618, 'p_miss': 0.1539799383958092}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:09:46,343] Trial 184 finished with value: 0.14497773658158003 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 2, 'learning_rate': 0.012273555729803839, 'p_miss': 0.18229895032049215}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:06,844] Trial 85 finished with value: 0.18743762893476693 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3891, 'learning_rate': 0.00403307864998201, 'p_miss': 0.11593989661706942}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:24,950] Trial 185 finished with value: 0.14880318075062599 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 3, 'learning_rate': 0.007428996294813296, 'p_miss': 0.18693819096234274}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:27,187] Trial 120 finished with value: 0.18550616292922992 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 3284, 'learning_rate': 0.00913581022228787, 'p_miss': 0.2600423129543277}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:33,107] Trial 186 finished with value: 0.14272112408760262 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 2, 'learning_rate': 0.012626314320258616, 'p_miss': 0.18256551706206361}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:53,713] Trial 187 finished with value: 0.15444718698348664 and parameters: {'model_name': 'VAE', 'batch_size': 87, 'iterations': 2, 'learning_rate': 0.01264367920612093, 'p_miss': 0.20103313002041248}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:10:54,983] Trial 188 finished with value: 0.14768116017996405 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 2, 'learning_rate': 0.014628559230508124, 'p_miss': 0.20258495186141975}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:11:03,838] Trial 189 finished with value: 0.1668068322508473 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 2, 'learning_rate': 0.01264422564393351, 'p_miss': 0.21281844602117456}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:11:29,070] Trial 191 finished with value: 0.14519787238399387 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 3, 'learning_rate': 0.010895259436055228, 'p_miss': 0.17793478894264092}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:11:44,300] Trial 192 finished with value: 0.16187499393808946 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 3, 'learning_rate': 0.010522332289448226, 'p_miss': 0.18411006379344824}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:11:45,275] Trial 190 finished with value: 0.19016002900993206 and parameters: {'model_name': 'VAE', 'batch_size': 182, 'iterations': 3, 'learning_rate': 0.010724315628834151, 'p_miss': 0.17859808245820757}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:12:05,134] Trial 193 finished with value: 0.1466293735022325 and parameters: {'model_name': 'VAE', 'batch_size': 155, 'iterations': 3, 'learning_rate': 0.01027331753591866, 'p_miss': 0.18436160808846122}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:12:39,292] Trial 194 finished with value: 0.16393565654809444 and parameters: {'model_name': 'VAE', 'batch_size': 237, 'iterations': 4, 'learning_rate': 0.008406801345553485, 'p_miss': 0.17080725203523775}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:12:43,210] Trial 196 finished with value: 0.13885677089378498 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 4, 'learning_rate': 0.008002314718637112, 'p_miss': 0.19428796898706152}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:13:18,015] Trial 197 finished with value: 0.16687978550399662 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 2, 'learning_rate': 0.011873229165293205, 'p_miss': 0.19409605867380225}. Best is trial 66 with value: 0.1383875032959215.
running
[I 2024-09-20 12:13:27,927] Trial 198 finished with value: 0.14779117388435056 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 5, 'learning_rate': 0.007277867405524359, 'p_miss': 0.19016321579419584}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 12:13:51,251] Trial 199 finished with value: 0.1516452972370525 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 5, 'learning_rate': 0.007155471854732975, 'p_miss': 0.16335350093102255}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 12:14:01,183] Trial 195 finished with value: 0.18718460312740004 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 28, 'learning_rate': 0.00801105098762667, 'p_miss': 0.16857585742586403}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 12:27:09,476] Trial 128 finished with value: 0.18554841376458864 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 3433, 'learning_rate': 0.01066557321561816, 'p_miss': 0.09171939691228392}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 13:07:06,539] Trial 83 finished with value: 0.18384901006004833 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 6312, 'learning_rate': 0.004193233040666831, 'p_miss': 0.06669483371009183}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 13:43:02,598] Trial 45 finished with value: 0.18707068432855323 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7420, 'learning_rate': 0.020844997073481634, 'p_miss': 0.05692270191516699}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 13:43:51,010] Trial 81 finished with value: 0.18584372794060525 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 7223, 'learning_rate': 0.023634810966021415, 'p_miss': 0.11686358319080972}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 13:52:59,052] Trial 87 finished with value: 0.18386653105932704 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 7617, 'learning_rate': 0.015526309439156278, 'p_miss': 0.11782838907125805}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:20:40,629] Trial 129 finished with value: 0.18592705817891206 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 6798, 'learning_rate': 0.010000788287025447, 'p_miss': 0.10005604032964611}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:35:43,177] Trial 144 finished with value: 0.18720715989231246 and parameters: {'model_name': 'VAE', 'batch_size': 195, 'iterations': 7605, 'learning_rate': 0.02718394202357518, 'p_miss': 0.01509342434386568}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:52:12,738] Trial 123 finished with value: 0.18536640362263396 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 9117, 'learning_rate': 0.014152233060427146, 'p_miss': 0.15554720343029255}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:53:14,644] Trial 143 finished with value: 0.18660849636579183 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 7128, 'learning_rate': 0.02172764282547762, 'p_miss': 0.05260620754499243}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:54:08,434] Trial 138 finished with value: 0.18631389157993816 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 8573, 'learning_rate': 0.010303498289921146, 'p_miss': 0.06521745926687146}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:54:24,327] Trial 183 finished with value: 0.18728768450055752 and parameters: {'model_name': 'VAE', 'batch_size': 115, 'iterations': 6309, 'learning_rate': 0.012771982933586785, 'p_miss': 0.17424454431297529}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:54:24,595] Trial 173 finished with value: 0.1855504123514429 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 6922, 'learning_rate': 0.006860450200575425, 'p_miss': 0.1755572974387815}. Best is trial 66 with value: 0.1383875032959215.
[I 2024-09-20 14:56:06,577] Trial 75 finished with value: 0.1862215798350202 and parameters: {'model_name': 'VAE', 'batch_size': 793, 'iterations': 8541, 'learning_rate': 0.011118801091528508, 'p_miss': 0.15722706151536842}. Best is trial 66 with value: 0.1383875032959215.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0.1383875032959215
{'model_name': 'VAE', 'batch_size': 106, 'iterations': 2, 'learning_rate': 0.012131575960690286, 'p_miss': 0.11803911832003963}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4c40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4d90> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  1
Best f1_score score: 0.04088888740233063
Generation:   4%|         | 1/25 [01:41<40:47, 101.99s/it]Generation:  2
Best f1_score score: 0.04088888740233063
Generation:   8%|         | 2/25 [04:03<47:55, 125.01s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5ff0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.04088888740233063
Generation:  12%|        | 3/25 [06:18<47:33, 129.71s/it]Generation:  4
Best f1_score score: 0.04088888740233063
Generation:  16%|        | 4/25 [07:25<36:47, 105.13s/it]Generation:  5
Best f1_score score: 0.04088888740233063
Generation:  20%|        | 5/25 [11:40<53:00, 159.05s/it]Generation:  6
Best f1_score score: 0.04088888740233063
Generation:  24%|       | 6/25 [17:33<1:11:15, 225.02s/it]Generation:  7
Best f1_score score: 0.04088888740233063
Generation:  28%|       | 7/25 [19:32<57:06, 190.34s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547473bfd0> 

Generation:  8
Best f1_score score: 0.04088888740233063
Generation:  32%|      | 8/25 [29:39<1:31:29, 322.93s/it]Generation:  9
Best f1_score score: 0.04088888740233063
Generation:  36%|      | 9/25 [32:09<1:11:44, 269.02s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679ac4f0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678fe0e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.04088888740233063
Generation:  40%|      | 10/25 [34:39<58:03, 232.26s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29840> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  11
Best f1_score score: 0.040959194686611404
Generation:  44%|     | 11/25 [35:53<42:51, 183.67s/it]Generation:  12
Best f1_score score: 0.040959194686611404
Generation:  48%|     | 12/25 [41:55<51:34, 238.02s/it]Generation:  13
Best f1_score score: 0.040959194686611404
Generation:  52%|    | 13/25 [42:40<35:53, 179.46s/it]Generation:  14
Best f1_score score: 0.040959194686611404
Generation:  56%|    | 14/25 [45:09<31:14, 170.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554654f7d90> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 598, in compute
    return ArgKminClassMode32.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  15
Best f1_score score: 0.040959194686611404
Generation:  60%|    | 15/25 [46:45<24:39, 147.92s/it]Generation:  16
Best f1_score score: 0.040959194686611404
Generation:  64%|   | 16/25 [50:48<26:28, 176.54s/it]Generation:  17
Best f1_score score: 0.040959194686611404
Generation:  68%|   | 17/25 [54:50<26:09, 196.20s/it]Generation:  18
Best f1_score score: 0.04209202929758739
Generation:  72%|  | 18/25 [57:57<22:33, 193.36s/it]Generation:  19
Best f1_score score: 0.04209202929758739
Generation:  76%|  | 19/25 [1:02:14<21:15, 212.60s/it]Generation:  20
Best f1_score score: 0.04209202929758739
Generation:  80%|  | 20/25 [1:04:32<15:50, 190.08s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f48160> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f766b0> 

Generation:  21
Best f1_score score: 0.04209202929758739
Generation:  84%| | 21/25 [1:14:43<21:06, 316.54s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554674a56c0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e46680> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.04209202929758739
Generation:  88%| | 22/25 [1:21:28<17:09, 343.18s/it]Generation:  23
Best f1_score score: 0.04209202929758739
Generation:  92%|| 23/25 [1:27:30<11:37, 348.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464ff3310> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.04209202929758739
Generation:  96%|| 24/25 [1:29:58<04:48, 288.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464abec50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.04209202929758739
Generation: 100%|| 25/25 [1:32:01<00:00, 238.79s/it]Generation: 100%|| 25/25 [1:32:04<00:00, 220.99s/it]
2024-09-20 16:28:24,556 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35537' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-f44562fbd7a1642dc081874940e80174', 'ndarray-481e2d94896c7f1f5042a2a80c31c086'} (stimulus_id='handle-worker-cleanup-1726874904.556731')
Fitted
Pipeline(steps=[('baggingclassifier',
                 BaggingClassifier(max_features=0.3979972472507,
                                   max_samples=0.149238284774, n_estimators=38,
                                   n_jobs=1, oob_score=True))])
score start
train score: {'auroc': 0.9814737657973805, 'accuracy': 0.823875, 'balanced_accuracy': 0.8237945657236729, 'logloss': 1.858017231338298, 'f1': 0.8245882379531024}
original test score: {'auroc': 0.5211849752380446, 'accuracy': 0.05475, 'balanced_accuracy': 0.05482029528277077, 'logloss': 10.119580727457604, 'f1': 0.047277591260755224}
imputed test score: {'auroc': 0.5003624827898197, 'accuracy': 0.04425, 'balanced_accuracy': 0.044069328075007776, 'logloss': 10.782186800986418, 'f1': 0.04308333093909174}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014520>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 3 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4dc0> 

Generation:  1
Best f1_score score: 0.5331810758951164
Generation:   4%|         | 1/25 [10:02<4:01:02, 602.60s/it]Generation:  2
Best f1_score score: 0.5535857317885409
Generation:   8%|         | 2/25 [14:57<2:41:35, 421.53s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474736d40> 

Generation:  3
Best f1_score score: 0.5679942988347184
Generation:  12%|        | 3/25 [25:02<3:05:15, 505.27s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459e86290> 

Generation:  4
Best f1_score score: 0.5679942988347184
Generation:  16%|        | 4/25 [35:07<3:10:43, 544.92s/it]Generation:  5
Best f1_score score: 0.5740087037512811
Generation:  20%|        | 5/25 [39:00<2:24:06, 432.31s/it]Generation:  6
Best f1_score score: 0.5967037005262438
Generation:  24%|       | 6/25 [44:39<2:06:48, 400.47s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466bbf640> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546793ef20> 

Generation:  7
Best f1_score score: 0.5967037005262438
Generation:  28%|       | 7/25 [54:44<2:20:14, 467.48s/it]Generation:  8
Best f1_score score: 0.5967037005262438
Generation:  32%|      | 8/25 [59:58<1:58:36, 418.65s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e3c4c0> 

Generation:  9
Best f1_score score: 0.6109602609338849
Generation:  36%|      | 9/25 [1:10:05<2:07:18, 477.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471c310> 

Generation:  10
Best f1_score score: 0.6109602609338849
Generation:  40%|      | 10/25 [1:20:11<2:09:15, 517.01s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459610a60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fc0d0> 

Generation:  11
Best f1_score score: 0.6121902377891819
Generation:  44%|     | 11/25 [1:30:15<2:06:53, 543.82s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467aaa3b0> 

Generation:  12
Best f1_score score: 0.6121902377891819
Generation:  48%|     | 12/25 [1:40:21<2:01:54, 562.63s/it]Generation:  13
Best f1_score score: 0.6121902377891819
Generation:  52%|    | 13/25 [1:45:55<1:38:42, 493.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459283ca0> 

Generation:  14
Best f1_score score: 0.6148754151125946
Generation:  56%|    | 14/25 [1:56:01<1:36:41, 527.43s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546687a2c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155391dc03d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553c6872020> 

Generation:  15
Best f1_score score: 0.6148754151125946
Generation:  60%|    | 15/25 [2:06:08<1:31:52, 551.30s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465691570> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5fc70> 

Generation:  16
Best f1_score score: 0.6200957513895812
Generation:  64%|   | 16/25 [2:16:14<1:25:10, 567.84s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155397650a90> 

Generation:  17
Best f1_score score: 0.6200957513895812
Generation:  68%|   | 17/25 [2:26:22<1:17:19, 579.88s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459d2abc0> 

Generation:  18
Best f1_score score: 0.6200957513895812
Generation:  72%|  | 18/25 [2:36:28<1:08:34, 587.81s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554772844f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546535f0a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5a770> 

Generation:  19
Best f1_score score: 0.6200957513895812
Generation:  76%|  | 19/25 [2:46:35<59:20, 593.47s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471c1c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465139600> 

Generation:  20
Best f1_score score: 0.6200957513895812
Generation:  80%|  | 20/25 [2:56:43<49:48, 597.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bd52bf0> 

Generation:  21
Best f1_score score: 0.6200957513895812
Generation:  84%| | 21/25 [3:06:50<40:02, 600.56s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459283400> 

Generation:  22
Best f1_score score: 0.6200957513895812
Generation:  88%| | 22/25 [3:16:56<30:06, 602.17s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b3e2170> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f70040> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554677b4700> 

Generation:  23
Best f1_score score: 0.6200957513895812
Generation:  92%|| 23/25 [3:27:03<20:07, 603.86s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465316e00> 

Generation:  24
Best f1_score score: 0.6200957513895812
Generation:  96%|| 24/25 [3:37:08<10:04, 604.15s/it]Generation:  25
Best f1_score score: 0.6200982869859112
Generation: 100%|| 25/25 [3:41:00<00:00, 492.29s/it]Generation: 100%|| 25/25 [3:41:00<00:00, 530.41s/it]
2024-09-20 20:10:40,724 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36943' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-0286bb2d1e9aa2f42f39b6f3cc1cdd31', 'ndarray-f44562fbd7a1642dc081874940e80174'} (stimulus_id='handle-worker-cleanup-1726888240.723885')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=KNeighborsRegressor(),
                                  imputation_order='random',
                                  initial_strategy='median',
                                  n_nearest_features=10)),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=0.0445976084069,
                                                learning_rate=0.0381706469908,
                                                max_features=0.3719730798983,
                                                max_leaf_nodes=346,
                                                min_samples_leaf=85, tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9995262008496303, 'accuracy': 0.961, 'balanced_accuracy': 0.9609914345902877, 'logloss': 0.3431837151291537, 'f1': 0.9609934838553322}
test score: {'auroc': 0.9489951284057819, 'accuracy': 0.63325, 'balanced_accuracy': 0.6327752601286237, 'logloss': 1.3532975555480797, 'f1': 0.6356086505538681}
original test score: {'auroc': 0.9969398679138077, 'accuracy': 0.90025, 'balanced_accuracy': 0.8999327882036549, 'logloss': 0.43198769813773524, 'f1': 0.899893065644989}
score end
6
lvl
0.5
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
13.086447911593648
hours
DONE
