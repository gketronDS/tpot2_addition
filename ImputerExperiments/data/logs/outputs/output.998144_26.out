Run: 26
/cm/local/apps/slurm/var/spool/job998144/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/32/32.pkl
working on 
../data/c/32/class_full_MCAR_0.1_2
3.717118263244629
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-12 23:23:56,498] A new study created in memory with name: no-name-9086a818-a1b4-4f92-8ee7-43e78b49bf1a
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-12 23:23:56,799] Trial 0 finished with value: 0.3024104960518007 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.3024104960518007.
running
[I 2024-10-12 23:23:56,973] Trial 9 finished with value: 0.3024104960518007 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.3024104960518007.
running
[I 2024-10-12 23:23:57,133] Trial 4 finished with value: 0.5043388477580057 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3024104960518007.
running
[I 2024-10-12 23:23:57,240] Trial 2 finished with value: 0.5043388477580057 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.3024104960518007.
running
[I 2024-10-12 23:24:02,723] Trial 6 finished with value: 0.1789936361849474 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 243, 'weights': 'uniform'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:03,037] Trial 20 finished with value: 0.5782354213152568 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:03,686] Trial 21 finished with value: 0.3024104960518007 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:04,281] Trial 12 finished with value: 0.20366927694918405 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 743, 'weights': 'uniform'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:04,562] Trial 10 finished with value: 0.2729280676367204 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:05,822] Trial 13 finished with value: 0.3392859695368423 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0001167130545729461, 'p_miss': 0.24852120137367384}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:06,067] Trial 19 finished with value: 0.2587304524467354 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3583, 'weights': 'uniform'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:06,337] Trial 15 finished with value: 0.5645785260377872 and parameters: {'model_name': 'GAIN', 'batch_size': 51, 'hint_rate': 0.9456051683856349, 'alpha': 30, 'iterations': 2, 'learning_rate': 0.00042179465905887076, 'p_miss': 0.0850736948977681}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:06,528] Trial 14 finished with value: 0.5677387343062053 and parameters: {'model_name': 'GAIN', 'batch_size': 71, 'hint_rate': 0.8419566077635089, 'alpha': 8, 'iterations': 1, 'learning_rate': 0.00371871759209936, 'p_miss': 0.06447122967272077}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:08,940] Trial 1 finished with value: 0.32463823801929 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.010716520725823209, 'p_miss': 0.09270770057033799}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:09,254] Trial 16 finished with value: 0.5550025455442003 and parameters: {'model_name': 'GAIN', 'batch_size': 82, 'hint_rate': 0.513832603745592, 'alpha': 96, 'iterations': 7, 'learning_rate': 0.00016235002080280708, 'p_miss': 0.13636389985943664}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:10,271] Trial 22 finished with value: 0.3350684489701388 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 6, 'learning_rate': 0.0007938211359636954, 'p_miss': 0.22604205636475264}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:11,006] Trial 18 finished with value: 0.2764779066705962 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8698, 'weights': 'distance'}. Best is trial 6 with value: 0.1789936361849474.
running
[I 2024-10-12 23:24:15,699] Trial 26 finished with value: 0.14956337689414784 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19, 'weights': 'uniform'}. Best is trial 26 with value: 0.14956337689414784.
running
[I 2024-10-12 23:24:16,452] Trial 27 finished with value: 0.18728189686008984 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 378, 'weights': 'uniform'}. Best is trial 26 with value: 0.14956337689414784.
running
[I 2024-10-12 23:24:16,809] Trial 28 finished with value: 0.17961387945237067 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 252, 'weights': 'uniform'}. Best is trial 26 with value: 0.14956337689414784.
running
[I 2024-10-12 23:24:18,961] Trial 29 finished with value: 0.15751682156310395 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 48, 'weights': 'uniform'}. Best is trial 26 with value: 0.14956337689414784.
running
[I 2024-10-12 23:24:19,173] Trial 30 finished with value: 0.14758238906423338 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:19,916] Trial 31 finished with value: 0.14920494965227654 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:20,949] Trial 32 finished with value: 0.1822068948892984 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 291, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:24,719] Trial 11 finished with value: 0.29963092544996106 and parameters: {'model_name': 'VAE', 'batch_size': 315, 'iterations': 2, 'learning_rate': 0.023572818431935143, 'p_miss': 0.2709234004008708}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:25,847] Trial 33 finished with value: 0.17143372806368123 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 148, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:26,153] Trial 34 finished with value: 0.16823764718196826 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 115, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:26,378] Trial 3 finished with value: 0.20441365358972402 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:29,028] Trial 36 finished with value: 0.15064931374880047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:31,677] Trial 37 finished with value: 0.2373354758950635 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2070, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:24:59,547] Trial 35 finished with value: 0.19398483256134696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:05,662] Trial 39 finished with value: 0.19398462736178645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:09,846] Trial 38 finished with value: 0.19398441152187187 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:11,178] Trial 8 finished with value: 0.3122236386806726 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 84, 'learning_rate': 0.009206631531828106, 'p_miss': 0.26801098917034966}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:13,518] Trial 46 finished with value: 0.22563120017969665 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2002, 'weights': 'distance'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:13,966] Trial 23 finished with value: 0.1875462534183547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:17,121] Trial 41 finished with value: 0.19398453897034781 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:18,762] Trial 47 finished with value: 0.2249130470440915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1959, 'weights': 'distance'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:21,081] Trial 50 finished with value: 0.23011844852343769 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1704, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
[I 2024-10-12 23:25:21,198] Trial 48 finished with value: 0.2302680356484971 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2289, 'weights': 'distance'}. Best is trial 30 with value: 0.14758238906423338.
running
running
[I 2024-10-12 23:25:21,480] Trial 49 finished with value: 0.2270749079506163 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2087, 'weights': 'distance'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:22,309] Trial 51 finished with value: 0.23465046746630014 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1926, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:25,257] Trial 52 finished with value: 0.23740105061651717 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2074, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:26,426] Trial 53 finished with value: 0.22743089345561743 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1580, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:29,636] Trial 54 finished with value: 0.2795530935372575 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5522, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:30,014] Trial 57 finished with value: 0.21416057251802906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1064, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:30,547] Trial 55 finished with value: 0.2824601003410661 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5802, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:31,441] Trial 56 finished with value: 0.29157583473752513 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6582, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:32,373] Trial 58 finished with value: 0.21803249326477828 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1198, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:33,369] Trial 59 finished with value: 0.21563098074536638 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1115, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:35,546] Trial 60 finished with value: 0.21431829254554327 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1069, 'weights': 'uniform'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:25:53,228] Trial 40 finished with value: 0.1576980160491843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:31:00,371] Trial 7 finished with value: 0.3258730530793664 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 431, 'learning_rate': 0.000478352064400325, 'p_miss': 0.144583647332864}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:31:00,728] Trial 68 finished with value: 0.29298000936911095 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-12 23:57:04,230] Trial 24 finished with value: 0.3031682049020934 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 2038, 'learning_rate': 0.07770840927966537, 'p_miss': 0.19307234327542014}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:13:38,068] Trial 67 finished with value: 0.5785621047413396 and parameters: {'model_name': 'GAIN', 'batch_size': 914, 'hint_rate': 0.06317382968706392, 'alpha': 83, 'iterations': 3680, 'learning_rate': 0.0581667550021146, 'p_miss': 0.010059978135865094}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:21:22,279] Trial 66 finished with value: 0.578356657769345 and parameters: {'model_name': 'GAIN', 'batch_size': 487, 'hint_rate': 0.02373330931981732, 'alpha': 81, 'iterations': 5950, 'learning_rate': 0.07374683087823793, 'p_miss': 0.011764671613241184}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:21:58,786] Trial 72 finished with value: 0.15792547062428325 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 11, 'imputation_order': 'arabic'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:27:18,965] Trial 25 finished with value: 0.577316730344481 and parameters: {'model_name': 'GAIN', 'batch_size': 575, 'hint_rate': 0.48500074674119814, 'alpha': 44, 'iterations': 5387, 'learning_rate': 0.05705096554130071, 'p_miss': 0.014550768101798173}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:27:19,235] Trial 74 finished with value: 0.29298000936911095 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 30 with value: 0.14758238906423338.
running
[I 2024-10-13 00:27:26,770] Trial 45 finished with value: 0.1402074360594226 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 45 with value: 0.1402074360594226.
running
[I 2024-10-13 00:28:01,410] Trial 75 finished with value: 0.3082789507635957 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 40, 'learning_rate': 0.002821937369707181, 'p_miss': 0.2954280558606891}. Best is trial 45 with value: 0.1402074360594226.
running
[I 2024-10-13 00:31:06,778] Trial 5 finished with value: 0.30081388080667026 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 4353, 'learning_rate': 0.0200068681633989, 'p_miss': 0.1302814476300002}. Best is trial 45 with value: 0.1402074360594226.
running
[I 2024-10-13 00:39:03,522] Trial 43 finished with value: 0.13636872960253063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.13636872960253063.
running
[I 2024-10-13 00:39:06,552] Trial 44 finished with value: 0.13625414585427173 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 00:39:08,265] Trial 42 finished with value: 0.13697671501703162 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 00:42:39,274] Trial 64 finished with value: 0.57817167036427 and parameters: {'model_name': 'GAIN', 'batch_size': 859, 'hint_rate': 0.08327620191000962, 'alpha': 80, 'iterations': 5480, 'learning_rate': 0.06765623508452956, 'p_miss': 0.01228295718015382}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:03:18,695] Trial 17 finished with value: 0.29793337800548375 and parameters: {'model_name': 'VAE', 'batch_size': 269, 'iterations': 2894, 'learning_rate': 0.00724823837255372, 'p_miss': 0.1631933395923625}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:17:20,871] Trial 71 finished with value: 0.1410587692658043 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 11, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:22:33,814] Trial 65 finished with value: 0.578615952920941 and parameters: {'model_name': 'GAIN', 'batch_size': 655, 'hint_rate': 0.02433030296883798, 'alpha': 78, 'iterations': 9252, 'learning_rate': 0.04770969335756055, 'p_miss': 0.012328472713449085}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:26:51,246] Trial 73 finished with value: 0.141677355276849 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 11, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:35:56,118] Trial 69 finished with value: 0.5782035681898886 and parameters: {'model_name': 'GAIN', 'batch_size': 860, 'hint_rate': 0.039321879542405624, 'alpha': 85, 'iterations': 7912, 'learning_rate': 0.06548001255435312, 'p_miss': 0.01508885153938197}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:37:00,081] Trial 76 finished with value: 0.138384450874729 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:37:25,449] Trial 77 finished with value: 0.13783316138489088 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:40:49,197] Trial 78 finished with value: 0.13876799732296446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:46:36,303] Trial 62 finished with value: 0.5775037622397474 and parameters: {'model_name': 'GAIN', 'batch_size': 873, 'hint_rate': 0.034360169032034094, 'alpha': 80, 'iterations': 8951, 'learning_rate': 0.07680841031381494, 'p_miss': 0.0220487299146456}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:48:55,979] Trial 81 finished with value: 0.139477540401729 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:48:56,415] Trial 79 finished with value: 0.1399454016884995 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:50:38,250] Trial 63 finished with value: 0.5762844012623225 and parameters: {'model_name': 'GAIN', 'batch_size': 854, 'hint_rate': 0.012532366854488386, 'alpha': 80, 'iterations': 9187, 'learning_rate': 0.09326942151615802, 'p_miss': 0.18324104074744876}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:52:03,431] Trial 82 finished with value: 0.13875104708952168 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 01:53:13,603] Trial 80 finished with value: 0.1383541359204027 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:00:16,753] Trial 61 finished with value: 0.5776317497734367 and parameters: {'model_name': 'GAIN', 'batch_size': 963, 'hint_rate': 0.10019846427761553, 'alpha': 80, 'iterations': 9831, 'learning_rate': 0.0754686107851642, 'p_miss': 0.025985795084690427}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:11:24,567] Trial 83 finished with value: 0.13930041338856952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:18:23,055] Trial 70 finished with value: 0.5782323367872294 and parameters: {'model_name': 'GAIN', 'batch_size': 883, 'hint_rate': 0.03813093939701251, 'alpha': 80, 'iterations': 9099, 'learning_rate': 0.0020560755448134345, 'p_miss': 0.012251534277214204}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:22:41,007] Trial 84 finished with value: 0.14040950774091288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:25:59,856] Trial 85 finished with value: 0.1397345681095345 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:29:30,754] Trial 86 finished with value: 0.1387381257698108 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:35:20,428] Trial 87 finished with value: 0.139085874970104 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:36:09,149] Trial 89 finished with value: 0.1379576686384545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:36:14,440] Trial 88 finished with value: 0.13751374040081815 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:38:34,615] Trial 90 finished with value: 0.13839141664370183 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:43:38,331] Trial 91 finished with value: 0.13831802212360494 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:48:22,853] Trial 92 finished with value: 0.13805253065609252 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:48:42,686] Trial 93 finished with value: 0.13869936471522323 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:49:23,639] Trial 94 finished with value: 0.13883605281415126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:50:51,395] Trial 95 finished with value: 0.13882535073151736 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:51:49,630] Trial 96 finished with value: 0.13730304108743466 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 02:56:47,573] Trial 97 finished with value: 0.13877154699394795 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 03:09:55,914] Trial 98 finished with value: 0.1368658342248922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 03:11:57,290] Trial 114 finished with value: 0.3135459583458015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 03:17:21,957] Trial 99 finished with value: 0.1373627763079952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.13625414585427173.
running
[I 2024-10-13 03:21:46,318] Trial 100 finished with value: 0.13597693748409606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:24:52,694] Trial 101 finished with value: 0.1363764198878486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:28:28,021] Trial 102 finished with value: 0.13708394438840818 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:30:03,813] Trial 119 finished with value: 0.19399080684372422 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:35:33,411] Trial 103 finished with value: 0.13666964110296473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:36:09,977] Trial 105 finished with value: 0.1368929874289681 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:36:10,380] Trial 104 finished with value: 0.13728482183686402 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:38:36,850] Trial 106 finished with value: 0.1371381083943519 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:43:51,389] Trial 107 finished with value: 0.13665120192817742 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:44:21,260] Trial 125 finished with value: 0.19398465704431117 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:49:05,583] Trial 108 finished with value: 0.13634419423639682 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:49:33,581] Trial 127 finished with value: 0.15760839419409062 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:49:34,790] Trial 109 finished with value: 0.13723047397121582 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:49:59,774] Trial 110 finished with value: 0.13601646122931815 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:50:48,023] Trial 130 finished with value: 0.3268203212825588 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 364, 'learning_rate': 0.001296600758127168, 'p_miss': 0.21573494705318325}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:50:48,255] Trial 131 finished with value: 0.5782354213152568 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:50:50,948] Trial 129 finished with value: 0.34072308845003085 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 848, 'learning_rate': 0.001316251956227793, 'p_miss': 0.22363443936429456}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:52:04,444] Trial 111 finished with value: 0.1366804632718776 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:52:11,149] Trial 112 finished with value: 0.13753401023894857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 03:57:55,427] Trial 113 finished with value: 0.13658459813127763 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 100 with value: 0.13597693748409606.
running
[I 2024-10-13 04:14:50,408] Trial 115 finished with value: 0.13557355947651006 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:19:48,297] Trial 116 finished with value: 0.1356168859514518 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:24:47,196] Trial 117 finished with value: 0.13674488177957786 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:27:16,646] Trial 118 finished with value: 0.13631922550153688 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:31:34,834] Trial 120 finished with value: 0.13637411766050206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:37:17,085] Trial 121 finished with value: 0.13702415566565862 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:37:41,283] Trial 122 finished with value: 0.13618205146393605 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:37:48,547] Trial 142 finished with value: 0.15786973810436483 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:37:57,707] Trial 123 finished with value: 0.13627943555594557 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:38:38,051] Trial 144 finished with value: 0.19398444562491673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:38:46,580] Trial 145 finished with value: 0.19398444562491673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:38:59,407] Trial 143 finished with value: 0.15736883128139917 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:41:05,501] Trial 124 finished with value: 0.13691384117717814 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:43:21,626] Trial 126 finished with value: 0.13716624583863427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:47:27,185] Trial 137 finished with value: 0.15581970064653622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:51:47,558] Trial 128 finished with value: 0.1363546220421077 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:51:47,849] Trial 152 finished with value: 0.29298000936911095 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:52:50,905] Trial 132 finished with value: 0.13599157446000135 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:52:54,118] Trial 133 finished with value: 0.13632610256858638 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:54:21,420] Trial 135 finished with value: 0.1359259443166021 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:54:46,937] Trial 134 finished with value: 0.1361239204546411 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 04:56:21,758] Trial 155 finished with value: 0.26712187535737986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:01:23,875] Trial 136 finished with value: 0.13605770608775938 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:02:49,493] Trial 147 finished with value: 0.17998285713110745 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:04:34,954] Trial 149 finished with value: 0.17405850825398161 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:14:02,943] Trial 148 finished with value: 0.1495744412566794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:21:22,247] Trial 138 finished with value: 0.13577288310343547 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:26:12,243] Trial 139 finished with value: 0.13629692103400382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:27:36,180] Trial 164 finished with value: 0.3118202676782046 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:29:36,192] Trial 140 finished with value: 0.1359039219435487 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:33:42,910] Trial 141 finished with value: 0.13622984202861185 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:40:58,754] Trial 146 finished with value: 0.13684100221251924 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:44:40,474] Trial 150 finished with value: 0.13649926179464086 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:48:17,344] Trial 151 finished with value: 0.13611386164950434 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:52:23,265] Trial 153 finished with value: 0.13593008329383188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:53:17,351] Trial 154 finished with value: 0.13630195821110822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:54:42,677] Trial 156 finished with value: 0.13667412868212742 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:55:13,380] Trial 157 finished with value: 0.13588867135395888 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 05:56:40,053] Trial 158 finished with value: 0.13595334275817433 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:02:36,256] Trial 159 finished with value: 0.1368029580476015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:03:08,604] Trial 160 finished with value: 0.1363149629980524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:05:05,422] Trial 161 finished with value: 0.13628434117021093 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:14:23,990] Trial 162 finished with value: 0.1360354199706059 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:21:35,702] Trial 163 finished with value: 0.1359803010910994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:26:40,404] Trial 165 finished with value: 0.1360913047574185 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:26:42,816] Trial 181 finished with value: 0.3310444522769953 and parameters: {'model_name': 'VAE', 'batch_size': 207, 'iterations': 22, 'learning_rate': 0.00030681271680178834, 'p_miss': 0.10723713777836003}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:28:52,616] Trial 166 finished with value: 0.13654593319996158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:32:49,724] Trial 167 finished with value: 0.13637934282425013 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:40:56,135] Trial 168 finished with value: 0.13624228074304265 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:40:56,353] Trial 185 finished with value: 0.5043388477580057 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:44:16,690] Trial 169 finished with value: 0.1370637031856661 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:47:20,687] Trial 170 finished with value: 0.13623572194930902 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:51:27,990] Trial 171 finished with value: 0.13653307589430935 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:52:23,546] Trial 172 finished with value: 0.13657716062782244 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 115 with value: 0.13557355947651006.
running
[I 2024-10-13 06:53:48,804] Trial 173 finished with value: 0.13544364939423853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 06:54:17,863] Trial 174 finished with value: 0.13638465558333415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 06:56:15,015] Trial 175 finished with value: 0.13658643368884435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:02:20,306] Trial 177 finished with value: 0.13595313439683276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:02:59,593] Trial 176 finished with value: 0.13665504444545026 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:04:22,661] Trial 178 finished with value: 0.13607261025789263 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'roman'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:13:31,695] Trial 179 finished with value: 0.13633469579736437 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:21:01,465] Trial 180 finished with value: 0.13645497388089559 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:25:49,170] Trial 182 finished with value: 0.13625704535778907 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
running
[I 2024-10-13 07:28:01,500] Trial 183 finished with value: 0.13646250056960327 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:32:17,805] Trial 184 finished with value: 0.13610919700926022 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:40:45,451] Trial 186 finished with value: 0.13555160306701758 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:44:08,974] Trial 187 finished with value: 0.13656433530244855 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:46:31,308] Trial 188 finished with value: 0.13567135701102934 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:50:33,913] Trial 189 finished with value: 0.13662791137503433 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:51:30,634] Trial 190 finished with value: 0.13651629084783795 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:52:50,103] Trial 191 finished with value: 0.13672695919634276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:53:24,090] Trial 192 finished with value: 0.13568468483974844 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 07:55:21,209] Trial 193 finished with value: 0.13602936910846983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:01:03,574] Trial 194 finished with value: 0.1355988970453375 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:02:27,792] Trial 195 finished with value: 0.13633147151152708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:03:27,300] Trial 196 finished with value: 0.13761339296003777 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:12:13,833] Trial 197 finished with value: 0.1367629428537367 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:19:24,675] Trial 198 finished with value: 0.1357812087360531 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 173 with value: 0.13544364939423853.
[I 2024-10-13 08:23:54,773] Trial 199 finished with value: 0.13613226357339248 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 173 with value: 0.13544364939423853.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0.13544364939423853
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9847137293888946
Generation:   4%|         | 1/25 [00:48<19:23, 48.48s/it]Generation:  2
Best f1_score score: 0.9855079446248467
Generation:   8%|         | 2/25 [01:26<16:11, 42.24s/it]Generation:  3
Best f1_score score: 0.9855079446248467
Generation:  12%|        | 3/25 [02:14<16:33, 45.16s/it]Generation:  4
Best f1_score score: 0.9885933744026781
Generation:  16%|        | 4/25 [08:03<57:45, 165.04s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554743c7790> 

Generation:  5
Best f1_score score: 0.9885933744026781
Generation:  20%|        | 5/25 [18:08<1:47:51, 323.56s/it]Generation:  6
Best f1_score score: 0.9885933744026781
Generation:  24%|       | 6/25 [18:55<1:12:38, 229.38s/it]Generation:  7
Best f1_score score: 0.9889201087891714
Generation:  28%|       | 7/25 [21:25<1:01:03, 203.54s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546f9b76d0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  8
Best f1_score score: 0.9889201087891714
Generation:  32%|      | 8/25 [29:00<1:20:19, 283.52s/it]Generation:  9
Best f1_score score: 0.9899720083801091
Generation:  36%|      | 9/25 [34:41<1:20:26, 301.68s/it]Generation:  10
Best f1_score score: 0.9899720083801091
Generation:  40%|      | 10/25 [36:41<1:01:21, 245.46s/it]Generation:  11
Best f1_score score: 0.9899720083801091
Generation:  44%|     | 11/25 [41:23<59:53, 256.67s/it]  Generation:  12
Best f1_score score: 0.9899720083801091
Generation:  48%|     | 12/25 [49:32<1:10:57, 327.51s/it]Generation:  13
Best f1_score score: 0.9899720083801091
Generation:  52%|    | 13/25 [59:35<1:22:11, 410.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546f729810> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546d062cb0> 

Generation:  14
Best f1_score score: 0.9899720083801091
Generation:  56%|    | 14/25 [1:09:42<1:26:11, 470.10s/it]Generation:  15
Best f1_score score: 0.9906526927843411
Generation:  60%|    | 15/25 [1:13:08<1:05:03, 390.40s/it]Generation:  16
Best f1_score score: 0.9906526927843411
Generation:  64%|   | 16/25 [1:19:41<58:42, 391.34s/it]  Generation:  17
Best f1_score score: 0.9906526927843411
Generation:  68%|   | 17/25 [1:27:02<54:09, 406.22s/it]Generation:  18
Best f1_score score: 0.9915937692120149
Generation:  72%|  | 18/25 [1:31:52<43:19, 371.36s/it]Generation:  19
Best f1_score score: 0.9915937692120149
Generation:  76%|  | 19/25 [1:35:51<33:08, 331.43s/it]Generation:  20
Best f1_score score: 0.9915937692120149
Generation:  80%|  | 20/25 [1:43:12<30:21, 364.39s/it]Generation:  21
Best f1_score score: 0.9915937692120149
Generation:  84%| | 21/25 [1:44:58<19:06, 286.71s/it]Generation:  22
Best f1_score score: 0.9915937692120149
Generation:  88%| | 22/25 [1:52:31<16:49, 336.64s/it]Generation:  23
Best f1_score score: 0.9915937692120149
Generation:  92%|| 23/25 [1:58:55<11:41, 350.94s/it]Generation:  24
Best f1_score score: 0.9915937692120149
Generation:  96%|| 24/25 [2:03:09<05:21, 321.97s/it]Generation:  25
Best f1_score score: 0.9915937692120149
Generation: 100%|| 25/25 [2:10:53<00:00, 364.44s/it]Generation: 100%|| 25/25 [2:10:56<00:00, 314.24s/it]
2024-10-13 10:49:18,428 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44323' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-3a0b6b21e4ad2c119bea3229c66fba4b', 'ndarray-43b3f1f1519cef9204d9df3fe7f7335b'} (stimulus_id='handle-worker-cleanup-1728841758.428369')
Fitted
Pipeline(steps=[('mlpclassifier',
                 MLPClassifier(alpha=0.0030376530922,
                               hidden_layer_sizes=[376, 376],
                               learning_rate_init=0.0013734892536,
                               n_iter_no_change=32))])
score start
train score: {'auroc': 0.9999989480194525, 'accuracy': 0.9993176390310474, 'balanced_accuracy': 0.9992983139650725, 'logloss': 0.004067219224188152, 'f1': 0.9993117482600958}
original test score: {'auroc': 0.9998930808724056, 'accuracy': 0.9940882219190541, 'balanced_accuracy': 0.9940566313131699, 'logloss': 0.02571758932824182, 'f1': 0.9940955584437624}
imputed test score: {'auroc': 0.9997379581633723, 'accuracy': 0.9909049567985448, 'balanced_accuracy': 0.9907782634632483, 'logloss': 0.04063508690697646, 'f1': 0.9909163325565509}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155434ce8580>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474550fa0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547432d450> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547432c220> 

Generation:  1
Best f1_score score: 0.9637142875039076
Generation:   4%|         | 1/25 [10:03<4:01:34, 603.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547438cb80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.9637142875039076
Generation:   8%|         | 2/25 [10:24<1:39:53, 260.58s/it]Generation:  3
Best f1_score score: 0.987967991200934
Generation:  12%|        | 3/25 [11:01<58:10, 158.65s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546cfea860> 

Generation:  4
Best f1_score score: 0.9884255934309083
Generation:  16%|        | 4/25 [21:06<1:57:10, 334.79s/it]Generation:  5
Best f1_score score: 0.9884255934309083
Generation:  20%|        | 5/25 [23:33<1:29:04, 267.23s/it]Generation:  6
Best f1_score score: 0.9892629324763857
Generation:  24%|       | 6/25 [24:15<1:00:22, 190.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546fb12020> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.9915200806627853
Generation:  28%|       | 7/25 [24:55<42:24, 141.35s/it]  Generation:  8
Best f1_score score: 0.9915200806627853
Generation:  32%|      | 8/25 [26:15<34:31, 121.87s/it]Generation:  9
Best f1_score score: 0.9915200806627853
Generation:  36%|      | 9/25 [28:20<32:41, 122.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545960fbe0> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  10
Best f1_score score: 0.9915200806627853
Generation:  40%|      | 10/25 [29:34<26:54, 107.65s/it]Generation:  11
Best f1_score score: 0.9915200806627853
Generation:  44%|     | 11/25 [30:24<21:02, 90.15s/it] Generation:  12
Best f1_score score: 0.9915200806627853
Generation:  48%|     | 12/25 [31:11<16:42, 77.13s/it]Generation:  13
Best f1_score score: 0.9915200806627853
Generation:  52%|    | 13/25 [32:50<16:43, 83.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546d7b4400> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546cba72b0> 

Generation:  14
Best f1_score score: 0.9915200806627853
Generation:  56%|    | 14/25 [42:55<44:10, 240.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458cbe920> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546d49b6a0> 

Generation:  15
Best f1_score score: 0.9925473826037644
Generation:  60%|    | 15/25 [52:59<58:23, 350.37s/it]Generation:  16
Best f1_score score: 0.9925473826037644
Generation:  64%|   | 16/25 [54:05<39:42, 264.78s/it]Generation:  17
Best f1_score score: 0.9925473826037644
Generation:  68%|   | 17/25 [56:52<31:22, 235.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546fb3fa00> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  18
Best f1_score score: 0.9925473826037644
Generation:  72%|  | 18/25 [58:11<21:59, 188.49s/it]Generation:  19
Best f1_score score: 0.9925473826037644
Generation:  76%|  | 19/25 [1:00:46<17:51, 178.57s/it]Generation:  20
Best f1_score score: 0.9925473826037644
Generation:  80%|  | 20/25 [1:02:07<12:25, 149.06s/it]Generation:  21
Best f1_score score: 0.9925473826037644
Generation:  84%| | 21/25 [1:03:34<08:41, 130.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546c802230> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  22
Best f1_score score: 0.9925473826037644
Generation:  88%| | 22/25 [1:05:41<06:28, 129.42s/it]Generation:  23
Best f1_score score: 0.9925473826037644
Generation:  92%|| 23/25 [1:06:50<03:42, 111.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459ac5330> 

Generation:  24
Best f1_score score: 0.9925473826037644
Generation:  96%|| 24/25 [1:16:54<04:19, 259.11s/it]Generation:  25
Best f1_score score: 0.9925473826037644
Generation: 100%|| 25/25 [1:18:17<00:00, 206.41s/it]Generation: 100%|| 25/25 [1:18:17<00:00, 187.91s/it]
2024-10-13 12:07:48,941 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35859' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-43b3f1f1519cef9204d9df3fe7f7335b', 'DataFrame-a157b5609848c006c20150003e61af5e'} (stimulus_id='handle-worker-cleanup-1728846468.9415114')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=6, weights='distance')),
                ('svc',
                 SVC(C=181.6816719036374, gamma=3.5957923629115, max_iter=3000,
                     probability=True))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 0.004502846664330135, 'f1': 1.0}
test score: {'auroc': 0.9998434591168539, 'accuracy': 0.9927239654388358, 'balanced_accuracy': 0.9927876706086705, 'logloss': 0.035860880977746104, 'f1': 0.9927798953421382}
original test score: {'auroc': 0.9999632611366642, 'accuracy': 0.9949977262391997, 'balanced_accuracy': 0.9950083291487892, 'logloss': 0.025493027729629407, 'f1': 0.9950234544845431}
score end
32
lvl
0.1
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
12.742239660554462
hours
DONE
