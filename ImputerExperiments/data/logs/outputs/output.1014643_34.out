Run: 34
/cm/local/apps/slurm/var/spool/job1014643/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/728/728.pkl
working on 
../data/c/728/class_full_MNAR_0.1_2
0.2841165065765381
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-24 14:35:37,587] A new study created in memory with name: no-name-a978e0b3-b663-40e1-b926-57e24cd80d39
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-24 14:35:37,901] Trial 15 finished with value: 0.4399339610322043 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.4399339610322043.
running
[I 2024-10-24 14:35:38,226] Trial 3 finished with value: 0.4399339610322043 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 15 with value: 0.4399339610322043.
running
[I 2024-10-24 14:35:38,382] Trial 9 finished with value: 0.4399339610322043 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 15 with value: 0.4399339610322043.
running
[I 2024-10-24 14:35:38,682] Trial 18 finished with value: 0.4399339610322043 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.4399339610322043.
running
[I 2024-10-24 14:35:39,996] Trial 4 finished with value: 0.32849543488667576 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 825, 'weights': 'uniform'}. Best is trial 4 with value: 0.32849543488667576.
running
[I 2024-10-24 14:35:48,629] Trial 17 finished with value: 0.4675106916217002 and parameters: {'model_name': 'GAIN', 'batch_size': 33, 'hint_rate': 0.06553298187349699, 'alpha': 96, 'iterations': 2, 'learning_rate': 0.0006959452272095678, 'p_miss': 0.21960500175732273}. Best is trial 4 with value: 0.32849543488667576.
running
[I 2024-10-24 14:35:50,214] Trial 13 finished with value: 0.4606039029887296 and parameters: {'model_name': 'GAIN', 'batch_size': 474, 'hint_rate': 0.9139557632884063, 'alpha': 75, 'iterations': 3, 'learning_rate': 0.008528503053755118, 'p_miss': 0.10566531383125943}. Best is trial 4 with value: 0.32849543488667576.
running
[I 2024-10-24 14:35:51,406] Trial 21 finished with value: 0.32602149876483194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 463, 'weights': 'uniform'}. Best is trial 21 with value: 0.32602149876483194.
running
[I 2024-10-24 14:35:51,706] Trial 5 finished with value: 0.3294869700173071 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 21 with value: 0.32602149876483194.
running
[I 2024-10-24 14:35:55,071] Trial 22 finished with value: 0.3441220478095401 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2817, 'weights': 'distance'}. Best is trial 21 with value: 0.32602149876483194.
running
[I 2024-10-24 14:35:55,693] Trial 7 finished with value: 0.35223904965033787 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 21 with value: 0.32602149876483194.
running
[I 2024-10-24 14:35:57,365] Trial 11 finished with value: 0.35104477542041973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.32602149876483194.
running
[I 2024-10-24 14:35:58,227] Trial 26 finished with value: 0.3246254757021362 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 351, 'weights': 'uniform'}. Best is trial 26 with value: 0.3246254757021362.
running
[I 2024-10-24 14:35:58,493] Trial 19 finished with value: 0.35473327142862876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 26 with value: 0.3246254757021362.
running
[I 2024-10-24 14:35:59,271] Trial 23 finished with value: 0.44246865302645794 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 1, 'learning_rate': 0.007606241844560904, 'p_miss': 0.1261580616933854}. Best is trial 26 with value: 0.3246254757021362.
running
[I 2024-10-24 14:35:59,978] Trial 27 finished with value: 0.3241834256360176 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 301, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:00,360] Trial 29 finished with value: 0.35480882798640534 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:00,501] Trial 28 finished with value: 0.3624559890297167 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:02,058] Trial 31 finished with value: 0.35536686690024694 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:02,216] Trial 30 finished with value: 0.32469750775148365 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 338, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:07,659] Trial 1 finished with value: 0.44640708382845684 and parameters: {'model_name': 'GAIN', 'batch_size': 77, 'hint_rate': 0.8846744963426976, 'alpha': 56, 'iterations': 19, 'learning_rate': 0.00015520767381157748, 'p_miss': 0.059833048500147486}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:10,557] Trial 36 finished with value: 0.32946967871626537 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1232, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:36:14,189] Trial 37 finished with value: 0.34408115236634335 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1704, 'weights': 'distance'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:39:09,656] Trial 20 finished with value: 0.4424545996296382 and parameters: {'model_name': 'GAIN', 'batch_size': 64, 'hint_rate': 0.7018142635182538, 'alpha': 28, 'iterations': 126, 'learning_rate': 0.038168052671469145, 'p_miss': 0.03374600177006223}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:46:36,193] Trial 24 finished with value: 0.3361979660431115 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:46:39,124] Trial 12 finished with value: 0.3254190879103857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:46:55,275] Trial 16 finished with value: 0.33411412797895024 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:47:03,363] Trial 8 finished with value: 0.33608472564976655 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:49:13,087] Trial 10 finished with value: 0.44191794251739697 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.3720515050901118, 'alpha': 10, 'iterations': 513, 'learning_rate': 0.0008074156508362457, 'p_miss': 0.23708736469486097}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:49:30,431] Trial 2 finished with value: 0.44785875324882907 and parameters: {'model_name': 'GAIN', 'batch_size': 420, 'hint_rate': 0.7645632423185196, 'alpha': 53, 'iterations': 455, 'learning_rate': 0.00028275690726875725, 'p_miss': 0.0908401930542498}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 14:56:26,536] Trial 0 finished with value: 0.4724285968496802 and parameters: {'model_name': 'GAIN', 'batch_size': 27, 'hint_rate': 0.1125107270822778, 'alpha': 95, 'iterations': 859, 'learning_rate': 0.0017980797172024142, 'p_miss': 0.17641669121571482}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 15:08:31,317] Trial 6 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.0659390937291544, 'alpha': 17, 'iterations': 1389, 'learning_rate': 0.05670870569443857, 'p_miss': 0.23727047405380702}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 16:49:24,066] Trial 42 finished with value: 0.39224758085060624 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2820, 'learning_rate': 0.09009626647217178, 'p_miss': 0.27086315356816415}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 16:49:25,250] Trial 48 finished with value: 0.3284674587517763 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 770, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 16:49:26,714] Trial 49 finished with value: 0.3317835427473189 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1714, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:43,656] Trial 43 finished with value: 0.4351274431846187 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4648, 'learning_rate': 0.08915186909734851, 'p_miss': 0.2967850023870262}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:44,888] Trial 51 finished with value: 0.3283675622384147 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 659, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:46,584] Trial 52 finished with value: 0.3440403358652381 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1172, 'weights': 'distance'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:47,877] Trial 53 finished with value: 0.3247904470638516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 359, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:49,123] Trial 54 finished with value: 0.32524859887100044 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 412, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:50,375] Trial 55 finished with value: 0.32500990925710715 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 379, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:52,043] Trial 56 finished with value: 0.3247205895451733 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 368, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:53,294] Trial 57 finished with value: 0.3248061258945306 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 374, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:54,411] Trial 58 finished with value: 0.3245989366525189 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 322, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:56,130] Trial 59 finished with value: 0.329154518838047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 963, 'weights': 'uniform'}. Best is trial 27 with value: 0.3241834256360176.
running
[I 2024-10-24 17:43:57,326] Trial 60 finished with value: 0.32412964864893373 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 212, 'weights': 'uniform'}. Best is trial 60 with value: 0.32412964864893373.
running
[I 2024-10-24 17:43:58,425] Trial 61 finished with value: 0.3239657304967221 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 175, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:43:58,769] Trial 62 finished with value: 0.33427574650758707 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:43:59,951] Trial 63 finished with value: 0.3256243889653611 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 144, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:01,122] Trial 64 finished with value: 0.32834834190239065 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 653, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:38,248] Trial 65 finished with value: 0.3606946276037215 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 12, 'learning_rate': 0.01633129964178724, 'p_miss': 0.16906922313228315}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:39,268] Trial 66 finished with value: 0.32454850598894014 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 190, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:40,227] Trial 67 finished with value: 0.3239972226966406 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 176, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:41,425] Trial 68 finished with value: 0.3255402109748911 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 159, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:42,727] Trial 69 finished with value: 0.3334728851314238 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2274, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 17:44:43,211] Trial 70 finished with value: 0.4017077614495152 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:38:02,347] Trial 33 finished with value: 0.3736070733229457 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4893, 'learning_rate': 0.0001467067063072871, 'p_miss': 0.013426180309305674}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:47,057] Trial 72 finished with value: 0.44321680143306547 and parameters: {'model_name': 'GAIN', 'batch_size': 180, 'hint_rate': 0.4552196423401849, 'alpha': 35, 'iterations': 79, 'learning_rate': 0.0042971450305236665, 'p_miss': 0.14887801735143902}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:48,858] Trial 73 finished with value: 0.34403726204201346 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 585, 'weights': 'distance'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:49,817] Trial 74 finished with value: 0.3242862829319858 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 206, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:51,065] Trial 75 finished with value: 0.3256392005551865 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 137, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:52,309] Trial 76 finished with value: 0.3244630237786156 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 199, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:53,456] Trial 77 finished with value: 0.3241742683845326 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 180, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:54,735] Trial 78 finished with value: 0.32671149945611183 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 532, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:39:55,749] Trial 79 finished with value: 0.32415163162028804 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 211, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:04,841] Trial 80 finished with value: 0.33360068019968514 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:26,137] Trial 81 finished with value: 0.4727140531074607 and parameters: {'model_name': 'GAIN', 'batch_size': 852, 'hint_rate': 0.26904662159262027, 'alpha': 0, 'iterations': 13, 'learning_rate': 0.0012389213055455594, 'p_miss': 0.20533832550477013}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:27,331] Trial 82 finished with value: 0.33427574650758707 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3085, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:27,694] Trial 83 finished with value: 0.33427574650758707 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:29,439] Trial 84 finished with value: 0.3288470421909285 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 885, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:30,715] Trial 85 finished with value: 0.3376953477800095 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 36, 'weights': 'uniform'}. Best is trial 61 with value: 0.3239657304967221.
running
[I 2024-10-24 18:40:32,220] Trial 86 finished with value: 0.3238081225705729 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 227, 'weights': 'uniform'}. Best is trial 86 with value: 0.3238081225705729.
running
[I 2024-10-24 18:40:33,432] Trial 87 finished with value: 0.3241311143564749 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 220, 'weights': 'uniform'}. Best is trial 86 with value: 0.3238081225705729.
running
[I 2024-10-24 18:40:34,842] Trial 88 finished with value: 0.3263011350023938 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 500, 'weights': 'uniform'}. Best is trial 86 with value: 0.3238081225705729.
running
[I 2024-10-24 18:40:36,014] Trial 89 finished with value: 0.3233312267313041 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 253, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:40:37,010] Trial 90 finished with value: 0.3244498767590149 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 191, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:40:38,301] Trial 91 finished with value: 0.3512284589093385 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25, 'weights': 'distance'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:40:44,054] Trial 92 finished with value: 0.33289756680215443 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:40:45,160] Trial 93 finished with value: 0.3263278178945545 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 514, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:40:46,212] Trial 94 finished with value: 0.36996192150071794 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:42,085] Trial 95 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.6211705018155346, 'alpha': 70, 'iterations': 205, 'learning_rate': 0.0275887725519974, 'p_miss': 0.06185092025522812}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:43,274] Trial 96 finished with value: 0.3233897761218858 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 259, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:44,538] Trial 97 finished with value: 0.3237320400195133 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 271, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:46,487] Trial 98 finished with value: 0.32369024514896105 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 276, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:47,945] Trial 99 finished with value: 0.3286507175128099 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 739, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:41:49,620] Trial 100 finished with value: 0.32436401161526857 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 311, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:43:57,757] Trial 101 finished with value: 0.4408734927754968 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 33, 'learning_rate': 0.00036808805492796694, 'p_miss': 0.29696577535978896}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:43:58,976] Trial 102 finished with value: 0.3263072651570676 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 472, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:00,866] Trial 103 finished with value: 0.3322663501190936 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1885, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:01,972] Trial 104 finished with value: 0.3440612355835869 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 321, 'weights': 'distance'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:02,484] Trial 105 finished with value: 0.4017077614495152 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:03,594] Trial 106 finished with value: 0.323378460830492 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 258, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:05,006] Trial 107 finished with value: 0.3240366957405467 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 287, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:06,295] Trial 108 finished with value: 0.32583523607013276 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 439, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:07,451] Trial 109 finished with value: 0.3240484260499684 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 288, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:08,690] Trial 110 finished with value: 0.32827670540635456 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 87, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:09,816] Trial 111 finished with value: 0.3244401646765784 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 316, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:10,774] Trial 112 finished with value: 0.3278448265052184 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 617, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:12,314] Trial 113 finished with value: 0.3251685530890159 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 415, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:31,415] Trial 114 finished with value: 0.44103234921375856 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:46,392] Trial 115 finished with value: 0.4419772181438059 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.003154954464417699, 'p_miss': 0.19555179668587253}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:47,476] Trial 116 finished with value: 0.32371201875847555 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 267, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:48,744] Trial 117 finished with value: 0.3240977487173903 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 300, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:50,105] Trial 118 finished with value: 0.3240272220003546 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 290, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:50,941] Trial 119 finished with value: 0.3274194535986677 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 93, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:52,179] Trial 120 finished with value: 0.32538544718030293 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 404, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:53,287] Trial 121 finished with value: 0.32371235412957733 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 265, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:54,640] Trial 122 finished with value: 0.3261988336005114 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 108, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:55,728] Trial 123 finished with value: 0.33427574650758707 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2539, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:44:58,430] Trial 124 finished with value: 0.4625635681530678 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.2629671388986722, 'alpha': 76, 'iterations': 1, 'learning_rate': 0.01549081040865744, 'p_miss': 0.14013068744902624}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:00,356] Trial 125 finished with value: 0.34403337930163874 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1072, 'weights': 'distance'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:01,813] Trial 126 finished with value: 0.3302741697377651 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1402, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:03,160] Trial 127 finished with value: 0.3236501085512745 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 275, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:04,381] Trial 128 finished with value: 0.3237126649041343 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 279, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:05,694] Trial 129 finished with value: 0.3255488635074501 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 426, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:06,818] Trial 130 finished with value: 0.326213576799377 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 106, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:08,291] Trial 131 finished with value: 0.3269453063688693 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 561, 'weights': 'uniform'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:08,667] Trial 132 finished with value: 0.4399339610322043 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 89 with value: 0.3233312267313041.
running
[I 2024-10-24 18:45:09,821] Trial 133 finished with value: 0.3232435421584698 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 239, 'weights': 'uniform'}. Best is trial 133 with value: 0.3232435421584698.
running
[I 2024-10-24 18:45:10,939] Trial 134 finished with value: 0.3233312267313041 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 253, 'weights': 'uniform'}. Best is trial 133 with value: 0.3232435421584698.
running
[I 2024-10-24 18:45:12,123] Trial 135 finished with value: 0.32884084950527165 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 722, 'weights': 'uniform'}. Best is trial 133 with value: 0.3232435421584698.
running
[I 2024-10-24 18:45:13,202] Trial 136 finished with value: 0.3231320406374748 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 245, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:14,283] Trial 137 finished with value: 0.323347679913374 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 255, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:15,451] Trial 138 finished with value: 0.3247488091065046 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 367, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:16,983] Trial 139 finished with value: 0.3233897761218858 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 259, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:18,009] Trial 140 finished with value: 0.3262481771744893 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 478, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:19,067] Trial 141 finished with value: 0.324963255523867 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 378, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:19,992] Trial 142 finished with value: 0.3263525880230532 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 122, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:28,572] Trial 143 finished with value: 0.32892260050013133 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:29,715] Trial 144 finished with value: 0.3237065701662182 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 270, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:31,064] Trial 145 finished with value: 0.3241202575191453 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 213, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:32,157] Trial 146 finished with value: 0.3232419291348726 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 250, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:33,558] Trial 147 finished with value: 0.3242181927751998 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 224, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:34,739] Trial 148 finished with value: 0.32838311931503905 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 84, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:45:36,062] Trial 149 finished with value: 0.3247389338546594 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 373, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:47:47,608] Trial 150 finished with value: 0.37760844501521484 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 50, 'learning_rate': 0.002669956915105575, 'p_miss': 0.26086176826664464}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:47:49,158] Trial 151 finished with value: 0.3232300548432019 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 251, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 18:47:50,522] Trial 152 finished with value: 0.3443155964361777 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 144, 'weights': 'distance'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:36,796] Trial 47 finished with value: 0.4149895667606077 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5333, 'learning_rate': 0.009508891855460269, 'p_miss': 0.2997421005176846}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:37,827] Trial 154 finished with value: 0.32632295694519076 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 513, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:48,536] Trial 155 finished with value: 0.46188705704543426 and parameters: {'model_name': 'GAIN', 'batch_size': 960, 'hint_rate': 0.5661814807147386, 'alpha': 25, 'iterations': 6, 'learning_rate': 0.00023652346049248603, 'p_miss': 0.07858654005582247}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:49,708] Trial 156 finished with value: 0.32386176706498854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 284, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:51,114] Trial 157 finished with value: 0.39754574929213726 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:52,230] Trial 158 finished with value: 0.3236694537769115 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 263, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:53,795] Trial 159 finished with value: 0.3247168984310831 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 353, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:54,772] Trial 160 finished with value: 0.3241385516008012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 178, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:55,896] Trial 161 finished with value: 0.3259596047153752 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 455, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:56,919] Trial 162 finished with value: 0.32336660198343264 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 235, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:57,761] Trial 163 finished with value: 0.3282508675090189 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 80, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:58,280] Trial 164 finished with value: 0.4017077614495152 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:22:59,286] Trial 165 finished with value: 0.32602089659919053 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 154, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:00,396] Trial 166 finished with value: 0.32347748031962215 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 233, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:01,515] Trial 167 finished with value: 0.3232435421584698 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 239, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:02,449] Trial 168 finished with value: 0.3247904470638516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 359, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:03,643] Trial 169 finished with value: 0.32347748031962215 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 233, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:04,640] Trial 170 finished with value: 0.32417920583515947 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 219, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:05,502] Trial 171 finished with value: 0.330612636938875 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 61, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:06,510] Trial 172 finished with value: 0.32508457378271727 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 162, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:07,647] Trial 173 finished with value: 0.32469750775148365 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 338, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:08,567] Trial 174 finished with value: 0.32538593875136124 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 423, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:23,636] Trial 175 finished with value: 0.32699818372600875 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:24,686] Trial 176 finished with value: 0.32369621447583147 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 228, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:25,821] Trial 177 finished with value: 0.3232272707097917 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 240, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:27,009] Trial 178 finished with value: 0.32537155501161086 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 160, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:28,122] Trial 179 finished with value: 0.3233169856083664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 252, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:29,674] Trial 180 finished with value: 0.3327635025515779 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1993, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:31,006] Trial 181 finished with value: 0.3439890008339387 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 350, 'weights': 'distance'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:32,078] Trial 182 finished with value: 0.32447650617813667 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 203, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:33,309] Trial 183 finished with value: 0.330586062235262 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 58, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:34,663] Trial 184 finished with value: 0.3253699839506463 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 406, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:35,716] Trial 185 finished with value: 0.3257002089169255 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 139, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:36,514] Trial 186 finished with value: 0.3244093831439116 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 315, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:37,507] Trial 187 finished with value: 0.32325335851740716 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 247, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:38,397] Trial 188 finished with value: 0.3232131730719134 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 236, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:39,477] Trial 189 finished with value: 0.3241311143564749 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 220, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 19:23:40,422] Trial 190 finished with value: 0.3255908446265015 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 141, 'weights': 'uniform'}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 20:13:23,682] Trial 40 finished with value: 0.4284534694268218 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7291, 'learning_rate': 0.07683939514128552, 'p_miss': 0.2985661347854831}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 20:16:11,190] Trial 44 finished with value: 0.3954966003426326 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5899, 'learning_rate': 0.049510319421380636, 'p_miss': 0.28479347715113557}. Best is trial 136 with value: 0.3231320406374748.
running
[I 2024-10-24 20:16:12,146] Trial 193 finished with value: 0.32309219647191767 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 244, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:16:13,486] Trial 194 finished with value: 0.330643303512341 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1464, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:17:20,558] Trial 195 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.9772419207805745, 'alpha': 42, 'iterations': 254, 'learning_rate': 0.00053234961252502, 'p_miss': 0.017878245996509723}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:17:22,091] Trial 196 finished with value: 0.3234881263860835 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 232, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:17:23,313] Trial 197 finished with value: 0.324706974622677 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 332, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:17:24,475] Trial 198 finished with value: 0.3231320406374748 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 245, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
running
[I 2024-10-24 20:17:25,858] Trial 199 finished with value: 0.32595817047245157 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 442, 'weights': 'uniform'}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:19:28,969] Trial 192 finished with value: 0.45008631931762777 and parameters: {'model_name': 'GAIN', 'batch_size': 49, 'hint_rate': 0.961528126340662, 'alpha': 43, 'iterations': 285, 'learning_rate': 0.00010187901937841958, 'p_miss': 0.11302146959839225}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:23:36,600] Trial 46 finished with value: 0.42003245742712886 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7448, 'learning_rate': 0.08119216977717167, 'p_miss': 0.29755112927929045}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:29:26,836] Trial 35 finished with value: 0.4140829863442822 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6686, 'learning_rate': 0.08017876230407243, 'p_miss': 0.2995850574930335}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:43:15,616] Trial 38 finished with value: 0.4086791043605256 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8871, 'learning_rate': 0.09672369112920577, 'p_miss': 0.2984343509070779}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:43:32,822] Trial 45 finished with value: 0.39675597543894287 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9321, 'learning_rate': 0.030493440157374128, 'p_miss': 0.27787781201410644}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:48:07,531] Trial 71 finished with value: 0.44217940404681483 and parameters: {'model_name': 'GAIN', 'batch_size': 166, 'hint_rate': 0.4274813127955648, 'alpha': 38, 'iterations': 8825, 'learning_rate': 0.003722331480605524, 'p_miss': 0.01753921565710348}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:50:41,239] Trial 34 finished with value: 0.4041844339948102 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8097, 'learning_rate': 0.00011043416492991782, 'p_miss': 0.29924795426534007}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 20:56:11,506] Trial 32 finished with value: 0.3772851149632414 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8464, 'learning_rate': 0.07125727597883254, 'p_miss': 0.010990786639860417}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:00:33,193] Trial 39 finished with value: 0.4037392344523257 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8807, 'learning_rate': 0.0001063756280966409, 'p_miss': 0.27495562077723434}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:01:19,282] Trial 153 finished with value: 0.48081622960239423 and parameters: {'model_name': 'GAIN', 'batch_size': 41, 'hint_rate': 0.5697465396413491, 'alpha': 42, 'iterations': 7800, 'learning_rate': 0.0003644110329262671, 'p_miss': 0.0913288120614467}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:02:12,504] Trial 25 finished with value: 0.382496552008334 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9169, 'learning_rate': 0.053233359203844456, 'p_miss': 0.011065777927202425}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:02:32,326] Trial 41 finished with value: 0.44549694725391226 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9917, 'learning_rate': 0.06065411502896218, 'p_miss': 0.2678663049778819}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:02:54,162] Trial 14 finished with value: 0.3767340293388055 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9093, 'learning_rate': 0.04376729284997918, 'p_miss': 0.03298531598286948}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:03:49,888] Trial 191 finished with value: 0.4676265487451164 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.9738163449314463, 'alpha': 42, 'iterations': 9469, 'learning_rate': 0.0006156426421038682, 'p_miss': 0.10957587987238901}. Best is trial 193 with value: 0.32309219647191767.
[I 2024-10-24 21:04:35,170] Trial 50 finished with value: 0.424291258123206 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9926, 'learning_rate': 0.00997922265589836, 'p_miss': 0.2974987299801368}. Best is trial 193 with value: 0.32309219647191767.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
dtype: int64
0.32309219647191767
{'model_name': 'KNNImputer', 'n_neighbors': 244, 'weights': 'uniform'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9625908483790739
Generation:   4%|         | 1/25 [00:03<01:25,  3.58s/it]Generation:  2
Best f1_score score: 0.9625908483790739
Generation:   8%|         | 2/25 [00:10<02:04,  5.42s/it]Generation:  3
Best f1_score score: 0.9625908483790739
Generation:  12%|        | 3/25 [00:17<02:14,  6.12s/it]Generation:  4
Best f1_score score: 0.9625908483790739
Generation:  16%|        | 4/25 [00:36<04:01, 11.48s/it]Generation:  5
Best f1_score score: 0.9625908483790739
Generation:  20%|        | 5/25 [01:01<05:21, 16.08s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ffa00> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  6
Best f1_score score: 0.9625908483790739
Generation:  24%|       | 6/25 [01:08<04:10, 13.17s/it]Generation:  7
Best f1_score score: 0.9625908483790739
Generation:  28%|       | 7/25 [01:18<03:35, 11.99s/it]Generation:  8
Best f1_score score: 0.9625908483790739
Generation:  32%|      | 8/25 [01:27<03:09, 11.15s/it]Generation:  9
Best f1_score score: 0.9625908483790739
Generation:  36%|      | 9/25 [01:35<02:44, 10.27s/it]Generation:  10
Best f1_score score: 0.9625908483790739
Generation:  40%|      | 10/25 [01:43<02:19,  9.31s/it]Generation:  11
Best f1_score score: 0.9625908483790739
Generation:  44%|     | 11/25 [01:54<02:20, 10.00s/it]Generation:  12
Best f1_score score: 0.9625908483790739
Generation:  48%|     | 12/25 [02:06<02:16, 10.51s/it]Generation:  13
Best f1_score score: 0.9625908483790739
Generation:  52%|    | 13/25 [02:18<02:11, 10.99s/it]Generation:  14
Best f1_score score: 0.9625908483790739
Generation:  56%|    | 14/25 [02:27<01:55, 10.46s/it]Generation:  15
Best f1_score score: 0.9625908483790739
Generation:  60%|    | 15/25 [02:38<01:45, 10.59s/it]Generation:  16
Best f1_score score: 0.9625908483790739
Generation:  64%|   | 16/25 [02:50<01:38, 10.98s/it]Generation:  17
Best f1_score score: 0.9625908483790739
Generation:  68%|   | 17/25 [03:02<01:30, 11.26s/it]Generation:  18
Best f1_score score: 0.9625908483790739
Generation:  72%|  | 18/25 [03:14<01:20, 11.47s/it]Generation:  19
Best f1_score score: 0.9625908483790739
Generation:  76%|  | 19/25 [03:28<01:13, 12.26s/it]Generation:  20
Best f1_score score: 0.9625908483790739
Generation:  80%|  | 20/25 [03:40<01:01, 12.35s/it]Generation:  21
Best f1_score score: 0.9630731847737991
Generation:  84%| | 21/25 [03:55<00:52, 13.12s/it]Generation:  22
Best f1_score score: 0.9630731847737991
Generation:  88%| | 22/25 [04:10<00:40, 13.51s/it]Generation:  23
Best f1_score score: 0.9630731847737991
Generation:  92%|| 23/25 [04:25<00:28, 14.05s/it]Generation:  24
Best f1_score score: 0.9630731847737991
Generation:  96%|| 24/25 [05:55<00:36, 36.87s/it]Generation:  25
Best f1_score score: 0.9630731847737991
Generation: 100%|| 25/25 [06:12<00:00, 30.90s/it]Generation: 100%|| 25/25 [06:16<00:00, 15.04s/it]
2024-10-24 21:11:03,073 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:33183' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-98384d096df9b91ea418777d7047bef4', 'ndarray-5e2f73c39db49b5ed02253049114adae'} (stimulus_id='handle-worker-cleanup-1729829463.073468')
Fitted
Pipeline(steps=[('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=True,
                                                l2_regularization=0.0061656266542,
                                                learning_rate=0.1558403307367,
                                                max_features=0.2186451738784,
                                                max_leaf_nodes=1860,
                                                min_samples_leaf=121,
                                                n_iter_no_change=1, tol=0.0001,
                                                validation_fraction=None))])
score start
train score: {'auroc': 0.9970198921091779, 'accuracy': 0.97655044739278, 'balanced_accuracy': 0.9528562653562653, 'logloss': 0.058583940003677316, 'f1': 0.9668219097485256}
original test score: {'auroc': 0.9984878611171448, 'accuracy': 0.9938347718865598, 'balanced_accuracy': 0.9888803488780096, 'logloss': 0.02530808588871699, 'f1': 0.9914854749131224}
imputed test score: {'auroc': 0.9862737890357398, 'accuracy': 0.9704069050554871, 'balanced_accuracy': 0.9399112767130612, 'logloss': 0.09355780221078405, 'f1': 0.9576589746267099}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350185b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd5450> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4af0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.9625908483790739
Generation:   4%|         | 1/25 [05:44<2:17:42, 344.27s/it]Generation:  2
Best f1_score score: 0.9625908483790739
Generation:   8%|         | 2/25 [07:57<1:24:20, 220.04s/it]Generation:  3
Best f1_score score: 0.9625908483790739
Generation:  12%|        | 3/25 [09:03<54:53, 149.70s/it]  Generation:  4
Best f1_score score: 0.9625908483790739
Generation:  16%|        | 4/25 [13:44<1:10:33, 201.60s/it]Generation:  5
Best f1_score score: 0.9625908483790739
Generation:  20%|        | 5/25 [14:54<51:19, 153.99s/it]  Generation:  6
Best f1_score score: 0.9625908483790739
Generation:  24%|       | 6/25 [16:06<39:55, 126.09s/it]Generation:  7
Best f1_score score: 0.9626228234430206
Generation:  28%|       | 7/25 [17:13<32:05, 106.97s/it]Generation:  8
Best f1_score score: 0.9626228234430206
Generation:  32%|      | 8/25 [19:40<33:53, 119.65s/it]Generation:  9
Best f1_score score: 0.9626228234430206
Generation:  36%|      | 9/25 [21:18<30:06, 112.92s/it]Generation:  10
Best f1_score score: 0.963105927307011
Generation:  40%|      | 10/25 [21:27<20:12, 80.81s/it]Generation:  11
Best f1_score score: 0.963105927307011
Generation:  44%|     | 11/25 [22:34<17:51, 76.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474598970> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d26a40> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  12
Best f1_score score: 0.963105927307011
Generation:  48%|     | 12/25 [23:41<15:57, 73.66s/it]Generation:  13
Best f1_score score: 0.963105927307011
Generation:  52%|    | 13/25 [24:03<11:34, 57.91s/it]Generation:  14
Best f1_score score: 0.963105927307011
Generation:  56%|    | 14/25 [25:09<11:04, 60.41s/it]Generation:  15
Best f1_score score: 0.963105927307011
Generation:  60%|    | 15/25 [25:18<07:29, 44.96s/it]Generation:  16
Best f1_score score: 0.963105927307011
Generation:  64%|   | 16/25 [26:24<07:42, 51.34s/it]Generation:  17
Best f1_score score: 0.9639576593332387
Generation:  68%|   | 17/25 [30:41<15:04, 113.08s/it]Generation:  18
Best f1_score score: 0.9639576593332387
Generation:  72%|  | 18/25 [33:05<14:16, 122.39s/it]Generation:  19
Best f1_score score: 0.9639692365766008
Generation:  76%|  | 19/25 [35:33<13:00, 130.08s/it]Generation:  20
Best f1_score score: 0.9639692365766008
Generation:  80%|  | 20/25 [36:42<09:18, 111.74s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474585b40> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  21
Best f1_score score: 0.9639692365766008
Generation:  84%| | 21/25 [37:49<06:33, 98.36s/it] Generation:  22
Best f1_score score: 0.9639692365766008
Generation:  88%| | 22/25 [38:57<04:28, 89.41s/it]Generation:  23
Best f1_score score: 0.9639692365766008
Generation:  92%|| 23/25 [41:10<03:24, 102.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fb9f310> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  24
Best f1_score score: 0.9639692365766008
Generation:  96%|| 24/25 [43:21<01:50, 110.93s/it]Generation:  25
Best f1_score score: 0.9639692365766008
Generation: 100%|| 25/25 [44:30<00:00, 98.38s/it] Generation: 100%|| 25/25 [44:30<00:00, 106.83s/it]
2024-10-24 21:55:56,242 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45795' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-98384d096df9b91ea418777d7047bef4', 'DataFrame-a9ff967471a81f5b2a8a35939dac7a1c'} (stimulus_id='handle-worker-cleanup-1729832156.2426043')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=RandomForestRegressor(),
                                  imputation_order='roman',
                                  n_nearest_features=84)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(max_features=0.7173915161065,
                                      min_samples_leaf=8, min_samples_split=13,
                                      n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9933910603553461, 'accuracy': 0.9734649799444616, 'balanced_accuracy': 0.9455401017901017, 'logloss': 0.086786724274828, 'f1': 0.9622052091469235}
test score: {'auroc': 0.9873556784574512, 'accuracy': 0.9704069050554871, 'balanced_accuracy': 0.9434451703453692, 'logloss': 0.10764780681202143, 'f1': 0.9579829030308263}
original test score: {'auroc': 0.9987384918712092, 'accuracy': 0.9950678175092479, 'balanced_accuracy': 0.9896907216494846, 'logloss': 0.04131173208043268, 'f1': 0.9931761577813678}
score end
728
lvl
0.1
type
MNAR
num_run
2
class_full
finished
all finished
full run takes
7.344355946116977
hours
DONE
