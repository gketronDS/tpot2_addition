Run: 49
/cm/local/apps/slurm/var/spool/job1069106/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MCAR_0.01_3
1.4591302871704102
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 13:40:40,515] A new study created in memory with name: no-name-d526cd7c-ed24-4127-81fb-0a80bb1de20e
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 13:40:41,112] Trial 2 finished with value: 0.36506998161954807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.36506998161954807.
running
[I 2024-11-22 13:40:41,496] Trial 8 finished with value: 0.3586012268397175 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:41,919] Trial 12 finished with value: 0.595650754697777 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:42,112] Trial 17 finished with value: 0.638075894142798 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:42,572] Trial 18 finished with value: 0.595650754697777 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:42,885] Trial 19 finished with value: 0.36506998161954807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:43,037] Trial 20 finished with value: 0.3586012268397175 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 8 with value: 0.3586012268397175.
running
[I 2024-11-22 13:40:50,013] Trial 7 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:40:52,605] Trial 6 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9154916349657382, 'alpha': 30, 'iterations': 5, 'learning_rate': 0.0026962498533527387, 'p_miss': 0.057164931579225094}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:40:54,887] Trial 15 finished with value: 0.369609100104587 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 1, 'learning_rate': 0.00015647178198736021, 'p_miss': 0.18020634718425504}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:40:55,643] Trial 0 finished with value: 0.6377757990174264 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.9201755580723342, 'alpha': 7, 'iterations': 1, 'learning_rate': 0.000106301310549102, 'p_miss': 0.08304540014342057}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:04,304] Trial 21 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9233030162294213, 'alpha': 49, 'iterations': 80, 'learning_rate': 0.035584531977758745, 'p_miss': 0.07273382518992455}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:05,866] Trial 4 finished with value: 0.36921705356494033 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8, 'learning_rate': 0.00610423916871254, 'p_miss': 0.26397961555320915}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:12,656] Trial 16 finished with value: 0.36199787567253333 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 3, 'learning_rate': 0.012540645336738347, 'p_miss': 0.014148770239026418}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:15,599] Trial 3 finished with value: 0.3586012268397175 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28144, 'weights': 'uniform'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:18,325] Trial 22 finished with value: 0.3586012268397175 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 35664, 'weights': 'uniform'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:20,481] Trial 25 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:21,291] Trial 26 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:21,845] Trial 5 finished with value: 0.35861087689254123 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24121, 'weights': 'uniform'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:26,490] Trial 27 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:27,643] Trial 28 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:32,624] Trial 29 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:34,407] Trial 30 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:37,660] Trial 31 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:38,048] Trial 23 finished with value: 0.4063382705503293 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28527, 'weights': 'distance'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:39,109] Trial 32 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:40,161] Trial 33 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:40,420] Trial 10 finished with value: 0.4042374029635292 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:41,348] Trial 34 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:43,933] Trial 24 finished with value: 0.40633869715741583 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22493, 'weights': 'distance'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:48,127] Trial 36 finished with value: 0.3585630774483296 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:53,471] Trial 1 finished with value: 0.5095704460214507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:55,394] Trial 13 finished with value: 0.39156730709586657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 7 with value: 0.3585630774483296.
running
[I 2024-11-22 13:41:56,341] Trial 37 finished with value: 0.35856305879603495 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 37 with value: 0.35856305879603495.
running
[I 2024-11-22 13:42:05,378] Trial 38 finished with value: 0.35854881757483414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 38 with value: 0.35854881757483414.
running
[I 2024-11-22 13:42:07,849] Trial 39 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 38 with value: 0.35854881757483414.
running
[I 2024-11-22 13:42:08,247] Trial 42 finished with value: 0.35855430993102033 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 38 with value: 0.35854881757483414.
running
[I 2024-11-22 13:42:27,830] Trial 47 finished with value: 0.3585544012352846 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 38 with value: 0.35854881757483414.
running
[I 2024-11-22 13:42:28,468] Trial 48 finished with value: 0.3585544012352846 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 38 with value: 0.35854881757483414.
running
[I 2024-11-22 13:42:37,138] Trial 50 finished with value: 0.3585363906111188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 13:54:38,850] Trial 11 finished with value: 0.36054959894772937 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 13:55:18,532] Trial 35 finished with value: 0.3588886890634272 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 13:58:29,987] Trial 43 finished with value: 0.3625129201807841 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:05:04,660] Trial 40 finished with value: 0.3628983215615579 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:09:38,860] Trial 9 finished with value: 0.3685060302028384 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 497, 'learning_rate': 0.0010711251601471304, 'p_miss': 0.1656350319361976}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:10:56,752] Trial 44 finished with value: 0.37794610415259455 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:11:02,491] Trial 45 finished with value: 0.37677914222930187 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:11:19,213] Trial 41 finished with value: 0.3765818911216206 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:12:04,711] Trial 46 finished with value: 0.37569612450148143 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:12:17,541] Trial 49 finished with value: 0.3770149680598735 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:38:20,300] Trial 55 finished with value: 0.6440669592662764 and parameters: {'model_name': 'GAIN', 'batch_size': 765, 'hint_rate': 0.01684088111569948, 'alpha': 97, 'iterations': 2237, 'learning_rate': 0.08928217614295561, 'p_miss': 0.2969408958726396}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 14:46:15,855] Trial 14 finished with value: 0.36012970288955837 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 1503, 'learning_rate': 0.00015782466065489425, 'p_miss': 0.25276819197054445}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:36:31,395] Trial 51 finished with value: 0.6353935642656133 and parameters: {'model_name': 'GAIN', 'batch_size': 849, 'hint_rate': 0.04012830679178042, 'alpha': 91, 'iterations': 4595, 'learning_rate': 0.000966691140973771, 'p_miss': 0.2971762818840422}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:37:38,663] Trial 63 finished with value: 0.6424133357444234 and parameters: {'model_name': 'GAIN', 'batch_size': 723, 'hint_rate': 0.017033395774101956, 'alpha': 100, 'iterations': 3460, 'learning_rate': 0.09868851595991296, 'p_miss': 0.2779430965593102}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:38:06,979] Trial 52 finished with value: 0.6452003387510293 and parameters: {'model_name': 'GAIN', 'batch_size': 992, 'hint_rate': 0.033179916479643745, 'alpha': 95, 'iterations': 4576, 'learning_rate': 0.0010354871105861174, 'p_miss': 0.2647983945398964}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:38:23,727] Trial 68 finished with value: 0.3653628879297305 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 36, 'learning_rate': 0.0005914916638328576, 'p_miss': 0.12451279279445605}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:38:37,921] Trial 71 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:38:52,799] Trial 57 finished with value: 0.6515346954067497 and parameters: {'model_name': 'GAIN', 'batch_size': 928, 'hint_rate': 0.029896118626229096, 'alpha': 99, 'iterations': 4134, 'learning_rate': 0.0011008944786664765, 'p_miss': 0.2803932818454818}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:38:54,019] Trial 72 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:05,843] Trial 70 finished with value: 0.3632148746482165 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 49, 'learning_rate': 0.019723281339431405, 'p_miss': 0.20899179717986813}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:10,039] Trial 73 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:13,037] Trial 74 finished with value: 0.40629282856061205 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 417, 'weights': 'distance'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:15,096] Trial 69 finished with value: 0.36489242576946157 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 74, 'learning_rate': 0.0005240804748102839, 'p_miss': 0.2150772309764668}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:27,861] Trial 76 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:30,369] Trial 77 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:31,737] Trial 75 finished with value: 0.4063217581835433 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2798, 'weights': 'distance'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:32,832] Trial 78 finished with value: 0.3585565511969757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:43,740] Trial 79 finished with value: 0.35856326479357253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:46,915] Trial 81 finished with value: 0.35856326479357253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:47,515] Trial 80 finished with value: 0.35856326479357253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:47,789] Trial 84 finished with value: 0.638075894142798 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:48,074] Trial 85 finished with value: 0.638075894142798 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:39:49,538] Trial 82 finished with value: 0.35856326479357253 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:02,044] Trial 83 finished with value: 0.3585927351003894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:05,246] Trial 86 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:06,356] Trial 87 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:07,461] Trial 88 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:13,406] Trial 91 finished with value: 0.3585571933105489 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:20,142] Trial 89 finished with value: 0.35854881757483414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:22,732] Trial 90 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:55,580] Trial 93 finished with value: 0.3941703671645307 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:56,416] Trial 92 finished with value: 0.40543012790822414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:40:59,437] Trial 94 finished with value: 0.3900969681216341 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:02,751] Trial 95 finished with value: 0.3900969681216341 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:14,114] Trial 97 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:14,883] Trial 96 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:17,367] Trial 98 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:20,782] Trial 99 finished with value: 0.35854881757483414 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:31,411] Trial 100 finished with value: 0.35853987360485623 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:34,420] Trial 101 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:36,039] Trial 102 finished with value: 0.35855100080022234 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:39,158] Trial 103 finished with value: 0.3585363906111188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:53,446] Trial 106 finished with value: 0.3585363906111188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:41:54,923] Trial 107 finished with value: 0.3585363906111188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:42:01,802] Trial 104 finished with value: 0.35854775172981057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11610, 'weights': 'uniform'}. Best is trial 50 with value: 0.3585363906111188.
running
[I 2024-11-22 15:42:02,776] Trial 105 finished with value: 0.3585199951137849 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10690, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:10,025] Trial 108 finished with value: 0.3585363906111188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:21,119] Trial 109 finished with value: 0.3585440787551288 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11349, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:25,941] Trial 110 finished with value: 0.3585321846086427 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11042, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:27,515] Trial 111 finished with value: 0.35854178960080635 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11545, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:32,392] Trial 112 finished with value: 0.3585456391830349 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11734, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:44,003] Trial 113 finished with value: 0.3585436190677976 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11705, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:48,230] Trial 114 finished with value: 0.3585220008364201 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10720, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:50,608] Trial 115 finished with value: 0.3585428974127736 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12026, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:42:54,665] Trial 116 finished with value: 0.35854053451334 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11261, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:43:06,138] Trial 117 finished with value: 0.35854673186528824 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11595, 'weights': 'uniform'}. Best is trial 105 with value: 0.3585199951137849.
running
[I 2024-11-22 15:43:09,088] Trial 118 finished with value: 0.35846478969179907 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7828, 'weights': 'uniform'}. Best is trial 118 with value: 0.35846478969179907.
running
[I 2024-11-22 15:43:12,107] Trial 119 finished with value: 0.3584580232170313 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7382, 'weights': 'uniform'}. Best is trial 119 with value: 0.3584580232170313.
running
[I 2024-11-22 15:43:15,263] Trial 120 finished with value: 0.3584478665896976 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6612, 'weights': 'uniform'}. Best is trial 120 with value: 0.3584478665896976.
running
[I 2024-11-22 15:43:26,949] Trial 121 finished with value: 0.3584501360447932 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6578, 'weights': 'uniform'}. Best is trial 120 with value: 0.3584478665896976.
running
[I 2024-11-22 15:43:30,007] Trial 122 finished with value: 0.3584450214993047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5996, 'weights': 'uniform'}. Best is trial 122 with value: 0.3584450214993047.
running
[I 2024-11-22 15:43:33,312] Trial 123 finished with value: 0.3584452528234374 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5960, 'weights': 'uniform'}. Best is trial 122 with value: 0.3584450214993047.
running
[I 2024-11-22 15:43:35,497] Trial 124 finished with value: 0.3584473070979776 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6057, 'weights': 'uniform'}. Best is trial 122 with value: 0.3584450214993047.
running
[I 2024-11-22 15:43:47,737] Trial 125 finished with value: 0.35843988843054725 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5336, 'weights': 'uniform'}. Best is trial 125 with value: 0.35843988843054725.
running
[I 2024-11-22 15:43:50,191] Trial 126 finished with value: 0.35844306544316995 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5905, 'weights': 'uniform'}. Best is trial 125 with value: 0.35843988843054725.
running
[I 2024-11-22 15:43:54,640] Trial 127 finished with value: 0.3584572834511655 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6472, 'weights': 'uniform'}. Best is trial 125 with value: 0.35843988843054725.
running
[I 2024-11-22 15:43:56,692] Trial 128 finished with value: 0.35844155703730624 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6157, 'weights': 'uniform'}. Best is trial 125 with value: 0.35843988843054725.
running
[I 2024-11-22 15:44:08,354] Trial 129 finished with value: 0.35844571110299583 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5944, 'weights': 'uniform'}. Best is trial 125 with value: 0.35843988843054725.
running
[I 2024-11-22 15:44:10,662] Trial 130 finished with value: 0.35843719193587725 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5731, 'weights': 'uniform'}. Best is trial 130 with value: 0.35843719193587725.
running
[I 2024-11-22 15:44:15,185] Trial 131 finished with value: 0.3584353751063615 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5721, 'weights': 'uniform'}. Best is trial 131 with value: 0.3584353751063615.
running
[I 2024-11-22 15:44:17,018] Trial 132 finished with value: 0.35844095067396464 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5779, 'weights': 'uniform'}. Best is trial 131 with value: 0.3584353751063615.
running
[I 2024-11-22 15:44:28,671] Trial 133 finished with value: 0.35843581756267706 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5456, 'weights': 'uniform'}. Best is trial 131 with value: 0.3584353751063615.
running
[I 2024-11-22 15:44:30,633] Trial 134 finished with value: 0.3584344666266688 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5744, 'weights': 'uniform'}. Best is trial 134 with value: 0.3584344666266688.
running
[I 2024-11-22 15:44:35,383] Trial 135 finished with value: 0.3584413392779532 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5678, 'weights': 'uniform'}. Best is trial 134 with value: 0.3584344666266688.
running
[I 2024-11-22 15:44:37,223] Trial 136 finished with value: 0.35844002841897915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5571, 'weights': 'uniform'}. Best is trial 134 with value: 0.3584344666266688.
running
[I 2024-11-22 15:44:49,591] Trial 137 finished with value: 0.35844143603781226 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5207, 'weights': 'uniform'}. Best is trial 134 with value: 0.3584344666266688.
running
[I 2024-11-22 15:44:50,328] Trial 138 finished with value: 0.3584460252661138 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4709, 'weights': 'uniform'}. Best is trial 134 with value: 0.3584344666266688.
running
[I 2024-11-22 15:44:55,129] Trial 139 finished with value: 0.3584340214772873 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4152, 'weights': 'uniform'}. Best is trial 139 with value: 0.3584340214772873.
running
[I 2024-11-22 15:44:57,016] Trial 140 finished with value: 0.35842386135810184 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3637, 'weights': 'uniform'}. Best is trial 140 with value: 0.35842386135810184.
running
[I 2024-11-22 15:45:09,013] Trial 141 finished with value: 0.35841533474163645 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3507, 'weights': 'uniform'}. Best is trial 141 with value: 0.35841533474163645.
running
[I 2024-11-22 15:45:09,900] Trial 142 finished with value: 0.35841395267793663 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3542, 'weights': 'uniform'}. Best is trial 142 with value: 0.35841395267793663.
running
[I 2024-11-22 15:45:15,210] Trial 143 finished with value: 0.35841432562322667 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3506, 'weights': 'uniform'}. Best is trial 142 with value: 0.35841395267793663.
running
[I 2024-11-22 15:45:16,693] Trial 144 finished with value: 0.3583809740881424 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2969, 'weights': 'uniform'}. Best is trial 144 with value: 0.3583809740881424.
running
[I 2024-11-22 15:45:29,420] Trial 145 finished with value: 0.3583910221485013 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3147, 'weights': 'uniform'}. Best is trial 144 with value: 0.3583809740881424.
running
[I 2024-11-22 15:45:29,955] Trial 146 finished with value: 0.3583912732918624 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3132, 'weights': 'uniform'}. Best is trial 144 with value: 0.3583809740881424.
running
[I 2024-11-22 15:45:34,468] Trial 147 finished with value: 0.35836036827179196 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2788, 'weights': 'uniform'}. Best is trial 147 with value: 0.35836036827179196.
running
[I 2024-11-22 15:45:35,078] Trial 148 finished with value: 0.3582904455391693 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2006, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:45:48,578] Trial 149 finished with value: 0.35836338053068595 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2778, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:45:50,212] Trial 150 finished with value: 0.3583661051587813 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2643, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:45:52,849] Trial 151 finished with value: 0.3583276431193802 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2288, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:45:54,157] Trial 152 finished with value: 0.3583257193223333 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2304, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:46:08,229] Trial 153 finished with value: 0.3583241940181229 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2338, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:46:10,401] Trial 154 finished with value: 0.35829454594402177 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2005, 'weights': 'uniform'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:46:14,454] Trial 155 finished with value: 0.4063176315995277 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1819, 'weights': 'distance'}. Best is trial 148 with value: 0.3582904455391693.
running
[I 2024-11-22 15:46:14,743] Trial 156 finished with value: 0.3582782373361407 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1975, 'weights': 'uniform'}. Best is trial 156 with value: 0.3582782373361407.
running
[I 2024-11-22 15:46:29,136] Trial 157 finished with value: 0.40631816061064424 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2012, 'weights': 'distance'}. Best is trial 156 with value: 0.3582782373361407.
running
[I 2024-11-22 15:46:31,560] Trial 158 finished with value: 0.4063102595367754 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1076, 'weights': 'distance'}. Best is trial 156 with value: 0.3582782373361407.
running
[I 2024-11-22 15:46:33,502] Trial 159 finished with value: 0.3582874260977082 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1986, 'weights': 'uniform'}. Best is trial 156 with value: 0.3582782373361407.
running
[I 2024-11-22 15:46:34,315] Trial 160 finished with value: 0.35814344069418536 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1403, 'weights': 'uniform'}. Best is trial 160 with value: 0.35814344069418536.
running
[I 2024-11-22 15:46:45,955] Trial 161 finished with value: 0.35771688441623384 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 139, 'weights': 'uniform'}. Best is trial 161 with value: 0.35771688441623384.
running
[I 2024-11-22 15:46:49,494] Trial 162 finished with value: 0.35753037854712877 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 393, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:46:51,934] Trial 163 finished with value: 0.35834785866483854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2553, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:47:04,695] Trial 166 finished with value: 0.35810928628828254 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 97, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:47:19,860] Trial 168 finished with value: 0.3576429710382759 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 221, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:47:34,768] Trial 169 finished with value: 0.3576742119081874 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 250, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:47:35,751] Trial 170 finished with value: 0.36506998161954807 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:47:50,202] Trial 171 finished with value: 0.35934773835891426 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 67, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:59:29,206] Trial 164 finished with value: 0.3604632093225068 and parameters: {'model_name': 'VAE', 'batch_size': 119, 'iterations': 309, 'learning_rate': 0.0034889749965978114, 'p_miss': 0.12374809197147074}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 15:59:44,514] Trial 173 finished with value: 0.35781295369342 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 779, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:00:00,126] Trial 174 finished with value: 0.3577036166676423 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 679, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:00:15,547] Trial 175 finished with value: 0.3579080628125704 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 926, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:00:30,985] Trial 176 finished with value: 0.3579300041461833 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 943, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:00:46,483] Trial 177 finished with value: 0.3578925420075045 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 875, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:00:59,424] Trial 167 finished with value: 0.3605444365988852 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 337, 'learning_rate': 0.003842251730295855, 'p_miss': 0.12338838401882712}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:02,137] Trial 178 finished with value: 0.35762953884205245 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 489, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:15,015] Trial 179 finished with value: 0.35792977862901626 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 966, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:33,235] Trial 180 finished with value: 0.6386097165718311 and parameters: {'model_name': 'GAIN', 'batch_size': 337, 'hint_rate': 0.43284957611210995, 'alpha': 64, 'iterations': 21, 'learning_rate': 0.04364642486630119, 'p_miss': 0.0110617409370809}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:34,853] Trial 181 finished with value: 0.6380495724485972 and parameters: {'model_name': 'GAIN', 'batch_size': 308, 'hint_rate': 0.444951744655531, 'alpha': 68, 'iterations': 12, 'learning_rate': 0.041417132132799725, 'p_miss': 0.22603157596516235}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:49,464] Trial 182 finished with value: 0.3577684210286149 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 730, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:51,401] Trial 183 finished with value: 0.3577601591616915 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 724, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:01:52,912] Trial 165 finished with value: 0.3601353603074167 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 354, 'learning_rate': 0.0044281669165140486, 'p_miss': 0.11244724379688306}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:07,087] Trial 185 finished with value: 0.35900515693408735 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 77, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:07,407] Trial 184 finished with value: 0.35764406729592024 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 639, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:09,908] Trial 186 finished with value: 0.3578081741160593 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 776, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:24,928] Trial 188 finished with value: 0.3578447606689446 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 836, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:25,112] Trial 187 finished with value: 0.3578542665316102 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 843, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:27,260] Trial 189 finished with value: 0.35786215828589285 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 847, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:42,824] Trial 190 finished with value: 0.3578877684855961 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 870, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:43,052] Trial 191 finished with value: 0.35771611217001337 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 709, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:02:44,795] Trial 192 finished with value: 0.3577684210286149 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 730, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:03:00,395] Trial 193 finished with value: 0.35785973621721506 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 857, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:03:00,641] Trial 194 finished with value: 0.35771611217001337 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 709, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:03:00,837] Trial 195 finished with value: 0.37483206474878494 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 15, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:03:16,570] Trial 196 finished with value: 0.3819226986651998 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
running
[I 2024-11-22 16:03:17,187] Trial 197 finished with value: 0.3669397970813522 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 25, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:03:23,938] Trial 198 finished with value: 0.3586018129634382 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19189, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:03:32,078] Trial 199 finished with value: 0.3579553681264658 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1034, 'weights': 'uniform'}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:11:10,909] Trial 53 finished with value: 0.6315525538118132 and parameters: {'model_name': 'GAIN', 'batch_size': 753, 'hint_rate': 0.06350878734197696, 'alpha': 96, 'iterations': 6421, 'learning_rate': 0.0008327755063310628, 'p_miss': 0.2690518704035339}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:15:54,202] Trial 64 finished with value: 0.6388491354537617 and parameters: {'model_name': 'GAIN', 'batch_size': 773, 'hint_rate': 0.09905603615547631, 'alpha': 93, 'iterations': 5519, 'learning_rate': 0.08396316952087349, 'p_miss': 0.2964857142131918}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:15:56,997] Trial 172 finished with value: 0.3597261122001465 and parameters: {'model_name': 'VAE', 'batch_size': 191, 'iterations': 747, 'learning_rate': 0.005396474096041966, 'p_miss': 0.12726108828388694}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:25:12,790] Trial 66 finished with value: 0.3614763899392771 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 3421, 'learning_rate': 0.0006756982829168752, 'p_miss': 0.21472730983242033}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:35:50,305] Trial 58 finished with value: 0.6366288548388646 and parameters: {'model_name': 'GAIN', 'batch_size': 802, 'hint_rate': 0.011054361241251365, 'alpha': 92, 'iterations': 7398, 'learning_rate': 0.0013034166792792834, 'p_miss': 0.29936078924431336}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:37:05,650] Trial 61 finished with value: 0.6409133859402709 and parameters: {'model_name': 'GAIN', 'batch_size': 807, 'hint_rate': 0.05987658948083158, 'alpha': 92, 'iterations': 6998, 'learning_rate': 0.06185512575558081, 'p_miss': 0.2823585987668494}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:37:38,003] Trial 54 finished with value: 0.6380073338713235 and parameters: {'model_name': 'GAIN', 'batch_size': 792, 'hint_rate': 0.06783752304806617, 'alpha': 97, 'iterations': 8325, 'learning_rate': 0.000700120470404643, 'p_miss': 0.2857134247416646}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:44:24,147] Trial 62 finished with value: 0.6289236221990545 and parameters: {'model_name': 'GAIN', 'batch_size': 943, 'hint_rate': 0.031776882694253106, 'alpha': 100, 'iterations': 8093, 'learning_rate': 0.09313227742214278, 'p_miss': 0.2978894503893943}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:45:13,955] Trial 59 finished with value: 0.6479767339244826 and parameters: {'model_name': 'GAIN', 'batch_size': 998, 'hint_rate': 0.017758080268925447, 'alpha': 97, 'iterations': 8701, 'learning_rate': 0.0008673253037932352, 'p_miss': 0.289684838428967}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:45:25,368] Trial 56 finished with value: 0.632217551899046 and parameters: {'model_name': 'GAIN', 'batch_size': 919, 'hint_rate': 0.0464283232535917, 'alpha': 100, 'iterations': 9284, 'learning_rate': 0.0009284194748349423, 'p_miss': 0.29463257516799995}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:45:47,322] Trial 60 finished with value: 0.6383518728983852 and parameters: {'model_name': 'GAIN', 'batch_size': 810, 'hint_rate': 0.026159451057086724, 'alpha': 94, 'iterations': 9170, 'learning_rate': 0.06112945945955667, 'p_miss': 0.2755474089615974}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:46:04,409] Trial 65 finished with value: 0.6491071476290537 and parameters: {'model_name': 'GAIN', 'batch_size': 797, 'hint_rate': 0.09419164093089555, 'alpha': 95, 'iterations': 9578, 'learning_rate': 0.08721587676377573, 'p_miss': 0.2991531011875008}. Best is trial 162 with value: 0.35753037854712877.
[I 2024-11-22 16:46:31,247] Trial 67 finished with value: 0.6293568548113418 and parameters: {'model_name': 'GAIN', 'batch_size': 802, 'hint_rate': 0.29558187016154813, 'alpha': 98, 'iterations': 9621, 'learning_rate': 0.0007479833103428544, 'p_miss': 0.20599785135441168}. Best is trial 162 with value: 0.35753037854712877.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.35753037854712877
{'model_name': 'KNNImputer', 'n_neighbors': 393, 'weights': 'uniform'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fb190> 

Generation:  1
Best f1_score score: 0.796283564941619
Generation:   4%|         | 1/25 [10:03<4:01:22, 603.45s/it]Generation:  2
Best f1_score score: 0.796283564941619
Generation:   8%|         | 2/25 [17:37<3:17:38, 515.59s/it]Generation:  3
Best f1_score score: 0.7994854460592191
Generation:  12%|        | 3/25 [20:08<2:08:00, 349.09s/it]Generation:  4
Best f1_score score: 0.8059773045998249
Generation:  16%|        | 4/25 [21:30<1:25:19, 243.77s/it]Generation:  5
Best f1_score score: 0.8059773045998249
Generation:  20%|        | 5/25 [22:51<1:01:37, 184.87s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467988190> 

Generation:  6
Best f1_score score: 0.8059773045998249
Generation:  24%|       | 6/25 [32:57<1:43:52, 328.03s/it]Generation:  7
Best f1_score score: 0.8060688230310202
Generation:  28%|       | 7/25 [33:37<1:10:11, 234.00s/it]Generation:  8
Best f1_score score: 0.8078954795844352
Generation:  32%|      | 8/25 [35:29<55:18, 195.23s/it]  Generation:  9
Best f1_score score: 0.8078954795844352
Generation:  36%|      | 9/25 [39:38<56:31, 211.95s/it]Generation:  10
Best f1_score score: 0.8078954795844352
Generation:  40%|      | 10/25 [41:08<43:32, 174.18s/it]Generation:  11
Best f1_score score: 0.8078954795844352
Generation:  44%|     | 11/25 [45:41<47:43, 204.51s/it]Generation:  12
Best f1_score score: 0.8078954795844352
Generation:  48%|     | 12/25 [50:03<48:05, 221.95s/it]Generation:  13
Best f1_score score: 0.8078954795844352
Generation:  52%|    | 13/25 [50:36<32:57, 164.77s/it]Generation:  14
Best f1_score score: 0.808445255476953
Generation:  56%|    | 14/25 [51:05<22:41, 123.76s/it]Generation:  15
Best f1_score score: 0.808445255476953
Generation:  60%|    | 15/25 [51:29<15:35, 93.59s/it] Generation:  16
Best f1_score score: 0.8088495910479871
Generation:  64%|   | 16/25 [53:59<16:36, 110.71s/it]Generation:  17
Best f1_score score: 0.8088495910479871
Generation:  68%|   | 17/25 [54:40<11:57, 89.66s/it] Generation:  18
Best f1_score score: 0.809494324273536
Generation:  72%|  | 18/25 [55:44<09:34, 82.11s/it]Generation:  19
Best f1_score score: 0.809494324273536
Generation:  76%|  | 19/25 [56:26<07:00, 70.02s/it]Generation:  20
Best f1_score score: 0.809494324273536
Generation:  80%|  | 20/25 [1:01:31<11:42, 140.52s/it]Generation:  21
Best f1_score score: 0.809494324273536
Generation:  84%| | 21/25 [1:08:32<14:59, 224.82s/it]Generation:  22
Best f1_score score: 0.809494324273536
Generation:  88%| | 22/25 [1:10:34<09:41, 193.79s/it]Generation:  23
Best f1_score score: 0.8386060884448054
Generation:  92%|| 23/25 [1:17:24<08:37, 258.62s/it]Generation:  24
Best f1_score score: 0.8386060884448054
Generation:  96%|| 24/25 [1:24:19<05:05, 305.74s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f70a0> 

Generation:  25
Best f1_score score: 0.8386060884448054
Generation: 100%|| 25/25 [1:34:31<00:00, 397.53s/it]Generation: 100%|| 25/25 [1:34:35<00:00, 227.02s/it]
2024-11-22 18:22:30,322 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36753' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-46c1eaffdd670f607785a21c6a1afa0d', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732328550.3222291')
Fitted
Pipeline(steps=[('mlpclassifier',
                 MLPClassifier(alpha=0.000247074317, early_stopping=True,
                               hidden_layer_sizes=[81, 81, 81],
                               learning_rate='invscaling',
                               learning_rate_init=0.0100890500433,
                               n_iter_no_change=32))])
score start
train score: {'auroc': 0.992884754463078, 'accuracy': 0.9380002789011296, 'balanced_accuracy': 0.9174505062058692, 'logloss': 0.14375144653159905, 'f1': 0.9236100836084726}
original test score: {'auroc': 0.9910529307125365, 'accuracy': 0.9260374832663989, 'balanced_accuracy': 0.9052606323144904, 'logloss': 0.15944837348270768, 'f1': 0.9106489679402611}
imputed test score: {'auroc': 0.9846055118470961, 'accuracy': 0.9138777331548416, 'balanced_accuracy': 0.8903206246146221, 'logloss': 0.23115676398133486, 'f1': 0.896374191385835}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014580>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.7758160548021187
Generation:   4%|         | 1/25 [04:25<1:46:12, 265.54s/it]Generation:  2
Best f1_score score: 0.7758160548021187
Generation:   8%|         | 2/25 [06:50<1:14:39, 194.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f036d0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474718100> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467973ac0> 

Generation:  3
Best f1_score score: 0.7758160548021187
Generation:  12%|        | 3/25 [16:54<2:19:52, 381.50s/it]Generation:  4
Best f1_score score: 0.7758160548021187
Generation:  16%|        | 4/25 [20:27<1:50:12, 314.86s/it]Generation:  5
Best f1_score score: 0.8196031001242737
Generation:  20%|        | 5/25 [22:56<1:25:05, 255.26s/it]Generation:  6
Best f1_score score: 0.82169897045826
Generation:  24%|       | 6/25 [25:54<1:12:28, 228.88s/it]Generation:  7
Best f1_score score: 0.8239643179356861
Generation:  28%|       | 7/25 [28:25<1:01:00, 203.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e61d50> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454822440> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1990> 

Generation:  8
Best f1_score score: 0.8239643179356861
Generation:  32%|      | 8/25 [38:30<1:33:50, 331.23s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554653e4e50> 

Generation:  9
Best f1_score score: 0.8243179857673251
Generation:  36%|      | 9/25 [48:36<1:51:16, 417.31s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546538a410> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2ec0> 

Generation:  10
Best f1_score score: 0.8243179857673251
Generation:  40%|      | 10/25 [58:43<1:58:56, 475.78s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474734d90> 

Generation:  11
Best f1_score score: 0.8243179857673251
Generation:  44%|     | 11/25 [1:08:49<2:00:17, 515.51s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ee63b0> 

Generation:  12
Best f1_score score: 0.8243179857673251
Generation:  48%|     | 12/25 [1:18:53<1:57:34, 542.63s/it]Generation:  13
Best f1_score score: 0.8266944918373618
Generation:  52%|    | 13/25 [1:27:35<1:47:13, 536.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545463a470> 

Generation:  14
Best f1_score score: 0.8266944918373618
Generation:  56%|    | 14/25 [1:37:41<1:42:11, 557.45s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554528fe200> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ad3eaa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467590130> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a33d0> 

Generation:  15
Best f1_score score: 0.8266944918373618
Generation:  60%|    | 15/25 [1:47:47<1:35:21, 572.10s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471aad0> 

Generation:  16
Best f1_score score: 0.8266944918373618
Generation:  64%|   | 16/25 [1:57:53<1:27:19, 582.22s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464679870> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452275540> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f03a60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554674dc700> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554525e1810> 

Generation:  17
Best f1_score score: 0.8266944918373618
Generation:  68%|   | 17/25 [2:08:00<1:18:37, 589.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f6b5b0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546581cd90> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467970370> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e0c550> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e51000> 

Generation:  18
Best f1_score score: 0.8266944918373618
Generation:  72%|  | 18/25 [2:18:06<1:09:21, 594.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b5c36d0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465903af0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747350f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545307a5c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f24fd0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546767b160> 

Generation:  19
Best f1_score score: 0.8266944918373618
Generation:  76%|  | 19/25 [2:28:13<59:49, 598.18s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679f3220> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474725f60> 

Generation:  20
Best f1_score score: 0.8266944918373618
Generation:  80%|  | 20/25 [2:38:19<50:03, 600.64s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b082710> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451901f00> 

Generation:  21
Best f1_score score: 0.8266944918373618
Generation:  84%| | 21/25 [2:48:25<40:08, 602.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467321db0> 
 Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1096, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467aaeb60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453139420> 

Generation:  22
Best f1_score score: 0.8266944918373618
Generation:  88%| | 22/25 [2:58:31<30:10, 603.51s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451d775b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a96410> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452241b40> 

Generation:  23
Best f1_score score: 0.8266944918373618
Generation:  92%|| 23/25 [3:08:36<20:08, 604.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1810> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474654d60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0bdf0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f08f10> 

Generation:  24
Best f1_score score: 0.8266944918373618
Generation:  96%|| 24/25 [3:18:44<10:05, 605.17s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f25db0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467145900> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b7e170> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554650285e0> 

Generation:  25
Best f1_score score: 0.8286220404857332
Generation: 100%|| 25/25 [3:28:49<00:00, 605.04s/it]Generation: 100%|| 25/25 [3:28:49<00:00, 501.18s/it]
2024-11-22 21:52:23,951 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:46479' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-cb5c6758630249e619a6402e797a5243', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732341143.9513009')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),
                ('mlpclassifier',
                 MLPClassifier(activation='tanh', alpha=0.0024641454036,
                               hidden_layer_sizes=[120, 120, 120],
                               learning_rate='invscaling',
                               learning_rate_init=0.0010863482502,
                               n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9956928151493581, 'accuracy': 0.9515827639101938, 'balanced_accuracy': 0.9358946522430146, 'logloss': 0.11610026651457443, 'f1': 0.9362643593416716}
test score: {'auroc': 0.9736260824805303, 'accuracy': 0.8736055332440874, 'balanced_accuracy': 0.8382201617824884, 'logloss': 0.3142419704295487, 'f1': 0.8381505819285167}
original test score: {'auroc': 0.9807044363496793, 'accuracy': 0.8850959393128068, 'balanced_accuracy': 0.8539051962316239, 'logloss': 0.24571690133454194, 'f1': 0.8520695558828971}
score end
41027
lvl
0.01
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
8.199054235021274
hours
DONE
