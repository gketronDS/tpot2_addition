Run: 30
/cm/local/apps/slurm/var/spool/job1024529/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/737/737.pkl
working on 
../data/c/737/class_full_MAR_0.1_2
0.7659034729003906
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-25 23:30:21,587] A new study created in memory with name: no-name-13061282-2a46-459b-97ef-57375a007df9
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-25 23:30:21,898] Trial 11 finished with value: 0.14900101616374664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.14900101616374664.
[I 2024-10-25 23:30:22,052] Trial 13 finished with value: 0.14900101616374664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.14900101616374664.
running
running
[I 2024-10-25 23:30:22,327] Trial 16 finished with value: 0.14450487551698804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 16 with value: 0.14450487551698804.
running
[I 2024-10-25 23:30:22,595] Trial 14 finished with value: 0.14450487551698804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 16 with value: 0.14450487551698804.
running
[I 2024-10-25 23:30:23,070] Trial 2 finished with value: 0.12796579520011214 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2045, 'weights': 'distance'}. Best is trial 2 with value: 0.12796579520011214.
running
[I 2024-10-25 23:30:23,299] Trial 9 finished with value: 0.14669986951303987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1660, 'weights': 'uniform'}. Best is trial 2 with value: 0.12796579520011214.
[I 2024-10-25 23:30:23,484] Trial 17 finished with value: 0.12285638918806523 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 828, 'weights': 'uniform'}. Best is trial 17 with value: 0.12285638918806523.
running
running
[I 2024-10-25 23:30:23,740] Trial 12 finished with value: 0.13645330223334615 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1333, 'weights': 'uniform'}. Best is trial 17 with value: 0.12285638918806523.
running
[I 2024-10-25 23:30:23,987] Trial 10 finished with value: 0.10959838298597173 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 708, 'weights': 'distance'}. Best is trial 10 with value: 0.10959838298597173.
running
[I 2024-10-25 23:30:24,215] Trial 24 finished with value: 0.5006661779122471 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 10 with value: 0.10959838298597173.
running
[I 2024-10-25 23:30:24,487] Trial 20 finished with value: 0.0957467170877502 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 105, 'weights': 'uniform'}. Best is trial 20 with value: 0.0957467170877502.
running
[I 2024-10-25 23:30:25,962] Trial 1 finished with value: 0.095619587153196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 1 with value: 0.095619587153196.
running
[I 2024-10-25 23:30:27,254] Trial 19 finished with value: 0.10337295692441166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 1 with value: 0.095619587153196.
running
[I 2024-10-25 23:30:28,202] Trial 18 finished with value: 0.09259424160722603 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 18 with value: 0.09259424160722603.
running
[I 2024-10-25 23:30:28,631] Trial 15 finished with value: 0.09133705353444063 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:28,996] Trial 27 finished with value: 0.095619587153196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:29,521] Trial 26 finished with value: 0.09153996277805972 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:30,058] Trial 29 finished with value: 0.09259429623223661 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:33,080] Trial 33 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.847122397870985, 'alpha': 100, 'iterations': 4, 'learning_rate': 0.06975983980564361, 'p_miss': 0.028207430095933322}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:35,028] Trial 32 finished with value: 0.3050539151866004 and parameters: {'model_name': 'GAIN', 'batch_size': 72, 'hint_rate': 0.1790833119570543, 'alpha': 29, 'iterations': 1, 'learning_rate': 0.07079605083225202, 'p_miss': 0.15228271222116938}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:35,460] Trial 28 finished with value: 0.3090485002098705 and parameters: {'model_name': 'GAIN', 'batch_size': 21, 'hint_rate': 0.44962175886811895, 'alpha': 48, 'iterations': 1, 'learning_rate': 0.0015658589718033715, 'p_miss': 0.04580882648537145}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:38,943] Trial 7 finished with value: 0.184932289301798 and parameters: {'model_name': 'VAE', 'batch_size': 885, 'iterations': 1, 'learning_rate': 0.0003032307369673476, 'p_miss': 0.29258085964012226}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:46,418] Trial 37 finished with value: 0.09145637042689472 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:30:55,492] Trial 38 finished with value: 0.09137341887797416 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 15 with value: 0.09133705353444063.
running
[I 2024-10-25 23:31:06,008] Trial 39 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:32:11,278] Trial 31 finished with value: 0.30376696772379386 and parameters: {'model_name': 'GAIN', 'batch_size': 32, 'hint_rate': 0.34645388090385343, 'alpha': 92, 'iterations': 48, 'learning_rate': 0.00012261843664728583, 'p_miss': 0.03434093807120028}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:33:36,001] Trial 22 finished with value: 0.30860527729766163 and parameters: {'model_name': 'GAIN', 'batch_size': 655, 'hint_rate': 0.12813116505766478, 'alpha': 64, 'iterations': 79, 'learning_rate': 0.0022149467113148757, 'p_miss': 0.018613907160999938}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:35:14,529] Trial 0 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.3775726096798667, 'alpha': 59, 'iterations': 240, 'learning_rate': 0.00015284297991642146, 'p_miss': 0.22339652538065422}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:39:28,953] Trial 21 finished with value: 0.1217412625336457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:39:51,864] Trial 6 finished with value: 0.10735762994677585 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:39:55,465] Trial 25 finished with value: 0.3210107973909995 and parameters: {'model_name': 'GAIN', 'batch_size': 94, 'hint_rate': 0.7972715098700887, 'alpha': 35, 'iterations': 272, 'learning_rate': 0.0008385252879811884, 'p_miss': 0.22186641023945172}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:40:01,544] Trial 46 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 39 with value: 0.09131691244679771.
running
[I 2024-10-25 23:40:47,069] Trial 8 finished with value: 0.08718704128767445 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-25 23:44:52,516] Trial 30 finished with value: 0.25093059895534475 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 248, 'learning_rate': 0.009215674178766486, 'p_miss': 0.28956903875420326}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-25 23:45:01,294] Trial 49 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-25 23:45:08,774] Trial 50 finished with value: 0.09136245974353659 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-25 23:54:50,232] Trial 51 finished with value: 0.0921313386165713 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 00:10:59,465] Trial 5 finished with value: 0.32621462794968215 and parameters: {'model_name': 'GAIN', 'batch_size': 791, 'hint_rate': 0.8526817339483429, 'alpha': 81, 'iterations': 1135, 'learning_rate': 0.0001509451493577944, 'p_miss': 0.26960002139083333}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 00:20:10,383] Trial 4 finished with value: 0.15047034062164366 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 637, 'learning_rate': 0.0348032808124524, 'p_miss': 0.21314219422638445}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 00:20:18,208] Trial 54 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:15:05,162] Trial 23 finished with value: 0.23402688723459036 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2488, 'learning_rate': 0.02272986048269269, 'p_miss': 0.24378780978911815}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:15:14,693] Trial 56 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:15:21,843] Trial 57 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:15:28,304] Trial 58 finished with value: 0.09131691244679771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:15:34,429] Trial 59 finished with value: 0.10591243561392738 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:24:53,891] Trial 60 finished with value: 0.08773485949908968 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:34:03,718] Trial 61 finished with value: 0.0890007771453634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:42:19,142] Trial 62 finished with value: 0.09734623584245901 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:42:38,431] Trial 63 finished with value: 0.17376226294245384 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.006528763848300026, 'p_miss': 0.11797798915889174}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:51:28,480] Trial 64 finished with value: 0.09144113513878241 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 02:59:31,218] Trial 65 finished with value: 0.0918033565045607 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:08:45,295] Trial 66 finished with value: 0.09025498402144222 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:17:53,095] Trial 67 finished with value: 0.08895005131786039 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:24:07,996] Trial 68 finished with value: 0.13784212154254796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:32:49,252] Trial 69 finished with value: 0.0891288676689624 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:32:50,263] Trial 70 finished with value: 0.12796579520011214 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2455, 'weights': 'distance'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:41:42,452] Trial 71 finished with value: 0.08988675949761596 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:41:42,836] Trial 72 finished with value: 0.46035450035515585 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:49:30,302] Trial 35 finished with value: 0.15019384101562452 and parameters: {'model_name': 'VAE', 'batch_size': 938, 'iterations': 2785, 'learning_rate': 0.00011734181301540209, 'p_miss': 0.2972544222218741}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:50:23,194] Trial 73 finished with value: 0.08975058593532352 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:58:33,991] Trial 74 finished with value: 0.08916142097372248 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 03:59:06,552] Trial 75 finished with value: 0.09013693554843015 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:07:25,798] Trial 76 finished with value: 0.09006301641671419 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:08:03,107] Trial 77 finished with value: 0.09021230961830767 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:16:43,840] Trial 78 finished with value: 0.09062343589485794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:16:44,743] Trial 80 finished with value: 0.09813979591125996 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 239, 'weights': 'distance'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:17:08,028] Trial 79 finished with value: 0.08938653846980765 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:17:08,469] Trial 82 finished with value: 0.46035450035515585 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:25:00,585] Trial 81 finished with value: 0.09557992641406114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:26:05,424] Trial 83 finished with value: 0.08981778551603303 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:32:19,238] Trial 84 finished with value: 0.09086277481853666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:34:37,034] Trial 85 finished with value: 0.08873725226825055 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:40:58,475] Trial 86 finished with value: 0.08967095354684149 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:41:02,034] Trial 88 finished with value: 0.09611813610057016 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:41:25,270] Trial 89 finished with value: 0.15769013247675462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 04:43:42,510] Trial 87 finished with value: 0.0903536780136754 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:33:59,740] Trial 3 finished with value: 0.1744871053137506 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 5659, 'learning_rate': 0.006961371746658881, 'p_miss': 0.16665110912327966}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:35:37,414] Trial 92 finished with value: 0.19213222102146493 and parameters: {'model_name': 'VAE', 'batch_size': 255, 'iterations': 20, 'learning_rate': 0.0004581046088607979, 'p_miss': 0.07671437084927835}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:38:27,374] Trial 36 finished with value: 0.15107941693471175 and parameters: {'model_name': 'VAE', 'batch_size': 939, 'iterations': 3894, 'learning_rate': 0.00010734772717545258, 'p_miss': 0.2916961999777653}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:45:40,220] Trial 93 finished with value: 0.09001128589075186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:45:41,688] Trial 95 finished with value: 0.11232229327370935 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 852, 'weights': 'distance'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:48:25,237] Trial 94 finished with value: 0.08849277346035538 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:50:46,193] Trial 43 finished with value: 0.20780576424783725 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6332, 'learning_rate': 0.01601826118324419, 'p_miss': 0.12581323051069593}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:55:39,375] Trial 96 finished with value: 0.09032804557904123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 05:58:46,623] Trial 97 finished with value: 0.09094062950639129 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:01:05,328] Trial 98 finished with value: 0.09140081766713637 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:05:46,347] Trial 99 finished with value: 0.0891644666615545 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:05:57,624] Trial 102 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.6392605777451974, 'alpha': 4, 'iterations': 9, 'learning_rate': 0.0014147399674307205, 'p_miss': 0.08131960622605912}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:06:18,292] Trial 103 finished with value: 0.17139004388760634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:06:18,668] Trial 104 finished with value: 0.5006661779122471 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:06:22,299] Trial 105 finished with value: 0.0961180814989331 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:08:19,862] Trial 42 finished with value: 0.23691803435196995 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6827, 'learning_rate': 0.013173946842190434, 'p_miss': 0.2894292380731137}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:09:13,134] Trial 100 finished with value: 0.08867766454828178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:11:36,007] Trial 101 finished with value: 0.08841937113375467 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:16:56,464] Trial 106 finished with value: 0.08913207821318683 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:18:29,071] Trial 52 finished with value: 0.15725088361279618 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5906, 'learning_rate': 0.01412746141853073, 'p_miss': 0.110053846354354}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:19:37,513] Trial 107 finished with value: 0.08960219876560793 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:19:52,222] Trial 108 finished with value: 0.08969779864222908 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:22:33,660] Trial 109 finished with value: 0.08783738426159002 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:27:11,266] Trial 34 finished with value: 0.15054850541729647 and parameters: {'model_name': 'VAE', 'batch_size': 530, 'iterations': 5399, 'learning_rate': 0.0003336364003057559, 'p_miss': 0.2462175701966206}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:28:24,139] Trial 110 finished with value: 0.08941045820339444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:29:36,691] Trial 111 finished with value: 0.08922015665203147 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:31:11,518] Trial 113 finished with value: 0.08917738649566533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:31:45,180] Trial 112 finished with value: 0.08896279373499842 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:33:56,018] Trial 114 finished with value: 0.0906039034276708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:38:39,760] Trial 115 finished with value: 0.0895575342147643 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:40:33,579] Trial 116 finished with value: 0.08894916698325231 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:40:48,886] Trial 117 finished with value: 0.09029468559718777 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:42:42,280] Trial 118 finished with value: 0.08930451790251812 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:43:49,727] Trial 119 finished with value: 0.08908187421568317 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:43:50,656] Trial 123 finished with value: 0.34941977559791904 and parameters: {'model_name': 'GAIN', 'batch_size': 162, 'hint_rate': 0.010571051692509714, 'alpha': 1, 'iterations': 80, 'learning_rate': 0.0038329887423096455, 'p_miss': 0.19196641129940425}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:44:34,978] Trial 124 finished with value: 0.3038335573834572 and parameters: {'model_name': 'GAIN', 'batch_size': 197, 'hint_rate': 0.025750493616324033, 'alpha': 6, 'iterations': 52, 'learning_rate': 0.004147296206848322, 'p_miss': 0.18690854795242623}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:45:06,641] Trial 125 finished with value: 0.31313788291921396 and parameters: {'model_name': 'GAIN', 'batch_size': 159, 'hint_rate': 0.6279641835108472, 'alpha': 0, 'iterations': 34, 'learning_rate': 0.0043259162375426175, 'p_miss': 0.1832017759529128}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:46:09,562] Trial 120 finished with value: 0.0893838438385554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:49:28,673] Trial 121 finished with value: 0.09415327926269039 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:51:05,757] Trial 122 finished with value: 0.1003345142302748 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:51:47,765] Trial 131 finished with value: 0.17120099441553543 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:51:50,065] Trial 132 finished with value: 0.14900101616374664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2462, 'weights': 'uniform'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:54:39,444] Trial 126 finished with value: 0.09973136177248154 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:54:49,481] Trial 134 finished with value: 0.10533051936193591 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:54:49,932] Trial 135 finished with value: 0.14450487551698804 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:55:22,976] Trial 53 finished with value: 0.1547216510800379 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 6190, 'learning_rate': 0.012452385979329815, 'p_miss': 0.10348369740143777}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:56:01,509] Trial 127 finished with value: 0.1015539856422915 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:57:49,067] Trial 128 finished with value: 0.09945047938530836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 06:58:33,158] Trial 129 finished with value: 0.09870823962641509 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:01:00,519] Trial 130 finished with value: 0.09386979508975235 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:04:12,835] Trial 133 finished with value: 0.08907582342998646 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:06:17,083] Trial 136 finished with value: 0.089262113751824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:08:07,823] Trial 137 finished with value: 0.09017091420971751 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:08:12,351] Trial 138 finished with value: 0.08943798403344713 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:10:03,118] Trial 139 finished with value: 0.08982920896167086 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:11:32,683] Trial 140 finished with value: 0.08776016132735934 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:13:24,091] Trial 141 finished with value: 0.08895879546926808 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:17:18,830] Trial 142 finished with value: 0.09077302581556748 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:17:44,274] Trial 40 finished with value: 0.21893760002123175 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7458, 'learning_rate': 0.0001553994795643425, 'p_miss': 0.297463614227814}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:18:18,524] Trial 143 finished with value: 0.08921413092574952 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:20:21,264] Trial 145 finished with value: 0.08977036011802073 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:20:41,569] Trial 144 finished with value: 0.08914938283121202 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:21:46,561] Trial 146 finished with value: 0.09018281871412938 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:24:45,350] Trial 147 finished with value: 0.09095082088228156 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:25:23,167] Trial 148 finished with value: 0.08940054907022235 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:30:19,465] Trial 149 finished with value: 0.08968336100672905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:30:46,965] Trial 151 finished with value: 0.09018080578289175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:30:57,519] Trial 150 finished with value: 0.08986420728111658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:32:33,754] Trial 152 finished with value: 0.08843786770295135 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:33:28,075] Trial 153 finished with value: 0.0890438696997301 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:33:30,050] Trial 161 finished with value: 0.14749479472077553 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1735, 'weights': 'uniform'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:33:58,230] Trial 162 finished with value: 0.09259430062330985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:34:03,777] Trial 163 finished with value: 0.0961181084679964 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:34:04,382] Trial 164 finished with value: 0.46035450035515585 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:34:27,188] Trial 154 finished with value: 0.08943715222939247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:35:20,419] Trial 41 finished with value: 0.2064406606088657 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7376, 'learning_rate': 0.007310225908273364, 'p_miss': 0.2936756805509617}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:37:57,988] Trial 156 finished with value: 0.09002373357732094 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:38:07,451] Trial 155 finished with value: 0.09000617718363073 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:44:30,566] Trial 157 finished with value: 0.08853489722770062 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:44:36,891] Trial 158 finished with value: 0.08753503035418826 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:44:47,002] Trial 171 finished with value: 0.0913104306035085 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:44:58,929] Trial 159 finished with value: 0.0888211164666117 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:45:33,896] Trial 160 finished with value: 0.09129171925326188 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:46:53,860] Trial 166 finished with value: 0.10609295617341959 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:47:14,737] Trial 165 finished with value: 0.09915149987648611 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:47:49,743] Trial 167 finished with value: 0.08970246699240028 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:50:15,762] Trial 168 finished with value: 0.08895735339315178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:51:48,936] Trial 169 finished with value: 0.08893698036367192 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:57:25,344] Trial 170 finished with value: 0.10811701300379417 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:57:31,178] Trial 172 finished with value: 0.08981851800108125 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:58:15,938] Trial 173 finished with value: 0.09036218260642573 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:58:25,054] Trial 174 finished with value: 0.08940356991526319 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 07:59:52,460] Trial 177 finished with value: 0.089030711360172 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:00:23,842] Trial 175 finished with value: 0.08995963351365399 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:01:26,684] Trial 176 finished with value: 0.08975922237319242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:02:45,253] Trial 178 finished with value: 0.08842175337809753 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:05:38,320] Trial 179 finished with value: 0.09021156056084761 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:10:43,061] Trial 181 finished with value: 0.08973886340014428 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:11:05,185] Trial 183 finished with value: 0.09039016040546426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:11:28,567] Trial 180 finished with value: 0.08882718363767801 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:11:44,569] Trial 182 finished with value: 0.08844223519474884 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:12:19,215] Trial 184 finished with value: 0.09089357754700786 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:12:21,289] Trial 193 finished with value: 0.10526110761529621 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 504, 'weights': 'distance'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:12:57,236] Trial 185 finished with value: 0.08952251077119613 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:13:25,435] Trial 45 finished with value: 0.21355060102811257 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9215, 'learning_rate': 0.011848241388806201, 'p_miss': 0.12679886279201535}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:13:42,207] Trial 195 finished with value: 0.15887022487488056 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:15:50,800] Trial 187 finished with value: 0.08808590486263704 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:15:54,815] Trial 186 finished with value: 0.08856410987523806 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
running
[I 2024-10-26 08:18:28,395] Trial 47 finished with value: 0.20901291053414628 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8508, 'learning_rate': 0.012339691669184286, 'p_miss': 0.10976942938043648}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:19:46,918] Trial 188 finished with value: 0.08958356988067534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:23:20,942] Trial 48 finished with value: 0.22207990433351527 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8559, 'learning_rate': 0.015020392424677157, 'p_miss': 0.10056916844606281}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:23:47,232] Trial 189 finished with value: 0.08918215347370667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:24:25,654] Trial 190 finished with value: 0.08786930253814099 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:24:33,302] Trial 194 finished with value: 0.08923972766921792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:24:48,803] Trial 192 finished with value: 0.08836170761359836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:24:57,680] Trial 191 finished with value: 0.08999665547127837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:24:57,939] Trial 197 finished with value: 0.0887104541242072 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:25:19,491] Trial 196 finished with value: 0.08947206556478407 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:25:24,500] Trial 44 finished with value: 0.21521933124068768 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8541, 'learning_rate': 0.012452902970663648, 'p_miss': 0.11918076985345324}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:26:02,570] Trial 198 finished with value: 0.08797532052157038 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:26:28,897] Trial 199 finished with value: 0.08823512766890876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:28:44,010] Trial 55 finished with value: 0.15712135389612486 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 9432, 'learning_rate': 0.009100923315883537, 'p_miss': 0.10072496133637551}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:36:02,282] Trial 90 finished with value: 0.15053608594425694 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9131, 'learning_rate': 0.0005788363918053906, 'p_miss': 0.08452192892203017}. Best is trial 8 with value: 0.08718704128767445.
[I 2024-10-26 08:37:24,877] Trial 91 finished with value: 0.1510603982124949 and parameters: {'model_name': 'VAE', 'batch_size': 237, 'iterations': 8528, 'learning_rate': 0.0005057281081356737, 'p_miss': 0.08727715437456991}. Best is trial 8 with value: 0.08718704128767445.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.08718704128767445
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.8215126913777443
Generation:   4%|▍         | 1/25 [00:04<01:47,  4.48s/it]Generation:  2
Best f1_score score: 0.8390978916017422
Generation:   8%|▊         | 2/25 [00:11<02:16,  5.92s/it]Generation:  3
Best f1_score score: 0.8390978916017422
Generation:  12%|█▏        | 3/25 [00:20<02:43,  7.44s/it]Generation:  4
Best f1_score score: 0.847772631272855
Generation:  16%|█▌        | 4/25 [01:03<07:27, 21.29s/it]Generation:  5
Best f1_score score: 0.847772631272855
Generation:  20%|██        | 5/25 [01:11<05:31, 16.55s/it]Generation:  6
Best f1_score score: 0.847772631272855
Generation:  24%|██▍       | 6/25 [01:21<04:32, 14.36s/it]Generation:  7
Best f1_score score: 0.847772631272855
Generation:  28%|██▊       | 7/25 [01:33<04:05, 13.64s/it]Generation:  8
Best f1_score score: 0.847772631272855
Generation:  32%|███▏      | 8/25 [01:51<04:12, 14.88s/it]Generation:  9
Best f1_score score: 0.847772631272855
Generation:  36%|███▌      | 9/25 [02:04<03:50, 14.39s/it]Generation:  10
Best f1_score score: 0.847772631272855
Generation:  40%|████      | 10/25 [03:15<07:57, 31.81s/it]Generation:  11
Best f1_score score: 0.847772631272855
Generation:  44%|████▍     | 11/25 [03:31<06:18, 27.05s/it]Generation:  12
Best f1_score score: 0.847772631272855
Generation:  48%|████▊     | 12/25 [04:23<07:32, 34.77s/it]Generation:  13
Best f1_score score: 0.847772631272855
Generation:  52%|█████▏    | 13/25 [06:33<12:40, 63.34s/it]Generation:  14
Best f1_score score: 0.847772631272855
Generation:  56%|█████▌    | 14/25 [09:27<17:45, 96.87s/it]Generation:  15
Best f1_score score: 0.847772631272855
Generation:  60%|██████    | 15/25 [09:39<11:53, 71.37s/it]Generation:  16
Best f1_score score: 0.847772631272855
Generation:  64%|██████▍   | 16/25 [10:16<09:08, 60.99s/it]Generation:  17
Best f1_score score: 0.847772631272855
Generation:  68%|██████▊   | 17/25 [10:32<06:19, 47.43s/it]Generation:  18
Best f1_score score: 0.847772631272855
Generation:  72%|███████▏  | 18/25 [11:14<05:21, 45.91s/it]Generation:  19
Best f1_score score: 0.847772631272855
Generation:  76%|███████▌  | 19/25 [13:04<06:30, 65.03s/it]Generation:  20
Best f1_score score: 0.847772631272855
Generation:  80%|████████  | 20/25 [13:24<04:18, 51.64s/it]Generation:  21
Best f1_score score: 0.847772631272855
Generation:  84%|████████▍ | 21/25 [13:45<02:49, 42.36s/it]Generation:  22
Best f1_score score: 0.847772631272855
Generation:  88%|████████▊ | 22/25 [16:04<03:34, 71.37s/it]Generation:  23
Best f1_score score: 0.847772631272855
Generation:  92%|█████████▏| 23/25 [18:51<03:20, 100.11s/it]Generation:  24
Best f1_score score: 0.8560832338415612
Generation:  96%|█████████▌| 24/25 [23:53<02:40, 160.60s/it]Generation:  25
Best f1_score score: 0.8560832338415612
Generation: 100%|██████████| 25/25 [24:12<00:00, 118.10s/it]Generation: 100%|██████████| 25/25 [24:17<00:00, 58.31s/it] 
2024-10-26 09:03:28,214 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42621' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bc1ee22df90b340c13f4c4b70d48b351', 'ndarray-914e4e701905bf28d2d3ff44bf967e5c'} (stimulus_id='handle-worker-cleanup-1729958608.2141485')
Fitted
Pipeline(steps=[('mlpclassifier',
                 MLPClassifier(alpha=0.0005980392552,
                               hidden_layer_sizes=[502, 502, 502],
                               learning_rate_init=0.0011727639907,
                               n_iter_no_change=32))])
score start
train score: {'auroc': 0.9473471804399256, 'accuracy': 0.8804828973843059, 'balanced_accuracy': 0.8802635977083868, 'logloss': 0.29383004713215677, 'f1': 0.8803328295620205}
original test score: {'auroc': 0.9423752998593764, 'accuracy': 0.8729903536977492, 'balanced_accuracy': 0.8726218049466457, 'logloss': 0.3028661184047208, 'f1': 0.8727136614314985}
imputed test score: {'auroc': 0.9410621225907849, 'accuracy': 0.8713826366559485, 'balanced_accuracy': 0.8709984283232691, 'logloss': 0.3080681388132187, 'f1': 0.8710827391808987}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4df0> 
 Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 732, in fit
    X, y = self._check_X_y(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 1184, in _check_X_y
    X, y = super()._check_X_y(X, y, reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 578, in _check_X_y
    return self._validate_data(X, y, accept_sparse="csr", reset=reset)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BernoulliNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.8234319542664948
Generation:   4%|▍         | 1/25 [03:41<1:28:42, 221.77s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d48dc0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.829073773338124
Generation:   8%|▊         | 2/25 [07:23<1:25:01, 221.80s/it]Generation:  3
Best f1_score score: 0.8342714842972712
Generation:  12%|█▏        | 3/25 [11:05<1:21:24, 222.04s/it]Generation:  4
Best f1_score score: 0.8342714842972712
Generation:  16%|█▌        | 4/25 [14:52<1:18:16, 223.66s/it]Generation:  5
Best f1_score score: 0.8343412761429952
Generation:  20%|██        | 5/25 [18:33<1:14:13, 222.68s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455116b30> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  6
Best f1_score score: 0.8343412761429952
Generation:  24%|██▍       | 6/25 [22:18<1:10:50, 223.72s/it]Generation:  7
Best f1_score score: 0.8343412761429952
Generation:  28%|██▊       | 7/25 [26:04<1:07:17, 224.33s/it]Generation:  8
Best f1_score score: 0.8343412761429952
Generation:  32%|███▏      | 8/25 [29:47<1:03:25, 223.86s/it]Generation:  9
Best f1_score score: 0.8367423155508209
Generation:  36%|███▌      | 9/25 [33:30<59:37, 223.61s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554575dc160> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  10
Best f1_score score: 0.8367423155508209
Generation:  40%|████      | 10/25 [37:11<55:43, 222.89s/it]Generation:  11
Best f1_score score: 0.8367423155508209
Generation:  44%|████▍     | 11/25 [47:16<1:19:15, 339.70s/it]Generation:  12
Best f1_score score: 0.8367423155508209
Generation:  48%|████▊     | 12/25 [50:59<1:05:55, 304.28s/it]Generation:  13
Best f1_score score: 0.8367423155508209
Generation:  52%|█████▏    | 13/25 [54:42<55:55, 279.65s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474230820> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  14
Best f1_score score: 0.8367423155508209
Generation:  56%|█████▌    | 14/25 [58:27<48:13, 263.06s/it]Generation:  15
Best f1_score score: 0.8367423155508209
Generation:  60%|██████    | 15/25 [1:02:12<41:56, 251.64s/it]Generation:  16
Best f1_score score: 0.8367423155508209
Generation:  64%|██████▍   | 16/25 [1:05:57<36:33, 243.67s/it]Generation:  17
Best f1_score score: 0.8398066701641277
Generation:  68%|██████▊   | 17/25 [1:10:13<32:59, 247.49s/it]Generation:  18
Best f1_score score: 0.8398066701641277
Generation:  72%|███████▏  | 18/25 [1:13:57<28:02, 240.43s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554742201f0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  19
Best f1_score score: 0.8424499993342117
Generation:  76%|███████▌  | 19/25 [1:18:16<24:35, 245.86s/it]Generation:  20
Best f1_score score: 0.8428007207006021
Generation:  80%|████████  | 20/25 [1:22:43<21:02, 252.42s/it]Generation:  21
Best f1_score score: 0.8428007207006021
Generation:  84%|████████▍ | 21/25 [1:28:39<18:53, 283.48s/it]Generation:  22
Best f1_score score: 0.8428007207006021
Generation:  88%|████████▊ | 22/25 [1:33:05<13:54, 278.03s/it]Generation:  23
Best f1_score score: 0.8481845736498681
Generation:  92%|█████████▏| 23/25 [1:37:25<09:05, 272.78s/it]Generation:  24
Best f1_score score: 0.8481845736498681
Generation:  96%|█████████▌| 24/25 [1:41:52<04:30, 270.94s/it]Generation:  25
Best f1_score score: 0.8481845736498681
Generation: 100%|██████████| 25/25 [1:46:01<00:00, 264.36s/it]Generation: 100%|██████████| 25/25 [1:46:01<00:00, 254.46s/it]
2024-10-26 10:50:43,296 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34449' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bc1ee22df90b340c13f4c4b70d48b351', 'DataFrame-d57d8811512a4af77c5e1d8e2502a15a'} (stimulus_id='handle-worker-cleanup-1729965043.2962065')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=RandomForestRegressor(),
                                  imputation_order='arabic',
                                  n_nearest_features=81)),
                ('mlpclassifier',
                 MLPClassifier(activation='tanh', alpha=0.000306692916,
                               hidden_layer_sizes=[220],
                               learning_rate='invscaling',
                               learning_rate_init=0.0441621044112,
                               n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9123115909921254, 'accuracy': 0.8346076458752515, 'balanced_accuracy': 0.8350441402434126, 'logloss': 0.4043399018586105, 'f1': 0.834181339618846}
test score: {'auroc': 0.9237219786582843, 'accuracy': 0.8440514469453376, 'balanced_accuracy': 0.8446418231450079, 'logloss': 0.3854085344886604, 'f1': 0.8436112443136898}
original test score: {'auroc': 0.9234944991314418, 'accuracy': 0.8440514469453376, 'balanced_accuracy': 0.8445797832740508, 'logloss': 0.3824249962659413, 'f1': 0.8437117108715868}
score end
737
lvl
0.1
type
MAR
num_run
2
class_full
finished
all finished
full run takes
11.350704138941236
hours
DONE
