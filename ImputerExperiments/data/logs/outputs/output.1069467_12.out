Run: 12
/cm/local/apps/slurm/var/spool/job1069467/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40922/40922.pkl
working on 
../data/c/40922/class_full_MNAR_0.5_1
2.654940366744995
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-23 12:25:33,453] A new study created in memory with name: no-name-d3e34cb3-b902-4456-8d52-6571d7038f3e
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-23 12:25:34,052] Trial 15 finished with value: 0.364829351508016 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.364829351508016.
running
[I 2024-11-23 12:25:41,503] Trial 3 finished with value: 0.18882335932536126 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 3 with value: 0.18882335932536126.
running
[I 2024-11-23 12:25:42,826] Trial 17 finished with value: 0.364829351508016 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 3 with value: 0.18882335932536126.
running
[I 2024-11-23 12:25:44,660] Trial 13 finished with value: 0.328760491614558 and parameters: {'model_name': 'GAIN', 'batch_size': 603, 'hint_rate': 0.6499120693116659, 'alpha': 32, 'iterations': 2, 'learning_rate': 0.003924835590983144, 'p_miss': 0.23568647673646476}. Best is trial 3 with value: 0.18882335932536126.
running
[I 2024-11-23 12:25:45,563] Trial 19 finished with value: 0.29123281226479664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 3 with value: 0.18882335932536126.
running
[I 2024-11-23 12:25:49,313] Trial 14 finished with value: 0.18968580086603168 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 3 with value: 0.18882335932536126.
running
[I 2024-11-23 12:25:51,728] Trial 0 finished with value: 0.18859487019747273 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'random'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:25:55,422] Trial 18 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7212288357031578, 'alpha': 33, 'iterations': 78, 'learning_rate': 0.020089957248382063, 'p_miss': 0.2830998708729075}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:26:34,198] Trial 11 finished with value: 0.35377572536183316 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.6431748994888782, 'alpha': 76, 'iterations': 45, 'learning_rate': 0.0002959228117801956, 'p_miss': 0.058815270016330114}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:26:49,126] Trial 21 finished with value: 0.20473371937307752 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:26:59,459] Trial 16 finished with value: 0.18870765770467746 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29240, 'weights': 'uniform'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:27:06,567] Trial 7 finished with value: 0.19044246612317137 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 50526, 'weights': 'uniform'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:27:07,700] Trial 22 finished with value: 0.3405060452946125 and parameters: {'model_name': 'GAIN', 'batch_size': 746, 'hint_rate': 0.6550826330050621, 'alpha': 81, 'iterations': 47, 'learning_rate': 0.0002520883308204357, 'p_miss': 0.1507202591396824}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:27:23,615] Trial 6 finished with value: 0.21721588609063652 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 41983, 'weights': 'distance'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:09,772] Trial 24 finished with value: 0.2169584068306729 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 30409, 'weights': 'distance'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:16,096] Trial 26 finished with value: 0.18868632238250804 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28730, 'weights': 'uniform'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:16,750] Trial 28 finished with value: 0.21622562967477904 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7549, 'weights': 'distance'}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:21,068] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.2009169602171688, 'alpha': 0, 'iterations': 751, 'learning_rate': 0.000308405703870808, 'p_miss': 0.29682485431827255}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:47,303] Trial 9 finished with value: 0.21971376778556934 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 87, 'learning_rate': 0.011180523970561969, 'p_miss': 0.23929924736444935}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:49,665] Trial 23 finished with value: 0.3500003632059382 and parameters: {'model_name': 'GAIN', 'batch_size': 58, 'hint_rate': 0.639674845775615, 'alpha': 36, 'iterations': 141, 'learning_rate': 0.003228195951178757, 'p_miss': 0.1238543452434086}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:28:51,777] Trial 5 finished with value: 0.3440875623753207 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.5983765755093304, 'alpha': 22, 'iterations': 170, 'learning_rate': 0.03891330052735939, 'p_miss': 0.23169536862902834}. Best is trial 0 with value: 0.18859487019747273.
running
[I 2024-11-23 12:29:01,350] Trial 1 finished with value: 0.09944641173853105 and parameters: {'model_name': 'VAE', 'batch_size': 764, 'iterations': 43, 'learning_rate': 0.0007308498201437253, 'p_miss': 0.1876580107863796}. Best is trial 1 with value: 0.09944641173853105.
running
[I 2024-11-23 12:29:16,205] Trial 35 finished with value: 0.18989224278424394 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 1 with value: 0.09944641173853105.
running
[I 2024-11-23 12:29:43,197] Trial 4 finished with value: 0.35999838607540713 and parameters: {'model_name': 'GAIN', 'batch_size': 676, 'hint_rate': 0.601279580432704, 'alpha': 87, 'iterations': 192, 'learning_rate': 0.00012021822966260223, 'p_miss': 0.010772473101136331}. Best is trial 1 with value: 0.09944641173853105.
running
[I 2024-11-23 12:30:00,721] Trial 36 finished with value: 0.1884293784382194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23125, 'weights': 'uniform'}. Best is trial 1 with value: 0.09944641173853105.
running
[I 2024-11-23 13:05:09,679] Trial 8 finished with value: 0.35591746975524136 and parameters: {'model_name': 'GAIN', 'batch_size': 172, 'hint_rate': 0.15915156233622837, 'alpha': 86, 'iterations': 1764, 'learning_rate': 0.00023044235807667213, 'p_miss': 0.06895561975325018}. Best is trial 1 with value: 0.09944641173853105.
running
[I 2024-11-23 13:05:25,613] Trial 41 finished with value: 0.09774644850330505 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0009344341050733604, 'p_miss': 0.1793928003526062}. Best is trial 41 with value: 0.09774644850330505.
running
[I 2024-11-23 13:05:42,580] Trial 42 finished with value: 0.09713738956884113 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0010419481741404347, 'p_miss': 0.18977429913592575}. Best is trial 42 with value: 0.09713738956884113.
running
[I 2024-11-23 13:05:56,163] Trial 43 finished with value: 0.09349500221377954 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0010014799880897188, 'p_miss': 0.19087614842994333}. Best is trial 43 with value: 0.09349500221377954.
running
[I 2024-11-23 13:06:06,556] Trial 44 finished with value: 0.09651741158245083 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.001171491299472578, 'p_miss': 0.1916366685989271}. Best is trial 43 with value: 0.09349500221377954.
running
[I 2024-11-23 13:06:31,462] Trial 45 finished with value: 0.0976268702095992 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8, 'learning_rate': 0.0011994780400480028, 'p_miss': 0.19628381924687038}. Best is trial 43 with value: 0.09349500221377954.
running
[I 2024-11-23 13:06:53,684] Trial 46 finished with value: 0.0935250717085281 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7, 'learning_rate': 0.0011639490476282053, 'p_miss': 0.19735188736733186}. Best is trial 43 with value: 0.09349500221377954.
running
[I 2024-11-23 13:06:59,087] Trial 47 finished with value: 0.09516407003502025 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.001812675076781584, 'p_miss': 0.14922307131004134}. Best is trial 43 with value: 0.09349500221377954.
running
[I 2024-11-23 13:07:04,390] Trial 48 finished with value: 0.09099271045795351 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 1, 'learning_rate': 0.0017713191523409187, 'p_miss': 0.12977356971092158}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:07:09,948] Trial 49 finished with value: 0.09195077773064339 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.0022625708079101756, 'p_miss': 0.12698118222466792}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:07:53,745] Trial 50 finished with value: 0.11998155818866167 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 12, 'learning_rate': 0.006067693514421757, 'p_miss': 0.11057325419813709}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:07:58,782] Trial 51 finished with value: 0.10112876425355899 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 1, 'learning_rate': 0.0022055673313405473, 'p_miss': 0.11312773453570744}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:08:03,381] Trial 52 finished with value: 0.10379592939890696 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 1, 'learning_rate': 0.0004993147121485784, 'p_miss': 0.13606529027140102}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:08:46,232] Trial 53 finished with value: 0.10438948326622768 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 16, 'learning_rate': 0.006431320271158049, 'p_miss': 0.09164375689706135}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:08:54,216] Trial 54 finished with value: 0.10397545062518727 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2, 'learning_rate': 0.0022781131350035114, 'p_miss': 0.16601425460954375}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:09:11,253] Trial 55 finished with value: 0.09544066094562961 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6, 'learning_rate': 0.0006426672071101658, 'p_miss': 0.2150201898739827}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:09:16,464] Trial 56 finished with value: 0.10809724976146692 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 1, 'learning_rate': 0.001745585722327191, 'p_miss': 0.15509909521034848}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:09:21,125] Trial 57 finished with value: 0.0924128516999598 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0016229081315570018, 'p_miss': 0.14252881487625427}. Best is trial 48 with value: 0.09099271045795351.
running
[I 2024-11-23 13:09:28,761] Trial 58 finished with value: 0.09098321402498324 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.0037603971423479463, 'p_miss': 0.0929819873498948}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:09:37,980] Trial 59 finished with value: 0.09650252787379651 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.00586749068943034, 'p_miss': 0.08984291809171203}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:09:43,686] Trial 60 finished with value: 0.10136673734006045 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.003952169969847829, 'p_miss': 0.1294547892207191}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:10:49,933] Trial 61 finished with value: 0.09694971626930719 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 19, 'learning_rate': 0.0005076936288375115, 'p_miss': 0.09767192375635868}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:10:59,039] Trial 62 finished with value: 0.09953212303311738 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 2, 'learning_rate': 0.002571489711617319, 'p_miss': 0.06274443827670251}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:11:07,407] Trial 63 finished with value: 0.09554602447920091 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2, 'learning_rate': 0.010888447979396837, 'p_miss': 0.13702708092128887}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:11:08,377] Trial 64 finished with value: 0.19105733443961787 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:14:58,568] Trial 10 finished with value: 0.20749915652370365 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 882, 'learning_rate': 0.004139389721801232, 'p_miss': 0.1558556392038669}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:17:38,276] Trial 2 finished with value: 0.2042153296441918 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:17:59,626] Trial 67 finished with value: 0.09595958376999573 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6, 'learning_rate': 0.001544794516113476, 'p_miss': 0.21433694070375353}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:00,418] Trial 20 finished with value: 0.20508218836934883 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:12,759] Trial 68 finished with value: 0.09342135701734175 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 3, 'learning_rate': 0.0007579176000420361, 'p_miss': 0.1713091294689571}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:13,875] Trial 69 finished with value: 0.10250083741334215 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.0007645507012414555, 'p_miss': 0.17058533658655556}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:23,739] Trial 70 finished with value: 0.10010113975283068 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.0007873307621817217, 'p_miss': 0.17337671521237605}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:31,331] Trial 72 finished with value: 0.09185913484928857 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 1, 'learning_rate': 0.0015578688897835108, 'p_miss': 0.035102613772932785}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:32,483] Trial 73 finished with value: 0.19105733443961787 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:37,716] Trial 74 finished with value: 0.09805613158635074 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 1, 'learning_rate': 0.0026121589669488095, 'p_miss': 0.020828171388803315}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:42,965] Trial 75 finished with value: 0.1002979057480858 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 1, 'learning_rate': 0.00038965110481123947, 'p_miss': 0.03792796365174048}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:51,881] Trial 76 finished with value: 0.09462023167566735 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 2, 'learning_rate': 0.0014759693805751256, 'p_miss': 0.07225237441024805}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 13:18:59,080] Trial 77 finished with value: 0.13762677496408013 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 1, 'learning_rate': 0.09416179262865958, 'p_miss': 0.11964713070831423}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 14:02:25,600] Trial 65 finished with value: 0.2043661392811671 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 14:02:46,016] Trial 79 finished with value: 0.09166795426241661 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 4, 'learning_rate': 0.00010545881548432379, 'p_miss': 0.0468842295574529}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 14:02:56,031] Trial 80 finished with value: 0.0948933310505831 and parameters: {'model_name': 'VAE', 'batch_size': 170, 'iterations': 2, 'learning_rate': 0.00010608496088478883, 'p_miss': 0.050781002098928246}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 14:03:07,070] Trial 81 finished with value: 0.09718771119686144 and parameters: {'model_name': 'VAE', 'batch_size': 189, 'iterations': 2, 'learning_rate': 0.0035305637272998237, 'p_miss': 0.019164288761239663}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:45:22,920] Trial 29 finished with value: 0.20697357452000023 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5830, 'learning_rate': 0.09806665580178427, 'p_miss': 0.03491432388932239}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:45:33,197] Trial 83 finished with value: 0.34858399118170574 and parameters: {'model_name': 'GAIN', 'batch_size': 104, 'hint_rate': 0.9268775785463961, 'alpha': 61, 'iterations': 3, 'learning_rate': 0.005072322292872524, 'p_miss': 0.09959438555624375}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:55:16,867] Trial 32 finished with value: 0.20115766550935996 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5726, 'learning_rate': 0.0721283226930533, 'p_miss': 0.027792717144972723}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:55:18,163] Trial 85 finished with value: 0.29123281226479664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:56:20,631] Trial 86 finished with value: 0.1600227977245111 and parameters: {'model_name': 'VAE', 'batch_size': 391, 'iterations': 10, 'learning_rate': 0.008826808761462947, 'p_miss': 0.07364946769564261}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 16:56:36,837] Trial 87 finished with value: 0.10411246603494588 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 4, 'learning_rate': 0.0002265694515545407, 'p_miss': 0.04746593730911268}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:11:34,436] Trial 84 finished with value: 0.11294479247596209 and parameters: {'model_name': 'VAE', 'batch_size': 344, 'iterations': 494, 'learning_rate': 0.00016606348154426804, 'p_miss': 0.08375651628093089}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:11:56,600] Trial 89 finished with value: 0.09127888924780825 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.0029064861310182724, 'p_miss': 0.1529361830675834}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:12:45,489] Trial 90 finished with value: 0.26089836904087677 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:14:05,185] Trial 91 finished with value: 0.2175496686958011 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 66774, 'weights': 'distance'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:14:33,147] Trial 92 finished with value: 0.09243193226544258 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 5, 'learning_rate': 0.002058813209519947, 'p_miss': 0.13580256197354823}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:14:49,662] Trial 93 finished with value: 0.1013924378593698 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5, 'learning_rate': 0.0031575351683172164, 'p_miss': 0.14353261207010817}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:15:42,844] Trial 94 finished with value: 0.21621015946402222 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 13, 'learning_rate': 0.020802477481891932, 'p_miss': 0.10879853262877909}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:16:06,626] Trial 95 finished with value: 0.09418547159259114 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 8, 'learning_rate': 0.0019635954172915076, 'p_miss': 0.1254043948044455}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:17:28,533] Trial 96 finished with value: 0.10514181427029674 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 21, 'learning_rate': 0.0030880730935844507, 'p_miss': 0.16318112025991716}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:17:42,252] Trial 97 finished with value: 0.10734879102145067 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 3, 'learning_rate': 0.001519951967492904, 'p_miss': 0.14644290093490792}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:19:08,254] Trial 98 finished with value: 0.10673043738825112 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 27, 'learning_rate': 0.0027002609245621416, 'p_miss': 0.13329793803636608}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:19:24,116] Trial 99 finished with value: 0.10063198869772325 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 4, 'learning_rate': 0.004595161980026538, 'p_miss': 0.01070002180590228}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:19:34,559] Trial 100 finished with value: 0.34017137231215905 and parameters: {'model_name': 'GAIN', 'batch_size': 78, 'hint_rate': 0.39461220461205077, 'alpha': 5, 'iterations': 3, 'learning_rate': 0.0013546312025507952, 'p_miss': 0.15551506694363132}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:19:43,918] Trial 101 finished with value: 0.10144308015552905 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 2, 'learning_rate': 0.0019988274564748812, 'p_miss': 0.1829857479663854}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:27:59,688] Trial 88 finished with value: 0.1161555025867669 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 606, 'learning_rate': 0.00014919365501553982, 'p_miss': 0.14686870407978025}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:28:17,607] Trial 103 finished with value: 0.09602931991940167 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0009507698611581003, 'p_miss': 0.11788556807529108}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:29:10,297] Trial 104 finished with value: 0.18680786411422076 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3438, 'weights': 'uniform'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:30:02,751] Trial 105 finished with value: 0.2020447137318563 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:30:34,045] Trial 106 finished with value: 0.09588871297600303 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 8, 'learning_rate': 0.0012914876095237538, 'p_miss': 0.13965881032961877}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:30:51,940] Trial 107 finished with value: 0.09836020730711799 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.002191016814187292, 'p_miss': 0.16670285577708438}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:30:57,764] Trial 108 finished with value: 0.10373943741185639 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 1, 'learning_rate': 0.0016981768967811448, 'p_miss': 0.2003813699669537}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:31:18,353] Trial 109 finished with value: 0.09278336741917168 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0010095209802603003, 'p_miss': 0.17784605111166188}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:31:29,544] Trial 110 finished with value: 0.11063086266775479 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0006535226711985908, 'p_miss': 0.17806723183815124}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:32:04,034] Trial 111 finished with value: 0.10645770485627207 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 10, 'learning_rate': 0.0010762760284164022, 'p_miss': 0.15804809843962067}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:32:15,749] Trial 112 finished with value: 0.09327321547978593 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 2, 'learning_rate': 0.004165855910116219, 'p_miss': 0.12399697508678864}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:36:57,666] Trial 102 finished with value: 0.18898920366341052 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 319, 'learning_rate': 0.0009878260831461855, 'p_miss': 0.11627140794909023}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:37:15,652] Trial 114 finished with value: 0.09258738027638577 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 5, 'learning_rate': 0.0037754791691556855, 'p_miss': 0.1295335994226899}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:37:16,477] Trial 115 finished with value: 0.364829351508016 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:40:16,662] Trial 38 finished with value: 0.20219740770489913 and parameters: {'model_name': 'VAE', 'batch_size': 155, 'iterations': 5208, 'learning_rate': 0.00105528605249957, 'p_miss': 0.02927927072763395}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:40:36,984] Trial 117 finished with value: 0.10229789535345701 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 6, 'learning_rate': 0.007504535236789933, 'p_miss': 0.1295857703854755}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:40:54,953] Trial 118 finished with value: 0.09353321562741632 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 5, 'learning_rate': 0.003797312764071095, 'p_miss': 0.10365046083521252}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:46:13,011] Trial 119 finished with value: 0.18563582947647772 and parameters: {'model_name': 'VAE', 'batch_size': 950, 'iterations': 55, 'learning_rate': 0.0029488035593030417, 'p_miss': 0.12773643221701456}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 17:46:21,646] Trial 120 finished with value: 0.09278354811653886 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 2, 'learning_rate': 0.002418480510869675, 'p_miss': 0.13589822553861194}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:05:06,240] Trial 39 finished with value: 0.20078866257306865 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 5967, 'learning_rate': 0.0009224257479548638, 'p_miss': 0.18989476587709192}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:13:35,291] Trial 78 finished with value: 0.2057281241612067 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 5016, 'learning_rate': 0.0018206665554935404, 'p_miss': 0.03893962692868318}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:16:16,396] Trial 123 finished with value: 0.34656350824327575 and parameters: {'model_name': 'GAIN', 'batch_size': 41, 'hint_rate': 0.044014163036014575, 'alpha': 99, 'iterations': 108, 'learning_rate': 0.002425072334947422, 'p_miss': 0.14170133273813462}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:16:32,810] Trial 124 finished with value: 0.09147264802676408 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.005048048524466728, 'p_miss': 0.15297097477856583}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:17:13,485] Trial 125 finished with value: 0.09777396016061883 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 11, 'learning_rate': 0.0048920853018920366, 'p_miss': 0.16094310665264128}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:17:32,317] Trial 126 finished with value: 0.09184680083897102 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 4, 'learning_rate': 0.0034134253570599223, 'p_miss': 0.15207621417346923}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:17:54,452] Trial 127 finished with value: 0.10135640300027729 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 5, 'learning_rate': 0.005287897408796474, 'p_miss': 0.14919111834700657}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:18:31,714] Trial 128 finished with value: 0.09522248443632675 and parameters: {'model_name': 'VAE', 'batch_size': 117, 'iterations': 7, 'learning_rate': 0.0035964442042610845, 'p_miss': 0.15182475536470086}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:18:47,877] Trial 129 finished with value: 0.09673432886228182 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 4, 'learning_rate': 0.0027963302215803626, 'p_miss': 0.13776715650586482}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:25:39,023] Trial 31 finished with value: 0.21003928118719006 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7343, 'learning_rate': 0.08633074193839188, 'p_miss': 0.011610059078283552}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 18:26:06,552] Trial 131 finished with value: 0.10077335294316922 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 6, 'learning_rate': 0.00758565949870081, 'p_miss': 0.05608095415990598}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:08:34,164] Trial 37 finished with value: 0.20198111539595026 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 6010, 'learning_rate': 0.0006891500476866947, 'p_miss': 0.021310056196254534}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:09:03,369] Trial 121 finished with value: 0.20564192266501288 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 1616, 'learning_rate': 0.0024072941744359426, 'p_miss': 0.13632080423852197}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:09:30,050] Trial 133 finished with value: 0.20326135097460715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:09:58,238] Trial 134 finished with value: 0.20326135097460715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:10:07,376] Trial 135 finished with value: 0.10199245337795051 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 8, 'learning_rate': 0.004256001884049408, 'p_miss': 0.26676410175692333}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:10:10,197] Trial 136 finished with value: 0.0954888650336686 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 3, 'learning_rate': 0.0032236837697520726, 'p_miss': 0.15428992548309226}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:10:24,434] Trial 137 finished with value: 0.09795433227446682 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 3, 'learning_rate': 0.003435870331935075, 'p_miss': 0.028642268444446672}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:10:26,772] Trial 138 finished with value: 0.09296241741029557 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 4, 'learning_rate': 0.002126257999123358, 'p_miss': 0.13231386021490912}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:11:20,082] Trial 122 finished with value: 0.2032647307284746 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 1196, 'learning_rate': 0.002475191942279038, 'p_miss': 0.14044181193555447}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:11:54,240] Trial 139 finished with value: 0.2175496686958011 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 66456, 'weights': 'distance'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:11:56,201] Trial 140 finished with value: 0.2175496686958011 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 60357, 'weights': 'distance'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:00,571] Trial 142 finished with value: 0.09256293045286182 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 1, 'learning_rate': 0.0017187345953327447, 'p_miss': 0.1087014984357658}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:01,634] Trial 143 finished with value: 0.09461245774342567 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 1, 'learning_rate': 0.0016686192397875738, 'p_miss': 0.12301967585607758}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:02,412] Trial 144 finished with value: 0.364829351508016 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:24,033] Trial 145 finished with value: 0.09641153463823246 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5, 'learning_rate': 0.0013234939482809213, 'p_miss': 0.08194050143000389}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:25,348] Trial 146 finished with value: 0.09678265389261373 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5, 'learning_rate': 0.001402111194613521, 'p_miss': 0.11190801859470048}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:32,967] Trial 147 finished with value: 0.09990761780692434 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 2, 'learning_rate': 0.0018683758355361494, 'p_miss': 0.10978551569319844}. Best is trial 58 with value: 0.09098321402498324.
running
[I 2024-11-23 19:12:33,597] Trial 148 finished with value: 0.08985893363907198 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 2, 'learning_rate': 0.0019046231659502568, 'p_miss': 0.10713712445934839}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:12:39,259] Trial 149 finished with value: 0.09086898986869166 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1, 'learning_rate': 0.002140014091225221, 'p_miss': 0.14609137276629608}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:12:41,647] Trial 150 finished with value: 0.10322533489805072 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1, 'learning_rate': 0.0016296699127375627, 'p_miss': 0.10389442883393836}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:12:45,922] Trial 151 finished with value: 0.0959184436615513 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.0055786273307607236, 'p_miss': 0.1032999900999065}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:12:46,082] Trial 141 finished with value: 0.2175496686958011 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 70269, 'weights': 'distance'}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:12:48,665] Trial 152 finished with value: 0.09684803204585052 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.005978178301379802, 'p_miss': 0.09471455123431596}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:07,252] Trial 155 finished with value: 0.09182511189268536 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0020650534112582027, 'p_miss': 0.12008794674257964}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:13,799] Trial 154 finished with value: 0.10196952775078136 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.00207768864675762, 'p_miss': 0.0909662665838381}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:19,010] Trial 153 finished with value: 0.2189185038466563 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 7, 'learning_rate': 0.027575309759731707, 'p_miss': 0.11976994489849271}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:23,123] Trial 156 finished with value: 0.09900375649139281 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0028377260013145384, 'p_miss': 0.12011078137679879}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:29,736] Trial 157 finished with value: 0.09430923339619825 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 4, 'learning_rate': 0.0027931087768576254, 'p_miss': 0.1190155470726204}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:31,789] Trial 159 finished with value: 0.09313405385342274 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.0018471761510211837, 'p_miss': 0.14479006558454433}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:33,511] Trial 158 finished with value: 0.09913915726803177 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 4, 'learning_rate': 0.0028631068170161924, 'p_miss': 0.04510979834731446}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:43,879] Trial 162 finished with value: 0.3436908664692983 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.9571055785771325, 'alpha': 59, 'iterations': 3, 'learning_rate': 0.001192094969053917, 'p_miss': 0.13087450567098985}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:13:50,264] Trial 161 finished with value: 0.3561817549366636 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.9877331923946209, 'alpha': 58, 'iterations': 9, 'learning_rate': 0.004571227973051005, 'p_miss': 0.04278817918744421}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:14:09,319] Trial 163 finished with value: 0.09392164999999311 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 6, 'learning_rate': 0.0021581067447755536, 'p_miss': 0.14927667802861522}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:14:24,251] Trial 165 finished with value: 0.10193888711505934 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 2, 'learning_rate': 0.003801428283385671, 'p_miss': 0.11377476438531157}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:14:46,572] Trial 166 finished with value: 0.09515310318487365 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6, 'learning_rate': 0.0014708503125910864, 'p_miss': 0.16013191281918895}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:02,249] Trial 116 finished with value: 0.20994291513464375 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 1839, 'learning_rate': 0.008159603188632592, 'p_miss': 0.13044977120303217}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:10,098] Trial 167 finished with value: 0.09577864565111555 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 5, 'learning_rate': 0.0018126172921985098, 'p_miss': 0.14273550681695196}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:25,265] Trial 169 finished with value: 0.09386587203923702 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 3, 'learning_rate': 0.001590822078662553, 'p_miss': 0.16831076088539926}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:26,546] Trial 168 finished with value: 0.10128508890776844 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 5, 'learning_rate': 0.0018110108735502788, 'p_miss': 0.03350388526372879}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:31,330] Trial 170 finished with value: 0.09314081436163499 and parameters: {'model_name': 'VAE', 'batch_size': 128, 'iterations': 1, 'learning_rate': 0.003214729364662472, 'p_miss': 0.1258267311333181}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:15:54,935] Trial 164 finished with value: 0.1554820396506908 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 36, 'learning_rate': 0.003822307852431041, 'p_miss': 0.15049945962987357}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:16:20,504] Trial 171 finished with value: 0.10700827576704616 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 15, 'learning_rate': 0.0032539692525913465, 'p_miss': 0.15693396871251497}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:16:28,447] Trial 172 finished with value: 0.0965324558257828 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 17, 'learning_rate': 0.0002641421585958584, 'p_miss': 0.17545849791092882}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:16:32,511] Trial 173 finished with value: 0.09138654640778068 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 12, 'learning_rate': 0.0022125156182888736, 'p_miss': 0.1768739714635809}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:16:45,099] Trial 176 finished with value: 0.09677385022920748 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.0022793251744661824, 'p_miss': 0.13832825471870822}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:16:51,518] Trial 174 finished with value: 0.09746685624885622 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9, 'learning_rate': 0.002285277119471177, 'p_miss': 0.06511926029451973}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:17:04,542] Trial 178 finished with value: 0.11251391483506648 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.0011603838430819054, 'p_miss': 0.083882645256592}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:17:22,981] Trial 177 finished with value: 0.0918147956647131 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9, 'learning_rate': 0.0020619314881939123, 'p_miss': 0.18273710795475412}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:17:24,539] Trial 180 finished with value: 0.29123281226479664 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:17:46,536] Trial 179 finished with value: 0.0986433645368151 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 12, 'learning_rate': 0.002028894338569378, 'p_miss': 0.18468215383696854}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:18:06,788] Trial 181 finished with value: 0.21660148579780847 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 12, 'learning_rate': 0.05152249484787592, 'p_miss': 0.1855567441851178}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:18:33,745] Trial 183 finished with value: 0.09585461149683897 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7, 'learning_rate': 0.0025584873541425845, 'p_miss': 0.16420575818999034}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:19:12,666] Trial 184 finished with value: 0.09366470313134286 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 9, 'learning_rate': 0.002648721260325282, 'p_miss': 0.1452685993094429}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:19:26,441] Trial 185 finished with value: 0.10007464471639307 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 2, 'learning_rate': 0.013038474816167612, 'p_miss': 0.198292956841096}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:20:35,910] Trial 186 finished with value: 0.09903084806636384 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 24, 'learning_rate': 0.0015002558819046327, 'p_miss': 0.20901585724303845}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:21:02,762] Trial 187 finished with value: 0.10069433649880691 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 6, 'learning_rate': 0.0020328082671288877, 'p_miss': 0.17747589647262993}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:21:21,545] Trial 188 finished with value: 0.09949774091526127 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 5, 'learning_rate': 0.0003946503016322218, 'p_miss': 0.10659297451137209}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:21:39,283] Trial 189 finished with value: 0.09167723808207466 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.0016638240232923352, 'p_miss': 0.13290208083382912}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:21:54,753] Trial 190 finished with value: 0.09347940945246674 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 4, 'learning_rate': 0.0017642665110598203, 'p_miss': 0.13220376812970835}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:22:06,793] Trial 191 finished with value: 0.09818702834376093 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0022890629994281545, 'p_miss': 0.11485790245226615}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:27:55,088] Trial 175 finished with value: 0.1363957120427965 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 195, 'learning_rate': 0.0005365094365852758, 'p_miss': 0.10716205177375539}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:02,071] Trial 193 finished with value: 0.0921742855973636 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 1, 'learning_rate': 0.0013398957326852493, 'p_miss': 0.12742989822833586}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:19,008] Trial 30 finished with value: 0.20210452934946238 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8745, 'learning_rate': 0.0637877488075958, 'p_miss': 0.011901313538288383}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:21,540] Trial 182 finished with value: 0.20207690967480718 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 207, 'learning_rate': 0.0025587271855695456, 'p_miss': 0.20469532353912132}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:24,405] Trial 196 finished with value: 0.09873626467100169 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.001368063283173862, 'p_miss': 0.12488935248577568}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:26,645] Trial 192 finished with value: 0.1619307303785149 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 165, 'learning_rate': 0.001347657627614102, 'p_miss': 0.12412814741073583}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:27,789] Trial 197 finished with value: 0.0984915346754455 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 1, 'learning_rate': 0.0016504125835598309, 'p_miss': 0.13591061091229076}. Best is trial 148 with value: 0.08985893363907198.
running
[I 2024-11-23 19:28:29,771] Trial 198 finished with value: 0.10657923318932552 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 1, 'learning_rate': 0.0016004195008048588, 'p_miss': 0.1336940271978908}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:28:32,759] Trial 199 finished with value: 0.10003183241924649 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 4, 'learning_rate': 0.0020819252463601602, 'p_miss': 0.12870366985321782}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:28:34,632] Trial 194 finished with value: 0.18999678044900184 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:28:57,522] Trial 195 finished with value: 0.26402930526197316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:31:25,678] Trial 130 finished with value: 0.2030415132986338 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1288, 'learning_rate': 0.007181308890984536, 'p_miss': 0.04461810649866374}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:37:42,888] Trial 34 finished with value: 0.20139029302675127 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 9311, 'learning_rate': 0.04758775906302107, 'p_miss': 0.01966051647133643}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:50:02,673] Trial 33 finished with value: 0.2043906919696748 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 9889, 'learning_rate': 0.08588015827681725, 'p_miss': 0.03717653679692333}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 19:55:03,406] Trial 132 finished with value: 0.2014599200176625 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 1710, 'learning_rate': 0.004192990318758821, 'p_miss': 0.11037013116530714}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:02:34,014] Trial 113 finished with value: 0.2038378395309978 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 3709, 'learning_rate': 0.004466648715871562, 'p_miss': 0.1282022513072991}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:05:09,232] Trial 160 finished with value: 0.35642468082575135 and parameters: {'model_name': 'GAIN', 'batch_size': 99, 'hint_rate': 0.938859837790488, 'alpha': 59, 'iterations': 3556, 'learning_rate': 0.0018309634350361613, 'p_miss': 0.042957449915986316}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:15:22,162] Trial 82 finished with value: 0.20235828680680318 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 8496, 'learning_rate': 0.00846626172514036, 'p_miss': 0.04138456611978543}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:16:37,897] Trial 66 finished with value: 0.2119498168726061 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7990, 'learning_rate': 0.001484710441383951, 'p_miss': 0.20813063819535316}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:20:26,755] Trial 71 finished with value: 0.20766625788394616 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 8802, 'learning_rate': 0.0005041263910488046, 'p_miss': 0.11258160030446482}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:21:56,625] Trial 40 finished with value: 0.20148073514972425 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 9721, 'learning_rate': 0.0011925616524002386, 'p_miss': 0.09654656326196553}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:22:47,407] Trial 27 finished with value: 0.19927776491710403 and parameters: {'model_name': 'VAE', 'batch_size': 983, 'iterations': 8776, 'learning_rate': 0.09491316846542597, 'p_miss': 0.021910323527721265}. Best is trial 148 with value: 0.08985893363907198.
[I 2024-11-23 20:22:57,763] Trial 25 finished with value: 0.19932218012627226 and parameters: {'model_name': 'VAE', 'batch_size': 413, 'iterations': 9937, 'learning_rate': 0.09201218319816944, 'p_miss': 0.010159894968118782}. Best is trial 148 with value: 0.08985893363907198.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.08985893363907198
{'model_name': 'VAE', 'batch_size': 14, 'iterations': 2, 'learning_rate': 0.0019046231659502568, 'p_miss': 0.10713712445934839}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470c130> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.6059643684668734
Generation:   4%|▍         | 1/25 [05:01<2:00:28, 301.17s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f6260> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.6067900905215308
Generation:   8%|▊         | 2/25 [08:28<1:34:19, 246.08s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474733c10> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.6067900905215308
Generation:  12%|█▏        | 3/25 [13:33<1:40:08, 273.12s/it]Generation:  4
Best f1_score score: 0.6067900905215308
Generation:  16%|█▌        | 4/25 [15:58<1:17:45, 222.18s/it]Generation:  5
Best f1_score score: 0.6067900905215308
Generation:  20%|██        | 5/25 [18:21<1:04:37, 193.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474731c60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474731ea0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.6067900905215308
Generation:  24%|██▍       | 6/25 [21:10<58:39, 185.24s/it]  Generation:  7
Best f1_score score: 0.6067900905215308
Generation:  28%|██▊       | 7/25 [24:08<54:51, 182.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466c2b910> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.6067900905215308
Generation:  32%|███▏      | 8/25 [26:31<48:15, 170.32s/it]Generation:  9
Best f1_score score: 0.6067900905215308
Generation:  36%|███▌      | 9/25 [31:35<56:32, 212.06s/it]Generation:  10
Best f1_score score: 0.6067900905215308
Generation:  40%|████      | 10/25 [39:48<1:14:42, 298.84s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474712230> 

Generation:  11
Best f1_score score: 0.6067900905215308
Generation:  44%|████▍     | 11/25 [49:54<1:31:36, 392.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b70eb0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451b4c310> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.6067900905215308
Generation:  48%|████▊     | 12/25 [52:01<1:07:35, 311.99s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e76710> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ffcee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d688e0> 

Generation:  13
Best f1_score score: 0.6067900905215308
Generation:  52%|█████▏    | 13/25 [1:02:10<1:20:22, 401.84s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d29d20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.6067900905215308
Generation:  56%|█████▌    | 14/25 [1:04:21<58:42, 320.21s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546471d120> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.6067900905215308
Generation:  60%|██████    | 15/25 [1:08:49<50:43, 304.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d6ce50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544ceb7970> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.6067900905215308
Generation:  64%|██████▍   | 16/25 [1:11:16<38:32, 256.97s/it]Generation:  17
Best f1_score score: 0.6067900905215308
Generation:  68%|██████▊   | 17/25 [1:16:48<37:17, 279.72s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554648f1360> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  18
Best f1_score score: 0.6067900905215308
Generation:  72%|███████▏  | 18/25 [1:20:34<30:44, 263.49s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f4f70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b1f5b0> 

Generation:  19
Best f1_score score: 0.6067900905215308
Generation:  76%|███████▌  | 19/25 [1:30:45<36:46, 367.78s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676f4730> 

Generation:  20
Best f1_score score: 0.6067900905215308
Generation:  80%|████████  | 20/25 [1:40:55<36:42, 440.45s/it]Generation:  21
Best f1_score score: 0.6067900905215308
Generation:  84%|████████▍ | 21/25 [1:44:04<24:20, 365.18s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652e7430> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  22
Best f1_score score: 0.6067900905215308
Generation:  88%|████████▊ | 22/25 [1:46:25<14:53, 297.82s/it]Generation:  23
Best f1_score score: 0.6067900905215308
Generation:  92%|█████████▏| 23/25 [1:48:36<08:15, 247.77s/it]Generation:  24
Best f1_score score: 0.6067900905215308
Generation:  96%|█████████▌| 24/25 [1:56:50<05:21, 321.66s/it]Generation:  25
Best f1_score score: 0.6067900905215308
Generation: 100%|██████████| 25/25 [2:00:22<00:00, 288.87s/it]Generation: 100%|██████████| 25/25 [2:00:26<00:00, 289.05s/it]
2024-11-23 22:23:48,978 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45553' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-a3a0dca8dfbd2e0d6e6757ca0dceb219', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732429428.9779887')
Fitted
Pipeline(steps=[('adaboostclassifier',
                 AdaBoostClassifier(algorithm='SAMME',
                                    learning_rate=0.5696997875579,
                                    n_estimators=289))])
score start
train score: {'auroc': 0.642415627154665, 'accuracy': 0.6074220403555807, 'balanced_accuracy': 0.607407451345596, 'logloss': 0.6631080321140242, 'f1': 0.6073824121075708}
original test score: {'auroc': 0.29222484201250265, 'accuracy': 0.3346314482447229, 'balanced_accuracy': 0.3346318379886976, 'logloss': 0.7537662014535671, 'f1': 0.3346313952572852}
imputed test score: {'auroc': 0.5285515786262743, 'accuracy': 0.5185122474319901, 'balanced_accuracy': 0.5185125612427919, 'logloss': 0.7019720950804634, 'f1': 0.518512061847624}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435018580>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4f40> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 727, in predict
    pred = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 788, in decision_function
    X = self._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4d60> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4fa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4fa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4e50> 

Generation:  1
Best f1_score score: 0.866570644062447
Generation:   4%|▍         | 1/25 [10:03<4:01:17, 603.23s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471e200> 

Generation:  2
Best f1_score score: 0.8734417326047639
Generation:   8%|▊         | 2/25 [20:07<3:51:23, 603.64s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471ed40> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554665a71c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471d690> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471fa00> 

Generation:  3
Best f1_score score: 0.8734417326047639
Generation:  12%|█▏        | 3/25 [30:12<3:41:33, 604.27s/it]Generation:  4
Best f1_score score: 0.8762024578494806
Generation:  16%|█▌        | 4/25 [35:29<2:51:51, 491.04s/it]Generation:  5
Best f1_score score: 0.8810892248460691
Generation:  20%|██        | 5/25 [36:20<1:50:45, 332.27s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eacc40> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464caeef0> 

Generation:  6
Best f1_score score: 0.8810892248460691
Generation:  24%|██▍       | 6/25 [46:25<2:14:33, 424.92s/it]Generation:  7
Best f1_score score: 0.8810892248460691
Generation:  28%|██▊       | 7/25 [48:17<1:36:46, 322.58s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f39300> 

Generation:  8
Best f1_score score: 0.8827040753606635
Generation:  32%|███▏      | 8/25 [58:22<1:56:52, 412.52s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467cf4610> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464cbe3e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471f850> 

Generation:  9
Best f1_score score: 0.8827040753606635
Generation:  36%|███▌      | 9/25 [1:08:28<2:06:10, 473.16s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467845ed0> 

Generation:  10
Best f1_score score: 0.8827040753606635
Generation:  40%|████      | 10/25 [1:18:33<2:08:29, 513.94s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546730e590> 

Generation:  11
Best f1_score score: 0.8827040753606635
Generation:  44%|████▍     | 11/25 [1:28:37<2:06:18, 541.35s/it]Generation:  12
Best f1_score score: 0.883009321114324
Generation:  48%|████▊     | 12/25 [1:31:11<1:31:48, 423.70s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a6b00> 

Generation:  13
Best f1_score score: 0.883009321114324
Generation:  52%|█████▏    | 13/25 [1:41:16<1:35:43, 478.59s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c43580> 

Generation:  14
Best f1_score score: 0.883009321114324
Generation:  56%|█████▌    | 14/25 [1:51:22<1:34:46, 516.93s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467bd3a00> 

Generation:  15
Best f1_score score: 0.883009321114324
Generation:  60%|██████    | 15/25 [2:01:28<1:30:38, 543.84s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a43460> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467dc2530> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f45b70> 

Generation:  16
Best f1_score score: 0.883009321114324
Generation:  64%|██████▍   | 16/25 [2:11:34<1:24:22, 562.50s/it]Generation:  17
Best f1_score score: 0.883009321114324
Generation:  68%|██████▊   | 17/25 [2:13:57<58:11, 436.45s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546756efe0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464eef2e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450cbde40> 

Generation:  18
Best f1_score score: 0.883009321114324
Generation:  72%|███████▏  | 18/25 [2:24:04<56:53, 487.63s/it]Generation:  19
Best f1_score score: 0.883009321114324
Generation:  76%|███████▌  | 19/25 [2:29:14<43:24, 434.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464dddbd0> 

Generation:  20
Best f1_score score: 0.883009321114324
Generation:  80%|████████  | 20/25 [2:39:21<40:31, 486.23s/it]Generation:  21
Best f1_score score: 0.883009321114324
Generation:  84%|████████▍ | 21/25 [2:41:49<25:38, 384.50s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546654d120> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454aa4100> 

Generation:  22
Best f1_score score: 0.883009321114324
Generation:  88%|████████▊ | 22/25 [2:51:57<22:35, 451.83s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b250> 

Generation:  23
Best f1_score score: 0.883009321114324
Generation:  92%|█████████▏| 23/25 [3:02:03<16:36, 498.09s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474709870> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554597a7df0> 

Generation:  24
Best f1_score score: 0.883009321114324
Generation:  96%|█████████▌| 24/25 [3:12:10<08:50, 530.72s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466b1ed70> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f50820> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466ca5e10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474707eb0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b8ed3c0> 

Generation:  25
Best f1_score score: 0.883009321114324
Generation: 100%|██████████| 25/25 [3:22:18<00:00, 553.83s/it]Generation: 100%|██████████| 25/25 [3:22:18<00:00, 485.54s/it]
2024-11-24 01:46:22,503 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34917' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-17e6a0c9b0ee68187c88f22d960e3205', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732441582.5031106')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),
                ('lgbmclassifier',
                 LGBMClassifier(max_depth=10, n_estimators=87, n_jobs=1,
                                num_leaves=226, verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9700788602603723, 'accuracy': 0.8959362212501764, 'balanced_accuracy': 0.8959736527969632, 'logloss': 0.21970898360197058, 'f1': 0.8958866120367708}
test score: {'auroc': 0.9438554613092214, 'accuracy': 0.8631335365165369, 'balanced_accuracy': 0.8631766315924536, 'logloss': 0.29145475372584234, 'f1': 0.8630416218997843}
original test score: {'auroc': 0.9990112087934909, 'accuracy': 0.9867930917710802, 'balanced_accuracy': 0.986802513223308, 'logloss': 0.037958841121971176, 'f1': 0.9867928358126797}
score end
40922
lvl
0.5
type
MNAR
num_run
1
class_full
finished
all finished
full run takes
13.350619023508496
hours
DONE
