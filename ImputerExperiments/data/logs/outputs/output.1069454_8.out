Run: 8
/cm/local/apps/slurm/var/spool/job1069454/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40922/40922.pkl
working on 
../data/c/40922/class_full_MAR_0.5_1
0.3370187282562256
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-23 11:13:05,607] A new study created in memory with name: no-name-b92db4f9-6c1a-4e47-a4ab-3260b0a515b7
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-23 11:13:06,179] Trial 4 finished with value: 0.17913090178550373 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:06,312] Trial 10 finished with value: 0.43039558592967975 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:06,692] Trial 9 finished with value: 0.43039558592967975 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:07,501] Trial 0 finished with value: 0.25535405913291287 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:08,817] Trial 18 finished with value: 0.2954882313812557 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:29,242] Trial 6 finished with value: 0.39860410170906796 and parameters: {'model_name': 'GAIN', 'batch_size': 21, 'hint_rate': 0.5864534195021954, 'alpha': 50, 'iterations': 5, 'learning_rate': 0.0020057891973839534, 'p_miss': 0.1526639764934633}. Best is trial 4 with value: 0.17913090178550373.
running
[I 2024-11-23 11:13:42,729] Trial 2 finished with value: 0.160214000183114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:44,411] Trial 21 finished with value: 0.40551191458231484 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.9444916008686568, 'alpha': 88, 'iterations': 7, 'learning_rate': 0.04562776071051661, 'p_miss': 0.11830145367693037}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:52,388] Trial 17 finished with value: 0.17913090178550373 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 61126, 'weights': 'uniform'}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:53,173] Trial 14 finished with value: 0.16940058573560574 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:53,837] Trial 22 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.0872250243069623, 'alpha': 55, 'iterations': 26, 'learning_rate': 0.08704592813301837, 'p_miss': 0.05284325201650093}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:55,149] Trial 12 finished with value: 0.17716256416064027 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22528, 'weights': 'uniform'}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:13:57,028] Trial 20 finished with value: 0.17913090178550373 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 66976, 'weights': 'uniform'}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:14:00,978] Trial 1 finished with value: 0.17541522564826256 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20419, 'weights': 'distance'}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:14:06,798] Trial 13 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.08479277866598604, 'alpha': 3, 'iterations': 211, 'learning_rate': 0.0018477989610614567, 'p_miss': 0.08648742652690027}. Best is trial 2 with value: 0.160214000183114.
running
[I 2024-11-23 11:14:08,025] Trial 11 finished with value: 0.15941439462452994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 11 with value: 0.15941439462452994.
running
[I 2024-11-23 11:14:14,477] Trial 15 finished with value: 0.11411830446371048 and parameters: {'model_name': 'VAE', 'batch_size': 926, 'iterations': 5, 'learning_rate': 0.001294042583751508, 'p_miss': 0.037800401204833016}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:29,592] Trial 25 finished with value: 0.160214000183114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:32,562] Trial 16 finished with value: 0.18910328270895163 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 31, 'learning_rate': 0.01974246826868623, 'p_miss': 0.0421765757579241}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:43,032] Trial 31 finished with value: 0.160214000183114 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:54,067] Trial 24 finished with value: 0.1636644342090169 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:59,311] Trial 28 finished with value: 0.1637565278703525 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:14:59,765] Trial 27 finished with value: 0.15994175033118324 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:15:03,968] Trial 26 finished with value: 0.16079009311722875 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:15:04,788] Trial 29 finished with value: 0.1638871533456423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:15:05,746] Trial 30 finished with value: 0.16031472806354377 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:22:02,813] Trial 3 finished with value: 0.39940180407014114 and parameters: {'model_name': 'GAIN', 'batch_size': 46, 'hint_rate': 0.1779351251653045, 'alpha': 33, 'iterations': 327, 'learning_rate': 0.0009108165747812768, 'p_miss': 0.151989274470244}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:26:41,638] Trial 5 finished with value: 0.1417440046919987 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 148, 'learning_rate': 0.0004791198644726005, 'p_miss': 0.2684562419449087}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:30:59,052] Trial 7 finished with value: 0.18635468014275278 and parameters: {'model_name': 'VAE', 'batch_size': 712, 'iterations': 208, 'learning_rate': 0.010772639608755758, 'p_miss': 0.16847517798862333}. Best is trial 15 with value: 0.11411830446371048.
running
[I 2024-11-23 11:31:10,718] Trial 44 finished with value: 0.1078981925401783 and parameters: {'model_name': 'VAE', 'batch_size': 722, 'iterations': 1, 'learning_rate': 0.0001231247997210924, 'p_miss': 0.2887555081842541}. Best is trial 44 with value: 0.1078981925401783.
running
[I 2024-11-23 11:31:20,066] Trial 45 finished with value: 0.11205656403919884 and parameters: {'model_name': 'VAE', 'batch_size': 1000, 'iterations': 1, 'learning_rate': 0.00010251504436503311, 'p_miss': 0.2971168153058575}. Best is trial 44 with value: 0.1078981925401783.
running
[I 2024-11-23 11:31:28,596] Trial 46 finished with value: 0.10589044214446766 and parameters: {'model_name': 'VAE', 'batch_size': 834, 'iterations': 1, 'learning_rate': 0.00011620156832916518, 'p_miss': 0.2975166127222504}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 11:31:40,294] Trial 47 finished with value: 0.11618605472628393 and parameters: {'model_name': 'VAE', 'batch_size': 978, 'iterations': 1, 'learning_rate': 0.00012092904915413499, 'p_miss': 0.2995839553020097}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 11:31:49,169] Trial 48 finished with value: 0.10937202026136097 and parameters: {'model_name': 'VAE', 'batch_size': 406, 'iterations': 1, 'learning_rate': 0.00010191294205229305, 'p_miss': 0.2446625382086586}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 11:31:56,455] Trial 49 finished with value: 0.11300073565125701 and parameters: {'model_name': 'VAE', 'batch_size': 259, 'iterations': 1, 'learning_rate': 0.00010397289640176122, 'p_miss': 0.24710674079558403}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:28:14,201] Trial 23 finished with value: 0.4087863946456537 and parameters: {'model_name': 'GAIN', 'batch_size': 95, 'hint_rate': 0.48962079760358185, 'alpha': 2, 'iterations': 2273, 'learning_rate': 0.0006026894375847727, 'p_miss': 0.1963880464587735}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:28:21,517] Trial 51 finished with value: 0.12376915817137783 and parameters: {'model_name': 'VAE', 'batch_size': 394, 'iterations': 1, 'learning_rate': 0.0002054134764045195, 'p_miss': 0.293956884223823}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:28:38,534] Trial 52 finished with value: 0.11536875377027915 and parameters: {'model_name': 'VAE', 'batch_size': 431, 'iterations': 2, 'learning_rate': 0.0002485455930672397, 'p_miss': 0.25492460401333095}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:28:59,292] Trial 53 finished with value: 0.10666885135178987 and parameters: {'model_name': 'VAE', 'batch_size': 353, 'iterations': 3, 'learning_rate': 0.0002602134853570436, 'p_miss': 0.23447143848233232}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:29:16,843] Trial 54 finished with value: 0.11598959594818939 and parameters: {'model_name': 'VAE', 'batch_size': 339, 'iterations': 3, 'learning_rate': 0.00029253838983116904, 'p_miss': 0.22548573675490352}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:29:33,203] Trial 55 finished with value: 0.11394435692653311 and parameters: {'model_name': 'VAE', 'batch_size': 151, 'iterations': 2, 'learning_rate': 0.00022089725052680084, 'p_miss': 0.22013111455808299}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:29:41,166] Trial 56 finished with value: 0.10876990006151288 and parameters: {'model_name': 'VAE', 'batch_size': 606, 'iterations': 1, 'learning_rate': 0.00011878998681054702, 'p_miss': 0.2818306419058333}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:29:49,622] Trial 57 finished with value: 0.11664789633613475 and parameters: {'model_name': 'VAE', 'batch_size': 443, 'iterations': 1, 'learning_rate': 0.00017329373171559055, 'p_miss': 0.2678101191520522}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:30:52,659] Trial 58 finished with value: 0.10939160802812294 and parameters: {'model_name': 'VAE', 'batch_size': 496, 'iterations': 11, 'learning_rate': 0.0003797591855514377, 'p_miss': 0.2717156707700137}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:31:05,095] Trial 59 finished with value: 0.11589232118354476 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 2, 'learning_rate': 0.00010720965756585938, 'p_miss': 0.24234405275402554}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:31:18,493] Trial 60 finished with value: 0.12002526403986377 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 2, 'learning_rate': 0.00017725717742339146, 'p_miss': 0.28023526977100344}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:31:28,516] Trial 61 finished with value: 0.10988766963965409 and parameters: {'model_name': 'VAE', 'batch_size': 541, 'iterations': 1, 'learning_rate': 0.00016601660198123025, 'p_miss': 0.22351055182561214}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:31:53,932] Trial 62 finished with value: 0.11362139293116395 and parameters: {'model_name': 'VAE', 'batch_size': 260, 'iterations': 3, 'learning_rate': 0.0051656199584985485, 'p_miss': 0.2450224645693858}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:33:03,121] Trial 63 finished with value: 0.12269011317842862 and parameters: {'model_name': 'VAE', 'batch_size': 594, 'iterations': 11, 'learning_rate': 0.0003372805550040973, 'p_miss': 0.27515937720309136}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:33:04,806] Trial 64 finished with value: 0.25535405913291287 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:34:15,300] Trial 19 finished with value: 0.4129520045107046 and parameters: {'model_name': 'GAIN', 'batch_size': 85, 'hint_rate': 0.45731113257722045, 'alpha': 70, 'iterations': 2474, 'learning_rate': 0.0002260630858348282, 'p_miss': 0.08994065647282211}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:35:32,862] Trial 66 finished with value: 0.11020164855948603 and parameters: {'model_name': 'VAE', 'batch_size': 520, 'iterations': 13, 'learning_rate': 0.00042575451500048196, 'p_miss': 0.2762001449489592}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:35:59,853] Trial 67 finished with value: 0.1193343533586843 and parameters: {'model_name': 'VAE', 'batch_size': 589, 'iterations': 3, 'learning_rate': 0.00014277919588366158, 'p_miss': 0.26140662519167535}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:36:06,802] Trial 68 finished with value: 0.11582034615292791 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 1, 'learning_rate': 0.0006528245396829857, 'p_miss': 0.2847897707586242}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 12:36:38,711] Trial 69 finished with value: 0.17057679599495437 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6079, 'weights': 'distance'}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 13:10:48,838] Trial 8 finished with value: 0.41835986834879846 and parameters: {'model_name': 'GAIN', 'batch_size': 424, 'hint_rate': 0.08501874810731598, 'alpha': 23, 'iterations': 3242, 'learning_rate': 0.006142162752731702, 'p_miss': 0.0971501021503089}. Best is trial 46 with value: 0.10589044214446766.
running
[I 2024-11-23 13:11:03,689] Trial 71 finished with value: 0.10464897122130516 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 2, 'learning_rate': 0.00040569697689279147, 'p_miss': 0.1940230843204367}. Best is trial 71 with value: 0.10464897122130516.
running
[I 2024-11-23 13:11:19,070] Trial 72 finished with value: 0.10752967122909603 and parameters: {'model_name': 'VAE', 'batch_size': 185, 'iterations': 2, 'learning_rate': 0.0008121560244105092, 'p_miss': 0.17964207121405212}. Best is trial 71 with value: 0.10464897122130516.
running
[I 2024-11-23 14:11:26,203] Trial 73 finished with value: 0.1865097766865293 and parameters: {'model_name': 'VAE', 'batch_size': 180, 'iterations': 807, 'learning_rate': 0.0006802653157739221, 'p_miss': 0.17951776883065418}. Best is trial 71 with value: 0.10464897122130516.
running
[I 2024-11-23 14:11:28,966] Trial 74 finished with value: 0.2954882313812557 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 71 with value: 0.10464897122130516.
running
[I 2024-11-23 14:11:51,102] Trial 75 finished with value: 0.11072634563539555 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 4, 'learning_rate': 0.0009888001242571518, 'p_miss': 0.2002645770927361}. Best is trial 71 with value: 0.10464897122130516.
running
[I 2024-11-23 14:12:02,746] Trial 76 finished with value: 0.10380630727416187 and parameters: {'model_name': 'VAE', 'batch_size': 252, 'iterations': 2, 'learning_rate': 0.00014160436377207315, 'p_miss': 0.20294783557067828}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:12:19,695] Trial 77 finished with value: 0.10759371936982354 and parameters: {'model_name': 'VAE', 'batch_size': 259, 'iterations': 2, 'learning_rate': 0.00030348923331849554, 'p_miss': 0.18091373508834202}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:12:37,932] Trial 78 finished with value: 0.11447185272102718 and parameters: {'model_name': 'VAE', 'batch_size': 270, 'iterations': 2, 'learning_rate': 0.0004795612720316961, 'p_miss': 0.16919440253386553}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:13:13,396] Trial 79 finished with value: 0.10842704319946014 and parameters: {'model_name': 'VAE', 'batch_size': 145, 'iterations': 7, 'learning_rate': 0.0003180725816461962, 'p_miss': 0.13577584933168557}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:14:00,175] Trial 80 finished with value: 0.17762623743108624 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44129, 'weights': 'distance'}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:20:25,440] Trial 81 finished with value: 0.10645976029085862 and parameters: {'model_name': 'VAE', 'batch_size': 190, 'iterations': 76, 'learning_rate': 0.00025539010032873553, 'p_miss': 0.19179750332730627}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:24:51,749] Trial 82 finished with value: 0.1266161056266698 and parameters: {'model_name': 'VAE', 'batch_size': 185, 'iterations': 45, 'learning_rate': 0.0014428315702541147, 'p_miss': 0.19296885288912258}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:35:54,432] Trial 83 finished with value: 0.1201925022321521 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 125, 'learning_rate': 0.00047352049949724934, 'p_miss': 0.2108858955026602}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:49:27,012] Trial 40 finished with value: 0.18635765102224178 and parameters: {'model_name': 'VAE', 'batch_size': 980, 'iterations': 2159, 'learning_rate': 0.00012951762609753715, 'p_miss': 0.24348721614391644}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:49:28,336] Trial 85 finished with value: 0.17913090178550373 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:55:00,206] Trial 37 finished with value: 0.18785464195566356 and parameters: {'model_name': 'VAE', 'batch_size': 815, 'iterations': 2442, 'learning_rate': 0.00023727381205402895, 'p_miss': 0.2724281207779899}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:55:38,220] Trial 87 finished with value: 0.10885303122565201 and parameters: {'model_name': 'VAE', 'batch_size': 316, 'iterations': 5, 'learning_rate': 0.0002856315486608059, 'p_miss': 0.18074758937207205}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:55:51,109] Trial 88 finished with value: 0.10739504231135122 and parameters: {'model_name': 'VAE', 'batch_size': 203, 'iterations': 2, 'learning_rate': 0.00016536491689096028, 'p_miss': 0.14951244179329382}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:56:17,873] Trial 86 finished with value: 0.10853424177012919 and parameters: {'model_name': 'VAE', 'batch_size': 296, 'iterations': 68, 'learning_rate': 0.00026156328289587575, 'p_miss': 0.17858450784955546}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 14:56:31,464] Trial 90 finished with value: 0.3983380847793394 and parameters: {'model_name': 'GAIN', 'batch_size': 189, 'hint_rate': 0.9608421403837795, 'alpha': 92, 'iterations': 3, 'learning_rate': 0.00017274940576938566, 'p_miss': 0.14425140256777724}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:00:48,358] Trial 89 finished with value: 0.39980070184327404 and parameters: {'model_name': 'GAIN', 'batch_size': 199, 'hint_rate': 0.8990661756297702, 'alpha': 100, 'iterations': 139, 'learning_rate': 0.0031168116855008407, 'p_miss': 0.15488381401773907}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:07:59,825] Trial 91 finished with value: 0.13223161079415685 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 135, 'learning_rate': 0.0004291547324451429, 'p_miss': 0.1528073639775828}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:08:32,298] Trial 93 finished with value: 0.11810529222170603 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.0007650938386398559, 'p_miss': 0.16821798087448991}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:08:56,710] Trial 84 finished with value: 0.18685163288261467 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 404, 'learning_rate': 0.0009090444216543732, 'p_miss': 0.17918286426797253}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:09:11,381] Trial 94 finished with value: 0.17805322549553465 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 43428, 'weights': 'uniform'}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:09:21,871] Trial 96 finished with value: 0.11850460241187936 and parameters: {'model_name': 'VAE', 'batch_size': 129, 'iterations': 2, 'learning_rate': 0.00014846691770841792, 'p_miss': 0.20225179085667794}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:09:36,647] Trial 95 finished with value: 0.17821106183097885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 45293, 'weights': 'uniform'}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:09:42,109] Trial 97 finished with value: 0.11157353230113076 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4, 'learning_rate': 0.00021139176227205552, 'p_miss': 0.19050730579976358}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:10:11,756] Trial 98 finished with value: 0.11166640298606809 and parameters: {'model_name': 'VAE', 'batch_size': 746, 'iterations': 5, 'learning_rate': 0.00021165773463969264, 'p_miss': 0.1295320561292097}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:12:11,649] Trial 99 finished with value: 0.10598100703372038 and parameters: {'model_name': 'VAE', 'batch_size': 711, 'iterations': 21, 'learning_rate': 0.00014555346531921066, 'p_miss': 0.1349484690081588}. Best is trial 76 with value: 0.10380630727416187.
running
[I 2024-11-23 15:14:22,574] Trial 101 finished with value: 0.10365264323343218 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 30, 'learning_rate': 0.00033952744555768624, 'p_miss': 0.12011628902542783}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:16:02,186] Trial 102 finished with value: 0.10761166754816702 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 22, 'learning_rate': 0.0005746652681163718, 'p_miss': 0.10930210510056815}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:17:44,027] Trial 100 finished with value: 0.10840385012890548 and parameters: {'model_name': 'VAE', 'batch_size': 371, 'iterations': 76, 'learning_rate': 0.00013665478733496087, 'p_miss': 0.23211858915962602}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:19:21,060] Trial 104 finished with value: 0.1147312849741152 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 18, 'learning_rate': 0.00019097091920969113, 'p_miss': 0.1183228528044057}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:23:04,516] Trial 105 finished with value: 0.10792530088215975 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 50, 'learning_rate': 0.0002497786318232341, 'p_miss': 0.20967416338650646}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:27:10,055] Trial 106 finished with value: 0.18672915390518038 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 48, 'learning_rate': 0.015474857622831718, 'p_miss': 0.07310924501897348}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:29:48,486] Trial 107 finished with value: 0.12040661318500882 and parameters: {'model_name': 'VAE', 'batch_size': 159, 'iterations': 33, 'learning_rate': 0.00033386709552518456, 'p_miss': 0.16498265657128722}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:39:12,037] Trial 108 finished with value: 0.11623925858317927 and parameters: {'model_name': 'VAE', 'batch_size': 354, 'iterations': 89, 'learning_rate': 0.00015336156454620224, 'p_miss': 0.14219352218838335}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 15:39:38,984] Trial 109 finished with value: 0.10680022411887782 and parameters: {'model_name': 'VAE', 'batch_size': 287, 'iterations': 3, 'learning_rate': 0.0002683453791424969, 'p_miss': 0.12477256327901609}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 16:25:39,650] Trial 32 finished with value: 0.1864576729477288 and parameters: {'model_name': 'VAE', 'batch_size': 688, 'iterations': 2971, 'learning_rate': 0.00010317883770659298, 'p_miss': 0.28301578030069263}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 16:44:39,819] Trial 33 finished with value: 0.18638501646966793 and parameters: {'model_name': 'VAE', 'batch_size': 774, 'iterations': 3139, 'learning_rate': 0.00010186484701081102, 'p_miss': 0.2835681382637469}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 16:55:44,951] Trial 111 finished with value: 0.1271092946392268 and parameters: {'model_name': 'VAE', 'batch_size': 738, 'iterations': 257, 'learning_rate': 0.00024014688431766939, 'p_miss': 0.1222929657976797}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 16:56:24,016] Trial 113 finished with value: 0.11254720954040558 and parameters: {'model_name': 'VAE', 'batch_size': 446, 'iterations': 4, 'learning_rate': 0.0005073918912661616, 'p_miss': 0.09778418707788562}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 16:56:25,950] Trial 114 finished with value: 0.2954882313812557 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:07:44,380] Trial 112 finished with value: 0.12539459367707437 and parameters: {'model_name': 'VAE', 'batch_size': 218, 'iterations': 288, 'learning_rate': 0.00024534083271183924, 'p_miss': 0.12173226842839029}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:08:08,011] Trial 116 finished with value: 0.10368828759614121 and parameters: {'model_name': 'VAE', 'batch_size': 283, 'iterations': 3, 'learning_rate': 0.0003531705449469367, 'p_miss': 0.108598683738059}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:09:05,939] Trial 117 finished with value: 0.10942084814402327 and parameters: {'model_name': 'VAE', 'batch_size': 316, 'iterations': 8, 'learning_rate': 0.0003935389681938892, 'p_miss': 0.1002887055674074}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:09:24,095] Trial 118 finished with value: 0.10886909232498136 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 3, 'learning_rate': 0.0001320796964351617, 'p_miss': 0.08234769504831546}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:34:43,992] Trial 50 finished with value: 0.18768862836169803 and parameters: {'model_name': 'VAE', 'batch_size': 420, 'iterations': 4417, 'learning_rate': 0.00026824996265053977, 'p_miss': 0.24755372127671502}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:36:01,246] Trial 120 finished with value: 0.1066499159402167 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 17, 'learning_rate': 0.0001806896314740311, 'p_miss': 0.10627384000737157}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:37:39,306] Trial 121 finished with value: 0.11238819188642772 and parameters: {'model_name': 'VAE', 'batch_size': 102, 'iterations': 17, 'learning_rate': 0.0001854370379835873, 'p_miss': 0.10781374154249879}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:37:56,236] Trial 122 finished with value: 0.1687607084470261 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:40:44,815] Trial 123 finished with value: 0.11211958517802487 and parameters: {'model_name': 'VAE', 'batch_size': 238, 'iterations': 33, 'learning_rate': 0.00033909778835403587, 'p_miss': 0.12954331023242377}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:41:46,603] Trial 124 finished with value: 0.39733405852966663 and parameters: {'model_name': 'GAIN', 'batch_size': 134, 'hint_rate': 0.6764733263737239, 'alpha': 71, 'iterations': 27, 'learning_rate': 0.00012260813584517136, 'p_miss': 0.14491240553521134}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:42:44,727] Trial 125 finished with value: 0.18405601062991894 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 9, 'learning_rate': 0.04796032126988063, 'p_miss': 0.10985514620305672}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:42:57,224] Trial 126 finished with value: 0.10888761548036563 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 2, 'learning_rate': 0.0001563800718681029, 'p_miss': 0.13568485210056166}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:43:11,523] Trial 127 finished with value: 0.11790992361530765 and parameters: {'model_name': 'VAE', 'batch_size': 205, 'iterations': 3, 'learning_rate': 0.0002063826144736402, 'p_miss': 0.18933467514343452}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:44:40,981] Trial 128 finished with value: 0.1072814345502886 and parameters: {'model_name': 'VAE', 'batch_size': 309, 'iterations': 18, 'learning_rate': 0.00034156576455900297, 'p_miss': 0.08608475966193513}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:46:12,092] Trial 129 finished with value: 0.10597760878308644 and parameters: {'model_name': 'VAE', 'batch_size': 301, 'iterations': 15, 'learning_rate': 0.000390484813001771, 'p_miss': 0.07357128969845571}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:47:45,737] Trial 130 finished with value: 0.11568480829043166 and parameters: {'model_name': 'VAE', 'batch_size': 471, 'iterations': 15, 'learning_rate': 0.0003602852084618487, 'p_miss': 0.08711582847086818}. Best is trial 101 with value: 0.10365264323343218.
running
[I 2024-11-23 17:50:36,014] Trial 131 finished with value: 0.10352922853187137 and parameters: {'model_name': 'VAE', 'batch_size': 872, 'iterations': 22, 'learning_rate': 0.00028696906125258036, 'p_miss': 0.06161344117839604}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 17:53:48,949] Trial 132 finished with value: 0.10784666527840192 and parameters: {'model_name': 'VAE', 'batch_size': 946, 'iterations': 24, 'learning_rate': 0.0005222087500526887, 'p_miss': 0.06412598554538966}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:00:44,898] Trial 133 finished with value: 0.11273559564124669 and parameters: {'model_name': 'VAE', 'batch_size': 596, 'iterations': 43, 'learning_rate': 0.00029524465835371877, 'p_miss': 0.050289262311380076}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:01:36,453] Trial 134 finished with value: 0.10365018264708074 and parameters: {'model_name': 'VAE', 'batch_size': 800, 'iterations': 6, 'learning_rate': 0.00041943736045493575, 'p_miss': 0.07480910871440628}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:03:03,418] Trial 135 finished with value: 0.1075581186969449 and parameters: {'model_name': 'VAE', 'batch_size': 708, 'iterations': 10, 'learning_rate': 0.00042764526459522213, 'p_miss': 0.06403051606318456}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:04:30,129] Trial 136 finished with value: 0.11431815347064456 and parameters: {'model_name': 'VAE', 'batch_size': 386, 'iterations': 13, 'learning_rate': 0.000287890218720688, 'p_miss': 0.03821081360439983}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:06:10,232] Trial 137 finished with value: 0.11177509936111071 and parameters: {'model_name': 'VAE', 'batch_size': 875, 'iterations': 13, 'learning_rate': 0.0003959616682021733, 'p_miss': 0.07250549103931778}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:08:15,487] Trial 138 finished with value: 0.11181124305454207 and parameters: {'model_name': 'VAE', 'batch_size': 820, 'iterations': 21, 'learning_rate': 0.0002308107591511552, 'p_miss': 0.10255438571482114}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:09:02,668] Trial 139 finished with value: 0.10705051172954543 and parameters: {'model_name': 'VAE', 'batch_size': 524, 'iterations': 6, 'learning_rate': 0.000585370044015088, 'p_miss': 0.05182048973929118}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:09:03,755] Trial 140 finished with value: 0.17913090178550373 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:09:40,219] Trial 141 finished with value: 0.10373404180902779 and parameters: {'model_name': 'VAE', 'batch_size': 668, 'iterations': 4, 'learning_rate': 0.00011838331739025227, 'p_miss': 0.02872819856126929}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:10:20,603] Trial 142 finished with value: 0.11457680706686812 and parameters: {'model_name': 'VAE', 'batch_size': 647, 'iterations': 5, 'learning_rate': 0.00010148996256360829, 'p_miss': 0.07638507809709075}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:10:47,927] Trial 143 finished with value: 0.15123418968112587 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 223, 'weights': 'distance'}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 18:13:49,644] Trial 144 finished with value: 0.11201973062345713 and parameters: {'model_name': 'VAE', 'batch_size': 639, 'iterations': 39, 'learning_rate': 0.00011565943294087858, 'p_miss': 0.023289504045113915}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 19:15:41,037] Trial 145 finished with value: 0.1909938524029164 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 19:16:24,049] Trial 146 finished with value: 0.11127827485576539 and parameters: {'model_name': 'VAE', 'batch_size': 843, 'iterations': 4, 'learning_rate': 0.00013846379624139158, 'p_miss': 0.013909302961182472}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 19:19:21,095] Trial 147 finished with value: 0.111477860315396 and parameters: {'model_name': 'VAE', 'batch_size': 510, 'iterations': 30, 'learning_rate': 0.00019486588773444575, 'p_miss': 0.2338755940878049}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 19:25:55,798] Trial 148 finished with value: 0.10941732250708176 and parameters: {'model_name': 'VAE', 'batch_size': 275, 'iterations': 62, 'learning_rate': 0.00017320298452923368, 'p_miss': 0.113269655587365}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 19:26:31,797] Trial 149 finished with value: 0.11909784134003967 and parameters: {'model_name': 'VAE', 'batch_size': 408, 'iterations': 6, 'learning_rate': 0.0002638052409400909, 'p_miss': 0.034032677106794244}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 20:11:19,935] Trial 34 finished with value: 0.18881118744482367 and parameters: {'model_name': 'VAE', 'batch_size': 410, 'iterations': 6388, 'learning_rate': 0.0001137639306954086, 'p_miss': 0.27571848577234814}. Best is trial 131 with value: 0.10352922853187137.
running
[I 2024-11-23 20:11:38,546] Trial 151 finished with value: 0.10341052329068523 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 4, 'learning_rate': 0.0002151620078181523, 'p_miss': 0.06199777786137099}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:12:53,564] Trial 152 finished with value: 0.10698085430373346 and parameters: {'model_name': 'VAE', 'batch_size': 978, 'iterations': 8, 'learning_rate': 0.0001471906495339088, 'p_miss': 0.06412389124664697}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:16:19,408] Trial 153 finished with value: 0.39583149619356606 and parameters: {'model_name': 'GAIN', 'batch_size': 337, 'hint_rate': 0.3227279419212167, 'alpha': 23, 'iterations': 96, 'learning_rate': 0.00021877964265873932, 'p_miss': 0.16049419952804458}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:16:47,902] Trial 154 finished with value: 0.10557823164722682 and parameters: {'model_name': 'VAE', 'batch_size': 531, 'iterations': 4, 'learning_rate': 0.0004517096986491567, 'p_miss': 0.09381846443141797}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:17:09,952] Trial 155 finished with value: 0.11684950699427152 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.002263727538908979, 'p_miss': 0.09535721377263773}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:17:34,864] Trial 156 finished with value: 0.10756375527333284 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.0004707611850209522, 'p_miss': 0.09313177048500992}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:23:12,939] Trial 157 finished with value: 0.10740525461328956 and parameters: {'model_name': 'VAE', 'batch_size': 563, 'iterations': 56, 'learning_rate': 0.00030773657227749386, 'p_miss': 0.08155833511639587}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:23:37,707] Trial 158 finished with value: 0.11652229305640227 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 4, 'learning_rate': 0.0003959008635509904, 'p_miss': 0.06033619105607432}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:25:38,440] Trial 159 finished with value: 0.1284049743480156 and parameters: {'model_name': 'VAE', 'batch_size': 463, 'iterations': 21, 'learning_rate': 0.00012675877066563806, 'p_miss': 0.20605758122354179}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:26:04,001] Trial 160 finished with value: 0.10436592967355876 and parameters: {'model_name': 'VAE', 'batch_size': 688, 'iterations': 3, 'learning_rate': 0.00019552519947947514, 'p_miss': 0.21488968088730862}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:27:43,370] Trial 161 finished with value: 0.10678923561700146 and parameters: {'model_name': 'VAE', 'batch_size': 701, 'iterations': 11, 'learning_rate': 0.00018395889778141037, 'p_miss': 0.04573281906121068}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:32:47,654] Trial 162 finished with value: 0.10524534639478975 and parameters: {'model_name': 'VAE', 'batch_size': 745, 'iterations': 36, 'learning_rate': 0.00015071771458607263, 'p_miss': 0.21665429381583343}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:36:13,273] Trial 163 finished with value: 0.10899021536074467 and parameters: {'model_name': 'VAE', 'batch_size': 803, 'iterations': 33, 'learning_rate': 0.00015028379450799826, 'p_miss': 0.21706415668343274}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:36:43,901] Trial 164 finished with value: 0.11431088045880759 and parameters: {'model_name': 'VAE', 'batch_size': 651, 'iterations': 5, 'learning_rate': 0.00011405636689125545, 'p_miss': 0.19697308651602555}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:40:19,042] Trial 165 finished with value: 0.17921490517107688 and parameters: {'model_name': 'VAE', 'batch_size': 991, 'iterations': 25, 'learning_rate': 0.00641601126584182, 'p_miss': 0.05573351268207164}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:40:44,252] Trial 166 finished with value: 0.10471484021504658 and parameters: {'model_name': 'VAE', 'batch_size': 781, 'iterations': 3, 'learning_rate': 0.00016874525710723598, 'p_miss': 0.0695430218013666}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:41:14,700] Trial 167 finished with value: 0.1172386529042514 and parameters: {'model_name': 'VAE', 'batch_size': 781, 'iterations': 3, 'learning_rate': 0.0002122613860915285, 'p_miss': 0.06968862045209442}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:41:39,856] Trial 168 finished with value: 0.11628525823449824 and parameters: {'model_name': 'VAE', 'batch_size': 580, 'iterations': 4, 'learning_rate': 0.000157399604927209, 'p_miss': 0.1858675279832796}. Best is trial 151 with value: 0.10341052329068523.
running
[I 2024-11-23 20:42:02,652] Trial 169 finished with value: 0.10193278575536424 and parameters: {'model_name': 'VAE', 'batch_size': 510, 'iterations': 3, 'learning_rate': 0.0001289981886289223, 'p_miss': 0.07843046602991677}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:42:26,013] Trial 170 finished with value: 0.10973140038546918 and parameters: {'model_name': 'VAE', 'batch_size': 521, 'iterations': 3, 'learning_rate': 0.00012563173106810304, 'p_miss': 0.08243890611348526}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:42:51,647] Trial 171 finished with value: 0.11694489622269508 and parameters: {'model_name': 'VAE', 'batch_size': 709, 'iterations': 4, 'learning_rate': 0.00010319719342952067, 'p_miss': 0.06970353647313333}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:43:22,805] Trial 172 finished with value: 0.11421578757531806 and parameters: {'model_name': 'VAE', 'batch_size': 432, 'iterations': 5, 'learning_rate': 0.0001344711219616527, 'p_miss': 0.07872380414932623}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:43:24,066] Trial 173 finished with value: 0.43039558592967975 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:44:05,419] Trial 174 finished with value: 0.17637493972064094 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 26590, 'weights': 'distance'}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:44:51,652] Trial 175 finished with value: 0.10662856137991258 and parameters: {'model_name': 'VAE', 'batch_size': 843, 'iterations': 3, 'learning_rate': 0.0006756207643123836, 'p_miss': 0.08921173190653049}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:45:03,935] Trial 176 finished with value: 0.11130322348498392 and parameters: {'model_name': 'VAE', 'batch_size': 643, 'iterations': 2, 'learning_rate': 0.00035613768660959445, 'p_miss': 0.21616596364162796}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:47:52,719] Trial 177 finished with value: 0.112991574795822 and parameters: {'model_name': 'VAE', 'batch_size': 363, 'iterations': 38, 'learning_rate': 0.00016310037850886125, 'p_miss': 0.058795314346659085}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 20:59:24,522] Trial 178 finished with value: 0.13125369724070737 and parameters: {'model_name': 'VAE', 'batch_size': 514, 'iterations': 107, 'learning_rate': 0.0002469363225460639, 'p_miss': 0.2004310632085023}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:00:00,482] Trial 179 finished with value: 0.11743442972931513 and parameters: {'model_name': 'VAE', 'batch_size': 247, 'iterations': 6, 'learning_rate': 0.00030647618420587866, 'p_miss': 0.22799064048851492}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:55:28,417] Trial 41 finished with value: 0.18733543463129382 and parameters: {'model_name': 'VAE', 'batch_size': 945, 'iterations': 6463, 'learning_rate': 0.00011450482158614195, 'p_miss': 0.27696456813496045}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:55:41,530] Trial 181 finished with value: 0.11429665660372226 and parameters: {'model_name': 'VAE', 'batch_size': 589, 'iterations': 2, 'learning_rate': 0.00017056278101363224, 'p_miss': 0.06781950976702007}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:56:06,243] Trial 182 finished with value: 0.1646896957296444 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:57:29,498] Trial 183 finished with value: 0.1239115314781835 and parameters: {'model_name': 'VAE', 'batch_size': 767, 'iterations': 14, 'learning_rate': 0.0004624177887209476, 'p_miss': 0.21034853738282927}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:57:47,985] Trial 184 finished with value: 0.12218599093237872 and parameters: {'model_name': 'VAE', 'batch_size': 425, 'iterations': 3, 'learning_rate': 0.00020948924112288898, 'p_miss': 0.07546641748256905}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:58:32,104] Trial 65 finished with value: 0.19127658482638504 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 6252, 'learning_rate': 0.0006947153456491135, 'p_miss': 0.21062127070880396}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:58:59,071] Trial 186 finished with value: 0.11566059682592274 and parameters: {'model_name': 'VAE', 'batch_size': 793, 'iterations': 3, 'learning_rate': 0.0003744229354010707, 'p_miss': 0.09246055399444805}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 21:59:29,775] Trial 187 finished with value: 0.11443022613068539 and parameters: {'model_name': 'VAE', 'batch_size': 916, 'iterations': 3, 'learning_rate': 0.0005056089014051928, 'p_miss': 0.2535513098401405}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:00:03,918] Trial 188 finished with value: 0.1172356620051348 and parameters: {'model_name': 'VAE', 'batch_size': 674, 'iterations': 4, 'learning_rate': 0.0006323021936478117, 'p_miss': 0.08922349402154876}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:08:47,719] Trial 189 finished with value: 0.10942371223236372 and parameters: {'model_name': 'VAE', 'batch_size': 868, 'iterations': 73, 'learning_rate': 0.00013569807100077588, 'p_miss': 0.10265709793141228}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:18:14,076] Trial 185 finished with value: 0.13243297731557063 and parameters: {'model_name': 'VAE', 'batch_size': 889, 'iterations': 187, 'learning_rate': 0.0005373817637689461, 'p_miss': 0.11336708742035378}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:18:40,529] Trial 191 finished with value: 0.4115585576998401 and parameters: {'model_name': 'GAIN', 'batch_size': 290, 'hint_rate': 0.7283402171074057, 'alpha': 42, 'iterations': 8, 'learning_rate': 0.00041758336278433536, 'p_miss': 0.07873316588452864}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:22:03,027] Trial 192 finished with value: 0.10381387339619708 and parameters: {'model_name': 'VAE', 'batch_size': 566, 'iterations': 29, 'learning_rate': 0.0002751371334006643, 'p_miss': 0.08343195859235224}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:24:19,707] Trial 193 finished with value: 0.10721276929467927 and parameters: {'model_name': 'VAE', 'batch_size': 512, 'iterations': 27, 'learning_rate': 0.00026358452118503873, 'p_miss': 0.04536902252503666}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:26:19,932] Trial 190 finished with value: 0.11915651090652524 and parameters: {'model_name': 'VAE', 'batch_size': 298, 'iterations': 188, 'learning_rate': 0.0002780151362767086, 'p_miss': 0.11340869340622026}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:26:29,571] Trial 194 finished with value: 0.10692051083695564 and parameters: {'model_name': 'VAE', 'batch_size': 391, 'iterations': 20, 'learning_rate': 0.0001149069063408361, 'p_miss': 0.2048722072501706}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:26:46,057] Trial 42 finished with value: 0.18633108624237887 and parameters: {'model_name': 'VAE', 'batch_size': 915, 'iterations': 7404, 'learning_rate': 0.00015027448015525376, 'p_miss': 0.2693110036254239}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:26:49,534] Trial 196 finished with value: 0.11454834349153246 and parameters: {'model_name': 'VAE', 'batch_size': 706, 'iterations': 2, 'learning_rate': 0.00023251149746488317, 'p_miss': 0.0836513551145468}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:30:31,383] Trial 195 finished with value: 0.11032299360598882 and parameters: {'model_name': 'VAE', 'batch_size': 347, 'iterations': 54, 'learning_rate': 0.00019427266560732793, 'p_miss': 0.03021987466036602}. Best is trial 169 with value: 0.10193278575536424.
running
[I 2024-11-23 22:31:16,840] Trial 198 finished with value: 0.11461743662472072 and parameters: {'model_name': 'VAE', 'batch_size': 770, 'iterations': 37, 'learning_rate': 0.00034484419406217325, 'p_miss': 0.08976918717324871}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:32:35,436] Trial 197 finished with value: 0.11040527996373377 and parameters: {'model_name': 'VAE', 'batch_size': 704, 'iterations': 40, 'learning_rate': 0.0003476844453089224, 'p_miss': 0.08569478791798964}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:33:03,957] Trial 199 finished with value: 0.10442694188427767 and parameters: {'model_name': 'VAE', 'batch_size': 613, 'iterations': 27, 'learning_rate': 0.0003361221480089547, 'p_miss': 0.08810998586622333}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:34:32,742] Trial 38 finished with value: 0.18705460959711798 and parameters: {'model_name': 'VAE', 'batch_size': 725, 'iterations': 7403, 'learning_rate': 0.00010051256307108381, 'p_miss': 0.2459589132455573}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:41:55,613] Trial 119 finished with value: 0.1874321156776857 and parameters: {'model_name': 'VAE', 'batch_size': 113, 'iterations': 4828, 'learning_rate': 0.00018951358522467245, 'p_miss': 0.11105086060205603}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:44:11,703] Trial 43 finished with value: 0.1873159694310693 and parameters: {'model_name': 'VAE', 'batch_size': 948, 'iterations': 7585, 'learning_rate': 0.00010625961040064534, 'p_miss': 0.27724208433711106}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 22:54:04,667] Trial 36 finished with value: 0.18660300129058585 and parameters: {'model_name': 'VAE', 'batch_size': 564, 'iterations': 8670, 'learning_rate': 0.00010189918865194924, 'p_miss': 0.27416681613582805}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:01:30,849] Trial 35 finished with value: 0.18716660875741264 and parameters: {'model_name': 'VAE', 'batch_size': 797, 'iterations': 8207, 'learning_rate': 0.00010870372294718391, 'p_miss': 0.27446997509714827}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:02:08,987] Trial 70 finished with value: 0.18817399022050643 and parameters: {'model_name': 'VAE', 'batch_size': 331, 'iterations': 8144, 'learning_rate': 0.0003178026905828425, 'p_miss': 0.19650377873807717}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:05:39,970] Trial 110 finished with value: 0.18670578823865022 and parameters: {'model_name': 'VAE', 'batch_size': 660, 'iterations': 5759, 'learning_rate': 0.00023919707203141978, 'p_miss': 0.11281835730635342}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:05:40,346] Trial 180 finished with value: 0.18334434549142456 and parameters: {'model_name': 'VAE', 'batch_size': 749, 'iterations': 1500, 'learning_rate': 0.00019552136681613114, 'p_miss': 0.11364727967585779}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:19:20,085] Trial 92 finished with value: 0.18631090772307232 and parameters: {'model_name': 'VAE', 'batch_size': 136, 'iterations': 8454, 'learning_rate': 0.0008248132440330264, 'p_miss': 0.16382504488148952}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:20:02,622] Trial 39 finished with value: 0.18735955301132973 and parameters: {'model_name': 'VAE', 'batch_size': 621, 'iterations': 9707, 'learning_rate': 0.00012962302243362033, 'p_miss': 0.2651282761284028}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:28:05,995] Trial 115 finished with value: 0.18871156388020965 and parameters: {'model_name': 'VAE', 'batch_size': 309, 'iterations': 8054, 'learning_rate': 0.00013237161819643634, 'p_miss': 0.02305155583093041}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:32:10,528] Trial 103 finished with value: 0.18780004595527258 and parameters: {'model_name': 'VAE', 'batch_size': 356, 'iterations': 9844, 'learning_rate': 0.00014110458390326322, 'p_miss': 0.1168085124484627}. Best is trial 169 with value: 0.10193278575536424.
[I 2024-11-23 23:36:15,218] Trial 150 finished with value: 0.18773812093260486 and parameters: {'model_name': 'VAE', 'batch_size': 372, 'iterations': 9155, 'learning_rate': 0.00029770387125535786, 'p_miss': 0.09289368899202124}. Best is trial 169 with value: 0.10193278575536424.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.10193278575536424
{'model_name': 'VAE', 'batch_size': 510, 'iterations': 3, 'learning_rate': 0.0001289981886289223, 'p_miss': 0.07843046602991677}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4220> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474714370> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5396499586532667
Generation:   4%|▍         | 1/25 [06:31<2:36:41, 391.74s/it]Generation:  2
Best f1_score score: 0.5414323829754923
Generation:   8%|▊         | 2/25 [12:15<2:19:22, 363.58s/it]Generation:  3
Best f1_score score: 0.5429627295203053
Generation:  12%|█▏        | 3/25 [17:48<2:08:08, 349.46s/it]Generation:  4
Best f1_score score: 0.5429627295203053
Generation:  16%|█▌        | 4/25 [23:55<2:04:46, 356.51s/it]Generation:  5
Best f1_score score: 0.5429627295203053
Generation:  20%|██        | 5/25 [25:43<1:28:56, 266.82s/it]Generation:  6
Best f1_score score: 0.5429627295203053
Generation:  24%|██▍       | 6/25 [31:49<1:35:11, 300.61s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a72e0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  7
Best f1_score score: 0.5445200095740214
Generation:  28%|██▊       | 7/25 [34:01<1:13:36, 245.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff1de0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5445200095740214
Generation:  32%|███▏      | 8/25 [34:51<51:53, 183.14s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554662ea380> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5445200095740214
Generation:  36%|███▌      | 9/25 [38:01<49:29, 185.57s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fd7550> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5445200095740214
Generation:  40%|████      | 10/25 [39:11<37:26, 149.76s/it]Generation:  11
Best f1_score score: 0.54514569341789
Generation:  44%|████▍     | 11/25 [44:06<45:17, 194.13s/it]Generation:  12
Best f1_score score: 0.54514569341789
Generation:  48%|████▊     | 12/25 [51:34<58:46, 271.31s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d5cee0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fcad10> 

Generation:  13
Best f1_score score: 0.5455490666529312
Generation:  52%|█████▏    | 13/25 [1:01:41<1:14:39, 373.25s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554663059c0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d7c3a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546723b340> 

Generation:  14
Best f1_score score: 0.5455490666529312
Generation:  56%|█████▌    | 14/25 [1:11:50<1:21:27, 444.28s/it]Generation:  15
Best f1_score score: 0.5455490666529312
Generation:  60%|██████    | 15/25 [1:12:39<54:10, 325.05s/it]  Generation:  16
Best f1_score score: 0.5455490666529312
Generation:  64%|██████▍   | 16/25 [1:15:49<42:39, 284.44s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546771e380> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  17
Best f1_score score: 0.5457317546835065
Generation:  68%|██████▊   | 17/25 [1:16:02<27:04, 203.03s/it]Generation:  18
Best f1_score score: 0.5457317546835065
Generation:  72%|███████▏  | 18/25 [1:18:08<20:57, 179.61s/it]Generation:  19
Best f1_score score: 0.5457317546835065
Generation:  76%|███████▌  | 19/25 [1:22:09<19:49, 198.21s/it]Generation:  20
Best f1_score score: 0.5457317546835065
Generation:  80%|████████  | 20/25 [1:24:04<14:26, 173.29s/it]Generation:  21
Best f1_score score: 0.5457317546835065
Generation:  84%|████████▍ | 21/25 [1:25:29<09:47, 146.79s/it]Generation:  22
Best f1_score score: 0.5457317546835065
Generation:  88%|████████▊ | 22/25 [1:33:34<12:24, 248.23s/it]Generation:  23
Best f1_score score: 0.5459369962248795
Generation:  92%|█████████▏| 23/25 [1:33:58<06:02, 181.05s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467882800> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5459369962248795
Generation:  96%|█████████▌| 24/25 [1:34:20<02:13, 133.15s/it]Generation:  25
Best f1_score score: 0.5459369962248795
Generation: 100%|██████████| 25/25 [1:35:26<00:00, 112.96s/it]Generation: 100%|██████████| 25/25 [1:35:29<00:00, 229.20s/it]
2024-11-24 01:11:55,076 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36643' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d', 'ndarray-ffb26fc4f803212e9acf5a1edd9aefdc'} (stimulus_id='handle-worker-cleanup-1732439515.0765789')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(boosting_type='dart', max_depth=7,
                                n_estimators=29, n_jobs=1, num_leaves=11,
                                verbose=-1))])
score start
train score: {'auroc': 0.5765278463158656, 'accuracy': 0.55656836461126, 'balanced_accuracy': 0.5565189619893465, 'logloss': 0.6852418260763897, 'f1': 0.5561249276114291}
original test score: {'auroc': 0.7386655943995086, 'accuracy': 0.5278812507054972, 'balanced_accuracy': 0.5271962305600345, 'logloss': 0.677862477921679, 'f1': 0.4181286476354061}
imputed test score: {'auroc': 0.5531369898594812, 'accuracy': 0.5187380065470143, 'balanced_accuracy': 0.5189957312970536, 'logloss': 0.6893554796010075, 'f1': 0.5057238520918828}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4e50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4ee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a53c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4a30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5060> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a48e0> 

Generation:  1
Best f1_score score: 0.9464876607351129
Generation:   4%|▍         | 1/25 [10:03<4:01:19, 603.30s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f05870> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15548648b130> 

Generation:  2
Best f1_score score: 0.9506784583257657
Generation:   8%|▊         | 2/25 [20:08<3:51:39, 604.32s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a7b80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466d2b0d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15541bcbe620> 

Generation:  3
Best f1_score score: 0.9607977724938946
Generation:  12%|█▏        | 3/25 [30:12<3:41:30, 604.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554668337c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554660c5b10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15548648b100> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f59e40> 

Generation:  4
Best f1_score score: 0.9607977724938946
Generation:  16%|█▌        | 4/25 [40:16<3:31:26, 604.14s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f05a50> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29420> 

Generation:  5
Best f1_score score: 0.9608683307995172
Generation:  20%|██        | 5/25 [50:21<3:21:28, 604.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155477284610> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5b0d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464f47f70> 

Generation:  6
Best f1_score score: 0.9608683307995172
Generation:  24%|██▍       | 6/25 [1:00:26<3:11:30, 604.77s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459a122f0> 

Generation:  7
Best f1_score score: 0.9610800466426731
Generation:  28%|██▊       | 7/25 [1:10:31<3:01:24, 604.67s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467db7730> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155451709ed0> 

Generation:  8
Best f1_score score: 0.9611096990602194
Generation:  32%|███▏      | 8/25 [1:20:37<2:51:27, 605.14s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467bff940> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f29f90> 

Generation:  9
Best f1_score score: 0.9614191246645817
Generation:  36%|███▌      | 9/25 [1:30:43<2:41:26, 605.41s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5930> 

Generation:  10
Best f1_score score: 0.9618144035377973
Generation:  40%|████      | 10/25 [1:40:47<2:31:17, 605.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474743d30> 

Generation:  11
Best f1_score score: 0.9618144035377973
Generation:  44%|████▍     | 11/25 [1:50:52<2:21:11, 605.08s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f53ca0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458b270d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554529e1030> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545146e2c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f9e440> 

Generation:  12
Best f1_score score: 0.9618144035377973
Generation:  48%|████▊     | 12/25 [2:00:59<2:11:10, 605.42s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5b220> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15541c01ca30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554031d2e00> 

Generation:  13
Best f1_score score: 0.9618144035377973
Generation:  52%|█████▏    | 13/25 [2:11:03<2:01:02, 605.22s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554668c6740> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464c7bfa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467888d30> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458b04be0> 

Generation:  14
Best f1_score score: 0.9635643616154246
Generation:  56%|█████▌    | 14/25 [2:21:09<1:50:59, 605.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e3b430> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b190> 

Generation:  15
Best f1_score score: 0.9635643616154246
Generation:  60%|██████    | 15/25 [2:31:15<1:40:56, 605.61s/it]Generation:  16
Best f1_score score: 0.9639028513778662
Generation:  64%|██████▍   | 16/25 [2:34:25<1:12:04, 480.49s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155458729d50> 

Generation:  17
Best f1_score score: 0.9639028513778662
Generation:  68%|██████▊   | 17/25 [2:44:32<1:09:08, 518.62s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465ed2f50> 

Generation:  18
Best f1_score score: 0.9640579022170247
Generation:  72%|███████▏  | 18/25 [2:54:39<1:03:34, 544.99s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467912d10> 

Generation:  19
Best f1_score score: 0.9640579022170247
Generation:  76%|███████▌  | 19/25 [3:04:44<56:17, 563.00s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5c8e0> 

Generation:  20
Best f1_score score: 0.9646653043292513
Generation:  80%|████████  | 20/25 [3:14:50<47:59, 575.84s/it]Generation:  21
Best f1_score score: 0.9646653043292513
Generation:  84%|████████▍ | 21/25 [3:23:16<37:00, 555.02s/it]Generation:  22
Best f1_score score: 0.9646653043292513
Generation:  88%|████████▊ | 22/25 [3:23:46<19:52, 397.50s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467909630> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553bef26230> 

Generation:  23
Best f1_score score: 0.9646653043292513
Generation:  92%|█████████▏| 23/25 [3:33:51<15:19, 459.86s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe350> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a78b0> 

Generation:  24
Best f1_score score: 0.9646653043292513
Generation:  96%|█████████▌| 24/25 [3:43:59<08:24, 504.27s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554673a3c10> 

Generation:  25
Best f1_score score: 0.9646653043292513
Generation: 100%|██████████| 25/25 [3:54:07<00:00, 535.35s/it]Generation: 100%|██████████| 25/25 [3:54:07<00:00, 561.91s/it]
2024-11-24 05:06:17,613 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42845' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-667d14bd0c17c4be62034c3603fb5018', 'ndarray-89eccf6bf6a2f74b785b9e31bcffba6d'} (stimulus_id='handle-worker-cleanup-1732453577.6135237')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='constant')),
                ('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=True,
                                                l2_regularization=0.0001515708316,
                                                learning_rate=0.1080314450611,
                                                max_features=0.7276608387494,
                                                max_leaf_nodes=1441,
                                                min_samples_leaf=164,
                                                tol=0.0001,
                                                validation_fraction=None))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9989562118121407, 'accuracy': 0.9825172851700297, 'balanced_accuracy': 0.9825299279255439, 'logloss': 0.04921631883685164, 'f1': 0.9825165958495947}
test score: {'auroc': 0.96232533106291, 'accuracy': 0.7647025623659556, 'balanced_accuracy': 0.764342081850052, 'logloss': 1.0281807968986476, 'f1': 0.7516426181190405}
original test score: {'auroc': 0.9994126527737014, 'accuracy': 0.9909696353990293, 'balanced_accuracy': 0.9909722886301435, 'logloss': 0.02718193762503189, 'f1': 0.9909696352839662}
score end
40922
lvl
0.5
type
MAR
num_run
1
class_full
finished
all finished
full run takes
17.88992842680878
hours
DONE
