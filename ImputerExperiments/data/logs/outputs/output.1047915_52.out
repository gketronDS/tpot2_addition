Run: 52
/cm/local/apps/slurm/var/spool/job1047915/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1481/1481.pkl
working on 
../data/c/1481/class_full_MCAR_0.5_3
3.4651312828063965
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-13 20:32:40,203] A new study created in memory with name: no-name-639e1acd-554f-41ea-9853-4c62854cb955
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-13 20:32:40,586] Trial 0 finished with value: 0.2920920678903716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.2920920678903716.
running
[I 2024-11-13 20:32:40,984] Trial 5 finished with value: 0.2920920678903716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.2920920678903716.
running
[I 2024-11-13 20:32:41,252] Trial 8 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.2920920678903716.
running
[I 2024-11-13 20:32:41,513] Trial 2 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.2920920678903716.
running
[I 2024-11-13 20:32:41,715] Trial 18 finished with value: 0.2920920678903716 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.2920920678903716.
running
[I 2024-11-13 20:32:50,314] Trial 1 finished with value: 0.2911322464553668 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.2911322464553668.
running
[I 2024-11-13 20:32:52,529] Trial 21 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.6020891291892961, 'alpha': 84, 'iterations': 3, 'learning_rate': 0.0004319090721627942, 'p_miss': 0.20020157874973993}. Best is trial 1 with value: 0.2911322464553668.
running
[I 2024-11-13 20:32:54,204] Trial 14 finished with value: 0.29107715499891906 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1299, 'weights': 'uniform'}. Best is trial 14 with value: 0.29107715499891906.
running
[I 2024-11-13 20:32:54,810] Trial 23 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 14 with value: 0.29107715499891906.
running
[I 2024-11-13 20:32:56,605] Trial 20 finished with value: 0.29171227966075103 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2813, 'weights': 'uniform'}. Best is trial 14 with value: 0.29107715499891906.
running
[I 2024-11-13 20:32:59,056] Trial 4 finished with value: 0.3030259895426584 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7963, 'weights': 'distance'}. Best is trial 14 with value: 0.29107715499891906.
running
[I 2024-11-13 20:33:01,769] Trial 13 finished with value: 0.30304730732566726 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19650, 'weights': 'distance'}. Best is trial 14 with value: 0.29107715499891906.
running
[I 2024-11-13 20:33:02,651] Trial 6 finished with value: 0.2423183868532223 and parameters: {'model_name': 'VAE', 'batch_size': 629, 'iterations': 2, 'learning_rate': 0.0005449822065815204, 'p_miss': 0.11423156312063679}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:02,991] Trial 15 finished with value: 0.4348681492842836 and parameters: {'model_name': 'GAIN', 'batch_size': 320, 'hint_rate': 0.1312417545418258, 'alpha': 65, 'iterations': 12, 'learning_rate': 0.002222205681346331, 'p_miss': 0.06329947365162238}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:03,575] Trial 19 finished with value: 0.30304267962793957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14214, 'weights': 'distance'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:08,662] Trial 22 finished with value: 0.3029977541892566 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3583, 'weights': 'distance'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:11,138] Trial 24 finished with value: 0.2910840164753409 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'roman'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:13,959] Trial 28 finished with value: 0.24380496906103075 and parameters: {'model_name': 'VAE', 'batch_size': 952, 'iterations': 1, 'learning_rate': 0.01095874876178591, 'p_miss': 0.029040013869155376}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:14,273] Trial 26 finished with value: 0.2911322464553668 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:17,000] Trial 27 finished with value: 0.2911322464553668 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:20,991] Trial 33 finished with value: 0.26148938848334985 and parameters: {'model_name': 'VAE', 'batch_size': 891, 'iterations': 1, 'learning_rate': 0.05280540896750058, 'p_miss': 0.017922850829690393}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:23,305] Trial 35 finished with value: 0.24972216278452083 and parameters: {'model_name': 'VAE', 'batch_size': 887, 'iterations': 1, 'learning_rate': 0.05314954892603716, 'p_miss': 0.015360726885553726}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:23,843] Trial 10 finished with value: 0.3875140850537889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:24,132] Trial 34 finished with value: 0.2695868159345413 and parameters: {'model_name': 'VAE', 'batch_size': 964, 'iterations': 1, 'learning_rate': 0.05305835146429974, 'p_miss': 0.023055082152561135}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:25,552] Trial 36 finished with value: 0.24965833021419875 and parameters: {'model_name': 'VAE', 'batch_size': 928, 'iterations': 1, 'learning_rate': 0.08588548499293115, 'p_miss': 0.011498228879482847}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:26,724] Trial 17 finished with value: 0.3770459839948336 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:29,319] Trial 3 finished with value: 0.37881777148858087 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:29,822] Trial 37 finished with value: 0.24642964989232247 and parameters: {'model_name': 'VAE', 'batch_size': 582, 'iterations': 1, 'learning_rate': 0.03980670042302695, 'p_miss': 0.06151068095058264}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:34,454] Trial 38 finished with value: 0.2602990036271782 and parameters: {'model_name': 'VAE', 'batch_size': 705, 'iterations': 1, 'learning_rate': 0.049423089299698915, 'p_miss': 0.06221980223613963}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:33:37,194] Trial 7 finished with value: 0.31144929328585175 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:34:13,530] Trial 9 finished with value: 0.43574185355758727 and parameters: {'model_name': 'GAIN', 'batch_size': 197, 'hint_rate': 0.9685836192252293, 'alpha': 85, 'iterations': 78, 'learning_rate': 0.0064435093626869725, 'p_miss': 0.08362668105855044}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:42:46,754] Trial 16 finished with value: 0.3049077881081544 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 204, 'learning_rate': 0.011373284621409272, 'p_miss': 0.22842376790429716}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:52:46,956] Trial 40 finished with value: 0.29722282162462105 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 303, 'learning_rate': 0.006290422478080097, 'p_miss': 0.12082812822315041}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 20:53:17,020] Trial 48 finished with value: 0.2440113317905826 and parameters: {'model_name': 'VAE', 'batch_size': 186, 'iterations': 8, 'learning_rate': 0.00012249250361167968, 'p_miss': 0.1273805648764419}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 21:13:51,924] Trial 11 finished with value: 0.29881459616779127 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 699, 'learning_rate': 0.000555857465538769, 'p_miss': 0.26147389034905916}. Best is trial 6 with value: 0.2423183868532223.
running
[I 2024-11-13 21:14:44,894] Trial 50 finished with value: 0.2412275122812959 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 9, 'learning_rate': 0.00012282749766949133, 'p_miss': 0.13828888587636265}. Best is trial 50 with value: 0.2412275122812959.
running
[I 2024-11-13 21:15:33,361] Trial 51 finished with value: 0.2432501931463973 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 10, 'learning_rate': 0.00010976170743482002, 'p_miss': 0.14850312196022492}. Best is trial 50 with value: 0.2412275122812959.
running
[I 2024-11-13 21:16:31,584] Trial 52 finished with value: 0.24274545032156486 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 14, 'learning_rate': 0.0001613833088820997, 'p_miss': 0.1657182987424943}. Best is trial 50 with value: 0.2412275122812959.
running
[I 2024-11-13 21:17:39,596] Trial 53 finished with value: 0.2403674130596567 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 18, 'learning_rate': 0.00010794555062302294, 'p_miss': 0.1692210857197197}. Best is trial 53 with value: 0.2403674130596567.
running
[I 2024-11-13 21:32:53,046] Trial 45 finished with value: 0.29649028881943756 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 872, 'learning_rate': 0.006961285362493063, 'p_miss': 0.1263698133533733}. Best is trial 53 with value: 0.2403674130596567.
running
[I 2024-11-13 21:42:48,970] Trial 43 finished with value: 0.29761500781307104 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 1020, 'learning_rate': 0.007964111549225102, 'p_miss': 0.11641992161476283}. Best is trial 53 with value: 0.2403674130596567.
running
[I 2024-11-13 21:44:01,608] Trial 56 finished with value: 0.24178408092016662 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 18, 'learning_rate': 0.00010120660982869647, 'p_miss': 0.17199831630050538}. Best is trial 53 with value: 0.2403674130596567.
running
[I 2024-11-13 21:46:16,659] Trial 57 finished with value: 0.24150306115730577 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 33, 'learning_rate': 0.00023268132044900695, 'p_miss': 0.17799000178293517}. Best is trial 53 with value: 0.2403674130596567.
running
[I 2024-11-13 21:48:02,097] Trial 58 finished with value: 0.24023940479532926 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 36, 'learning_rate': 0.00027424803925398547, 'p_miss': 0.18215374337037354}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:50:08,417] Trial 42 finished with value: 0.29850647254250967 and parameters: {'model_name': 'VAE', 'batch_size': 67, 'iterations': 977, 'learning_rate': 0.006482396361131407, 'p_miss': 0.1204926167714547}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:50:43,802] Trial 59 finished with value: 0.24193605016288347 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 37, 'learning_rate': 0.0002447590837777307, 'p_miss': 0.18543157002573796}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:51:52,625] Trial 60 finished with value: 0.24238702635005588 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 24, 'learning_rate': 0.0002477272003510354, 'p_miss': 0.18698860533375555}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:53:48,854] Trial 62 finished with value: 0.4302226144026989 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.036363930278799805, 'alpha': 0, 'iterations': 66, 'learning_rate': 0.00023216450116995434, 'p_miss': 0.21573489666611922}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:53:51,005] Trial 61 finished with value: 0.2429309109635866 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 44, 'learning_rate': 0.0002501536470982112, 'p_miss': 0.1892738528573358}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:54:11,410] Trial 63 finished with value: 0.24263437715457284 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 5, 'learning_rate': 0.001206052540989939, 'p_miss': 0.16516248092540908}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:54:12,618] Trial 65 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:55:41,110] Trial 66 finished with value: 0.24140318284565304 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 27, 'learning_rate': 0.00018227890109339724, 'p_miss': 0.15048230792297032}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 21:56:54,062] Trial 67 finished with value: 0.2415033297575825 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 18, 'learning_rate': 0.00010528562826698766, 'p_miss': 0.1490401702645059}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:01:40,975] Trial 39 finished with value: 0.294246628680131 and parameters: {'model_name': 'VAE', 'batch_size': 92, 'iterations': 1151, 'learning_rate': 0.01274269526656458, 'p_miss': 0.11484096969926325}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:04:54,983] Trial 68 finished with value: 0.2500275581264278 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 103, 'learning_rate': 0.0005045880042747465, 'p_miss': 0.14635575115136346}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:05:43,493] Trial 70 finished with value: 0.4346133557885155 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.5092081680870895, 'alpha': 20, 'iterations': 26, 'learning_rate': 0.00016718177931137365, 'p_miss': 0.14232083730721906}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:09:47,490] Trial 69 finished with value: 0.24610969771920727 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 99, 'learning_rate': 0.00043512022544732655, 'p_miss': 0.14166574171166207}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:34:58,911] Trial 32 finished with value: 0.2991769255932306 and parameters: {'model_name': 'VAE', 'batch_size': 989, 'iterations': 1211, 'learning_rate': 0.09251511884615303, 'p_miss': 0.08150137331911553}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 22:35:00,106] Trial 73 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 23:26:44,680] Trial 46 finished with value: 0.2962473981281704 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 2557, 'learning_rate': 0.008718088692908152, 'p_miss': 0.13106089070072927}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 23:27:09,936] Trial 75 finished with value: 0.24439668324995445 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 6, 'learning_rate': 0.00015750329822729063, 'p_miss': 0.21886729178286696}. Best is trial 58 with value: 0.24023940479532926.
running
[I 2024-11-13 23:28:24,412] Trial 76 finished with value: 0.23988320739986846 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 19, 'learning_rate': 0.00011084927078749628, 'p_miss': 0.16800431603920077}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-13 23:30:37,435] Trial 77 finished with value: 0.24191911491197246 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 41, 'learning_rate': 0.00032388183882252174, 'p_miss': 0.16609322882024438}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-13 23:30:48,301] Trial 78 finished with value: 0.29209206789037157 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19836, 'weights': 'uniform'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-13 23:31:49,011] Trial 79 finished with value: 0.24709679811352783 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 19, 'learning_rate': 0.00015899432545353739, 'p_miss': 0.09707782076407913}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-13 23:32:03,207] Trial 80 finished with value: 0.24575328633124438 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.0008103559416483506, 'p_miss': 0.20060810952476524}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-13 23:32:27,804] Trial 81 finished with value: 0.4327417966771131 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.9411020231570577, 'alpha': 40, 'iterations': 12, 'learning_rate': 0.00012831288231195245, 'p_miss': 0.2682633184193154}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:01:52,264] Trial 82 finished with value: 0.3039665730704028 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:06:07,663] Trial 83 finished with value: 0.2423813349637151 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 55, 'learning_rate': 0.00032159221211391773, 'p_miss': 0.17720373586478505}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:08:36,080] Trial 84 finished with value: 0.24441198178491857 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 28, 'learning_rate': 0.00010009655611416944, 'p_miss': 0.29514845512494353}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:08:48,237] Trial 85 finished with value: 0.29227223195938423 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12863, 'weights': 'uniform'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:09:54,836] Trial 86 finished with value: 0.241516647884665 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 16, 'learning_rate': 0.00015796684418349183, 'p_miss': 0.15924126141873082}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:11:01,156] Trial 87 finished with value: 0.24544863469104533 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 17, 'learning_rate': 0.00019135736437576683, 'p_miss': 0.1545884542181846}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:11:39,125] Trial 88 finished with value: 0.2404350214740328 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 8, 'learning_rate': 0.0003242665227939215, 'p_miss': 0.19843799987510047}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:11:58,361] Trial 89 finished with value: 0.24263906208878128 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 4, 'learning_rate': 0.00033419670928134366, 'p_miss': 0.20253653880290418}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:12:34,764] Trial 90 finished with value: 0.2424228100092881 and parameters: {'model_name': 'VAE', 'batch_size': 368, 'iterations': 8, 'learning_rate': 0.00021135518829420373, 'p_miss': 0.2441155986231179}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:13:00,406] Trial 12 finished with value: 0.2991524251265655 and parameters: {'model_name': 'VAE', 'batch_size': 181, 'iterations': 3089, 'learning_rate': 0.0003729416792120737, 'p_miss': 0.09902670151280392}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:13:01,505] Trial 92 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:14:44,955] Trial 91 finished with value: 0.24174441148615267 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 29, 'learning_rate': 0.0007722667977405667, 'p_miss': 0.17834901587708463}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:14:54,224] Trial 94 finished with value: 0.24371342233217855 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 2, 'learning_rate': 0.00012540708222612666, 'p_miss': 0.19229020567411648}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:22:21,900] Trial 93 finished with value: 0.27620805161385975 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 130, 'learning_rate': 0.0007651103830545083, 'p_miss': 0.17952402019422012}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:22:56,304] Trial 96 finished with value: 0.24446448821515004 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 12, 'learning_rate': 0.000142872278864563, 'p_miss': 0.15410843992432532}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:24:03,724] Trial 97 finished with value: 0.24268601359683867 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 21, 'learning_rate': 0.0001894999252982669, 'p_miss': 0.16073107196554068}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:24:33,478] Trial 98 finished with value: 0.2432696637992124 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 7, 'learning_rate': 0.00013262602334064124, 'p_miss': 0.13671283818121344}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:25:15,793] Trial 95 finished with value: 0.24422513032283044 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 180, 'learning_rate': 0.00012998707723878807, 'p_miss': 0.2074338604058537}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:25:20,878] Trial 99 finished with value: 0.24487135650968347 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 11, 'learning_rate': 0.0003050692213633985, 'p_miss': 0.20695934689958828}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:25:49,905] Trial 100 finished with value: 0.31727899679358984 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:25:58,110] Trial 101 finished with value: 0.31727899679358984 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:28:16,106] Trial 103 finished with value: 0.24029487469981228 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 35, 'learning_rate': 0.00019516724831310206, 'p_miss': 0.10440587026040798}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:28:43,030] Trial 102 finished with value: 0.24280774552181944 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 35, 'learning_rate': 0.00018274629304990196, 'p_miss': 0.10247041906309413}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:30:31,447] Trial 104 finished with value: 0.25955233928959787 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 35, 'learning_rate': 0.003132483603819781, 'p_miss': 0.09577181218252828}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:33:09,046] Trial 105 finished with value: 0.2414826429020466 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 66, 'learning_rate': 0.00027765138725061343, 'p_miss': 0.10674081350174155}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:33:47,718] Trial 106 finished with value: 0.2415492155099097 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 54, 'learning_rate': 0.0001006644057255718, 'p_miss': 0.1513974284628759}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:36:30,912] Trial 107 finished with value: 0.2414069796554442 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 55, 'learning_rate': 0.0002557054886593134, 'p_miss': 0.1092489921305636}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:39:27,973] Trial 108 finished with value: 0.24166798428796515 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 79, 'learning_rate': 0.00028117266590908335, 'p_miss': 0.07150649143044735}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:41:38,051] Trial 109 finished with value: 0.24016815088852286 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 91, 'learning_rate': 0.0002730557013977119, 'p_miss': 0.1074267778943436}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:42:33,673] Trial 110 finished with value: 0.24425314029727913 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 57, 'learning_rate': 0.0004766735050300183, 'p_miss': 0.08702555765068032}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:43:31,986] Trial 111 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.2999060908376193, 'alpha': 47, 'iterations': 347, 'learning_rate': 0.00039270301402993905, 'p_miss': 0.11004762970988985}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:43:45,700] Trial 113 finished with value: 0.30302691553796585 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8102, 'weights': 'distance'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:44:45,408] Trial 112 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.2654418943990655, 'alpha': 99, 'iterations': 428, 'learning_rate': 0.0003748958822792779, 'p_miss': 0.11039016924333404}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:46:21,920] Trial 41 finished with value: 0.2951763467047212 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 4016, 'learning_rate': 0.0056191252070937414, 'p_miss': 0.12420696991882041}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:48:20,136] Trial 114 finished with value: 0.2440317041819331 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 75, 'learning_rate': 0.0006503951465964115, 'p_miss': 0.08143947757966506}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:49:48,939] Trial 115 finished with value: 0.24171918684018814 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 86, 'learning_rate': 0.0006307440145877675, 'p_miss': 0.13315157844522926}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:50:17,692] Trial 117 finished with value: 0.2433663005119712 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 40, 'learning_rate': 0.0002188235780509628, 'p_miss': 0.10345382999890695}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:52:00,223] Trial 116 finished with value: 0.24800758561804934 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 90, 'learning_rate': 0.00021103864203659268, 'p_miss': 0.08793050437899153}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:58:54,334] Trial 119 finished with value: 0.2415246587178576 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 130, 'learning_rate': 0.0002815259909264973, 'p_miss': 0.17053931930028268}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 00:58:55,257] Trial 121 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:00:31,116] Trial 122 finished with value: 0.24309597362524177 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 24, 'learning_rate': 0.00025582059104235804, 'p_miss': 0.12161469191276325}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:01:10,532] Trial 120 finished with value: 0.2439733981904622 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 127, 'learning_rate': 0.0002798163544635154, 'p_miss': 0.17133148196132333}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:02:06,677] Trial 44 finished with value: 0.2957589249264797 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 4380, 'learning_rate': 0.007763425451969302, 'p_miss': 0.11130809296366005}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:03:31,327] Trial 123 finished with value: 0.29651269694363375 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 52, 'learning_rate': 0.018592021137219174, 'p_miss': 0.041021005250360246}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:04:37,204] Trial 126 finished with value: 0.24385087884093762 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 15, 'learning_rate': 0.00011899242465388007, 'p_miss': 0.1409626925661119}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:04:46,701] Trial 124 finished with value: 0.2401735224596492 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 46, 'learning_rate': 0.00019750672000709853, 'p_miss': 0.18568167841860075}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:04:54,468] Trial 125 finished with value: 0.314297497132887 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 49, 'learning_rate': 0.01964832829580449, 'p_miss': 0.19463299830772077}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:06:38,387] Trial 127 finished with value: 0.24104507326541244 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 28, 'learning_rate': 0.00017374390058918671, 'p_miss': 0.19439857000297817}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:06:51,487] Trial 128 finished with value: 0.2417909132728012 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 29, 'learning_rate': 0.00018893681654594786, 'p_miss': 0.19340619429537198}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:07:07,093] Trial 129 finished with value: 0.24317552913579168 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 32, 'learning_rate': 0.00017510445769638715, 'p_miss': 0.17882328190581945}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:07:10,585] Trial 130 finished with value: 0.241187327074933 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 9, 'learning_rate': 0.00018163597838907595, 'p_miss': 0.18267923450852794}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:07:49,532] Trial 133 finished with value: 0.24152840812511492 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 9, 'learning_rate': 0.00014862003089514682, 'p_miss': 0.217707446106416}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:08:18,487] Trial 132 finished with value: 0.2422763562504861 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 21, 'learning_rate': 0.0001478663111803754, 'p_miss': 0.1854815570174242}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:08:20,100] Trial 134 finished with value: 0.2463992118309477 and parameters: {'model_name': 'VAE', 'batch_size': 245, 'iterations': 5, 'learning_rate': 0.00014639814432005504, 'p_miss': 0.1833418009184357}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:08:27,246] Trial 131 finished with value: 0.24376199223424977 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 22, 'learning_rate': 0.0001542444888108505, 'p_miss': 0.1816243862954187}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:08:28,853] Trial 135 finished with value: 0.29209206789037157 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22271, 'weights': 'uniform'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:11:38,689] Trial 137 finished with value: 0.2447847294020745 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 43, 'learning_rate': 0.00021321183669871518, 'p_miss': 0.11601225975036969}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:12:33,737] Trial 139 finished with value: 0.24289785800570182 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 14, 'learning_rate': 0.0016855474522508057, 'p_miss': 0.16187953495606894}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:13:08,310] Trial 136 finished with value: 0.24375599428711842 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 67, 'learning_rate': 0.00022323917352809014, 'p_miss': 0.16147424578644393}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:13:36,234] Trial 138 finished with value: 0.24167239688705164 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 66, 'learning_rate': 0.00019966580269539121, 'p_miss': 0.16379024001914652}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:13:36,841] Trial 141 finished with value: 0.24074328931718045 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 6, 'learning_rate': 0.00040524018650825455, 'p_miss': 0.19732192191632866}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:13:53,302] Trial 143 finished with value: 0.24795106022996158 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 4, 'learning_rate': 0.00035444533326554493, 'p_miss': 0.19894752588343417}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:13:54,584] Trial 144 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:14:15,001] Trial 142 finished with value: 0.24474615500304725 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 10, 'learning_rate': 0.0003596762748493406, 'p_miss': 0.19604702230553844}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:14:23,979] Trial 145 finished with value: 0.2424644184608169 and parameters: {'model_name': 'VAE', 'batch_size': 142, 'iterations': 6, 'learning_rate': 0.00011535998135233811, 'p_miss': 0.2119718963390439}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:14:43,765] Trial 146 finished with value: 0.24081794763171943 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 6, 'learning_rate': 0.0002639472805026719, 'p_miss': 0.21076356874382202}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:14:54,416] Trial 147 finished with value: 0.2417964395143628 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7, 'learning_rate': 0.0002619790000131496, 'p_miss': 0.18817935036340225}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:14:56,320] Trial 148 finished with value: 0.2413691850997191 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 2, 'learning_rate': 0.00042070205324225854, 'p_miss': 0.22684894739027184}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:15:10,496] Trial 149 finished with value: 0.24449181244043006 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 3, 'learning_rate': 0.00017040316447044124, 'p_miss': 0.22809039997503683}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:19:01,199] Trial 47 finished with value: 0.29821826509374005 and parameters: {'model_name': 'VAE', 'batch_size': 153, 'iterations': 3341, 'learning_rate': 0.000124177156703879, 'p_miss': 0.13625085970583428}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:19:09,901] Trial 152 finished with value: 0.2414002853355986 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 2, 'learning_rate': 0.0003990583458390888, 'p_miss': 0.23427625727837553}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:19:19,591] Trial 153 finished with value: 0.24490477140028286 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 2, 'learning_rate': 0.0004428027943368193, 'p_miss': 0.24198822735198974}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:28:51,468] Trial 150 finished with value: 0.290901329619236 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:29:09,693] Trial 155 finished with value: 0.24233187330934486 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 4, 'learning_rate': 0.000310205612625098, 'p_miss': 0.22672521877489293}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:30:02,720] Trial 156 finished with value: 0.24304714167412328 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 13, 'learning_rate': 0.0005959893266572414, 'p_miss': 0.243547387783619}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:30:23,260] Trial 157 finished with value: 0.24204075181019702 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 5, 'learning_rate': 0.0004997528534086248, 'p_miss': 0.20808095712212105}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:30:32,560] Trial 158 finished with value: 0.24299122578265275 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 2, 'learning_rate': 0.00017456823854772598, 'p_miss': 0.202107547927656}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:38:45,270] Trial 74 finished with value: 0.30575788559927786 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 3428, 'learning_rate': 0.00016538134563627384, 'p_miss': 0.2385881853583425}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:39:01,083] Trial 160 finished with value: 0.2455036262171225 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.0003850311699545544, 'p_miss': 0.2233972261731905}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:39:39,108] Trial 161 finished with value: 0.24240680020667874 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 9, 'learning_rate': 0.00023482332041346965, 'p_miss': 0.23430703482724108}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:39:39,573] Trial 151 finished with value: 0.29539001623951117 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:40:14,820] Trial 163 finished with value: 0.43477179856295445 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.6991649064378438, 'alpha': 0, 'iterations': 18, 'learning_rate': 0.00012901711679099087, 'p_miss': 0.25523357642893063}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:40:19,099] Trial 162 finished with value: 0.24383748424755125 and parameters: {'model_name': 'VAE', 'batch_size': 533, 'iterations': 7, 'learning_rate': 0.0001322936386906199, 'p_miss': 0.25161346923971}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:40:42,807] Trial 164 finished with value: 0.24721750207395718 and parameters: {'model_name': 'VAE', 'batch_size': 517, 'iterations': 6, 'learning_rate': 0.0004172377784350092, 'p_miss': 0.17304882405421246}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:42:23,411] Trial 166 finished with value: 0.24275513070336902 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 28, 'learning_rate': 0.00031852306588098017, 'p_miss': 0.1735936664144245}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:44:20,156] Trial 154 finished with value: 0.29825113632767797 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:47:13,030] Trial 168 finished with value: 0.2414343728213833 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 40, 'learning_rate': 0.00023704613255773834, 'p_miss': 0.2128161931155423}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:48:34,395] Trial 169 finished with value: 0.2439938346261556 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 24, 'learning_rate': 0.00019751171766743575, 'p_miss': 0.2337513580598091}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 01:49:08,137] Trial 170 finished with value: 0.24117054599814933 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.00011121904133009686, 'p_miss': 0.1902425443965636}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:31:22,075] Trial 165 finished with value: 0.2907601210733402 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 1837, 'learning_rate': 0.00011003373376706962, 'p_miss': 0.17228437746887101}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:32:03,651] Trial 172 finished with value: 0.24075791578507028 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 12, 'learning_rate': 0.00011512619559915579, 'p_miss': 0.1908036644586102}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:32:14,947] Trial 173 finished with value: 0.29224260669137664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16091, 'weights': 'uniform'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:32:48,846] Trial 174 finished with value: 0.242023679609968 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.00010101752637824362, 'p_miss': 0.18772724278603253}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:33:22,328] Trial 175 finished with value: 0.2417254187496783 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9, 'learning_rate': 0.000135830109673873, 'p_miss': 0.2039065252201799}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:34:08,182] Trial 176 finished with value: 0.2439856928684197 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 15, 'learning_rate': 0.00012368590451022766, 'p_miss': 0.18854641855968543}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:34:54,747] Trial 177 finished with value: 0.24622597913826838 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 12, 'learning_rate': 0.00011176658297159254, 'p_miss': 0.19496504658786032}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:35:59,938] Trial 178 finished with value: 0.2424415048918466 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 18, 'learning_rate': 0.000162414899851381, 'p_miss': 0.22018085787007302}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:36:46,505] Trial 179 finished with value: 0.24224045915280357 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 16, 'learning_rate': 0.00019158992375262795, 'p_miss': 0.21107018018319243}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:37:15,070] Trial 180 finished with value: 0.24468360211197976 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7, 'learning_rate': 0.004299550706976021, 'p_miss': 0.18226640688726176}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:38:54,659] Trial 30 finished with value: 0.29816198863255233 and parameters: {'model_name': 'VAE', 'batch_size': 926, 'iterations': 4081, 'learning_rate': 0.06245771135556824, 'p_miss': 0.08952527620188937}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:39:06,439] Trial 181 finished with value: 0.24388486179059038 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 33, 'learning_rate': 0.0002954822274202361, 'p_miss': 0.19901718048880093}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:39:07,086] Trial 183 finished with value: 0.43524534134532294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:39:46,442] Trial 184 finished with value: 0.24161568861914823 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 8, 'learning_rate': 0.0001466118683589018, 'p_miss': 0.19195017852729307}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:41:01,706] Trial 185 finished with value: 0.24171547477278463 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 20, 'learning_rate': 0.00011317435902070944, 'p_miss': 0.1568329352230942}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:41:37,710] Trial 182 finished with value: 0.24163467346432652 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 34, 'learning_rate': 0.0001426555695820285, 'p_miss': 0.19906481564417122}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:42:14,961] Trial 187 finished with value: 0.23999346758907603 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 10, 'learning_rate': 0.0002535212690795568, 'p_miss': 0.09352609385476644}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:42:55,776] Trial 188 finished with value: 0.24905539775297636 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 10, 'learning_rate': 0.0002496554250000887, 'p_miss': 0.0962785117799634}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:43:44,394] Trial 186 finished with value: 0.24087526522675295 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 47, 'learning_rate': 0.0002491279217005615, 'p_miss': 0.09796195643271796}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:43:56,451] Trial 189 finished with value: 0.24654368141666452 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 13, 'learning_rate': 0.0003431340731732472, 'p_miss': 0.17678988734976597}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:44:09,994] Trial 191 finished with value: 0.24403400169345452 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0005381422579316725, 'p_miss': 0.0687069043328582}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:44:23,639] Trial 190 finished with value: 0.24889195185778035 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 12, 'learning_rate': 0.0002256663061349417, 'p_miss': 0.09245839288348696}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:44:27,854] Trial 192 finished with value: 0.24604742095427112 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 5, 'learning_rate': 0.00020989243440422845, 'p_miss': 0.16672200659050163}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:44:57,819] Trial 194 finished with value: 0.24448474529983333 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 8, 'learning_rate': 0.0002897714178345079, 'p_miss': 0.10293270535040071}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:47:46,469] Trial 193 finished with value: 0.2429249329370453 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 46, 'learning_rate': 0.00041310055551169606, 'p_miss': 0.07953819207721444}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:48:16,409] Trial 195 finished with value: 0.24554899069992225 and parameters: {'model_name': 'VAE', 'batch_size': 219, 'iterations': 44, 'learning_rate': 0.00045354014841310515, 'p_miss': 0.0809008345574127}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:49:22,004] Trial 196 finished with value: 0.24218212537558442 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 26, 'learning_rate': 0.00016144898237697996, 'p_miss': 0.1816294174276583}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:50:06,286] Trial 197 finished with value: 0.24032337600286424 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 27, 'learning_rate': 0.00018705145852486384, 'p_miss': 0.14750461321429392}. Best is trial 76 with value: 0.23988320739986846.
running
[I 2024-11-14 03:51:09,014] Trial 198 finished with value: 0.2428970731444716 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 20, 'learning_rate': 0.00018560887475460786, 'p_miss': 0.14460109176790864}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 03:51:50,327] Trial 199 finished with value: 0.24018512121041166 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 23, 'learning_rate': 0.00018822393129834346, 'p_miss': 0.18899538297923263}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 04:16:43,575] Trial 55 finished with value: 0.30029556172022814 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 7278, 'learning_rate': 0.0002826936212689593, 'p_miss': 0.1787048027797541}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 04:39:11,191] Trial 25 finished with value: 0.2997955748735941 and parameters: {'model_name': 'VAE', 'batch_size': 748, 'iterations': 5775, 'learning_rate': 0.0440989264726968, 'p_miss': 0.034262692961493146}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 05:16:47,992] Trial 49 finished with value: 0.29704216015232987 and parameters: {'model_name': 'VAE', 'batch_size': 137, 'iterations': 7325, 'learning_rate': 0.00011720822146229226, 'p_miss': 0.1421472421779494}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 05:22:57,920] Trial 31 finished with value: 0.29911856670138126 and parameters: {'model_name': 'VAE', 'batch_size': 851, 'iterations': 5570, 'learning_rate': 0.05767516716426575, 'p_miss': 0.08024103307346853}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 05:24:14,944] Trial 54 finished with value: 0.29873782281509875 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 8808, 'learning_rate': 0.0002697980842325703, 'p_miss': 0.1817747562780545}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 05:50:36,636] Trial 29 finished with value: 0.2988778890345207 and parameters: {'model_name': 'VAE', 'batch_size': 854, 'iterations': 6142, 'learning_rate': 0.09027843614469706, 'p_miss': 0.08473966927674643}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:10:52,943] Trial 71 finished with value: 0.2977098458235067 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 8257, 'learning_rate': 0.00037401022243358867, 'p_miss': 0.09455201135794875}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:14:17,172] Trial 171 finished with value: 0.31761292107403855 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6752, 'learning_rate': 0.000114195571841572, 'p_miss': 0.18876030527858662}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:15:18,530] Trial 72 finished with value: 0.3035878012806194 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 9912, 'learning_rate': 0.0001834307112431926, 'p_miss': 0.21139978445098903}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:17:14,627] Trial 64 finished with value: 0.2976651259425038 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 9513, 'learning_rate': 0.001195654473616071, 'p_miss': 0.15961294673908577}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:17:51,496] Trial 167 finished with value: 0.29581360164323717 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 6045, 'learning_rate': 0.00023799355925929673, 'p_miss': 0.21277087710341192}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:18:52,026] Trial 159 finished with value: 0.2996796075526104 and parameters: {'model_name': 'VAE', 'batch_size': 430, 'iterations': 6431, 'learning_rate': 0.0004109476864802441, 'p_miss': 0.2122523966985281}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:18:53,966] Trial 118 finished with value: 0.2985516021742739 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 8652, 'learning_rate': 0.00022169220309002725, 'p_miss': 0.16932237007628706}. Best is trial 76 with value: 0.23988320739986846.
[I 2024-11-14 06:22:12,981] Trial 140 finished with value: 0.2983772327683648 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 8033, 'learning_rate': 0.0003578266624581344, 'p_miss': 0.1713557149368799}. Best is trial 76 with value: 0.23988320739986846.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.23988320739986846
{'model_name': 'VAE', 'batch_size': 11, 'iterations': 19, 'learning_rate': 0.00011084927078749628, 'p_miss': 0.16800431603920077}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0ca0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.05610296754437012
Generation:   4%|         | 1/25 [03:02<1:13:02, 182.61s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474717400> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.05610296754437012
Generation:   8%|         | 2/25 [08:57<1:48:56, 284.20s/it]Generation:  3
Best f1_score score: 0.05610296754437012
Generation:  12%|        | 3/25 [09:58<1:06:48, 182.19s/it]Generation:  4
Best f1_score score: 0.05610296754437012
Generation:  16%|        | 4/25 [16:21<1:31:32, 261.55s/it]Generation:  5
Best f1_score score: 0.05694583295202893
Generation:  20%|        | 5/25 [24:25<1:53:52, 341.61s/it]Generation:  6
Best f1_score score: 0.05694583295202893
Generation:  24%|       | 6/25 [26:51<1:27:08, 275.19s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474715090> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d9a050> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.05694583295202893
Generation:  28%|       | 7/25 [32:55<1:31:11, 303.98s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657573a0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467df9300> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.05694583295202893
Generation:  32%|      | 8/25 [37:37<1:24:10, 297.08s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467dd64d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.05694583295202893
Generation:  36%|      | 9/25 [38:36<59:21, 222.60s/it]  Generation:  10
Best f1_score score: 0.05694583295202893
Generation:  40%|      | 10/25 [39:47<43:59, 175.94s/it]Generation:  11
Best f1_score score: 0.05783252240446464
Generation:  44%|     | 11/25 [41:50<37:15, 159.69s/it]Generation:  12
Best f1_score score: 0.05783252240446464
Generation:  48%|     | 12/25 [48:40<51:05, 235.80s/it]Generation:  13
Best f1_score score: 0.058093580044580886
Generation:  52%|    | 13/25 [52:28<46:42, 233.52s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474715f00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.058093580044580886
Generation:  56%|    | 14/25 [52:56<31:24, 171.33s/it]Generation:  15
Best f1_score score: 0.058093580044580886
Generation:  60%|    | 15/25 [54:18<24:03, 144.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe7fa0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.058093580044580886
Generation:  64%|   | 16/25 [57:01<22:29, 149.98s/it]Generation:  17
Best f1_score score: 0.058093580044580886
Generation:  68%|   | 17/25 [1:04:51<32:51, 246.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465640d60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  18
Best f1_score score: 0.058093580044580886
Generation:  72%|  | 18/25 [1:05:50<22:10, 190.12s/it]Generation:  19
Best f1_score score: 0.058093580044580886
Generation:  76%|  | 19/25 [1:10:23<21:29, 214.86s/it]Generation:  20
Best f1_score score: 0.058093580044580886
Generation:  80%|  | 20/25 [1:12:06<15:07, 181.47s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546798dc00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.058093580044580886
Generation:  84%| | 21/25 [1:16:40<13:56, 209.24s/it]Generation:  22
Best f1_score score: 0.058093580044580886
Generation:  88%| | 22/25 [1:17:57<08:28, 169.34s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678cf9a0> 

Generation:  23
Best f1_score score: 0.058093580044580886
Generation:  92%|| 23/25 [1:28:10<10:05, 302.58s/it]Generation:  24
Best f1_score score: 0.058093580044580886
Generation:  96%|| 24/25 [1:30:28<04:13, 253.09s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a71330> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465215d50> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.058093580044580886
Generation: 100%|| 25/25 [1:33:43<00:00, 235.67s/it]Generation: 100%|| 25/25 [1:33:46<00:00, 225.05s/it]
2024-11-14 07:56:10,753 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:35795' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-04ef1e3a7246aa787bf6714e77e9803f', 'ndarray-9dab0b971f6fc1723e725d27ca3f0a7b'} (stimulus_id='handle-worker-cleanup-1731599770.7533593')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=9,
                                n_estimators=82, n_jobs=1, num_leaves=111,
                                verbose=-1))])
score start
train score: {'auroc': 0.9790740355194154, 'accuracy': 0.7397968276599537, 'balanced_accuracy': 0.873649607600878, 'logloss': 1.358786634568819, 'f1': 0.7561614377160117}
original test score: {'auroc': 0.5578190856653251, 'accuracy': 0.11778332145402709, 'balanced_accuracy': 0.05896224697868661, 'logloss': 2.5804142879759677, 'f1': 0.059360668404519465}
imputed test score: {'auroc': 0.5110332231679372, 'accuracy': 0.09836065573770492, 'balanced_accuracy': 0.06195529646520004, 'logloss': 2.7153160831921066, 'f1': 0.059684314061889704}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4cd0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  1
Best f1_score score: 0.17760922939219348
Generation:   4%|         | 1/25 [03:26<1:22:43, 206.82s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e096f0> 
 Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 263, in fit
    return self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 423, in _partial_fit
    X, y = self._validate_data(X, y, reset=first_call)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.17760922939219348
Generation:   8%|         | 2/25 [06:14<1:10:21, 183.56s/it]Generation:  3
Best f1_score score: 0.17860003193493063
Generation:  12%|        | 3/25 [09:34<1:10:10, 191.39s/it]Generation:  4
Best f1_score score: 0.18136437912608017
Generation:  16%|        | 4/25 [14:19<1:19:55, 228.37s/it]Generation:  5
Best f1_score score: 0.18136437912608017
Generation:  20%|        | 5/25 [19:06<1:23:04, 249.22s/it]Generation:  6
Best f1_score score: 0.18136437912608017
Generation:  24%|       | 6/25 [23:56<1:23:21, 263.23s/it]Generation:  7
Best f1_score score: 0.1819427160395895
Generation:  28%|       | 7/25 [31:27<1:37:21, 324.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554656457b0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  8
Best f1_score score: 0.18926428998878225
Generation:  32%|      | 8/25 [41:28<1:56:54, 412.62s/it]Generation:  9
Best f1_score score: 0.18926428998878225
Generation:  36%|      | 9/25 [49:58<1:58:07, 442.98s/it]Generation:  10
Best f1_score score: 0.18926428998878225
Generation:  40%|      | 10/25 [58:50<1:57:39, 470.65s/it]Generation:  11
Best f1_score score: 0.18926428998878225
Generation:  44%|     | 11/25 [1:07:26<1:53:02, 484.49s/it]Generation:  12
Best f1_score score: 0.1903052109602597
Generation:  48%|     | 12/25 [1:16:33<1:49:03, 503.31s/it]Generation:  13
Best f1_score score: 0.1903052109602597
Generation:  52%|    | 13/25 [1:25:00<1:40:55, 504.66s/it]Generation:  14
Best f1_score score: 0.19388190149349566
Generation:  56%|    | 14/25 [1:33:49<1:33:51, 511.95s/it]Generation:  15
Best f1_score score: 0.19388190149349566
Generation:  60%|    | 15/25 [1:42:33<1:25:55, 515.53s/it]Generation:  16
Best f1_score score: 0.20059887299213805
Generation:  64%|   | 16/25 [1:45:39<1:02:26, 416.25s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546562c7f0> 

Generation:  17
Best f1_score score: 0.20059887299213805
Generation:  68%|   | 17/25 [1:55:44<1:03:04, 473.04s/it]Generation:  18
Best f1_score score: 0.20059887299213805
Generation:  72%|  | 18/25 [1:58:48<45:03, 386.28s/it]  Generation:  19
Best f1_score score: 0.20059887299213805
Generation:  76%|  | 19/25 [2:07:13<42:11, 421.89s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452116110> 

Generation:  20
Best f1_score score: 0.20374556792485848
Generation:  80%|  | 20/25 [2:17:20<39:47, 477.56s/it]Generation:  21
Best f1_score score: 0.20374556792485848
Generation:  84%| | 21/25 [2:20:44<26:22, 395.51s/it]Generation:  22
Best f1_score score: 0.20374556792485848
Generation:  88%| | 22/25 [2:30:00<22:10, 443.45s/it]Generation:  23
Best f1_score score: 0.20374556792485848
Generation:  92%|| 23/25 [2:38:19<15:20, 460.18s/it]Generation:  24
Best f1_score score: 0.20374556792485848
Generation:  96%|| 24/25 [2:45:56<07:39, 459.41s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe4d0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  25
Best f1_score score: 0.20374556792485848
Generation: 100%|| 25/25 [2:54:22<00:00, 473.14s/it]Generation: 100%|| 25/25 [2:54:22<00:00, 418.48s/it]
2024-11-14 10:51:15,413 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37379' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-04ef1e3a7246aa787bf6714e77e9803f', 'DataFrame-9cf808796ac437c5812250ed173f31c9'} (stimulus_id='handle-worker-cleanup-1731610275.4129484')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.655377703798,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.2050448083342, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=6,
                               max_leaves=None, min_child_weight=4, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8759236945348224, 'accuracy': 0.3747995009802174, 'balanced_accuracy': 0.27884859241477644, 'logloss': 1.7878297073190588, 'f1': 0.32279407652657566}
test score: {'auroc': 0.822903519301701, 'accuracy': 0.29294369208838206, 'balanced_accuracy': 0.18479229786144627, 'logloss': 1.969638879753145, 'f1': 0.20468761365679805}
original test score: {'auroc': 0.9482586302079389, 'accuracy': 0.5687811831789024, 'balanced_accuracy': 0.5057362235727619, 'logloss': 1.2304261892783943, 'f1': 0.5198983923431252}
score end
1481
lvl
0.5
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
14.31438863641686
hours
DONE
