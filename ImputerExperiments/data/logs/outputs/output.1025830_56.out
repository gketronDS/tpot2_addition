Run: 56
/cm/local/apps/slurm/var/spool/job1025830/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/737/737.pkl
working on 
../data/c/737/class_full_MAR_0.5_3
3.649470567703247
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-26 13:43:23,644] A new study created in memory with name: no-name-5f53bc3b-2341-4153-9c59-e171244635cf
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-26 13:43:23,810] Trial 0 finished with value: 0.5854329734529614 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5854329734529614.
[I 2024-10-26 13:43:23,931] Trial 9 finished with value: 0.5854329734529614 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.5854329734529614.
running
running
[I 2024-10-26 13:43:24,092] Trial 11 finished with value: 0.10372605867999511 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.10372605867999511.
[I 2024-10-26 13:43:24,233] Trial 17 finished with value: 0.10372605867999511 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 11 with value: 0.10372605867999511.
running
running
[I 2024-10-26 13:43:24,544] Trial 2 finished with value: 0.10372605867999511 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2482, 'weights': 'uniform'}. Best is trial 11 with value: 0.10372605867999511.
running
[I 2024-10-26 13:43:24,703] Trial 12 finished with value: 0.10372605867999511 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1980, 'weights': 'uniform'}. Best is trial 11 with value: 0.10372605867999511.
[I 2024-10-26 13:43:24,794] Trial 5 finished with value: 0.10372605867999511 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2331, 'weights': 'uniform'}. Best is trial 11 with value: 0.10372605867999511.
running
[I 2024-10-26 13:43:24,924] Trial 16 finished with value: 0.09597260489882278 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1583, 'weights': 'uniform'}. Best is trial 16 with value: 0.09597260489882278.
running
running
[I 2024-10-26 13:43:25,043] Trial 6 finished with value: 0.07025311015842647 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 638, 'weights': 'distance'}. Best is trial 6 with value: 0.07025311015842647.
[I 2024-10-26 13:43:25,124] Trial 20 finished with value: 0.1048157077469678 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 6 with value: 0.07025311015842647.
running
running
[I 2024-10-26 13:43:27,558] Trial 22 finished with value: 0.066827056559186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 22 with value: 0.066827056559186.
running
[I 2024-10-26 13:43:27,840] Trial 25 finished with value: 0.07797361223398203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 22 with value: 0.066827056559186.
running
[I 2024-10-26 13:43:28,879] Trial 13 finished with value: 0.08156651994418242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 22 with value: 0.066827056559186.
running
[I 2024-10-26 13:43:29,482] Trial 26 finished with value: 0.066827056559186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 22 with value: 0.066827056559186.
running
[I 2024-10-26 13:43:30,362] Trial 10 finished with value: 0.04877983922282421 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:30,491] Trial 8 finished with value: 0.05184174410808704 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:33,695] Trial 29 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5919810990014962, 'alpha': 91, 'iterations': 4, 'learning_rate': 0.0984546813664599, 'p_miss': 0.23541157177750566}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:48,052] Trial 14 finished with value: 0.19065569012970693 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0033373231706684795, 'p_miss': 0.03298194129246681}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:51,646] Trial 3 finished with value: 0.17992323118449544 and parameters: {'model_name': 'VAE', 'batch_size': 412, 'iterations': 4, 'learning_rate': 0.0027398142364573196, 'p_miss': 0.12093895144496881}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:53,047] Trial 21 finished with value: 0.10692517130581851 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 8, 'learning_rate': 0.047186105819576614, 'p_miss': 0.08609525526215117}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:43:53,856] Trial 31 finished with value: 0.5024214885569724 and parameters: {'model_name': 'GAIN', 'batch_size': 602, 'hint_rate': 0.40994347417609944, 'alpha': 81, 'iterations': 23, 'learning_rate': 0.0004960135380834419, 'p_miss': 0.045158034847858436}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:44:01,696] Trial 28 finished with value: 0.19594512745156575 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 28, 'learning_rate': 0.0001255175440985646, 'p_miss': 0.2787381763182047}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:44:07,786] Trial 33 finished with value: 0.04908987609133398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:44:09,065] Trial 34 finished with value: 0.04908987609133398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:44:09,414] Trial 35 finished with value: 0.04908987609133398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 10 with value: 0.04877983922282421.
running
[I 2024-10-26 13:44:11,001] Trial 36 finished with value: 0.048753819744354804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 36 with value: 0.048753819744354804.
running
[I 2024-10-26 13:44:11,960] Trial 27 finished with value: 0.11179076392033382 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 46, 'learning_rate': 0.05721069497337425, 'p_miss': 0.22165829669868425}. Best is trial 36 with value: 0.048753819744354804.
running
[I 2024-10-26 13:44:12,547] Trial 4 finished with value: 0.5054801339799321 and parameters: {'model_name': 'GAIN', 'batch_size': 798, 'hint_rate': 0.30564223945235597, 'alpha': 25, 'iterations': 73, 'learning_rate': 0.02011291809469053, 'p_miss': 0.18154540863689558}. Best is trial 36 with value: 0.048753819744354804.
running
[I 2024-10-26 13:44:14,811] Trial 40 finished with value: 0.03576994274719897 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 40 with value: 0.03576994274719897.
running
[I 2024-10-26 13:44:17,739] Trial 30 finished with value: 0.1882827081841673 and parameters: {'model_name': 'VAE', 'batch_size': 332, 'iterations': 24, 'learning_rate': 0.00021080871415494792, 'p_miss': 0.27281549929465304}. Best is trial 40 with value: 0.03576994274719897.
running
[I 2024-10-26 13:44:20,625] Trial 43 finished with value: 0.034865459346008654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:21,367] Trial 37 finished with value: 0.048753819744354804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:23,265] Trial 44 finished with value: 0.03821036126878817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:25,929] Trial 45 finished with value: 0.03821036126878817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:28,747] Trial 38 finished with value: 0.04908987609133398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:29,313] Trial 46 finished with value: 0.034865459346008654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:29,475] Trial 39 finished with value: 0.04908987609133398 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 43 with value: 0.034865459346008654.
running
[I 2024-10-26 13:44:30,408] Trial 47 finished with value: 0.0322828391081787 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:44:32,517] Trial 48 finished with value: 0.03821036126878817 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:44:34,346] Trial 49 finished with value: 0.03430165085137957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:44:37,664] Trial 50 finished with value: 0.03430165085137957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:44:38,437] Trial 51 finished with value: 0.0372956090849942 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:44:38,782] Trial 52 finished with value: 0.0372956090849942 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'arabic'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:53:45,229] Trial 19 finished with value: 0.03397994950251376 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:53:55,395] Trial 58 finished with value: 0.03285637777524435 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 47 with value: 0.0322828391081787.
running
[I 2024-10-26 13:54:00,882] Trial 41 finished with value: 0.0321284339025673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 41 with value: 0.0321284339025673.
running
[I 2024-10-26 13:54:09,035] Trial 24 finished with value: 0.02970402102958338 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 13:54:09,977] Trial 62 finished with value: 0.03745701543340208 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5, 'weights': 'distance'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 13:54:13,280] Trial 42 finished with value: 0.03127314544103308 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 13:54:13,837] Trial 64 finished with value: 0.1803829157252252 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 13:54:14,765] Trial 65 finished with value: 0.07641759178280286 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1040, 'weights': 'distance'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:01:23,639] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9897670070003426, 'alpha': 32, 'iterations': 4301, 'learning_rate': 0.015532492910989959, 'p_miss': 0.18693742200509855}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:03:28,763] Trial 7 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.8428103944304736, 'alpha': 31, 'iterations': 4634, 'learning_rate': 0.00042070423873395555, 'p_miss': 0.17617092480359983}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:08:51,764] Trial 67 finished with value: 0.057815983969877104 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:11:10,281] Trial 68 finished with value: 0.058802160096039134 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:11:18,924] Trial 55 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9677263346969018, 'alpha': 14, 'iterations': 5685, 'learning_rate': 0.006805695464820386, 'p_miss': 0.15865482444275802}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:17:47,494] Trial 53 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9899998331164177, 'alpha': 0, 'iterations': 7081, 'learning_rate': 0.005341663523172584, 'p_miss': 0.1599063594119947}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:17:52,424] Trial 69 finished with value: 0.03377426073142707 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:17:53,063] Trial 73 finished with value: 0.1803829157252252 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:20:18,714] Trial 70 finished with value: 0.03417717647188876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:20:19,622] Trial 71 finished with value: 0.03368163245758118 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:23:05,481] Trial 63 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9721092967952674, 'alpha': 1, 'iterations': 6055, 'learning_rate': 0.004793939493825688, 'p_miss': 0.16184006192739542}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:23:21,553] Trial 60 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9860281354159499, 'alpha': 3, 'iterations': 6120, 'learning_rate': 0.0061645518482096595, 'p_miss': 0.17192651533706468}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:27:12,336] Trial 72 finished with value: 0.03380893164545649 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:27:43,913] Trial 54 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9711761604815445, 'alpha': 3, 'iterations': 8666, 'learning_rate': 0.005436383505267691, 'p_miss': 0.1697628070183292}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:27:54,575] Trial 74 finished with value: 0.029988316232715882 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:30:14,349] Trial 76 finished with value: 0.030072245240008694 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:30:34,711] Trial 75 finished with value: 0.030329351193773023 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:31:24,583] Trial 57 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9559148480157973, 'alpha': 7, 'iterations': 9513, 'learning_rate': 0.005889342018445023, 'p_miss': 0.16323529012000468}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:32:28,548] Trial 56 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9683663422215317, 'alpha': 3, 'iterations': 9732, 'learning_rate': 0.007691130518061046, 'p_miss': 0.1571329014620747}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:34:15,595] Trial 77 finished with value: 0.029973220873259036 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 24 with value: 0.02970402102958338.
running
[I 2024-10-26 14:34:31,341] Trial 78 finished with value: 0.029657789427588593 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:35:06,279] Trial 59 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.987420610377689, 'alpha': 2, 'iterations': 8219, 'learning_rate': 0.005531159447417407, 'p_miss': 0.15846076760911837}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:37:24,132] Trial 61 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9585843067216132, 'alpha': 0, 'iterations': 8726, 'learning_rate': 0.0067195146230367144, 'p_miss': 0.13805806840809046}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:38:27,427] Trial 79 finished with value: 0.029855031288392054 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:38:32,897] Trial 90 finished with value: 0.19212948352821205 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0016269618957225997, 'p_miss': 0.011833413322316716}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:39:21,883] Trial 80 finished with value: 0.030168003096724443 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:39:23,127] Trial 81 finished with value: 0.02990103912432221 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:41:38,535] Trial 82 finished with value: 0.029975334148892696 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:41:39,956] Trial 94 finished with value: 0.06373288018024849 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 275, 'weights': 'distance'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:42:10,491] Trial 83 finished with value: 0.029735367972470193 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:45:39,891] Trial 86 finished with value: 0.03018874254772274 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:45:46,842] Trial 87 finished with value: 0.03050046165664927 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:46:30,819] Trial 88 finished with value: 0.02971635840388983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:47:00,951] Trial 66 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.97541630099672, 'alpha': 13, 'iterations': 9872, 'learning_rate': 0.006632186868965576, 'p_miss': 0.14875178844597348}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:48:40,218] Trial 89 finished with value: 0.029992662007544874 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:49:58,392] Trial 91 finished with value: 0.029869340439167648 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:50:56,491] Trial 93 finished with value: 0.030255772720323502 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:50:58,264] Trial 92 finished with value: 0.030036085994783523 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:51:04,681] Trial 103 finished with value: 0.03478792531037652 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:51:05,069] Trial 105 finished with value: 0.1048157077469678 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:51:06,571] Trial 104 finished with value: 0.03504873217233963 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:53:12,076] Trial 95 finished with value: 0.030232683939474137 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:53:56,119] Trial 96 finished with value: 0.0298754642337342 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:56:56,039] Trial 84 finished with value: 0.10603764213026215 and parameters: {'model_name': 'VAE', 'batch_size': 77, 'iterations': 359, 'learning_rate': 0.001295356547220622, 'p_miss': 0.09808239022876149}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:57:28,838] Trial 97 finished with value: 0.029787559009997227 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:57:36,757] Trial 98 finished with value: 0.030154187730976112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:58:10,622] Trial 99 finished with value: 0.030157913095513855 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 14:58:52,271] Trial 100 finished with value: 0.030013094853679194 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:00:33,719] Trial 101 finished with value: 0.03119094181301903 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:01:59,078] Trial 102 finished with value: 0.030205993462694397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:03:16,153] Trial 106 finished with value: 0.030068594258689872 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:03:19,450] Trial 107 finished with value: 0.0298105448961548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:05:24,395] Trial 108 finished with value: 0.03011871544172458 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:05:31,237] Trial 85 finished with value: 0.10659655277889926 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 451, 'learning_rate': 0.0012249795613189615, 'p_miss': 0.1094427131759503}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:06:14,870] Trial 109 finished with value: 0.03029211804088714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:09:16,096] Trial 110 finished with value: 0.030146336375341247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:10:03,067] Trial 111 finished with value: 0.030094793014154946 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:10:07,818] Trial 112 finished with value: 0.02991802211727943 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:10:46,924] Trial 113 finished with value: 0.02987628139855709 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:10:49,116] Trial 125 finished with value: 0.07783840776818858 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1157, 'weights': 'distance'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:11:28,360] Trial 114 finished with value: 0.030359671432424563 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:12:38,957] Trial 115 finished with value: 0.03006270786854473 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:14:05,893] Trial 116 finished with value: 0.030275251767037454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:15:34,410] Trial 117 finished with value: 0.030119863285812825 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:15:38,627] Trial 118 finished with value: 0.029901728276634298 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:15:38,978] Trial 131 finished with value: 0.1048157077469678 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:15:54,272] Trial 130 finished with value: 0.03516585732316026 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:15:57,268] Trial 132 finished with value: 0.03716081133423792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:17:42,208] Trial 119 finished with value: 0.03013660482959974 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:17:49,066] Trial 120 finished with value: 0.029766437008200614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:18:55,017] Trial 121 finished with value: 0.029832783209898416 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:21:44,247] Trial 122 finished with value: 0.030090485336041684 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:22:38,648] Trial 123 finished with value: 0.03006281542025472 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:22:48,637] Trial 124 finished with value: 0.03012889757179622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:23:06,367] Trial 126 finished with value: 0.03008998156735688 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:23:15,120] Trial 141 finished with value: 0.034411714035989166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:24:07,266] Trial 127 finished with value: 0.029961265552841638 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:25:04,875] Trial 128 finished with value: 0.02996853964741438 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:25:06,775] Trial 144 finished with value: 0.09744456603458246 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1661, 'weights': 'uniform'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:26:29,443] Trial 129 finished with value: 0.02989934918599736 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:28:06,375] Trial 133 finished with value: 0.030154905588664533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:28:23,649] Trial 134 finished with value: 0.029891737189336957 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:29:52,178] Trial 136 finished with value: 0.030213971705570657 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:29:55,181] Trial 135 finished with value: 0.03036477311725902 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:31:15,773] Trial 137 finished with value: 0.029924372658103392 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:34:08,467] Trial 138 finished with value: 0.029966871013870394 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:35:10,847] Trial 139 finished with value: 0.02996680121251427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:35:25,854] Trial 140 finished with value: 0.030045403491387956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:35:43,369] Trial 142 finished with value: 0.029747744953744028 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:36:25,417] Trial 143 finished with value: 0.03016149877849248 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:37:16,698] Trial 145 finished with value: 0.030081379020354355 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:38:16,401] Trial 146 finished with value: 0.030022128691661994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:39:44,411] Trial 147 finished with value: 0.030085166989022548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:39:49,698] Trial 148 finished with value: 0.030094233913547645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:40:56,557] Trial 150 finished with value: 0.03009228419632436 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:40:58,742] Trial 149 finished with value: 0.030030616888333573 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:40:59,026] Trial 162 finished with value: 0.5854329734529614 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:45:28,622] Trial 155 finished with value: 0.030027372759802457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:50:11,814] Trial 163 finished with value: 0.031058831052520074 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:50:17,385] Trial 165 finished with value: 0.03414976629142681 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 15:59:12,923] Trial 166 finished with value: 0.03000194770596179 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:06:24,852] Trial 154 finished with value: 0.11914610416512735 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 633, 'learning_rate': 0.0004483186329502568, 'p_miss': 0.2975755116814841}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:08:05,194] Trial 167 finished with value: 0.03013845242337667 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:15:54,383] Trial 168 finished with value: 0.030007782625074576 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:17:20,930] Trial 169 finished with value: 0.030408692310786058 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:24:17,610] Trial 171 finished with value: 0.07388742422944614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:25:24,353] Trial 158 finished with value: 0.11824896474889583 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 953, 'learning_rate': 0.0005123370771323649, 'p_miss': 0.07304942137318596}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:25:34,372] Trial 170 finished with value: 0.03076388094730862 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:33:17,755] Trial 172 finished with value: 0.02992061249841138 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:34:33,159] Trial 173 finished with value: 0.030102777568088566 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:35:23,775] Trial 174 finished with value: 0.030363486644927457 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:36:52,131] Trial 152 finished with value: 0.10594552558364582 and parameters: {'model_name': 'VAE', 'batch_size': 173, 'iterations': 1168, 'learning_rate': 0.0006137529623964067, 'p_miss': 0.07220560354174002}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:39:32,924] Trial 18 finished with value: 0.1277750720216944 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3152, 'learning_rate': 0.018785545145366702, 'p_miss': 0.12773596627125525}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:43:02,913] Trial 175 finished with value: 0.029966338916161496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:44:23,261] Trial 176 finished with value: 0.03008796441514382 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:45:38,324] Trial 177 finished with value: 0.03000435743643507 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:46:52,614] Trial 178 finished with value: 0.03015827369481227 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:46:53,683] Trial 183 finished with value: 0.08240614929344632 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 664, 'weights': 'uniform'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:46:57,590] Trial 164 finished with value: 0.12216783583191819 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1070, 'learning_rate': 0.015324698212820127, 'p_miss': 0.06771404015689689}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:47:09,916] Trial 184 finished with value: 0.03716081133423792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:47:12,813] Trial 185 finished with value: 0.03716081133423792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:49:22,498] Trial 179 finished with value: 0.029733202343523703 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:51:19,150] Trial 156 finished with value: 0.10641785587156845 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 1074, 'learning_rate': 0.0006666106342315189, 'p_miss': 0.06176380230837711}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:53:26,209] Trial 180 finished with value: 0.030280285703441878 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:55:00,061] Trial 181 finished with value: 0.029962499873484268 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:56:32,652] Trial 182 finished with value: 0.03036705990569406 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:57:40,835] Trial 187 finished with value: 0.03034521040831068 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:57:43,321] Trial 186 finished with value: 0.02983846420003621 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:57:47,205] Trial 193 finished with value: 0.03577003523744059 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 16:59:25,921] Trial 188 finished with value: 0.03024100857623161 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 17:00:09,337] Trial 157 finished with value: 0.10652642257718219 and parameters: {'model_name': 'VAE', 'batch_size': 155, 'iterations': 1525, 'learning_rate': 0.0006697962777610658, 'p_miss': 0.0685501750500982}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 17:01:28,076] Trial 151 finished with value: 0.12644656326165354 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1505, 'learning_rate': 0.0005607705792941043, 'p_miss': 0.2986779764913342}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 17:02:05,179] Trial 189 finished with value: 0.029917318072428138 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
running
[I 2024-10-26 17:04:11,878] Trial 190 finished with value: 0.030276453784778112 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:05:38,977] Trial 191 finished with value: 0.030902942147750155 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:06:13,641] Trial 153 finished with value: 0.11692571788824595 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1329, 'learning_rate': 0.0005098117288006248, 'p_miss': 0.29572520400846924}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:07:13,599] Trial 192 finished with value: 0.03095695873843482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:08:04,435] Trial 194 finished with value: 0.03142602827230138 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'ascending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:08:09,492] Trial 195 finished with value: 0.0303606531052664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:08:50,220] Trial 196 finished with value: 0.03004875496286099 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:09:27,502] Trial 197 finished with value: 0.029713505068561196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:10:06,068] Trial 160 finished with value: 0.11918089925941096 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1494, 'learning_rate': 0.016183853901645135, 'p_miss': 0.05996633958820288}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:10:13,122] Trial 198 finished with value: 0.03079614123314255 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:10:25,343] Trial 199 finished with value: 0.029994483577548116 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:10:51,129] Trial 161 finished with value: 0.11542999937857365 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1519, 'learning_rate': 0.0007039818179167619, 'p_miss': 0.07329399434015184}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:11:25,103] Trial 159 finished with value: 0.12294707853843731 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1875, 'learning_rate': 0.0005159187001557788, 'p_miss': 0.07391398971682096}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:11:34,988] Trial 23 finished with value: 0.44570787212495394 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.31015322732025846, 'alpha': 58, 'iterations': 8232, 'learning_rate': 0.017360466368757085, 'p_miss': 0.2812997261578081}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:18:56,361] Trial 1 finished with value: 0.1222337555292694 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7643, 'learning_rate': 0.022161869467935275, 'p_miss': 0.1940074715775146}. Best is trial 78 with value: 0.029657789427588593.
[I 2024-10-26 17:23:14,097] Trial 32 finished with value: 0.10622730338870331 and parameters: {'model_name': 'VAE', 'batch_size': 583, 'iterations': 8295, 'learning_rate': 0.00015453492126812852, 'p_miss': 0.015187977113221035}. Best is trial 78 with value: 0.029657789427588593.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.029657789427588593
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.8098285881888728
Generation:   4%|         | 1/25 [00:04<01:47,  4.49s/it]Generation:  2
Best f1_score score: 0.810213705009627
Generation:   8%|         | 2/25 [01:18<17:28, 45.60s/it]Generation:  3
Best f1_score score: 0.810286400998408
Generation:  12%|        | 3/25 [01:25<10:09, 27.72s/it]Generation:  4
Best f1_score score: 0.8106109333947726
Generation:  16%|        | 4/25 [01:33<07:02, 20.10s/it]Generation:  5
Best f1_score score: 0.8106109333947726
Generation:  20%|        | 5/25 [03:04<15:08, 45.43s/it]Generation:  6
Best f1_score score: 0.8143855289652985
Generation:  24%|       | 6/25 [03:13<10:32, 33.28s/it]Generation:  7
Best f1_score score: 0.8143855289652985
Generation:  28%|       | 7/25 [03:23<07:40, 25.58s/it]Generation:  8
Best f1_score score: 0.8152036447796658
Generation:  32%|      | 8/25 [04:45<12:19, 43.52s/it]Generation:  9
Best f1_score score: 0.8152036447796658
Generation:  36%|      | 9/25 [04:56<08:54, 33.41s/it]Generation:  10
Best f1_score score: 0.8152036447796658
Generation:  40%|      | 10/25 [05:37<08:54, 35.63s/it]Generation:  11
Best f1_score score: 0.8152036447796658
Generation:  44%|     | 11/25 [05:46<06:26, 27.62s/it]Generation:  12
Best f1_score score: 0.8152036447796658
Generation:  48%|     | 12/25 [05:56<04:49, 22.30s/it]Generation:  13
Best f1_score score: 0.8152036447796658
Generation:  52%|    | 13/25 [06:08<03:47, 18.94s/it]Generation:  14
Best f1_score score: 0.8152036447796658
Generation:  56%|    | 14/25 [06:17<02:57, 16.13s/it]Generation:  15
Best f1_score score: 0.8152036447796658
Generation:  60%|    | 15/25 [06:28<02:24, 14.42s/it]Generation:  16
Best f1_score score: 0.8152036447796658
Generation:  64%|   | 16/25 [06:58<02:52, 19.22s/it]Generation:  17
Best f1_score score: 0.8152036447796658
Generation:  68%|   | 17/25 [07:09<02:14, 16.79s/it]Generation:  18
Best f1_score score: 0.8152036447796658
Generation:  72%|  | 18/25 [07:43<02:32, 21.78s/it]Generation:  19
Best f1_score score: 0.8176069225198667
Generation:  76%|  | 19/25 [07:57<01:58, 19.70s/it]Generation:  20
Best f1_score score: 0.8176069225198667
Generation:  80%|  | 20/25 [08:14<01:33, 18.78s/it]Generation:  21
Best f1_score score: 0.8176069225198667
Generation:  84%| | 21/25 [08:26<01:07, 16.84s/it]Generation:  22
Best f1_score score: 0.8176069225198667
Generation:  88%| | 22/25 [08:40<00:48, 16.01s/it]Generation:  23
Best f1_score score: 0.8176069225198667
Generation:  92%|| 23/25 [09:36<00:55, 27.98s/it]Generation:  24
Best f1_score score: 0.8176069225198667
Generation:  96%|| 24/25 [09:49<00:23, 23.48s/it]Generation:  25
Best f1_score score: 0.8176069225198667
Generation: 100%|| 25/25 [10:08<00:00, 22.13s/it]Generation: 100%|| 25/25 [10:11<00:00, 24.48s/it]
2024-10-26 17:34:16,478 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45273' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-bc1ee22df90b340c13f4c4b70d48b351', 'ndarray-6153e506c1cd218ed23820be4c9270e1'} (stimulus_id='handle-worker-cleanup-1729989256.4787674')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(max_features=0.5229825222366,
                                      min_samples_leaf=2, min_samples_split=7,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.9917180362190974, 'accuracy': 0.9468812877263582, 'balanced_accuracy': 0.9468289504027942, 'logloss': 0.2329182668426752, 'f1': 0.9468707482993197}
original test score: {'auroc': 0.9013669451567541, 'accuracy': 0.8327974276527331, 'balanced_accuracy': 0.8323165687815369, 'logloss': 0.414961946263432, 'f1': 0.832235443011712}
imputed test score: {'auroc': 0.8795082306228802, 'accuracy': 0.8070739549839229, 'balanced_accuracy': 0.8067768219042104, 'logloss': 0.4419879361469561, 'f1': 0.8067862948735206}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014670>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d20d00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.8047735966791528
Generation:   4%|         | 1/25 [04:08<1:39:13, 248.05s/it]Generation:  2
Best f1_score score: 0.8047735966791528
Generation:   8%|         | 2/25 [05:11<53:30, 139.58s/it]  Generation:  3
Best f1_score score: 0.8063663055920113
Generation:  12%|        | 3/25 [05:58<35:37, 97.16s/it] Generation:  4
Best f1_score score: 0.8095966264208171
Generation:  16%|        | 4/25 [06:06<21:44, 62.11s/it]Generation:  5
Best f1_score score: 0.8103546186142416
Generation:  20%|        | 5/25 [07:13<21:16, 63.82s/it]Generation:  6
Best f1_score score: 0.818424596057907
Generation:  24%|       | 6/25 [07:24<14:27, 45.68s/it]Generation:  7
Best f1_score score: 0.818424596057907
Generation:  28%|       | 7/25 [07:38<10:38, 35.47s/it]Generation:  8
Best f1_score score: 0.818424596057907
Generation:  32%|      | 8/25 [07:51<08:01, 28.32s/it]Generation:  9
Best f1_score score: 0.818424596057907
Generation:  36%|      | 9/25 [08:03<06:10, 23.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554572c0340> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.818424596057907
Generation:  40%|      | 10/25 [10:07<13:35, 54.39s/it]Generation:  11
Best f1_score score: 0.818424596057907
Generation:  44%|     | 11/25 [11:59<16:49, 72.10s/it]Generation:  12
Best f1_score score: 0.818424596057907
Generation:  48%|     | 12/25 [14:50<22:06, 102.07s/it]Generation:  13
Best f1_score score: 0.818424596057907
Generation:  52%|    | 13/25 [15:01<14:53, 74.43s/it] Generation:  14
Best f1_score score: 0.8192095518560623
Generation:  56%|    | 14/25 [15:14<10:15, 55.92s/it]Generation:  15
Best f1_score score: 0.820027509646055
Generation:  60%|    | 15/25 [17:03<11:58, 71.83s/it]Generation:  16
Best f1_score score: 0.8212258334956468
Generation:  64%|   | 16/25 [18:17<10:51, 72.42s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545503e1a0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  17
Best f1_score score: 0.8212258334956468
Generation:  68%|   | 17/25 [18:36<07:31, 56.40s/it]Generation:  18
Best f1_score score: 0.8212258334956468
Generation:  72%|  | 18/25 [18:45<04:55, 42.28s/it]Generation:  19
Best f1_score score: 0.8212258334956468
Generation:  76%|  | 19/25 [21:37<08:08, 81.35s/it]Generation:  20
Best f1_score score: 0.8212258334956468
Generation:  80%|  | 20/25 [21:44<04:54, 58.92s/it]Generation:  21
Best f1_score score: 0.8224144457063154
Generation:  84%| | 21/25 [22:58<04:13, 63.29s/it]Generation:  22
Best f1_score score: 0.8224144457063154
Generation:  88%| | 22/25 [23:09<02:23, 47.70s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452f89f30> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  23
Best f1_score score: 0.8224144457063154
Generation:  92%|| 23/25 [23:36<01:22, 41.39s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554531cc0a0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  24
Best f1_score score: 0.8224144457063154
Generation:  96%|| 24/25 [24:50<00:51, 51.25s/it]Generation:  25
Best f1_score score: 0.8224144457063154
Generation: 100%|| 25/25 [29:59<00:00, 128.75s/it]Generation: 100%|| 25/25 [29:59<00:00, 72.00s/it] 
2024-10-26 18:04:26,819 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37261' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-815c13bf795fdf3ac981369b603ec156', 'ndarray-bc1ee22df90b340c13f4c4b70d48b351'} (stimulus_id='handle-worker-cleanup-1729991066.8189485')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=42)),
                ('extratreesclassifier',
                 ExtraTreesClassifier(criterion='entropy',
                                      max_features=0.8114978650506,
                                      min_samples_split=6, n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.999805987629849, 'accuracy': 0.9935613682092556, 'balanced_accuracy': 0.993567145770336, 'logloss': 0.1260848510305502, 'f1': 0.9935610668677376}
test score: {'auroc': 0.8800717594507403, 'accuracy': 0.8022508038585209, 'balanced_accuracy': 0.8019377119695591, 'logloss': 0.4381905388642476, 'f1': 0.8019308287962222}
original test score: {'auroc': 0.9073641326826042, 'accuracy': 0.8327974276527331, 'balanced_accuracy': 0.8326267681363223, 'logloss': 0.3955768479019304, 'f1': 0.8326867169475569}
score end
737
lvl
0.5
type
MAR
num_run
3
class_full
finished
all finished
full run takes
4.354002516733275
hours
DONE
