Run: 12
/cm/local/apps/slurm/var/spool/job1046485/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/1496/1496.pkl
working on 
../data/c/1496/class_full_MNAR_0.5_1
2.5574116706848145
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-12 14:05:15,206] A new study created in memory with name: no-name-14cc835b-71ad-455b-9cc9-5cf47aadee54
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-12 14:05:20,704] Trial 2 finished with value: 0.20349918705891823 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4744, 'weights': 'uniform'}. Best is trial 2 with value: 0.20349918705891823.
running
[I 2024-11-12 14:05:22,628] Trial 12 finished with value: 0.20330207637766962 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5753, 'weights': 'distance'}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:22,918] Trial 17 finished with value: 0.20349918705891823 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:23,214] Trial 3 finished with value: 0.20330207637766962 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4765, 'weights': 'distance'}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:23,562] Trial 19 finished with value: 0.3844599617826566 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:23,977] Trial 18 finished with value: 0.3844599617826566 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:27,786] Trial 11 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.10581115392224226, 'alpha': 46, 'iterations': 3, 'learning_rate': 0.048411168781763284, 'p_miss': 0.025100307142442425}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:32,053] Trial 1 finished with value: 0.3620408910737344 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.26548502866362084, 'alpha': 94, 'iterations': 1, 'learning_rate': 0.0002004683010780275, 'p_miss': 0.13953681032655585}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:32,805] Trial 8 finished with value: 0.3664649752640704 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.4992970282591572, 'alpha': 81, 'iterations': 2, 'learning_rate': 0.023907918990547224, 'p_miss': 0.13619849927959385}. Best is trial 12 with value: 0.20330207637766962.
running
[I 2024-11-12 14:05:33,656] Trial 20 finished with value: 0.1003589555270262 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3, 'learning_rate': 0.0019559742009022667, 'p_miss': 0.061721555642349324}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:05:34,431] Trial 23 finished with value: 0.3844599617826566 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:05:34,781] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5389256238112475, 'alpha': 14, 'iterations': 5, 'learning_rate': 0.013838089809775906, 'p_miss': 0.1596697469330009}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:05:35,573] Trial 14 finished with value: 0.37146773247074405 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7938843648178613, 'alpha': 20, 'iterations': 3, 'learning_rate': 0.02093219612945294, 'p_miss': 0.08745970440545224}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:05:41,080] Trial 22 finished with value: 0.2023877167020816 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2643, 'weights': 'distance'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:05:51,331] Trial 24 finished with value: 0.20977067290989987 and parameters: {'model_name': 'VAE', 'batch_size': 387, 'iterations': 1, 'learning_rate': 0.02900005722653409, 'p_miss': 0.07788376738396972}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:06:38,777] Trial 9 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5819126455250184, 'alpha': 71, 'iterations': 329, 'learning_rate': 0.0006317328761288169, 'p_miss': 0.10089776524881547}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:07:02,764] Trial 7 finished with value: 0.28217352005049556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 14, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:07:31,669] Trial 0 finished with value: 0.2199217659747533 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'descending'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:07:44,930] Trial 13 finished with value: 0.11027149222711449 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 77, 'learning_rate': 0.0009297533686618749, 'p_miss': 0.12572978969164272}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:08:26,571] Trial 31 finished with value: 0.2181395630222529 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 13, 'imputation_order': 'roman'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:09:04,529] Trial 32 finished with value: 0.1867251582876852 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 36, 'learning_rate': 0.0024307700175889837, 'p_miss': 0.25819086419457715}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:09:58,960] Trial 35 finished with value: 0.17150936023640181 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 45, 'learning_rate': 0.0021681505315905153, 'p_miss': 0.24918224807176115}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:10:41,388] Trial 4 finished with value: 0.2217025277130486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 19, 'imputation_order': 'roman'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:12:17,307] Trial 36 finished with value: 0.20866937463496268 and parameters: {'model_name': 'VAE', 'batch_size': 126, 'iterations': 55, 'learning_rate': 0.0019810665481245333, 'p_miss': 0.26578457583964826}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:12:38,964] Trial 37 finished with value: 0.20353077758157728 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 52, 'learning_rate': 0.0020325356085604844, 'p_miss': 0.23181813760887696}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:39:18,070] Trial 28 finished with value: 0.21487638471552145 and parameters: {'model_name': 'VAE', 'batch_size': 139, 'iterations': 699, 'learning_rate': 0.001194403127674627, 'p_miss': 0.2920239854041178}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:46:25,420] Trial 15 finished with value: 0.22343023819025604 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 14:50:52,204] Trial 27 finished with value: 0.21237466695839222 and parameters: {'model_name': 'VAE', 'batch_size': 393, 'iterations': 642, 'learning_rate': 0.0009597294031750584, 'p_miss': 0.0216663873157648}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:00:49,773] Trial 16 finished with value: 0.212722470628358 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 1051, 'learning_rate': 0.00013556453063946858, 'p_miss': 0.08183329451390055}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:14:57,470] Trial 21 finished with value: 0.20820248581119918 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:15:45,562] Trial 45 finished with value: 0.13681050025772398 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 15, 'learning_rate': 0.005868861312754864, 'p_miss': 0.19744844981300272}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:16:28,477] Trial 46 finished with value: 0.13972768243038244 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 13, 'learning_rate': 0.00770725306767638, 'p_miss': 0.19848352587150547}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:17:18,452] Trial 47 finished with value: 0.15026051928857567 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 13, 'learning_rate': 0.007216463137361982, 'p_miss': 0.19865665427517837}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:18:00,180] Trial 48 finished with value: 0.1159325440342696 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 12, 'learning_rate': 0.006402829464757353, 'p_miss': 0.19264704564827984}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:31:13,415] Trial 10 finished with value: 0.20236902203202645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:34:19,303] Trial 29 finished with value: 0.21331346881721497 and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 1501, 'learning_rate': 0.000651325342123359, 'p_miss': 0.27539604109386884}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:45:01,309] Trial 40 finished with value: 0.21909947557400677 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1903, 'learning_rate': 0.0005827772297721559, 'p_miss': 0.1907331900118221}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:45:39,699] Trial 52 finished with value: 0.10562976122229739 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 11, 'learning_rate': 0.0057082681787445156, 'p_miss': 0.1686283485397187}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:53:46,828] Trial 30 finished with value: 0.20164320556736284 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 18, 'imputation_order': 'roman'}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:53:51,753] Trial 53 finished with value: 0.22508455513226924 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 186, 'learning_rate': 0.004291961995912731, 'p_miss': 0.16656112882733468}. Best is trial 20 with value: 0.1003589555270262.
running
[I 2024-11-12 15:54:14,859] Trial 54 finished with value: 0.1001951111347007 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.004737889007305994, 'p_miss': 0.15777429932332274}. Best is trial 54 with value: 0.1001951111347007.
running
[I 2024-11-12 15:54:16,362] Trial 55 finished with value: 0.10681579489187991 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 7, 'learning_rate': 0.0003124849157223946, 'p_miss': 0.11795835165248436}. Best is trial 54 with value: 0.1001951111347007.
running
[I 2024-11-12 15:54:35,202] Trial 57 finished with value: 0.09818902718972185 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.00033700629648056405, 'p_miss': 0.10582405943562848}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:54:47,759] Trial 56 finished with value: 0.12295123998230366 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 8, 'learning_rate': 0.010698762370139725, 'p_miss': 0.12257829031327877}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:54:54,711] Trial 59 finished with value: 0.2018588002302908 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 478, 'weights': 'uniform'}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:54:56,488] Trial 58 finished with value: 0.0985437556100314 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.00027375588953468504, 'p_miss': 0.05368499280181287}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:55:10,900] Trial 60 finished with value: 0.09901827715422222 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5, 'learning_rate': 0.00030794528630140967, 'p_miss': 0.05623623485927214}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:55:19,592] Trial 62 finished with value: 0.10137531238083612 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.000286511452879196, 'p_miss': 0.04555392949654038}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:55:26,398] Trial 63 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8842522902445469, 'alpha': 46, 'iterations': 1, 'learning_rate': 0.00010318952525618358, 'p_miss': 0.05851377070335502}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:55:31,620] Trial 64 finished with value: 0.2065380754814532 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19, 'weights': 'uniform'}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:55:46,360] Trial 65 finished with value: 0.09980172358843044 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 4, 'learning_rate': 0.0002409729526119786, 'p_miss': 0.05301185424797077}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:58:12,215] Trial 6 finished with value: 0.20157813550538956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 20, 'imputation_order': 'arabic'}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 15:58:27,774] Trial 67 finished with value: 0.10060261240686308 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 4, 'learning_rate': 0.00025522784422432826, 'p_miss': 0.051766288702896686}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 17:26:39,920] Trial 25 finished with value: 0.21234138039091036 and parameters: {'model_name': 'VAE', 'batch_size': 752, 'iterations': 2446, 'learning_rate': 0.0011993710268859465, 'p_miss': 0.012978490426923027}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 17:26:49,235] Trial 69 finished with value: 0.10199617012125736 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0001702530732836548, 'p_miss': 0.061885619698520536}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:06:38,362] Trial 26 finished with value: 0.21247066283097965 and parameters: {'model_name': 'VAE', 'batch_size': 759, 'iterations': 3429, 'learning_rate': 0.0010050448007243103, 'p_miss': 0.2905931687370847}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:06:57,505] Trial 71 finished with value: 0.10221814461017524 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 5, 'learning_rate': 0.00041503531298112454, 'p_miss': 0.03763752362470467}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:07:08,352] Trial 72 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.012813117355790937, 'alpha': 28, 'iterations': 5, 'learning_rate': 0.00041077831471273465, 'p_miss': 0.10454571882948507}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:07:09,098] Trial 73 finished with value: 0.3144651444809812 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:08:21,429] Trial 74 finished with value: 0.09940770237860966 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 22, 'learning_rate': 0.00020926090517188212, 'p_miss': 0.14344254724562538}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:09:50,116] Trial 75 finished with value: 0.0998720831199275 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 23, 'learning_rate': 0.00019729059292246737, 'p_miss': 0.14690132052684313}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:11:09,834] Trial 76 finished with value: 0.1015561919800583 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 23, 'learning_rate': 0.00019568224332603337, 'p_miss': 0.1466653769783012}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:13:28,961] Trial 77 finished with value: 0.10061412247389774 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 30, 'learning_rate': 0.00014724268581693721, 'p_miss': 0.13967807939053226}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:14:00,798] Trial 78 finished with value: 0.09898213787413265 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 7, 'learning_rate': 0.00010111398529121471, 'p_miss': 0.10249633264810964}. Best is trial 57 with value: 0.09818902718972185.
running
[I 2024-11-12 18:19:25,973] Trial 79 finished with value: 0.0958476060500053 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 88, 'learning_rate': 0.00011708048492033611, 'p_miss': 0.10784841023430762}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:24:00,482] Trial 80 finished with value: 0.0967815656581594 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 96, 'learning_rate': 0.00010220726641072502, 'p_miss': 0.09508803481553584}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:24:13,298] Trial 81 finished with value: 0.20224514762397314 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2161, 'weights': 'distance'}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:24:13,825] Trial 82 finished with value: 0.3844599617826566 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:28:45,895] Trial 83 finished with value: 0.09834533708630942 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 98, 'learning_rate': 0.00011441268046839299, 'p_miss': 0.10008469220796058}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:35:41,193] Trial 84 finished with value: 0.09954936015501732 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 115, 'learning_rate': 0.00010552717250205194, 'p_miss': 0.09055091865950268}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:38:11,391] Trial 85 finished with value: 0.36529757647467703 and parameters: {'model_name': 'GAIN', 'batch_size': 20, 'hint_rate': 0.257385175898873, 'alpha': 0, 'iterations': 91, 'learning_rate': 0.00012839127322411282, 'p_miss': 0.10256729938892482}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:50:41,238] Trial 86 finished with value: 0.10038557091827358 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 227, 'learning_rate': 0.0001384032178969597, 'p_miss': 0.07385496634229702}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 18:59:07,095] Trial 87 finished with value: 0.09639642583888745 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 160, 'learning_rate': 0.00010636649394764268, 'p_miss': 0.11237356503465822}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 19:07:05,485] Trial 88 finished with value: 0.09774857983197384 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 160, 'learning_rate': 0.00010305444199517865, 'p_miss': 0.11364652898402995}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 19:09:29,087] Trial 42 finished with value: 0.2148324526232636 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 5633, 'learning_rate': 0.006953952429490157, 'p_miss': 0.18833741752310212}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 19:09:58,971] Trial 90 finished with value: 0.20226548483242057 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 19:13:07,065] Trial 49 finished with value: 0.22233842919144978 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 4949, 'learning_rate': 0.005676160413647174, 'p_miss': 0.18106773971400852}. Best is trial 79 with value: 0.0958476060500053.
running
[I 2024-11-12 19:13:39,727] Trial 89 finished with value: 0.0935749862402869 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 136, 'learning_rate': 0.00010323034304478451, 'p_miss': 0.1128664873245653}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:18:38,813] Trial 91 finished with value: 0.09866521148459911 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 149, 'learning_rate': 0.0001084205003124728, 'p_miss': 0.1167827924912001}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:20:10,320] Trial 92 finished with value: 0.09484957577586198 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 132, 'learning_rate': 0.00011041287908746232, 'p_miss': 0.11265555149047733}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:20:26,504] Trial 93 finished with value: 0.09792404737329523 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 134, 'learning_rate': 0.0001449145009565783, 'p_miss': 0.11355154165779748}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:34:43,462] Trial 94 finished with value: 0.11579384563292357 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 329, 'learning_rate': 0.00015509612938157977, 'p_miss': 0.09205252808158247}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:38:10,185] Trial 34 finished with value: 0.21359891868629427 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 6288, 'learning_rate': 0.0025620212034175804, 'p_miss': 0.24001690066407122}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:38:21,978] Trial 96 finished with value: 0.1232334053269541 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 350, 'learning_rate': 0.00015584428972563387, 'p_miss': 0.13006094605416754}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:39:21,491] Trial 97 finished with value: 0.09410759007901663 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 69, 'learning_rate': 0.00013292561258782153, 'p_miss': 0.12874476997742265}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:42:17,532] Trial 100 finished with value: 0.09748085536811679 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 61, 'learning_rate': 0.00017698999384708973, 'p_miss': 0.11286304513974188}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:42:23,365] Trial 99 finished with value: 0.09798042051712644 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 62, 'learning_rate': 0.00012696203441320923, 'p_miss': 0.11007981086216237}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:42:48,062] Trial 102 finished with value: 0.20331437210890044 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:42:48,858] Trial 103 finished with value: 0.3144651444809812 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:46:49,579] Trial 101 finished with value: 0.09393814497308033 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 68, 'learning_rate': 0.0001788019714706072, 'p_miss': 0.11373580941597634}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:46:58,506] Trial 95 finished with value: 0.15842577162712118 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 448, 'learning_rate': 0.00015837299122087856, 'p_miss': 0.13099039248655514}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:50:27,378] Trial 104 finished with value: 0.09906996828668516 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 136, 'learning_rate': 0.00017819615129663566, 'p_miss': 0.12902292126435772}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:51:19,474] Trial 105 finished with value: 0.09599764312631695 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 72, 'learning_rate': 0.0001846537589253539, 'p_miss': 0.13042745739952105}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:55:10,187] Trial 107 finished with value: 0.09540824834481565 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 75, 'learning_rate': 0.00012737674897194537, 'p_miss': 0.11336002260798733}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:56:35,033] Trial 44 finished with value: 0.21722543269526992 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 5309, 'learning_rate': 0.006922108709184264, 'p_miss': 0.1976879635832655}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:56:50,840] Trial 106 finished with value: 0.10583638304333495 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 149, 'learning_rate': 0.00019083365563880207, 'p_miss': 0.11541702117662382}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 19:57:01,114] Trial 111 finished with value: 0.20213093217244507 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1687, 'weights': 'uniform'}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:00:10,468] Trial 109 finished with value: 0.09697600673002113 and parameters: {'model_name': 'VAE', 'batch_size': 182, 'iterations': 70, 'learning_rate': 0.00020599715811769578, 'p_miss': 0.08083651026412642}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:01:04,592] Trial 110 finished with value: 0.0961688545547607 and parameters: {'model_name': 'VAE', 'batch_size': 190, 'iterations': 79, 'learning_rate': 0.00020341997223924182, 'p_miss': 0.07890915503939686}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:01:07,480] Trial 98 finished with value: 0.11805068209735758 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 342, 'learning_rate': 0.0001290267756664557, 'p_miss': 0.13049599372752504}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:02:12,891] Trial 112 finished with value: 0.0956987388883783 and parameters: {'model_name': 'VAE', 'batch_size': 178, 'iterations': 76, 'learning_rate': 0.00013182294496211287, 'p_miss': 0.08263580920590101}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:02:23,867] Trial 115 finished with value: 0.38422590784481325 and parameters: {'model_name': 'GAIN', 'batch_size': 122, 'hint_rate': 0.7043872585463429, 'alpha': 68, 'iterations': 42, 'learning_rate': 0.08471558227260191, 'p_miss': 0.06941460897074508}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:02:55,548] Trial 108 finished with value: 0.21376320375661964 and parameters: {'model_name': 'VAE', 'batch_size': 213, 'iterations': 212, 'learning_rate': 0.06433686618160256, 'p_miss': 0.08183871438090616}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:03:50,941] Trial 114 finished with value: 0.2129414642863158 and parameters: {'model_name': 'VAE', 'batch_size': 135, 'iterations': 39, 'learning_rate': 0.09223899886534039, 'p_miss': 0.09457363918277112}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:04:56,804] Trial 113 finished with value: 0.09776216579448477 and parameters: {'model_name': 'VAE', 'batch_size': 173, 'iterations': 78, 'learning_rate': 0.0001305942883894077, 'p_miss': 0.08090569980022738}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:09:11,704] Trial 117 finished with value: 0.09451739204490617 and parameters: {'model_name': 'VAE', 'batch_size': 216, 'iterations': 88, 'learning_rate': 0.00012630807376197566, 'p_miss': 0.09593484090542558}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:09:43,432] Trial 119 finished with value: 0.09714476399514332 and parameters: {'model_name': 'VAE', 'batch_size': 281, 'iterations': 83, 'learning_rate': 0.0002385355371493402, 'p_miss': 0.08547515370330366}. Best is trial 89 with value: 0.0935749862402869.
running
[I 2024-11-12 20:10:13,628] Trial 118 finished with value: 0.09338815734114682 and parameters: {'model_name': 'VAE', 'batch_size': 256, 'iterations': 97, 'learning_rate': 0.00012238192668633546, 'p_miss': 0.09506707719851594}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:10:43,182] Trial 120 finished with value: 0.09510422195180199 and parameters: {'model_name': 'VAE', 'batch_size': 314, 'iterations': 99, 'learning_rate': 0.0002236959664633312, 'p_miss': 0.1221724519282154}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:12:53,952] Trial 121 finished with value: 0.09585492161151063 and parameters: {'model_name': 'VAE', 'batch_size': 275, 'iterations': 51, 'learning_rate': 0.00021838294474080762, 'p_miss': 0.13350769003483703}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:13:08,101] Trial 122 finished with value: 0.09713056066965943 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 53, 'learning_rate': 0.00038176561272596974, 'p_miss': 0.12134815127879145}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:13:25,478] Trial 116 finished with value: 0.21353468569431225 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 235, 'learning_rate': 0.061927563703244724, 'p_miss': 0.07279491544374525}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:13:36,815] Trial 123 finished with value: 0.09717957362920226 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 48, 'learning_rate': 0.0001278723429746305, 'p_miss': 0.12313551438102124}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:14:03,080] Trial 124 finished with value: 0.09537071510485884 and parameters: {'model_name': 'VAE', 'batch_size': 427, 'iterations': 52, 'learning_rate': 0.00023393304708897988, 'p_miss': 0.12183894135935792}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:14:41,955] Trial 125 finished with value: 0.20199888361568927 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:14:49,723] Trial 126 finished with value: 0.09456422569516246 and parameters: {'model_name': 'VAE', 'batch_size': 488, 'iterations': 32, 'learning_rate': 0.0005338008100505616, 'p_miss': 0.1368795302728426}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:15:24,115] Trial 127 finished with value: 0.09547199512809963 and parameters: {'model_name': 'VAE', 'batch_size': 418, 'iterations': 33, 'learning_rate': 0.00024140884727681306, 'p_miss': 0.1363455478506243}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:16:17,390] Trial 129 finished with value: 0.0943576517837396 and parameters: {'model_name': 'VAE', 'batch_size': 598, 'iterations': 33, 'learning_rate': 0.0005327314297263171, 'p_miss': 0.0978742166539319}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:16:33,212] Trial 133 finished with value: 0.20287129331821188 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3747, 'weights': 'distance'}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:16:34,059] Trial 134 finished with value: 0.20349918705891823 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:17:39,827] Trial 130 finished with value: 0.09852162238913661 and parameters: {'model_name': 'VAE', 'batch_size': 545, 'iterations': 30, 'learning_rate': 0.0002456138680293891, 'p_miss': 0.09941780055606103}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:18:24,271] Trial 131 finished with value: 0.0982278372180573 and parameters: {'model_name': 'VAE', 'batch_size': 581, 'iterations': 31, 'learning_rate': 0.0006543977156690945, 'p_miss': 0.13967211803504803}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:18:37,524] Trial 132 finished with value: 0.09569544979857547 and parameters: {'model_name': 'VAE', 'batch_size': 534, 'iterations': 31, 'learning_rate': 0.0005913485696458108, 'p_miss': 0.1551434912934206}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:19:20,741] Trial 135 finished with value: 0.09476961769015221 and parameters: {'model_name': 'VAE', 'batch_size': 535, 'iterations': 31, 'learning_rate': 0.0005102585962887558, 'p_miss': 0.13896389606284845}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:19:32,695] Trial 128 finished with value: 0.09761125243157132 and parameters: {'model_name': 'VAE', 'batch_size': 420, 'iterations': 112, 'learning_rate': 0.00025249347063156227, 'p_miss': 0.151080591354102}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:20:40,587] Trial 136 finished with value: 0.09486072229526873 and parameters: {'model_name': 'VAE', 'batch_size': 544, 'iterations': 30, 'learning_rate': 0.00036107533523055537, 'p_miss': 0.15099400156653692}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:20:48,116] Trial 138 finished with value: 0.09737345720590267 and parameters: {'model_name': 'VAE', 'batch_size': 944, 'iterations': 18, 'learning_rate': 0.0005535738212317013, 'p_miss': 0.15011917704319067}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:21:09,490] Trial 140 finished with value: 0.09542189442963875 and parameters: {'model_name': 'VAE', 'batch_size': 812, 'iterations': 19, 'learning_rate': 0.0004925709576852192, 'p_miss': 0.14092045238754708}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:22:46,965] Trial 143 finished with value: 0.36081611051774953 and parameters: {'model_name': 'GAIN', 'batch_size': 662, 'hint_rate': 0.942124778502147, 'alpha': 94, 'iterations': 39, 'learning_rate': 0.0008010974172911583, 'p_miss': 0.16171952321221295}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:24:18,933] Trial 141 finished with value: 0.09542141823876892 and parameters: {'model_name': 'VAE', 'batch_size': 906, 'iterations': 39, 'learning_rate': 0.0004902795199777367, 'p_miss': 0.16462847117897514}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:26:22,845] Trial 137 finished with value: 0.13021481913168886 and parameters: {'model_name': 'VAE', 'batch_size': 458, 'iterations': 112, 'learning_rate': 0.00046381184158537377, 'p_miss': 0.12332501090383088}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:28:36,153] Trial 146 finished with value: 0.09781298181086961 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 25, 'learning_rate': 0.0003594861658051068, 'p_miss': 0.16628163108690935}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:29:39,880] Trial 144 finished with value: 0.10624938883783312 and parameters: {'model_name': 'VAE', 'batch_size': 316, 'iterations': 111, 'learning_rate': 0.00033683645459491073, 'p_miss': 0.12390729749758245}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:30:20,565] Trial 139 finished with value: 0.2005055438718629 and parameters: {'model_name': 'VAE', 'batch_size': 855, 'iterations': 115, 'learning_rate': 0.0007869153349024631, 'p_miss': 0.12270040552681592}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:31:44,255] Trial 145 finished with value: 0.11115933623036778 and parameters: {'model_name': 'VAE', 'batch_size': 341, 'iterations': 97, 'learning_rate': 0.0003523801717500391, 'p_miss': 0.12029911221724113}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:32:13,855] Trial 142 finished with value: 0.20388522169399442 and parameters: {'model_name': 'VAE', 'batch_size': 738, 'iterations': 112, 'learning_rate': 0.0007718236824880491, 'p_miss': 0.16571432307381045}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:32:59,466] Trial 147 finished with value: 0.1295126889608095 and parameters: {'model_name': 'VAE', 'batch_size': 285, 'iterations': 47, 'learning_rate': 0.0007720623438852446, 'p_miss': 0.1206830105889613}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:35:11,578] Trial 148 finished with value: 0.12931566373860476 and parameters: {'model_name': 'VAE', 'batch_size': 747, 'iterations': 49, 'learning_rate': 0.0007306818857163288, 'p_miss': 0.10663947171719483}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:36:45,012] Trial 149 finished with value: 0.20912290236888148 and parameters: {'model_name': 'VAE', 'batch_size': 678, 'iterations': 63, 'learning_rate': 0.0013830661588959327, 'p_miss': 0.09885326040810014}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:37:08,405] Trial 150 finished with value: 0.10227170584249996 and parameters: {'model_name': 'VAE', 'batch_size': 691, 'iterations': 59, 'learning_rate': 0.00046070768158077135, 'p_miss': 0.17234665483204398}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:37:20,677] Trial 151 finished with value: 0.18409005009516904 and parameters: {'model_name': 'VAE', 'batch_size': 229, 'iterations': 63, 'learning_rate': 0.0013218584847219722, 'p_miss': 0.09868772905452161}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:37:46,460] Trial 152 finished with value: 0.09828198463022644 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 60, 'learning_rate': 0.0002930219543220152, 'p_miss': 0.10559320187883703}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:38:07,664] Trial 155 finished with value: 0.0995196884043241 and parameters: {'model_name': 'VAE', 'batch_size': 231, 'iterations': 16, 'learning_rate': 0.0003144563898072372, 'p_miss': 0.21546688843828737}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:38:39,582] Trial 156 finished with value: 0.09630485435863581 and parameters: {'model_name': 'VAE', 'batch_size': 451, 'iterations': 16, 'learning_rate': 0.0004258817246521442, 'p_miss': 0.137633916240657}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:39:08,860] Trial 153 finished with value: 0.09560608168222451 and parameters: {'model_name': 'VAE', 'batch_size': 235, 'iterations': 58, 'learning_rate': 0.0002985870887349649, 'p_miss': 0.17166881268035467}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:39:17,610] Trial 158 finished with value: 0.09885736627868402 and parameters: {'model_name': 'VAE', 'batch_size': 504, 'iterations': 10, 'learning_rate': 0.0004832172485757315, 'p_miss': 0.14163964004628782}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:39:34,639] Trial 157 finished with value: 0.09352474973260742 and parameters: {'model_name': 'VAE', 'batch_size': 483, 'iterations': 21, 'learning_rate': 0.00044022357060995594, 'p_miss': 0.14332604677103192}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:39:35,131] Trial 162 finished with value: 0.20349918705891823 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:39:49,868] Trial 161 finished with value: 0.20334374479126271 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:40:29,617] Trial 160 finished with value: 0.09664148529101943 and parameters: {'model_name': 'VAE', 'batch_size': 1000, 'iterations': 20, 'learning_rate': 0.0005494135912411986, 'p_miss': 0.1443223678717988}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:40:35,582] Trial 159 finished with value: 0.09560071030108505 and parameters: {'model_name': 'VAE', 'batch_size': 972, 'iterations': 27, 'learning_rate': 0.0005126471063218247, 'p_miss': 0.14511542038339748}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:40:36,668] Trial 43 finished with value: 0.21496014532077665 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 7139, 'learning_rate': 0.00750705543221437, 'p_miss': 0.19465737380602122}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:41:03,198] Trial 163 finished with value: 0.20286266767941202 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:42:00,140] Trial 164 finished with value: 0.09559988839567565 and parameters: {'model_name': 'VAE', 'batch_size': 585, 'iterations': 37, 'learning_rate': 0.0001634535852705938, 'p_miss': 0.14529901287838706}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:42:29,186] Trial 165 finished with value: 0.1004819150399173 and parameters: {'model_name': 'VAE', 'batch_size': 602, 'iterations': 26, 'learning_rate': 0.00017099427350632156, 'p_miss': 0.08897333394901359}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:43:28,898] Trial 169 finished with value: 0.10280210404409615 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 22, 'learning_rate': 0.00014208617716788204, 'p_miss': 0.17884872380797928}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:43:37,474] Trial 170 finished with value: 0.09992898856789266 and parameters: {'model_name': 'VAE', 'batch_size': 100, 'iterations': 19, 'learning_rate': 0.00011544757431859033, 'p_miss': 0.1596871320540076}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:43:45,778] Trial 172 finished with value: 0.20193372452685435 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1267, 'weights': 'uniform'}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:43:49,434] Trial 166 finished with value: 0.09478796106785332 and parameters: {'model_name': 'VAE', 'batch_size': 588, 'iterations': 42, 'learning_rate': 0.0001613230159182446, 'p_miss': 0.1583081737583672}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:44:01,284] Trial 167 finished with value: 0.09579414235522807 and parameters: {'model_name': 'VAE', 'batch_size': 577, 'iterations': 37, 'learning_rate': 0.00015315617152372314, 'p_miss': 0.1580864035229913}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:44:40,539] Trial 168 finished with value: 0.09931018263607554 and parameters: {'model_name': 'VAE', 'batch_size': 614, 'iterations': 36, 'learning_rate': 0.0001631983844589552, 'p_miss': 0.15933694874818444}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:45:57,572] Trial 174 finished with value: 0.09688625691269727 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 35, 'learning_rate': 0.0001527624379055304, 'p_miss': 0.13422484409452531}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:46:32,160] Trial 173 finished with value: 0.10097080589204106 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 41, 'learning_rate': 0.0006744673270126122, 'p_miss': 0.15209782317952555}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:46:50,577] Trial 154 finished with value: 0.2010932497245841 and parameters: {'model_name': 'VAE', 'batch_size': 226, 'iterations': 188, 'learning_rate': 0.0005089463877779296, 'p_miss': 0.176566193778318}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:47:15,758] Trial 175 finished with value: 0.1263043495578734 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 40, 'learning_rate': 0.0010192592909793092, 'p_miss': 0.11055532215516468}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:48:22,483] Trial 180 finished with value: 0.09947315406010829 and parameters: {'model_name': 'VAE', 'batch_size': 378, 'iterations': 14, 'learning_rate': 0.00011350160877566647, 'p_miss': 0.12811975111220802}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:49:42,956] Trial 176 finished with value: 0.0964222346125388 and parameters: {'model_name': 'VAE', 'batch_size': 845, 'iterations': 43, 'learning_rate': 0.00041128904705541584, 'p_miss': 0.15214135506457885}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:53:38,863] Trial 171 finished with value: 0.21316481220819378 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 176, 'learning_rate': 0.0009598743957311238, 'p_miss': 0.15337890567052642}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:55:26,528] Trial 179 finished with value: 0.21266243282731634 and parameters: {'model_name': 'VAE', 'batch_size': 854, 'iterations': 89, 'learning_rate': 0.017638036405721882, 'p_miss': 0.12670576610319165}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:56:01,564] Trial 181 finished with value: 0.21175077148126548 and parameters: {'model_name': 'VAE', 'batch_size': 484, 'iterations': 86, 'learning_rate': 0.01898829443335575, 'p_miss': 0.11624353554071176}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:56:10,044] Trial 183 finished with value: 0.3625171663632002 and parameters: {'model_name': 'GAIN', 'batch_size': 153, 'hint_rate': 0.3346446674432214, 'alpha': 59, 'iterations': 83, 'learning_rate': 0.00012396182280723927, 'p_miss': 0.13581370338201082}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:56:54,584] Trial 185 finished with value: 0.3623541097367892 and parameters: {'model_name': 'GAIN', 'batch_size': 155, 'hint_rate': 0.3430833776232836, 'alpha': 56, 'iterations': 27, 'learning_rate': 0.00021417925932883079, 'p_miss': 0.13464923295703768}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:57:12,315] Trial 182 finished with value: 0.09692034491423353 and parameters: {'model_name': 'VAE', 'batch_size': 471, 'iterations': 86, 'learning_rate': 0.00021826816641625036, 'p_miss': 0.11637774326366529}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:57:57,130] Trial 184 finished with value: 0.36714416337245154 and parameters: {'model_name': 'GAIN', 'batch_size': 440, 'hint_rate': 0.3466861651319588, 'alpha': 61, 'iterations': 71, 'learning_rate': 0.00021956766223182772, 'p_miss': 0.1181074584959335}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:58:03,132] Trial 186 finished with value: 0.09505507787858489 and parameters: {'model_name': 'VAE', 'batch_size': 415, 'iterations': 25, 'learning_rate': 0.00026804135033482376, 'p_miss': 0.13930751518715798}. Best is trial 118 with value: 0.09338815734114682.
running
[I 2024-11-12 20:59:45,700] Trial 188 finished with value: 0.09307608837305995 and parameters: {'model_name': 'VAE', 'batch_size': 401, 'iterations': 32, 'learning_rate': 0.0003859163720438773, 'p_miss': 0.13794157311522104}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 20:59:46,865] Trial 177 finished with value: 0.15916104592579236 and parameters: {'model_name': 'VAE', 'batch_size': 820, 'iterations': 175, 'learning_rate': 0.00040097852746287933, 'p_miss': 0.15143293754665346}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:00:05,366] Trial 187 finished with value: 0.09982070319189633 and parameters: {'model_name': 'VAE', 'batch_size': 400, 'iterations': 32, 'learning_rate': 0.0002515294720583179, 'p_miss': 0.14012545572530472}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:00:30,260] Trial 189 finished with value: 0.09777562934722026 and parameters: {'model_name': 'VAE', 'batch_size': 388, 'iterations': 32, 'learning_rate': 0.0002659822832396234, 'p_miss': 0.13861645622556762}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:02:31,285] Trial 178 finished with value: 0.21218385253139666 and parameters: {'model_name': 'VAE', 'batch_size': 799, 'iterations': 196, 'learning_rate': 0.022959059777717263, 'p_miss': 0.11039000731703251}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:03:55,674] Trial 192 finished with value: 0.09645447487054146 and parameters: {'model_name': 'VAE', 'batch_size': 388, 'iterations': 48, 'learning_rate': 0.0002783829208758664, 'p_miss': 0.1102898178613629}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:03:56,858] Trial 191 finished with value: 0.09752481669301336 and parameters: {'model_name': 'VAE', 'batch_size': 516, 'iterations': 49, 'learning_rate': 0.0002684426220530559, 'p_miss': 0.10893986824887351}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:05:25,296] Trial 61 finished with value: 0.2398525551993605 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6253, 'learning_rate': 0.00030126999298194754, 'p_miss': 0.056394952396372634}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:05:30,913] Trial 197 finished with value: 0.0980568694993235 and parameters: {'model_name': 'VAE', 'batch_size': 317, 'iterations': 25, 'learning_rate': 0.0001364211598315348, 'p_miss': 0.1287985234088962}. Best is trial 188 with value: 0.09307608837305995.
running
[I 2024-11-12 21:05:34,463] Trial 196 finished with value: 0.10049653236680253 and parameters: {'model_name': 'VAE', 'batch_size': 298, 'iterations': 24, 'learning_rate': 0.0003541896846811898, 'p_miss': 0.12747736054456135}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:06:44,010] Trial 50 finished with value: 0.22625119588099207 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6931, 'learning_rate': 0.0055122559449003765, 'p_miss': 0.1955230114120902}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:06:54,870] Trial 198 finished with value: 0.09490490232554577 and parameters: {'model_name': 'VAE', 'batch_size': 289, 'iterations': 23, 'learning_rate': 0.0005993144456015869, 'p_miss': 0.09479378576107024}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:07:00,269] Trial 190 finished with value: 0.2121146630840117 and parameters: {'model_name': 'VAE', 'batch_size': 407, 'iterations': 132, 'learning_rate': 0.0031921592207348505, 'p_miss': 0.1088182976552341}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:08:49,788] Trial 194 finished with value: 0.2128596059228033 and parameters: {'model_name': 'VAE', 'batch_size': 285, 'iterations': 136, 'learning_rate': 0.030645788322479245, 'p_miss': 0.12819617761151664}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:08:51,843] Trial 193 finished with value: 0.11366098307835552 and parameters: {'model_name': 'VAE', 'batch_size': 303, 'iterations': 127, 'learning_rate': 0.00027933821194489443, 'p_miss': 0.10787429584321623}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:10:54,817] Trial 195 finished with value: 0.21258072292326718 and parameters: {'model_name': 'VAE', 'batch_size': 275, 'iterations': 138, 'learning_rate': 0.0030359636794289337, 'p_miss': 0.09445313673389188}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:11:48,956] Trial 199 finished with value: 0.1001527570192291 and parameters: {'model_name': 'VAE', 'batch_size': 264, 'iterations': 134, 'learning_rate': 0.00018067788178368165, 'p_miss': 0.09483235161188737}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:18:54,098] Trial 51 finished with value: 0.22361577225456825 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7177, 'learning_rate': 0.005228492746222834, 'p_miss': 0.18434212699268926}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:21:20,817] Trial 33 finished with value: 0.21410153790261846 and parameters: {'model_name': 'VAE', 'batch_size': 106, 'iterations': 9477, 'learning_rate': 0.001894716538356091, 'p_miss': 0.25551202370185855}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:26:11,417] Trial 38 finished with value: 0.21574479557552834 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 8730, 'learning_rate': 0.0021088039786828425, 'p_miss': 0.2216535149728401}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:28:58,087] Trial 66 finished with value: 0.2164989229594562 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7264, 'learning_rate': 0.0002650005723986518, 'p_miss': 0.05167170926272171}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:30:48,332] Trial 39 finished with value: 0.21803532359310318 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 9809, 'learning_rate': 0.0007276473731832756, 'p_miss': 0.195813288448007}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:32:11,488] Trial 41 finished with value: 0.2144197081980707 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 8974, 'learning_rate': 0.006072841093447992, 'p_miss': 0.21199121622338832}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:32:25,106] Trial 70 finished with value: 0.2457038827032215 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7926, 'learning_rate': 0.00035192183737353395, 'p_miss': 0.037370496784615403}. Best is trial 188 with value: 0.09307608837305995.
[I 2024-11-12 21:33:41,008] Trial 68 finished with value: 0.21783740410341848 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9912, 'learning_rate': 0.00017546940882510816, 'p_miss': 0.06615049472248367}. Best is trial 188 with value: 0.09307608837305995.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
16    0
17    0
18    0
19    0
dtype: int64
0.09307608837305995
{'model_name': 'VAE', 'batch_size': 401, 'iterations': 32, 'learning_rate': 0.0003859163720438773, 'p_miss': 0.13794157311522104}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f97b0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0fd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.5342054605439019
Generation:   4%|         | 1/25 [01:34<37:50, 94.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f8a60> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.5342054605439019
Generation:   8%|         | 2/25 [03:11<36:42, 95.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0aaa0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  3
Best f1_score score: 0.5342054605439019
Generation:  12%|        | 3/25 [04:11<29:11, 79.62s/it]Generation:  4
Best f1_score score: 0.5342054605439019
Generation:  16%|        | 4/25 [05:27<27:18, 78.02s/it]Generation:  5
Best f1_score score: 0.5342054605439019
Generation:  20%|        | 5/25 [06:11<21:58, 65.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474748a00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.5349907656357746
Generation:  24%|       | 6/25 [06:51<18:05, 57.12s/it]Generation:  7
Best f1_score score: 0.5352137137457451
Generation:  28%|       | 7/25 [07:54<17:40, 58.89s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e2d540> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.5370384876824115
Generation:  32%|      | 8/25 [08:38<15:24, 54.40s/it]Generation:  9
Best f1_score score: 0.5370384876824115
Generation:  36%|      | 9/25 [09:14<12:56, 48.51s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678d7490> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5379855785619118
Generation:  40%|      | 10/25 [09:55<11:32, 46.14s/it]Generation:  11
Best f1_score score: 0.5379855785619118
Generation:  44%|     | 11/25 [10:34<10:15, 43.99s/it]Generation:  12
Best f1_score score: 0.5380761144454038
Generation:  48%|     | 12/25 [11:12<09:08, 42.16s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554659bd030> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.5380761144454038
Generation:  52%|    | 13/25 [12:28<10:30, 52.51s/it]Generation:  14
Best f1_score score: 0.5380761144454038
Generation:  56%|    | 14/25 [13:06<08:48, 48.06s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f09570> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  15
Best f1_score score: 0.5380761144454038
Generation:  60%|    | 15/25 [13:48<07:42, 46.25s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554657d2f20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  16
Best f1_score score: 0.5380761144454038
Generation:  64%|   | 16/25 [14:31<06:45, 45.09s/it]Generation:  17
Best f1_score score: 0.5380761144454038
Generation:  68%|   | 17/25 [15:10<05:47, 43.41s/it]Generation:  18
Best f1_score score: 0.5380761144454038
Generation:  72%|  | 18/25 [16:06<05:29, 47.09s/it]Generation:  19
Best f1_score score: 0.5380761144454038
Generation:  76%|  | 19/25 [17:07<05:09, 51.50s/it]Generation:  20
Best f1_score score: 0.5380761144454038
Generation:  80%|  | 20/25 [17:51<04:05, 49.20s/it]Generation:  21
Best f1_score score: 0.5380761144454038
Generation:  84%| | 21/25 [18:54<03:33, 53.39s/it]Generation:  22
Best f1_score score: 0.5380761144454038
Generation:  88%| | 22/25 [19:50<02:42, 54.14s/it]Generation:  23
Best f1_score score: 0.5380761144454038
Generation:  92%|| 23/25 [20:33<01:41, 50.80s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554658c4cd0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5380761144454038
Generation:  96%|| 24/25 [22:03<01:02, 62.40s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546532b490> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.5380761144454038
Generation: 100%|| 25/25 [22:52<00:00, 58.48s/it]Generation: 100%|| 25/25 [22:56<00:00, 55.06s/it]
2024-11-12 21:56:52,427 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44585' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-8704a32b012b7a178b68e5b8619289f8', 'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8'} (stimulus_id='handle-worker-cleanup-1731477412.4272077')
Fitted
Pipeline(steps=[('adaboostclassifier',
                 AdaBoostClassifier(learning_rate=0.0845766072776,
                                    n_estimators=231))])
score start
train score: {'auroc': 0.6283392797359224, 'accuracy': 0.5871621621621622, 'balanced_accuracy': 0.5869073672726302, 'logloss': 0.6915638326693949, 'f1': 0.5867453983678756}
original test score: {'auroc': 0.6468228530310418, 'accuracy': 0.6162162162162163, 'balanced_accuracy': 0.6151974884531304, 'logloss': 0.6923629711189, 'f1': 0.611206488278475}
imputed test score: {'auroc': 0.5215304145184648, 'accuracy': 0.5175675675675676, 'balanced_accuracy': 0.5171664374642727, 'logloss': 0.6929108389727788, 'f1': 0.5164859299931366}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1f3a0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  1
Best f1_score score: 0.8960518701148027
Generation:   4%|         | 1/25 [01:08<27:31, 68.82s/it]Generation:  2
Best f1_score score: 0.8992736588702526
Generation:   8%|         | 2/25 [02:17<26:15, 68.48s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547457cac0> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  3
Best f1_score score: 0.9000837861842992
Generation:  12%|        | 3/25 [06:10<52:45, 143.87s/it]Generation:  4
Best f1_score score: 0.9000837861842992
Generation:  16%|        | 4/25 [08:46<51:57, 148.47s/it]Generation:  5
Best f1_score score: 0.9000837861842992
Generation:  20%|        | 5/25 [09:16<35:16, 105.85s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155455b40c70> 

Generation:  6
Best f1_score score: 0.9000837861842992
Generation:  24%|       | 6/25 [19:21<1:27:17, 275.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456fa8e80> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452fb3d00> 

Generation:  7
Best f1_score score: 0.9034553954231864
Generation:  28%|       | 7/25 [29:26<1:54:59, 383.28s/it]Generation:  8
Best f1_score score: 0.9034553954231864
Generation:  32%|      | 8/25 [29:50<1:16:08, 268.73s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545bbac370> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457103190> 

Generation:  9
Best f1_score score: 0.9034553954231864
Generation:  36%|      | 9/25 [39:54<1:39:41, 373.83s/it]Generation:  10
Best f1_score score: 0.9034553954231864
Generation:  40%|      | 10/25 [40:57<1:09:26, 277.77s/it]Generation:  11
Best f1_score score: 0.9034553954231864
Generation:  44%|     | 11/25 [42:01<49:31, 212.27s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554570476d0> 

Generation:  12
Best f1_score score: 0.9034553954231864
Generation:  48%|     | 12/25 [52:07<1:11:55, 331.96s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d5e440> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  13
Best f1_score score: 0.9034553954231864
Generation:  52%|    | 13/25 [53:48<52:25, 262.09s/it]  Generation:  14
Best f1_score score: 0.9034553954231864
Generation:  56%|    | 14/25 [54:22<35:24, 193.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547462e0e0> 

Generation:  15
Best f1_score score: 0.9034553954231864
Generation:  60%|    | 15/25 [1:04:26<52:51, 317.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554742486a0> 

Generation:  16
Best f1_score score: 0.9034553954231864
Generation:  64%|   | 16/25 [1:14:32<1:00:36, 404.02s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554740b0ac0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457418ca0> 

Generation:  17
Best f1_score score: 0.9034553954231864
Generation:  68%|   | 17/25 [1:24:37<1:01:55, 464.38s/it]Generation:  18
Best f1_score score: 0.9034553954231864
Generation:  72%|  | 18/25 [1:25:36<39:57, 342.51s/it]  Generation:  19
Best f1_score score: 0.9056021500242408
Generation:  76%|  | 19/25 [1:26:17<25:13, 252.20s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554524b9c60> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 133, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.9056021500242408
Generation:  80%|  | 20/25 [1:27:05<15:53, 190.77s/it]Generation:  21
Best f1_score score: 0.9056021500242408
Generation:  84%| | 21/25 [1:27:57<09:56, 149.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456718f40> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456886650> 

Generation:  22
Best f1_score score: 0.9056021500242408
Generation:  88%| | 22/25 [1:38:03<14:18, 286.10s/it]Generation:  23
Best f1_score score: 0.9056021500242408
Generation:  92%|| 23/25 [1:38:45<07:06, 213.05s/it]Generation:  24
Best f1_score score: 0.9056021500242408
Generation:  96%|| 24/25 [1:39:56<02:50, 170.26s/it]Generation:  25
Best f1_score score: 0.9056021500242408
Generation: 100%|| 25/25 [1:40:44<00:00, 133.65s/it]Generation: 100%|| 25/25 [1:40:44<00:00, 241.78s/it]
2024-11-12 23:37:46,937 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37143' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-8e3aee8f1f6c8d7e5c78d3e1aca39fc2', 'ndarray-4cb56bbbe4ce60b80e8b59051bc5b8d8'} (stimulus_id='handle-worker-cleanup-1731483466.9370015')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='most_frequent')),
                ('adaboostclassifier',
                 AdaBoostClassifier(learning_rate=0.5296908808859,
                                    n_estimators=179))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9798197850209097, 'accuracy': 0.9293918918918919, 'balanced_accuracy': 0.9290540922310498, 'logloss': 0.6468786478869291, 'f1': 0.9292575299666928}
test score: {'auroc': 0.9579253804668424, 'accuracy': 0.9054054054054054, 'balanced_accuracy': 0.9050773352619208, 'logloss': 0.6487487969090758, 'f1': 0.9052281841866456}
original test score: {'auroc': 0.9934252699748517, 'accuracy': 0.9608108108108108, 'balanced_accuracy': 0.9610246351481415, 'logloss': 0.608738973190663, 'f1': 0.9608036529680366}
score end
1496
lvl
0.5
type
MNAR
num_run
1
class_full
finished
all finished
full run takes
9.54607643312878
hours
DONE
