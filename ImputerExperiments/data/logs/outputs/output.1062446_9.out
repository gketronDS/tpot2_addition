Run: 9
/cm/local/apps/slurm/var/spool/job1062446/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40685/40685.pkl
working on 
../data/c/40685/class_full_MNAR_0.01_1
4.217770338058472
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-18 20:33:55,921] A new study created in memory with name: no-name-51266999-8486-49be-b7a8-2de9b9f136f7
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-18 20:33:56,699] Trial 15 finished with value: 0.08497767936773842 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 15 with value: 0.08497767936773842.
running
[I 2024-11-18 20:33:57,358] Trial 2 finished with value: 0.07067475909779322 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.07067475909779322.
running
[I 2024-11-18 20:34:01,811] Trial 16 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9013950105885022, 'alpha': 80, 'iterations': 2, 'learning_rate': 0.018179956580855076, 'p_miss': 0.04127867970563419}. Best is trial 2 with value: 0.07067475909779322.
running
[I 2024-11-18 20:34:03,033] Trial 18 finished with value: 0.07067475909779322 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 2 with value: 0.07067475909779322.
running
[I 2024-11-18 20:34:08,538] Trial 9 finished with value: 0.3533695727475156 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.01655165431568926, 'alpha': 38, 'iterations': 7, 'learning_rate': 0.014265142716290325, 'p_miss': 0.1337609612114976}. Best is trial 2 with value: 0.07067475909779322.
running
[I 2024-11-18 20:34:16,311] Trial 0 finished with value: 0.16214383962745277 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 13, 'learning_rate': 0.0001037584496187836, 'p_miss': 0.09722061360688032}. Best is trial 2 with value: 0.07067475909779322.
running
[I 2024-11-18 20:34:21,707] Trial 17 finished with value: 0.06373100691830927 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 17 with value: 0.06373100691830927.
running
[I 2024-11-18 20:34:28,691] Trial 5 finished with value: 0.07623346617845578 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 17 with value: 0.06373100691830927.
running
[I 2024-11-18 20:34:42,028] Trial 13 finished with value: 0.11998709908288618 and parameters: {'model_name': 'VAE', 'batch_size': 929, 'iterations': 6, 'learning_rate': 0.004673261126029484, 'p_miss': 0.12276708205381147}. Best is trial 17 with value: 0.06373100691830927.
running
[I 2024-11-18 20:34:47,509] Trial 8 finished with value: 0.04176318317112686 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 449, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:34:49,459] Trial 7 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.44270765014595687, 'alpha': 12, 'iterations': 352, 'learning_rate': 0.020320095125728705, 'p_miss': 0.07639050057134034}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:34:58,883] Trial 4 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8188977302836248, 'alpha': 41, 'iterations': 437, 'learning_rate': 0.009484034045648822, 'p_miss': 0.04591697008814542}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:35:01,585] Trial 12 finished with value: 0.05309845534841033 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7732, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:35:21,908] Trial 19 finished with value: 0.36036728245813865 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.557642936430433, 'alpha': 10, 'iterations': 114, 'learning_rate': 0.001412421142916378, 'p_miss': 0.07690475211542147}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:35:28,957] Trial 14 finished with value: 0.07015323373847955 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14114, 'weights': 'distance'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:35:56,965] Trial 25 finished with value: 0.04754763137439547 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3761, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:35:58,513] Trial 26 finished with value: 0.051239436658151546 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1347, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:02,165] Trial 27 finished with value: 0.04504378350363416 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 681, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:05,380] Trial 28 finished with value: 0.043170775197562565 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 548, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:09,185] Trial 23 finished with value: 0.07012048710968326 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14013, 'weights': 'distance'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:12,531] Trial 22 finished with value: 0.07435426105695771 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 38522, 'weights': 'distance'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:13,693] Trial 10 finished with value: 0.08906455306504747 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:24,665] Trial 29 finished with value: 0.04605502842537461 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 756, 'weights': 'uniform'}. Best is trial 8 with value: 0.04176318317112686.
running
[I 2024-11-18 20:36:29,153] Trial 30 finished with value: 0.03738333702538879 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 226, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:36:39,090] Trial 24 finished with value: 0.07233768099571089 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21982, 'weights': 'distance'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:36:51,139] Trial 31 finished with value: 0.03920151237425473 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 293, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:03,220] Trial 36 finished with value: 0.04327442725340344 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 555, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:07,586] Trial 37 finished with value: 0.04608258609223895 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2483, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:07,937] Trial 32 finished with value: 0.06811069610593952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 37870, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:10,459] Trial 34 finished with value: 0.06811069610593952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 36938, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:11,018] Trial 33 finished with value: 0.06811069610593952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 36543, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:12,449] Trial 11 finished with value: 0.358265559414143 and parameters: {'model_name': 'GAIN', 'batch_size': 169, 'hint_rate': 0.8142832337386294, 'alpha': 98, 'iterations': 279, 'learning_rate': 0.0011589804146953492, 'p_miss': 0.1867412209226336}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:12,855] Trial 35 finished with value: 0.06811069610593952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 37054, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:31,952] Trial 38 finished with value: 0.06561258414750469 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27475, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:33,115] Trial 40 finished with value: 0.05630045113780854 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 11051, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:37:35,218] Trial 39 finished with value: 0.0661179073362631 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29500, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 20:56:14,458] Trial 1 finished with value: 0.3604598125476598 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.7632275744739938, 'alpha': 65, 'iterations': 1054, 'learning_rate': 0.00194021794087115, 'p_miss': 0.1996108481867071}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 21:19:34,922] Trial 21 finished with value: 0.04587179869064277 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 21:34:40,510] Trial 6 finished with value: 0.39776112023587595 and parameters: {'model_name': 'GAIN', 'batch_size': 131, 'hint_rate': 0.6847998341837154, 'alpha': 31, 'iterations': 2438, 'learning_rate': 0.0009307862672764877, 'p_miss': 0.17528389140521278}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 21:59:54,043] Trial 20 finished with value: 0.04429832279203001 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 22:51:19,684] Trial 3 finished with value: 0.11459894691192388 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2603, 'learning_rate': 0.04721455074231809, 'p_miss': 0.23769698641985015}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 22:51:29,167] Trial 56 finished with value: 0.15816617089299734 and parameters: {'model_name': 'VAE', 'batch_size': 714, 'iterations': 1, 'learning_rate': 0.0001089164682816538, 'p_miss': 0.29208262124879825}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-18 22:51:30,215] Trial 57 finished with value: 0.5328633728222596 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-19 02:00:19,237] Trial 41 finished with value: 0.07646345824450632 and parameters: {'model_name': 'VAE', 'batch_size': 184, 'iterations': 3935, 'learning_rate': 0.08171851437457442, 'p_miss': 0.29975783004654605}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-19 02:00:59,676] Trial 59 finished with value: 0.05225045833465288 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6980, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-19 02:01:39,640] Trial 60 finished with value: 0.050649338599855244 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5800, 'weights': 'uniform'}. Best is trial 30 with value: 0.03738333702538879.
running
[I 2024-11-19 02:02:11,895] Trial 61 finished with value: 0.02873432437701719 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:02:53,874] Trial 62 finished with value: 0.05369505134624465 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8316, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:04:22,898] Trial 63 finished with value: 0.1465796295036943 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 23, 'learning_rate': 0.0004092932373495275, 'p_miss': 0.23672833296751356}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:04:24,145] Trial 64 finished with value: 0.06811069610593952 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:05:03,812] Trial 65 finished with value: 0.04927940217156044 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4954, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:05:38,019] Trial 66 finished with value: 0.038898542343018844 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 278, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:06:13,390] Trial 67 finished with value: 0.042055497174585885 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 469, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:06:51,676] Trial 68 finished with value: 0.04837659298394068 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4278, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:07:30,978] Trial 69 finished with value: 0.04808581770555957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4086, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:09:10,487] Trial 70 finished with value: 0.042866097886088375 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:18:04,424] Trial 44 finished with value: 0.07578389211030293 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 4028, 'learning_rate': 0.09360561340686002, 'p_miss': 0.27920679218520195}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:18:09,996] Trial 46 finished with value: 0.0756483621892308 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 4853, 'learning_rate': 0.07070203102992091, 'p_miss': 0.29948450513647085}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:18:25,676] Trial 72 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.1879296581727078, 'alpha': 63, 'iterations': 56, 'learning_rate': 0.00037732953564636145, 'p_miss': 0.011433283222083007}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:18:26,134] Trial 73 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.15241190662470494, 'alpha': 61, 'iterations': 45, 'learning_rate': 0.0004285290513053252, 'p_miss': 0.021766328626235204}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:19:00,178] Trial 74 finished with value: 0.033559866372132194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 120, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:19:01,935] Trial 75 finished with value: 0.032659365171128434 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 81, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:19:34,660] Trial 76 finished with value: 0.031230204627041163 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 54, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:19:45,015] Trial 77 finished with value: 0.0531925120412264 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 7822, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:20:14,579] Trial 78 finished with value: 0.04740429722377516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3675, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:20:24,816] Trial 79 finished with value: 0.04714624034528675 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3509, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:20:49,016] Trial 80 finished with value: 0.03253560162617652 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 73, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:20:49,987] Trial 82 finished with value: 0.5328633728222596 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:21:01,361] Trial 81 finished with value: 0.0399020125053476 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 330, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:21:49,017] Trial 83 finished with value: 0.07435426105695771 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46024, 'weights': 'distance'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:22:51,373] Trial 84 finished with value: 0.04316860492105866 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:23:24,701] Trial 86 finished with value: 0.029060813199131057 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:23:36,506] Trial 85 finished with value: 0.04284146064797335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:24:05,207] Trial 87 finished with value: 0.048178342044935527 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4142, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:24:16,038] Trial 88 finished with value: 0.04622538293001209 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2871, 'weights': 'uniform'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:24:57,925] Trial 89 finished with value: 0.06890432375651184 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10413, 'weights': 'distance'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:24:58,289] Trial 90 finished with value: 0.06655607361421009 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2386, 'weights': 'distance'}. Best is trial 61 with value: 0.02873432437701719.
running
[I 2024-11-19 02:25:32,844] Trial 92 finished with value: 0.02818988817236066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:25:37,526] Trial 91 finished with value: 0.04601400520277034 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2545, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:26:15,323] Trial 93 finished with value: 0.05178854401481664 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6602, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:26:24,644] Trial 94 finished with value: 0.06030018613343278 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16178, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:26:58,668] Trial 96 finished with value: 0.028214108993359834 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:27:05,585] Trial 95 finished with value: 0.06175081080839281 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18528, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:27:36,813] Trial 97 finished with value: 0.04691913812365471 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2279, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:27:40,231] Trial 98 finished with value: 0.02818988817236066 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:28:10,624] Trial 99 finished with value: 0.028690254623291257 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 36, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:28:17,597] Trial 100 finished with value: 0.04763159993693294 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2168, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:28:48,738] Trial 101 finished with value: 0.05168195883191591 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1810, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:28:55,244] Trial 102 finished with value: 0.051569316445409644 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1817, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:29:01,338] Trial 103 finished with value: 0.3441995298857394 and parameters: {'model_name': 'GAIN', 'batch_size': 59, 'hint_rate': 0.3627468367270964, 'alpha': 0, 'iterations': 2, 'learning_rate': 0.00483414687278204, 'p_miss': 0.23953648830516058}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:29:02,437] Trial 105 finished with value: 0.06811069610593952 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:29:04,865] Trial 104 finished with value: 0.3452604589161494 and parameters: {'model_name': 'GAIN', 'batch_size': 44, 'hint_rate': 0.3735134104957242, 'alpha': 99, 'iterations': 1, 'learning_rate': 0.006469479965742585, 'p_miss': 0.2408505922782037}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:29:38,223] Trial 106 finished with value: 0.03240757568700954 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 70, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:29:40,231] Trial 107 finished with value: 0.038158887827784524 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 250, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:30:19,102] Trial 108 finished with value: 0.05026445330235267 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5556, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:30:21,412] Trial 109 finished with value: 0.04981946582231292 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5288, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:30:57,192] Trial 110 finished with value: 0.04993388442646348 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1928, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:30:59,163] Trial 111 finished with value: 0.04682298580583638 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2297, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:31:31,151] Trial 112 finished with value: 0.02975441881905544 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 43, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:31:34,289] Trial 113 finished with value: 0.03636868461879304 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 195, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:32:15,861] Trial 114 finished with value: 0.06671339629054213 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3774, 'weights': 'distance'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:32:18,859] Trial 115 finished with value: 0.06680724401462086 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4119, 'weights': 'distance'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:32:48,612] Trial 117 finished with value: 0.08760303591739788 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:32:53,240] Trial 116 finished with value: 0.05193130466915907 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1465, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:33:26,496] Trial 118 finished with value: 0.052231021985842084 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1525, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:33:30,955] Trial 119 finished with value: 0.05247767606613467 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1574, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:33:48,770] Trial 43 finished with value: 0.07604527734617686 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 6675, 'learning_rate': 0.0007772667988673207, 'p_miss': 0.2913168015367196}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:34:26,205] Trial 122 finished with value: 0.04658049174717188 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3137, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:35:16,206] Trial 123 finished with value: 0.06520025098918866 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 26018, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:35:57,664] Trial 124 finished with value: 0.10164974815192332 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:36:31,414] Trial 125 finished with value: 0.03130912321217988 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 55, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:37:07,239] Trial 126 finished with value: 0.05016210789036648 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1195, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:37:40,975] Trial 127 finished with value: 0.032659365171128434 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 81, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:38:19,271] Trial 128 finished with value: 0.046527665875337985 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3099, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:38:52,386] Trial 129 finished with value: 0.02851863160268517 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:39:27,943] Trial 130 finished with value: 0.05117506649278212 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1338, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:39:29,830] Trial 131 finished with value: 0.08497767936773842 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:40:08,603] Trial 132 finished with value: 0.049386584946433006 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5021, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:42:49,622] Trial 120 finished with value: 0.07562371949856869 and parameters: {'model_name': 'VAE', 'batch_size': 339, 'iterations': 131, 'learning_rate': 0.032773563845043555, 'p_miss': 0.1638463394504708}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:43:12,048] Trial 51 finished with value: 0.07876527596766236 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 6486, 'learning_rate': 0.06959670683722774, 'p_miss': 0.2933777043365098}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:43:42,953] Trial 134 finished with value: 0.06766133742549493 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 33196, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:43:48,904] Trial 135 finished with value: 0.050075278096268674 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1183, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:44:16,952] Trial 136 finished with value: 0.0292724289454226 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 40, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:44:28,821] Trial 137 finished with value: 0.04646461966987393 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3044, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:44:55,395] Trial 138 finished with value: 0.046320990975745865 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2939, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:45:03,710] Trial 139 finished with value: 0.028828634710598385 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 37, 'weights': 'uniform'}. Best is trial 92 with value: 0.02818988817236066.
running
[I 2024-11-19 02:45:29,512] Trial 140 finished with value: 0.028166789884229798 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 29, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:45:41,163] Trial 141 finished with value: 0.05018912363462709 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1199, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:46:06,343] Trial 142 finished with value: 0.05161905102368571 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1404, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:46:19,428] Trial 143 finished with value: 0.05075159864287798 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1275, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:46:47,264] Trial 144 finished with value: 0.051365645197343435 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6290, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:46:59,142] Trial 145 finished with value: 0.04845812777672054 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4340, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:47:21,724] Trial 146 finished with value: 0.032606022073913554 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 76, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:47:34,118] Trial 147 finished with value: 0.03291643328649674 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 92, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:47:49,595] Trial 133 finished with value: 0.07984855954922096 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 131, 'learning_rate': 0.03137383224311646, 'p_miss': 0.15709527369255424}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:47:59,467] Trial 148 finished with value: 0.04784024204887928 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 913, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:48:13,100] Trial 149 finished with value: 0.04612685956260913 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2459, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:48:28,138] Trial 150 finished with value: 0.04601587263770672 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2543, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:48:38,924] Trial 151 finished with value: 0.04602698749741012 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2687, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:48:52,380] Trial 152 finished with value: 0.04610760129972583 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2779, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:49:13,805] Trial 154 finished with value: 0.04857571973080331 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 992, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:49:43,264] Trial 121 finished with value: 0.1154361916520068 and parameters: {'model_name': 'VAE', 'batch_size': 360, 'iterations': 155, 'learning_rate': 0.00021221649097199306, 'p_miss': 0.15186470203401348}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:49:45,768] Trial 156 finished with value: 0.032916671678487074 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 93, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:52:33,189] Trial 71 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.20712206699514107, 'alpha': 61, 'iterations': 8697, 'learning_rate': 0.0003970475601061912, 'p_miss': 0.016378209515069297}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:53:09,228] Trial 159 finished with value: 0.04917024623837607 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1058, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:53:21,016] Trial 157 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.9727232760610105, 'alpha': 84, 'iterations': 671, 'learning_rate': 0.002581689175728792, 'p_miss': 0.21620178761606243}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:53:57,031] Trial 161 finished with value: 0.051178484527036015 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1842, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:54:01,584] Trial 155 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.9692566263130338, 'alpha': 82, 'iterations': 1019, 'learning_rate': 0.000216212871781741, 'p_miss': 0.20672964624409185}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:54:32,416] Trial 158 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.9657946847566375, 'alpha': 82, 'iterations': 1104, 'learning_rate': 0.00254909566002504, 'p_miss': 0.2096252088711632}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:54:37,700] Trial 162 finished with value: 0.09358653880706551 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:55:11,809] Trial 164 finished with value: 0.04760654468412579 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3797, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:55:15,041] Trial 165 finished with value: 0.047613472295956236 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3801, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:55:45,938] Trial 166 finished with value: 0.031536664166416505 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 57, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:55:51,386] Trial 167 finished with value: 0.04634631096482648 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 779, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:56:21,401] Trial 168 finished with value: 0.048174978438233075 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 948, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:56:22,592] Trial 170 finished with value: 0.07067475909779322 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:56:26,964] Trial 169 finished with value: 0.05201347183746141 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1789, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:56:59,710] Trial 171 finished with value: 0.050249347297221504 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1905, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:57:01,506] Trial 172 finished with value: 0.06483498257242055 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 67, 'weights': 'distance'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:57:34,242] Trial 173 finished with value: 0.06456807103898773 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 110, 'weights': 'distance'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:57:36,354] Trial 174 finished with value: 0.02959307361258402 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 42, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:58:10,394] Trial 175 finished with value: 0.04806558148157029 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 936, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:58:12,458] Trial 176 finished with value: 0.04844467703132822 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 977, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:58:58,500] Trial 177 finished with value: 0.06357073560295146 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 22060, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:59:00,965] Trial 178 finished with value: 0.06334202398632396 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 21572, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:59:35,085] Trial 179 finished with value: 0.050725575607400195 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1872, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 02:59:37,728] Trial 180 finished with value: 0.0486645317463217 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2041, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:00:10,329] Trial 181 finished with value: 0.04579265502296252 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 736, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:00:13,574] Trial 182 finished with value: 0.043893823925117856 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 599, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:00:47,351] Trial 184 finished with value: 0.03308159223366416 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 102, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:00:52,055] Trial 183 finished with value: 0.06811069610593952 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 44593, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:01:25,363] Trial 185 finished with value: 0.046734817174384866 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3239, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:01:26,808] Trial 186 finished with value: 0.03309247033358257 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 103, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:01:59,099] Trial 187 finished with value: 0.034115548280896246 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 135, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:02:00,916] Trial 188 finished with value: 0.028909138680192775 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:02:35,201] Trial 189 finished with value: 0.05158954587313924 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1399, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:02:37,910] Trial 190 finished with value: 0.04945838179370223 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1964, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:03:11,484] Trial 191 finished with value: 0.048081546636675666 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2109, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:03:54,695] Trial 193 finished with value: 0.05831476493220711 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13477, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:04:06,008] Trial 47 finished with value: 0.07853254068277035 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 6990, 'learning_rate': 0.06798966222191095, 'p_miss': 0.29600795603422414}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:04:50,304] Trial 195 finished with value: 0.05076527219037756 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1277, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:05:04,624] Trial 194 finished with value: 0.08254964833444066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:05:25,522] Trial 196 finished with value: 0.028195366476404516 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:05:38,427] Trial 197 finished with value: 0.03284539173821497 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 89, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
running
[I 2024-11-19 03:06:01,361] Trial 198 finished with value: 0.04673581490300951 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 811, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 03:06:13,595] Trial 199 finished with value: 0.04933479171487616 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1078, 'weights': 'uniform'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 03:11:15,190] Trial 49 finished with value: 0.07699197430568372 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 5878, 'learning_rate': 0.09739534193298813, 'p_miss': 0.28148804779132075}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 03:47:29,029] Trial 50 finished with value: 0.0773657924100167 and parameters: {'model_name': 'VAE', 'batch_size': 68, 'iterations': 7507, 'learning_rate': 0.07642590606003376, 'p_miss': 0.2890860402656832}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 03:51:24,980] Trial 192 finished with value: 0.03509709180629538 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:01:20,011] Trial 58 finished with value: 0.07837965965179923 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 7019, 'learning_rate': 0.0003166652940023912, 'p_miss': 0.29663469255140096}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:01:26,831] Trial 160 finished with value: 0.03968653792184103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:07:40,387] Trial 153 finished with value: 0.04005707532326541 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:12:13,501] Trial 163 finished with value: 0.03970951089405208 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:20:16,798] Trial 42 finished with value: 0.07560339577977256 and parameters: {'model_name': 'VAE', 'batch_size': 212, 'iterations': 7614, 'learning_rate': 0.09796841917977353, 'p_miss': 0.2819545245809376}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:20:49,954] Trial 48 finished with value: 0.07642357698791305 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 9167, 'learning_rate': 0.09975782534083262, 'p_miss': 0.285779477890037}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:26:29,104] Trial 45 finished with value: 0.0758312166364696 and parameters: {'model_name': 'VAE', 'batch_size': 154, 'iterations': 9374, 'learning_rate': 0.09486611821726222, 'p_miss': 0.28576457208829487}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:31:39,646] Trial 52 finished with value: 0.07739331911988925 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 8317, 'learning_rate': 0.09979282093282484, 'p_miss': 0.2838469965189999}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:38:22,000] Trial 53 finished with value: 0.0768490337072335 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 9731, 'learning_rate': 0.07565982308448942, 'p_miss': 0.29758250677036513}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:42:22,123] Trial 54 finished with value: 0.07502638974236386 and parameters: {'model_name': 'VAE', 'batch_size': 828, 'iterations': 6969, 'learning_rate': 0.08438285766720315, 'p_miss': 0.29990267651446956}. Best is trial 140 with value: 0.028166789884229798.
[I 2024-11-19 04:49:35,325] Trial 55 finished with value: 0.07467274320755454 and parameters: {'model_name': 'VAE', 'batch_size': 943, 'iterations': 9646, 'learning_rate': 0.07282379302125057, 'p_miss': 0.29321866389268975}. Best is trial 140 with value: 0.028166789884229798.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0.028166789884229798
{'model_name': 'KNNImputer', 'n_neighbors': 29, 'weights': 'uniform'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5390> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fd6c20> 

Generation:  1
Best f1_score score: 0.9695234597543424
Generation:   4%|         | 1/25 [10:03<4:01:34, 603.93s/it]Generation:  2
Best f1_score score: 0.9695234597543424
Generation:   8%|         | 2/25 [15:03<2:42:54, 424.99s/it]Generation:  3
Best f1_score score: 0.9695234597543424
Generation:  12%|        | 3/25 [17:04<1:44:53, 286.06s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ff5e0> 

Generation:  4
Best f1_score score: 0.9695234597543424
Generation:  16%|        | 4/25 [27:10<2:24:22, 412.51s/it]Generation:  5
Best f1_score score: 0.9695234597543424
Generation:  20%|        | 5/25 [35:13<2:25:53, 437.66s/it]Generation:  6
Best f1_score score: 0.9695234597543424
Generation:  24%|       | 6/25 [36:31<1:39:55, 315.58s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ee9000> 

Generation:  7
Best f1_score score: 0.9695234597543424
Generation:  28%|       | 7/25 [46:39<2:03:17, 410.99s/it]Generation:  8
Best f1_score score: 0.9695234597543424
Generation:  32%|      | 8/25 [48:43<1:30:38, 319.88s/it]Generation:  9
Best f1_score score: 0.9695234597543424
Generation:  36%|      | 9/25 [50:28<1:07:19, 252.48s/it]Generation:  10
Best f1_score score: 0.9695234597543424
Generation:  40%|      | 10/25 [52:04<51:06, 204.44s/it] Generation:  11
Best f1_score score: 0.9722051757974951
Generation:  44%|     | 11/25 [54:01<41:25, 177.50s/it]Generation:  12
Best f1_score score: 0.9722051757974951
Generation:  48%|     | 12/25 [55:03<30:50, 142.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464a25f00> 

Generation:  13
Best f1_score score: 0.9722051757974951
Generation:  52%|    | 13/25 [1:05:12<56:44, 283.68s/it]Generation:  14
Best f1_score score: 0.9722051757974951
Generation:  56%|    | 14/25 [1:06:49<41:40, 227.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e08490> 

Generation:  15
Best f1_score score: 0.9736385019282832
Generation:  60%|    | 15/25 [1:16:59<57:06, 342.63s/it]Generation:  16
Best f1_score score: 0.9736385019282832
Generation:  64%|   | 16/25 [1:23:59<54:54, 366.03s/it]Generation:  17
Best f1_score score: 0.9736385019282832
Generation:  68%|   | 17/25 [1:28:25<44:48, 336.03s/it]Generation:  18
Best f1_score score: 0.9736385019282832
Generation:  72%|  | 18/25 [1:35:34<42:26, 363.85s/it]Generation:  19
Best f1_score score: 0.9736385019282832
Generation:  76%|  | 19/25 [1:44:34<41:41, 416.86s/it]Generation:  20
Best f1_score score: 0.9736385019282832
Generation:  80%|  | 20/25 [1:45:46<26:06, 313.33s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d26cb0> 

Generation:  21
Best f1_score score: 0.9736385019282832
Generation:  84%| | 21/25 [1:55:57<26:50, 402.67s/it]Generation:  22
Best f1_score score: 0.9736385019282832
Generation:  88%| | 22/25 [1:56:55<14:57, 299.10s/it]Generation:  23
Best f1_score score: 0.9736385019282832
Generation:  92%|| 23/25 [1:57:24<07:16, 218.09s/it]Generation:  24
Best f1_score score: 0.9736385019282832
Generation:  96%|| 24/25 [1:59:38<03:12, 193.00s/it]Generation:  25
Best f1_score score: 0.9736385019282832
Generation: 100%|| 25/25 [2:00:10<00:00, 144.44s/it]Generation: 100%|| 25/25 [2:00:13<00:00, 288.55s/it]
2024-11-19 06:50:16,461 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:34715' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-732d693602de5831bd20cd0deac1c857', 'ndarray-08e2b28cd26b443d1296bc2cda8a08c0'} (stimulus_id='handle-worker-cleanup-1732027816.4612498')
Fitted
Pipeline(steps=[('baggingclassifier',
                 BaggingClassifier(max_features=0.9020616960788,
                                   max_samples=0.6486409972091, n_estimators=88,
                                   n_jobs=1))])
score start
train score: {'auroc': 0.9999999770658837, 'accuracy': 0.9999353448275862, 'balanced_accuracy': 0.9785675113501487, 'logloss': 0.0007740814140330211, 'f1': 0.9881090843087312}
original test score: {'auroc': 1.0, 'accuracy': 0.9998275862068966, 'balanced_accuracy': 0.9957181075686873, 'logloss': 0.0009569108406383235, 'f1': 0.9978120190996209}
imputed test score: {'auroc': 0.9999873012564809, 'accuracy': 0.9993965517241379, 'balanced_accuracy': 0.9094120527694587, 'logloss': 0.0017357784642261986, 'f1': 0.8893234563613311}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145e0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a4220> 

Generation:  1
Best f1_score score: 0.933533326229082
Generation:   4%|         | 1/25 [10:02<4:00:53, 602.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fc2aa0> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  2
Best f1_score score: 0.933533326229082
Generation:   8%|         | 2/25 [13:41<2:24:36, 377.25s/it]Generation:  3
Best f1_score score: 0.933533326229082
Generation:  12%|        | 3/25 [15:44<1:35:42, 261.03s/it]Generation:  4
Best f1_score score: 0.9459126307404991
Generation:  16%|        | 4/25 [17:11<1:07:18, 192.30s/it]Generation:  5
Best f1_score score: 0.9459126307404991
Generation:  20%|        | 5/25 [18:45<52:17, 156.86s/it]  Generation:  6
Best f1_score score: 0.9597065586848869
Generation:  24%|       | 6/25 [20:27<43:46, 138.25s/it]Generation:  7
Best f1_score score: 0.9597065586848869
Generation:  28%|       | 7/25 [23:46<47:26, 158.15s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c1fb20> 

Generation:  8
Best f1_score score: 0.9597065586848869
Generation:  32%|      | 8/25 [33:53<1:25:15, 300.89s/it]Generation:  9
Best f1_score score: 0.9615311463838061
Generation:  36%|      | 9/25 [34:42<59:12, 222.03s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467149300> 

Generation:  10
Best f1_score score: 0.9615311463838061
Generation:  40%|      | 10/25 [44:48<1:25:12, 340.84s/it]Generation:  11
Best f1_score score: 0.9679026942360769
Generation:  44%|     | 11/25 [46:13<1:01:15, 262.54s/it]Generation:  12
Best f1_score score: 0.968270090753579
Generation:  48%|     | 12/25 [47:06<43:01, 198.56s/it]  Generation:  13
Best f1_score score: 0.9695618194487867
Generation:  52%|    | 13/25 [51:21<43:09, 215.81s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155465032d40> 

Generation:  14
Best f1_score score: 0.9695618194487867
Generation:  56%|    | 14/25 [1:01:28<1:01:13, 333.93s/it]Generation:  15
Best f1_score score: 0.9695618194487867
Generation:  60%|    | 15/25 [1:09:44<1:03:46, 382.68s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2de70> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554511e9660> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  16
Best f1_score score: 0.9695618194487867
Generation:  64%|   | 16/25 [1:11:25<44:41, 298.00s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467641000> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554538bca30> 

Generation:  17
Best f1_score score: 0.9725541214345252
Generation:  68%|   | 17/25 [1:21:34<52:11, 391.40s/it]Generation:  18
Best f1_score score: 0.9725541214345252
Generation:  72%|  | 18/25 [1:23:55<36:54, 316.29s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453514400> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464baece0> 

Generation:  19
Best f1_score score: 0.9725541214345252
Generation:  76%|  | 19/25 [1:34:04<40:24, 404.12s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676ec0a0> 

Generation:  20
Best f1_score score: 0.9725541214345252
Generation:  80%|  | 20/25 [1:44:12<38:47, 465.48s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466f114b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0ba60> 

Generation:  21
Best f1_score score: 0.9725541214345252
Generation:  84%| | 21/25 [1:54:19<33:51, 507.85s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466ef4970> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  22
Best f1_score score: 0.9757822167812135
Generation:  88%| | 22/25 [1:55:18<18:39, 373.18s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554675f8430> 

Generation:  23
Best f1_score score: 0.9757822167812135
Generation:  92%|| 23/25 [2:05:26<14:46, 443.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467896b90> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554646af9d0> 

Generation:  24
Best f1_score score: 0.9757822167812135
Generation:  96%|| 24/25 [2:15:32<08:12, 492.32s/it]Generation:  25
Best f1_score score: 0.9757822167812135
Generation: 100%|| 25/25 [2:16:56<00:00, 369.76s/it]Generation: 100%|| 25/25 [2:16:56<00:00, 328.65s/it]
2024-11-19 09:07:33,799 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:47045' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-08e2b28cd26b443d1296bc2cda8a08c0', 'DataFrame-48c9cd8dba1f620470d17d029552a75f'} (stimulus_id='handle-worker-cleanup-1732036053.7995667')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=40, weights='distance')),
                ('extratreesclassifier',
                 ExtraTreesClassifier(class_weight='balanced',
                                      criterion='entropy',
                                      max_features=0.5506015849677,
                                      min_samples_split=12, n_jobs=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9999995394121332, 'accuracy': 0.9996767241379311, 'balanced_accuracy': 0.9998766762818114, 'logloss': 0.0015447740113117944, 'f1': 0.9779532056166744}
test score: {'auroc': 0.9999928866484739, 'accuracy': 0.9992241379310345, 'balanced_accuracy': 0.9996558749720178, 'logloss': 0.0024312647618306145, 'f1': 0.9088981209393288}
original test score: {'auroc': 0.9999951041841031, 'accuracy': 0.9993965517241379, 'balanced_accuracy': 0.999890314796534, 'logloss': 0.001938554164655734, 'f1': 0.9394871503248986}
score end
40685
lvl
0.01
type
MNAR
num_run
1
class_full
finished
all finished
full run takes
12.57929386264748
hours
DONE
