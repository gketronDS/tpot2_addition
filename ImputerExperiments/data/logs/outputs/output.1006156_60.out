Run: 60
/cm/local/apps/slurm/var/spool/job1006156/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/151/151.pkl
working on 
../data/c/151/class_full_MNAR_0.5_3
2.903594732284546
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-16 15:34:06,489] A new study created in memory with name: no-name-f5336a1c-a0ef-45e6-acb2-857361b44a6c
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-16 15:34:07,883] Trial 9 finished with value: 0.20945658392574198 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:08,477] Trial 10 finished with value: 0.3253320817135761 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:09,244] Trial 13 finished with value: 0.3180253737971294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:11,234] Trial 18 finished with value: 0.3253320817135761 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:23,289] Trial 2 finished with value: 0.23073748932802887 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1, 'learning_rate': 0.0044203049715499255, 'p_miss': 0.18062382422544523}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:24,246] Trial 4 finished with value: 0.2230987691429101 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.047519169287574645, 'p_miss': 0.119938611932961}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:30,122] Trial 14 finished with value: 0.3192288847731707 and parameters: {'model_name': 'GAIN', 'batch_size': 865, 'hint_rate': 0.15059923953668186, 'alpha': 38, 'iterations': 1, 'learning_rate': 0.00041453605314292416, 'p_miss': 0.10142568397118527}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:30,823] Trial 11 finished with value: 0.31393338551746364 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.3501547423584763, 'alpha': 20, 'iterations': 2, 'learning_rate': 0.0002700376024888152, 'p_miss': 0.17829141373887183}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:33,124] Trial 12 finished with value: 0.3061873200739908 and parameters: {'model_name': 'GAIN', 'batch_size': 151, 'hint_rate': 0.0706012962020541, 'alpha': 91, 'iterations': 3, 'learning_rate': 0.0061150988337442475, 'p_miss': 0.2682402482927802}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:33,576] Trial 19 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.46133744817280153, 'alpha': 23, 'iterations': 16, 'learning_rate': 0.0013189976975568874, 'p_miss': 0.28096951015626426}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:36,480] Trial 8 finished with value: 0.323719775214304 and parameters: {'model_name': 'GAIN', 'batch_size': 511, 'hint_rate': 0.4871917913205523, 'alpha': 63, 'iterations': 4, 'learning_rate': 0.06979111549711946, 'p_miss': 0.03765700248241479}. Best is trial 9 with value: 0.20945658392574198.
running
[I 2024-10-16 15:34:41,093] Trial 21 finished with value: 0.20598977070873511 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.02602100469588833, 'p_miss': 0.026611972793679974}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:34:43,565] Trial 7 finished with value: 0.20945658392574198 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 35890, 'weights': 'uniform'}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:34:47,180] Trial 16 finished with value: 0.20945658392574198 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 34949, 'weights': 'uniform'}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:35:09,419] Trial 6 finished with value: 0.2216061090983743 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19780, 'weights': 'distance'}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:35:10,286] Trial 22 finished with value: 0.22141351177866925 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 280, 'weights': 'distance'}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:35:10,662] Trial 0 finished with value: 0.22161930708922065 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20265, 'weights': 'distance'}. Best is trial 21 with value: 0.20598977070873511.
running
[I 2024-10-16 15:35:11,897] Trial 26 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:13,017] Trial 1 finished with value: 0.2217245274962089 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23148, 'weights': 'distance'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:30,328] Trial 25 finished with value: 0.20343236542584692 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:30,915] Trial 20 finished with value: 0.22159715807964614 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 19431, 'weights': 'distance'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:32,072] Trial 28 finished with value: 0.20945658392574198 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 35261, 'weights': 'uniform'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:34,675] Trial 33 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:35,133] Trial 34 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:37,579] Trial 29 finished with value: 0.2213260343501695 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4077, 'weights': 'distance'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:42,909] Trial 3 finished with value: 0.20739620600455771 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:48,573] Trial 5 finished with value: 0.2066112153677932 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 26 with value: 0.20253947711642986.
[I 2024-10-16 15:35:48,776] Trial 15 finished with value: 0.20635394045740832 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
running
[I 2024-10-16 15:35:51,226] Trial 38 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:52,497] Trial 39 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:54,481] Trial 40 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:35:57,350] Trial 41 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:03,409] Trial 43 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:03,630] Trial 42 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:05,010] Trial 44 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
[I 2024-10-16 15:36:05,230] Trial 23 finished with value: 0.21032598150333234 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 58, 'learning_rate': 0.0009663363361316709, 'p_miss': 0.17791757132090255}. Best is trial 26 with value: 0.20253947711642986.
running
running
[I 2024-10-16 15:36:05,382] Trial 35 finished with value: 0.20291507242698267 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:05,803] Trial 36 finished with value: 0.20291507242698267 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:06,141] Trial 37 finished with value: 0.20291507242698267 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:09,542] Trial 46 finished with value: 0.20253947711642986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:17,188] Trial 24 finished with value: 0.20359956899292878 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:17,580] Trial 47 finished with value: 0.20702674919237438 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:27,479] Trial 30 finished with value: 0.20320593139366872 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:30,889] Trial 32 finished with value: 0.2724129160697802 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:36,374] Trial 27 finished with value: 0.2717865876113791 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:37,017] Trial 45 finished with value: 0.20588392769524183 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'ascending', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:42,107] Trial 48 finished with value: 0.20785464832469072 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:50,637] Trial 51 finished with value: 0.20502694709120095 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:36:53,315] Trial 52 finished with value: 0.20502694709120095 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:37:04,520] Trial 31 finished with value: 0.2689828980424648 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:37:08,293] Trial 54 finished with value: 0.2767860024160821 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:37:15,906] Trial 49 finished with value: 0.20281406426130885 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 15:37:42,129] Trial 17 finished with value: 0.3328957583284501 and parameters: {'model_name': 'GAIN', 'batch_size': 182, 'hint_rate': 0.7472720458290596, 'alpha': 32, 'iterations': 269, 'learning_rate': 0.04268732182543826, 'p_miss': 0.24175386275253163}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 16:01:27,992] Trial 50 finished with value: 0.20657865360465796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 16:14:11,832] Trial 53 finished with value: 0.20978007236471283 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 16:14:13,486] Trial 70 finished with value: 0.3253320817135761 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 16:14:44,978] Trial 55 finished with value: 0.20927685358436138 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 26 with value: 0.20253947711642986.
running
[I 2024-10-16 16:54:19,537] Trial 58 finished with value: 0.19412487474071083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 17:06:44,585] Trial 59 finished with value: 0.19438159092178928 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 17:07:35,708] Trial 56 finished with value: 0.19476574191918386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 17:07:40,211] Trial 57 finished with value: 0.19443054975279508 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 17:08:34,731] Trial 60 finished with value: 0.19433223365063917 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 18:41:01,479] Trial 64 finished with value: 0.21720683805128155 and parameters: {'model_name': 'VAE', 'batch_size': 78, 'iterations': 3961, 'learning_rate': 0.00010185764275756181, 'p_miss': 0.2244515652499476}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 18:41:02,152] Trial 78 finished with value: 0.3253320817135761 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 19:20:54,969] Trial 77 finished with value: 0.2178524678571409 and parameters: {'model_name': 'VAE', 'batch_size': 34, 'iterations': 2599, 'learning_rate': 0.0001489328817702177, 'p_miss': 0.08422621964518183}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 19:33:04,339] Trial 80 finished with value: 0.3282782287540892 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.9898887126023048, 'alpha': 1, 'iterations': 443, 'learning_rate': 0.014110389603342119, 'p_miss': 0.07258188446363972}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 19:36:33,173] Trial 68 finished with value: 0.21574543888670808 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 4778, 'learning_rate': 0.00011120927632024166, 'p_miss': 0.0789038617817832}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 19:49:58,261] Trial 66 finished with value: 0.21645610783200736 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 5196, 'learning_rate': 0.0001072801167100711, 'p_miss': 0.2263091793507623}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 19:58:00,645] Trial 62 finished with value: 0.2155279846644449 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 4620, 'learning_rate': 0.00010724975206899251, 'p_miss': 0.24890115411774094}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 20:35:43,265] Trial 67 finished with value: 0.2152195236658116 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 5701, 'learning_rate': 0.00010479321645097873, 'p_miss': 0.23251643393558707}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 20:56:08,160] Trial 81 finished with value: 0.19447951566730654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:07:37,706] Trial 82 finished with value: 0.19466319498192625 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:09:11,747] Trial 74 finished with value: 0.21420659548641047 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 5455, 'learning_rate': 0.010325585180284503, 'p_miss': 0.08215884517085002}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:12:20,850] Trial 83 finished with value: 0.1948654183934558 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:26:23,640] Trial 63 finished with value: 0.21587166046103884 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 6079, 'learning_rate': 0.00011453689335479163, 'p_miss': 0.2525370778496911}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:26:58,785] Trial 84 finished with value: 0.19438859581303847 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 21:45:08,917] Trial 71 finished with value: 0.2143398511550822 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 7856, 'learning_rate': 0.00012995309287047244, 'p_miss': 0.08383561595486874}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:00:02,019] Trial 76 finished with value: 0.21305707423639828 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 6623, 'learning_rate': 0.01000949182329816, 'p_miss': 0.07709162306082809}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:04:11,365] Trial 85 finished with value: 0.19461588126703186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:04:36,055] Trial 65 finished with value: 0.21412906782077695 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 8987, 'learning_rate': 0.0001252819451923553, 'p_miss': 0.23431084094284244}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:06:46,600] Trial 94 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7502971320729559, 'alpha': 100, 'iterations': 788, 'learning_rate': 0.0023250014063706096, 'p_miss': 0.12243466588975142}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:08:24,302] Trial 95 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7808561618404171, 'alpha': 70, 'iterations': 1281, 'learning_rate': 0.0017793272782187252, 'p_miss': 0.1404822598391941}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:09:41,110] Trial 75 finished with value: 0.2154466402615811 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 6012, 'learning_rate': 0.012492811888287087, 'p_miss': 0.0734691601396494}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:19:07,724] Trial 86 finished with value: 0.19483844662542835 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:25:53,142] Trial 72 finished with value: 0.21576591850621846 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 7991, 'learning_rate': 0.00011147159037397844, 'p_miss': 0.08478382759794953}. Best is trial 58 with value: 0.19412487474071083.
running
[I 2024-10-16 22:28:20,143] Trial 89 finished with value: 0.19412158497716608 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:32:37,880] Trial 87 finished with value: 0.19469784570639626 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:33:09,647] Trial 61 finished with value: 0.21639226471373788 and parameters: {'model_name': 'VAE', 'batch_size': 95, 'iterations': 8698, 'learning_rate': 0.00010221710602506838, 'p_miss': 0.23955134931406402}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:33:51,891] Trial 88 finished with value: 0.1943247404319614 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:34:18,770] Trial 104 finished with value: 0.20536753668599408 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9874, 'weights': 'uniform'}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:36:43,020] Trial 73 finished with value: 0.21492768935307938 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 9138, 'learning_rate': 0.011334285882154214, 'p_miss': 0.10289170934486247}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:37:32,090] Trial 69 finished with value: 0.21532571181836335 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 8536, 'learning_rate': 0.011488614135957448, 'p_miss': 0.08429299376335103}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:38:51,589] Trial 79 finished with value: 0.21558818550159292 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 7711, 'learning_rate': 0.01201790928712464, 'p_miss': 0.07616089949333203}. Best is trial 89 with value: 0.19412158497716608.
running
[I 2024-10-16 22:46:04,966] Trial 90 finished with value: 0.19407513213407057 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 22:47:23,868] Trial 91 finished with value: 0.19465746441150383 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:00:37,668] Trial 92 finished with value: 0.19484915466680935 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:12:06,266] Trial 93 finished with value: 0.19491250684399186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:12:23,898] Trial 112 finished with value: 0.20610560492695482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:17:17,857] Trial 96 finished with value: 0.19452987448437103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:18:41,060] Trial 97 finished with value: 0.19454472971700643 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:18:56,923] Trial 98 finished with value: 0.19481803005290985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:26:55,810] Trial 99 finished with value: 0.1951507370811704 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:32:39,197] Trial 100 finished with value: 0.19450708926504684 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:33:54,199] Trial 101 finished with value: 0.1944061524783569 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:38:12,372] Trial 102 finished with value: 0.19479970476109948 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:39:18,813] Trial 103 finished with value: 0.1947840220156311 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:39:35,314] Trial 105 finished with value: 0.19430581283073675 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:41:34,279] Trial 106 finished with value: 0.19539870770934853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:41:34,646] Trial 123 finished with value: 0.3180253737971294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:43:02,820] Trial 107 finished with value: 0.1946936649036291 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:43:24,997] Trial 125 finished with value: 0.20811708537706242 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:44:34,873] Trial 108 finished with value: 0.19430546082839217 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 90 with value: 0.19407513213407057.
running
[I 2024-10-16 23:51:08,731] Trial 109 finished with value: 0.19401000175178196 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-16 23:52:28,911] Trial 110 finished with value: 0.19476399219636553 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-16 23:54:30,391] Trial 114 finished with value: 0.20332519243758335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-16 23:54:56,349] Trial 130 finished with value: 0.20945658392574198 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27794, 'weights': 'uniform'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:06:18,062] Trial 111 finished with value: 0.19493656158356237 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:09:51,582] Trial 118 finished with value: 0.2048199924912873 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:15:33,992] Trial 120 finished with value: 0.20411332042593733 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:15:53,767] Trial 115 finished with value: 0.19614094931519827 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:17:40,840] Trial 124 finished with value: 0.2046322129997959 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:18:00,457] Trial 113 finished with value: 0.19449441613305218 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:20:48,774] Trial 126 finished with value: 0.2056016002327327 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:23:44,400] Trial 117 finished with value: 0.19621110321846025 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:24:46,486] Trial 116 finished with value: 0.19539738918943944 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:31:19,024] Trial 119 finished with value: 0.19581235581079337 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:36:28,088] Trial 121 finished with value: 0.196595625223369 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:36:30,568] Trial 122 finished with value: 0.19676894886633534 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:36:30,779] Trial 143 finished with value: 0.20945658392574198 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:41:39,569] Trial 127 finished with value: 0.19575884523462564 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:41:59,249] Trial 145 finished with value: 0.20866397706125644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:47:51,866] Trial 128 finished with value: 0.19621140702702683 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:49:10,883] Trial 129 finished with value: 0.19634592341889917 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 00:51:36,204] Trial 131 finished with value: 0.19654335366104972 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:03:02,797] Trial 132 finished with value: 0.19618102244367436 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:06:48,072] Trial 133 finished with value: 0.19658846809372302 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:12:05,388] Trial 134 finished with value: 0.19573520033056152 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:12:43,111] Trial 136 finished with value: 0.19551334162808973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:12:57,988] Trial 135 finished with value: 0.19528142940830168 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:12:58,918] Trial 154 finished with value: 0.3128034773134087 and parameters: {'model_name': 'GAIN', 'batch_size': 350, 'hint_rate': 0.2715066627022802, 'alpha': 1, 'iterations': 12, 'learning_rate': 0.0006105784698447487, 'p_miss': 0.2091592729672052}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:13:06,781] Trial 153 finished with value: 0.20566730183205523 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12082, 'weights': 'uniform'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:13:27,084] Trial 155 finished with value: 0.20566725670117095 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 12078, 'weights': 'uniform'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:14:52,782] Trial 137 finished with value: 0.1946333429398625 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:17:43,663] Trial 138 finished with value: 0.19525304046937256 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:29:06,615] Trial 139 finished with value: 0.19476956190860578 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 109 with value: 0.19401000175178196.
running
[I 2024-10-17 01:30:11,956] Trial 140 finished with value: 0.19357790881946174 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:37:03,596] Trial 141 finished with value: 0.19486678832507803 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:42:10,475] Trial 142 finished with value: 0.1954724743665322 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:42:10,754] Trial 144 finished with value: 0.19510060637012672 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:47:53,850] Trial 146 finished with value: 0.19466230715610158 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:53:13,341] Trial 147 finished with value: 0.194534631483558 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:54:39,845] Trial 148 finished with value: 0.19467784716749273 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 01:57:10,647] Trial 149 finished with value: 0.1944431349414022 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:08:42,004] Trial 150 finished with value: 0.19413701548172463 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:12:29,769] Trial 151 finished with value: 0.1946237776170094 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:16:42,780] Trial 156 finished with value: 0.19407415985999768 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:17:38,575] Trial 152 finished with value: 0.1939845912577809 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:19:09,127] Trial 157 finished with value: 0.19392103365360966 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:20:03,921] Trial 158 finished with value: 0.19435198675413723 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:23:16,970] Trial 159 finished with value: 0.19363670827257864 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:34:35,585] Trial 160 finished with value: 0.19443910339172335 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:35:30,855] Trial 161 finished with value: 0.19359149600081166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:42:45,313] Trial 162 finished with value: 0.1948985793221792 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:47:38,668] Trial 164 finished with value: 0.19429344146545413 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:48:06,002] Trial 163 finished with value: 0.19438918394358845 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:53:55,021] Trial 165 finished with value: 0.19387752554947366 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:53:55,306] Trial 181 finished with value: 0.3180253737971294 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:58:40,961] Trial 166 finished with value: 0.19419552914602298 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 02:59:25,097] Trial 183 finished with value: 0.2713559455116454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:00:27,644] Trial 167 finished with value: 0.19409272730026775 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:03:08,565] Trial 168 finished with value: 0.19424748477780512 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:14:41,831] Trial 169 finished with value: 0.193965560662276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:18:29,251] Trial 170 finished with value: 0.19469783815881983 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:21:20,691] Trial 171 finished with value: 0.19414174743076285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:23:23,617] Trial 172 finished with value: 0.1936968001138318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:25:10,779] Trial 173 finished with value: 0.1937345955825588 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:25:30,689] Trial 191 finished with value: 0.20795916055348976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:25:53,092] Trial 174 finished with value: 0.19461873566523455 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:29:08,646] Trial 175 finished with value: 0.194098329640837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:39:51,023] Trial 176 finished with value: 0.1944568230757309 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:39:51,807] Trial 195 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.9403265202213786, 'alpha': 73, 'iterations': 104, 'learning_rate': 0.004275272355711707, 'p_miss': 0.013999954491195316}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:41:15,822] Trial 177 finished with value: 0.19449975883198367 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:48:44,278] Trial 178 finished with value: 0.19366176017625011 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:53:27,032] Trial 179 finished with value: 0.1939725822027622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
running
[I 2024-10-17 03:54:00,475] Trial 180 finished with value: 0.19372598320258586 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:00:08,188] Trial 182 finished with value: 0.19444400275407056 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:04:55,547] Trial 184 finished with value: 0.19387560822298364 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:05:45,952] Trial 185 finished with value: 0.19368743908522343 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:08:21,554] Trial 186 finished with value: 0.19412008181585666 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:19:58,673] Trial 187 finished with value: 0.1936838119081084 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:23:31,241] Trial 188 finished with value: 0.19415597672328075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:25:31,742] Trial 189 finished with value: 0.1943549212892389 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:28:07,077] Trial 190 finished with value: 0.19444638265644673 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:30:26,970] Trial 192 finished with value: 0.19444707189352106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:30:39,319] Trial 193 finished with value: 0.1938771549935731 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:33:55,064] Trial 194 finished with value: 0.19448112686851265 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:43:49,960] Trial 196 finished with value: 0.19509837986207976 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:45:17,849] Trial 197 finished with value: 0.19368660708722096 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:52:34,238] Trial 198 finished with value: 0.1944458295182275 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 140 with value: 0.19357790881946174.
[I 2024-10-17 04:56:40,193] Trial 199 finished with value: 0.19343421732053928 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 199 with value: 0.19343421732053928.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0.19343421732053928
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0ca0> 

Generation:  1
Best f1_score score: 0.7277012669845406
Generation:   4%|▍         | 1/25 [10:03<4:01:25, 603.56s/it]Generation:  2
Best f1_score score: 0.7277012669845406
Generation:   8%|▊         | 2/25 [14:35<2:36:32, 408.38s/it]Generation:  3
Best f1_score score: 0.7277012669845406
Generation:  12%|█▏        | 3/25 [15:30<1:30:34, 247.03s/it]Generation:  4
Best f1_score score: 0.7289120685468766
Generation:  16%|█▌        | 4/25 [17:34<1:09:28, 198.52s/it]Generation:  5
Best f1_score score: 0.7289635610930606
Generation:  20%|██        | 5/25 [20:05<1:00:26, 181.34s/it]Generation:  6
Best f1_score score: 0.7289635610930606
Generation:  24%|██▍       | 6/25 [23:38<1:00:50, 192.11s/it]Generation:  7
Best f1_score score: 0.7306323102597225
Generation:  28%|██▊       | 7/25 [27:04<59:00, 196.69s/it]  Generation:  8
Best f1_score score: 0.7306323102597225
Generation:  32%|███▏      | 8/25 [33:26<1:12:26, 255.67s/it]Generation:  9
Best f1_score score: 0.7306323102597225
Generation:  36%|███▌      | 9/25 [38:39<1:12:58, 273.65s/it]Generation:  10
Best f1_score score: 0.7306323102597225
Generation:  40%|████      | 10/25 [41:56<1:02:30, 250.02s/it]Generation:  11
Best f1_score score: 0.7306323102597225
Generation:  44%|████▍     | 11/25 [45:20<54:59, 235.71s/it]  Generation:  12
Best f1_score score: 0.7306323102597225
Generation:  48%|████▊     | 12/25 [48:55<49:44, 229.57s/it]Generation:  13
Best f1_score score: 0.7326902441817911
Generation:  52%|█████▏    | 13/25 [52:44<45:54, 229.52s/it]Generation:  14
Best f1_score score: 0.7326902441817911
Generation:  56%|█████▌    | 14/25 [58:33<48:38, 265.36s/it]Generation:  15
Best f1_score score: 0.7326902441817911
Generation:  60%|██████    | 15/25 [1:00:32<36:52, 221.25s/it]Generation:  16
Best f1_score score: 0.7326902441817911
Generation:  64%|██████▍   | 16/25 [1:05:06<35:34, 237.14s/it]Generation:  17
Best f1_score score: 0.7326902441817911
Generation:  68%|██████▊   | 17/25 [1:07:35<28:06, 210.81s/it]Generation:  18
Best f1_score score: 0.7326902441817911
Generation:  72%|███████▏  | 18/25 [1:11:23<25:11, 215.86s/it]Generation:  19
Best f1_score score: 0.7326902441817911
Generation:  76%|███████▌  | 19/25 [1:13:44<19:20, 193.50s/it]Generation:  20
Best f1_score score: 0.7326902441817911
Generation:  80%|████████  | 20/25 [1:16:35<15:33, 186.74s/it]Generation:  21
Best f1_score score: 0.7326902441817911
Generation:  84%|████████▍ | 21/25 [1:19:12<11:51, 177.85s/it]Generation:  22
Best f1_score score: 0.7326902441817911
Generation:  88%|████████▊ | 22/25 [1:24:02<10:34, 211.50s/it]Generation:  23
Best f1_score score: 0.7326902441817911
Generation:  92%|█████████▏| 23/25 [1:27:11<06:49, 204.55s/it]Generation:  24
Best f1_score score: 0.7326902441817911
Generation:  96%|█████████▌| 24/25 [1:30:51<03:29, 209.37s/it]Generation:  25
Best f1_score score: 0.7326902441817911
Generation: 100%|██████████| 25/25 [1:33:49<00:00, 199.95s/it]Generation: 100%|██████████| 25/25 [1:33:53<00:00, 225.35s/it]
2024-10-17 06:43:55,212 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:42149' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-b74dc7c66dec5ac2b4700b93e84a6dd3', 'ndarray-28171ee619343a575278de6680340132'} (stimulus_id='handle-worker-cleanup-1729172635.2122152')
Fitted
Pipeline(steps=[('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features=0.79361239436,
                                        min_samples_leaf=5,
                                        min_samples_split=15,
                                        n_estimators=128))])
score start
train score: {'auroc': 0.970567946859977, 'accuracy': 0.9042180473944109, 'balanced_accuracy': 0.9055302479445324, 'logloss': 0.3143828922692256, 'f1': 0.9026232259467781}
original test score: {'auroc': 0.9258165514876925, 'accuracy': 0.8504910073926956, 'balanced_accuracy': 0.8465846460812904, 'logloss': 0.36739362011688476, 'f1': 0.8468788242139478}
imputed test score: {'auroc': 0.809985638341343, 'accuracy': 0.7326492331457575, 'balanced_accuracy': 0.7278728051379058, 'logloss': 0.5238960645307329, 'f1': 0.727190503642829}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1570> 
 Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_base.py", line 190, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a14e0> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 271, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 825, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a5330> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0b20> 
 Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 727, in predict
    pred = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 788, in decision_function
    X = self._check_X(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0d90> 

Generation:  1
Best f1_score score: 0.6925572316953403
Generation:   4%|▍         | 1/25 [10:03<4:01:15, 603.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fa7a0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474717a00> 
 Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 382, in predict
    scores = self.decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 760, in decision_function
    return super().decision_function(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py", line 363, in decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe1a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f25300> 

Generation:  2
Best f1_score score: 0.718458239426181
Generation:   8%|▊         | 2/25 [20:08<3:51:40, 604.38s/it]Generation:  3
Best f1_score score: 0.7202952020943177
Generation:  12%|█▏        | 3/25 [27:59<3:19:18, 543.55s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554656b9570> 

Generation:  4
Best f1_score score: 0.7283629272492703
Generation:  16%|█▌        | 4/25 [38:05<3:18:48, 568.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546557ae00> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f27460> 

Generation:  5
Best f1_score score: 0.7283629272492703
Generation:  20%|██        | 5/25 [48:10<3:13:49, 581.48s/it]Generation:  6
Best f1_score score: 0.7339935107007717
Generation:  24%|██▍       | 6/25 [55:33<2:49:15, 534.51s/it]Generation:  7
Best f1_score score: 0.734700620564334
Generation:  28%|██▊       | 7/25 [1:02:56<2:31:21, 504.53s/it]Generation:  8
Best f1_score score: 0.734700620564334
Generation:  32%|███▏      | 8/25 [1:05:23<1:50:40, 390.60s/it]Generation:  9
Best f1_score score: 0.734700620564334
Generation:  36%|███▌      | 9/25 [1:06:41<1:18:07, 292.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f324d0> 

Generation:  10
Best f1_score score: 0.734700620564334
Generation:  40%|████      | 10/25 [1:16:48<1:37:28, 389.90s/it]Generation:  11
Best f1_score score: 0.734700620564334
Generation:  44%|████▍     | 11/25 [1:24:21<1:35:29, 409.27s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464dc7700> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1552f171f610> 

Generation:  12
Best f1_score score: 0.735499193244893
Generation:  48%|████▊     | 12/25 [1:34:30<1:41:48, 469.87s/it]Generation:  13
Best f1_score score: 0.735499193244893
Generation:  52%|█████▏    | 13/25 [1:42:16<1:33:47, 468.95s/it]Generation:  14
Best f1_score score: 0.735499193244893
Generation:  56%|█████▌    | 14/25 [1:49:39<1:24:29, 460.90s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467de39a0> 

Generation:  15
Best f1_score score: 0.735499193244893
Generation:  60%|██████    | 15/25 [1:59:43<1:24:02, 504.25s/it]Generation:  16
Best f1_score score: 0.735499193244893
Generation:  64%|██████▍   | 16/25 [2:01:18<57:08, 380.90s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554651894e0> 

Generation:  17
Best f1_score score: 0.7369096569481842
Generation:  68%|██████▊   | 17/25 [2:11:27<59:55, 449.42s/it]Generation:  18
Best f1_score score: 0.7369096569481842
Generation:  72%|███████▏  | 18/25 [2:14:03<42:10, 361.47s/it]Generation:  19
Best f1_score score: 0.7369096569481842
Generation:  76%|███████▌  | 19/25 [2:21:38<38:56, 389.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547465bfd0> 

Generation:  20
Best f1_score score: 0.7369096569481842
Generation:  80%|████████  | 20/25 [2:31:42<37:49, 453.97s/it]Generation:  21
Best f1_score score: 0.7369096569481842
Generation:  84%|████████▍ | 21/25 [2:32:03<21:35, 323.98s/it]Generation:  22
Best f1_score score: 0.7369096569481842
Generation:  88%|████████▊ | 22/25 [2:39:43<18:13, 364.60s/it]Generation:  23
Best f1_score score: 0.7381788263510798
Generation:  92%|█████████▏| 23/25 [2:47:59<13:28, 404.21s/it]Generation:  24
Best f1_score score: 0.7381788263510798
Generation:  96%|█████████▌| 24/25 [2:55:43<07:02, 422.01s/it]Generation:  25
Best f1_score score: 0.7382187114780454
Generation: 100%|██████████| 25/25 [2:57:17<00:00, 323.62s/it]Generation: 100%|██████████| 25/25 [2:57:17<00:00, 425.49s/it]
2024-10-17 09:41:44,681 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41443' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-efd39e44c882b8541f83535047adc061', 'ndarray-b74dc7c66dec5ac2b4700b93e84a6dd3'} (stimulus_id='handle-worker-cleanup-1729183304.6810403')
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,671 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,673 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,673 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,673 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,687 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-10-17 09:41:48,688 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('xgbclassifier',
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=0.0174432522571,
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0778738818188, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=13,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1, nthread=1,
                               num_parallel_tree=None, ...))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9538505997267289, 'accuracy': 0.8719688819001904, 'balanced_accuracy': 0.8642081757418215, 'logloss': 0.3236880710626295, 'f1': 0.8675900011445331}
test score: {'auroc': 0.8219538284135599, 'accuracy': 0.7412556548604214, 'balanced_accuracy': 0.7271086273603052, 'logloss': 0.5034803193890786, 'f1': 0.7300816116735437}
original test score: {'auroc': 0.9249266469065126, 'accuracy': 0.8444223766964581, 'balanced_accuracy': 0.8388590504362317, 'logloss': 0.3437576924357297, 'f1': 0.8401539475933135}
score end
151
lvl
0.5
type
MNAR
num_run
3
class_full
finished
all finished
full run takes
18.132384198175536
hours
DONE
