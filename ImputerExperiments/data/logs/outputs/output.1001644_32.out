Run: 32
/cm/local/apps/slurm/var/spool/job1001644/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/137/137.pkl
working on 
../data/c/137/class_full_MAR_0.5_2
3.4674253463745117
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-10-15 00:34:54,027] A new study created in memory with name: no-name-06aa3a34-5921-45eb-9e01-11611fd5bc75
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-10-15 00:34:54,762] Trial 9 finished with value: 0.5321887136050101 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 9 with value: 0.5321887136050101.
[I 2024-10-15 00:34:54,912] Trial 0 finished with value: 0.4649479650732653 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.4649479650732653.
running
running
[I 2024-10-15 00:34:55,337] Trial 7 finished with value: 0.5321887136050101 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.4649479650732653.
running
[I 2024-10-15 00:34:56,029] Trial 18 finished with value: 0.4649479650732653 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.4649479650732653.
running
[I 2024-10-15 00:34:56,613] Trial 19 finished with value: 0.5321887136050101 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.4649479650732653.
running
[I 2024-10-15 00:35:08,469] Trial 12 finished with value: 0.3646055776549782 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 1, 'imputation_order': 'arabic'}. Best is trial 12 with value: 0.3646055776549782.
running
[I 2024-10-15 00:35:11,605] Trial 13 finished with value: 0.35742214840389164 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 13 with value: 0.35742214840389164.
running
[I 2024-10-15 00:35:14,791] Trial 4 finished with value: 0.3583173594638962 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2196, 'weights': 'distance'}. Best is trial 13 with value: 0.35742214840389164.
running
[I 2024-10-15 00:35:16,170] Trial 8 finished with value: 0.3695284648973275 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 26520, 'weights': 'uniform'}. Best is trial 13 with value: 0.35742214840389164.
running
[I 2024-10-15 00:35:16,374] Trial 22 finished with value: 0.34196764332928453 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0003275744559779269, 'p_miss': 0.09567063593252599}. Best is trial 22 with value: 0.34196764332928453.
running
[I 2024-10-15 00:35:17,336] Trial 6 finished with value: 0.3412848806470087 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 1, 'learning_rate': 0.00259135067802558, 'p_miss': 0.16105074628027394}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:18,103] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8703771307255623, 'alpha': 15, 'iterations': 2, 'learning_rate': 0.0329491446821548, 'p_miss': 0.29297487957389534}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:18,381] Trial 3 finished with value: 0.5834345127100194 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.37003636826889086, 'alpha': 77, 'iterations': 1, 'learning_rate': 0.052024230785539166, 'p_miss': 0.1070215844248685}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:18,918] Trial 20 finished with value: 0.35343189791989615 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6862, 'weights': 'uniform'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:19,514] Trial 25 finished with value: 0.34283495366893796 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0002701935798105382, 'p_miss': 0.08533297815694843}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:19,797] Trial 2 finished with value: 0.5814076145861795 and parameters: {'model_name': 'GAIN', 'batch_size': 101, 'hint_rate': 0.6052788671137774, 'alpha': 64, 'iterations': 2, 'learning_rate': 0.028649806517500907, 'p_miss': 0.16785387908115915}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:20,173] Trial 16 finished with value: 0.5811070076050528 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.12108738276256026, 'alpha': 31, 'iterations': 2, 'learning_rate': 0.0013805547440456792, 'p_miss': 0.18653065669240335}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:21,106] Trial 24 finished with value: 0.34396499578710316 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0002868657375765656, 'p_miss': 0.08623021818457732}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:22,303] Trial 26 finished with value: 0.3421055720051182 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 1, 'learning_rate': 0.0007518892132635568, 'p_miss': 0.1262714951019258}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:23,058] Trial 27 finished with value: 0.3426342406653117 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 1, 'learning_rate': 0.00027056388919317263, 'p_miss': 0.08682785912769658}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:24,118] Trial 14 finished with value: 0.5788400451534594 and parameters: {'model_name': 'GAIN', 'batch_size': 124, 'hint_rate': 0.2435673786651796, 'alpha': 47, 'iterations': 9, 'learning_rate': 0.06175457502905542, 'p_miss': 0.2177718648682086}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:24,500] Trial 1 finished with value: 0.5873638081903861 and parameters: {'model_name': 'GAIN', 'batch_size': 751, 'hint_rate': 0.7705036698064963, 'alpha': 33, 'iterations': 6, 'learning_rate': 0.002180411380966215, 'p_miss': 0.010171947110011802}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:29,107] Trial 21 finished with value: 0.3695284648973275 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28805, 'weights': 'uniform'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:35:57,115] Trial 10 finished with value: 0.3764204598024149 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:36:10,469] Trial 15 finished with value: 0.3708109224729511 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:36:13,288] Trial 11 finished with value: 0.45892886480204853 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 6, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:38:56,116] Trial 35 finished with value: 0.36992330367406884 and parameters: {'model_name': 'VAE', 'batch_size': 462, 'iterations': 44, 'learning_rate': 0.003144699194075757, 'p_miss': 0.021153604762204514}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:40:40,961] Trial 34 finished with value: 0.37130336696135 and parameters: {'model_name': 'VAE', 'batch_size': 901, 'iterations': 49, 'learning_rate': 0.004700153315770628, 'p_miss': 0.03523710977675728}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:43:18,298] Trial 33 finished with value: 0.3711817659871198 and parameters: {'model_name': 'VAE', 'batch_size': 894, 'iterations': 80, 'learning_rate': 0.002443257543223426, 'p_miss': 0.0111255728767439}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:50:12,805] Trial 32 finished with value: 0.37217234069288646 and parameters: {'model_name': 'VAE', 'batch_size': 730, 'iterations': 156, 'learning_rate': 0.0017366391252293988, 'p_miss': 0.013173862250597287}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:50:52,719] Trial 45 finished with value: 0.3437662461197848 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 9, 'learning_rate': 0.0006614489993351018, 'p_miss': 0.12640764730720758}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 00:56:31,777] Trial 36 finished with value: 0.3736074307091385 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 378, 'learning_rate': 0.0018184810641103158, 'p_miss': 0.021871606323205006}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:03:17,813] Trial 31 finished with value: 0.3717009222232677 and parameters: {'model_name': 'VAE', 'batch_size': 967, 'iterations': 415, 'learning_rate': 0.0008087838843991022, 'p_miss': 0.18501472073479175}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:09:11,809] Trial 23 finished with value: 0.3572103149206994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:18:25,137] Trial 17 finished with value: 0.37302833199920904 and parameters: {'model_name': 'VAE', 'batch_size': 489, 'iterations': 659, 'learning_rate': 0.0013505886758766429, 'p_miss': 0.2948439789914518}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:19:44,590] Trial 37 finished with value: 0.37416541123514807 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 777, 'learning_rate': 0.0011224565986083024, 'p_miss': 0.13638404534146858}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:41:49,365] Trial 30 finished with value: 0.3728811515928391 and parameters: {'model_name': 'VAE', 'batch_size': 225, 'iterations': 1185, 'learning_rate': 0.0005695225891640834, 'p_miss': 0.19878886738424995}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:42:03,779] Trial 52 finished with value: 0.3446287483825995 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 4, 'learning_rate': 0.00014432542285619006, 'p_miss': 0.0697744910711097}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:43:10,374] Trial 53 finished with value: 0.3650224294659098 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 21, 'learning_rate': 0.0072091252095851845, 'p_miss': 0.1360267551463074}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 01:47:25,764] Trial 40 finished with value: 0.3745202542707224 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 1136, 'learning_rate': 0.0008921921505874443, 'p_miss': 0.13354657458097402}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:07:48,041] Trial 38 finished with value: 0.3752310233048596 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 1753, 'learning_rate': 0.0010500858738899815, 'p_miss': 0.13818124657855976}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:07:54,348] Trial 56 finished with value: 0.34298138025340696 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.00029678862507185997, 'p_miss': 0.07251273173588146}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:31:48,728] Trial 39 finished with value: 0.37137979872650717 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 2204, 'learning_rate': 0.0009072862895694409, 'p_miss': 0.13802205814553187}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:43:42,599] Trial 28 finished with value: 0.3730207456704212 and parameters: {'model_name': 'VAE', 'batch_size': 238, 'iterations': 2156, 'learning_rate': 0.00022181669891394463, 'p_miss': 0.09950303061116483}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:43:52,158] Trial 59 finished with value: 0.3420330464856177 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.0004391791543729465, 'p_miss': 0.060880869843539284}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:44:01,725] Trial 60 finished with value: 0.5849357002571637 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.5396120257682883, 'alpha': 91, 'iterations': 3, 'learning_rate': 0.0004535357504733206, 'p_miss': 0.0555529142405074}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:44:18,684] Trial 61 finished with value: 0.35841653665352957 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 14953, 'weights': 'distance'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:54:41,256] Trial 41 finished with value: 0.3719329601215702 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 2392, 'learning_rate': 0.000992321346425609, 'p_miss': 0.1304567920260717}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:54:42,011] Trial 63 finished with value: 0.3695284648973275 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:55:07,297] Trial 64 finished with value: 0.3453305316204467 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 6, 'learning_rate': 0.0001400758130049491, 'p_miss': 0.11014532834551222}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:55:15,545] Trial 65 finished with value: 0.5819156880050047 and parameters: {'model_name': 'GAIN', 'batch_size': 71, 'hint_rate': 0.01870666163318213, 'alpha': 8, 'iterations': 2, 'learning_rate': 0.0004351011025090241, 'p_miss': 0.15862626152965825}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:55:21,519] Trial 66 finished with value: 0.34420645341009753 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00023578998762200122, 'p_miss': 0.0515012186387895}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:55:26,890] Trial 67 finished with value: 0.3448848390811353 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00011013163543627297, 'p_miss': 0.08757940630689934}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 02:55:33,585] Trial 68 finished with value: 0.3415805691992743 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.010228953775842192, 'p_miss': 0.11039745020871794}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:15:49,368] Trial 44 finished with value: 0.3748837909814636 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 2605, 'learning_rate': 0.0007424457094093967, 'p_miss': 0.13517590683738823}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:16:06,208] Trial 70 finished with value: 0.34775441676735863 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.016162821711148852, 'p_miss': 0.11433126525922968}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:16:06,857] Trial 71 finished with value: 0.5880046006380537 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:16:23,948] Trial 72 finished with value: 0.35844816668469814 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17418, 'weights': 'distance'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:38:17,748] Trial 73 finished with value: 0.3529094035420634 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:40:02,028] Trial 51 finished with value: 0.3732514246681578 and parameters: {'model_name': 'VAE', 'batch_size': 85, 'iterations': 2723, 'learning_rate': 0.00011308220017253348, 'p_miss': 0.06343025171416128}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:40:09,547] Trial 75 finished with value: 0.34377149535646245 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 2, 'learning_rate': 0.008832891654280906, 'p_miss': 0.09656250113292267}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:40:15,005] Trial 76 finished with value: 0.3435045703006404 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0003716263689338045, 'p_miss': 0.0769224404324229}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 03:40:22,514] Trial 77 finished with value: 0.3444100821415882 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 2, 'learning_rate': 0.00021349324764944648, 'p_miss': 0.08746894072480363}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:24:53,313] Trial 50 finished with value: 0.37530395766048397 and parameters: {'model_name': 'VAE', 'batch_size': 75, 'iterations': 3124, 'learning_rate': 0.00011001218480062484, 'p_miss': 0.13677989153928874}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:25:00,189] Trial 79 finished with value: 0.3423972512870872 and parameters: {'model_name': 'VAE', 'batch_size': 125, 'iterations': 1, 'learning_rate': 0.0003362462782616325, 'p_miss': 0.11420174554153384}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:35:23,759] Trial 46 finished with value: 0.37519441827596556 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 4372, 'learning_rate': 0.00012763076666366075, 'p_miss': 0.12210448837698812}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:35:34,826] Trial 81 finished with value: 0.583154813139154 and parameters: {'model_name': 'GAIN', 'batch_size': 130, 'hint_rate': 0.9558454836136967, 'alpha': 100, 'iterations': 4, 'learning_rate': 0.027301010884413064, 'p_miss': 0.15386409770958331}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:35:54,586] Trial 82 finished with value: 0.34728743715715316 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:36:00,393] Trial 83 finished with value: 0.34430010540940914 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 1, 'learning_rate': 0.00046892935279876956, 'p_miss': 0.09762925404699735}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:36:31,057] Trial 84 finished with value: 0.34450847586079736 and parameters: {'model_name': 'VAE', 'batch_size': 146, 'iterations': 9, 'learning_rate': 0.0001841392008342253, 'p_miss': 0.27697834115947384}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:36:31,791] Trial 85 finished with value: 0.3695284648973275 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:36:40,863] Trial 86 finished with value: 0.34232418623068434 and parameters: {'model_name': 'VAE', 'batch_size': 235, 'iterations': 2, 'learning_rate': 0.00028724872916542496, 'p_miss': 0.10845988395625018}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:36:53,369] Trial 87 finished with value: 0.3459283501352637 and parameters: {'model_name': 'VAE', 'batch_size': 254, 'iterations': 3, 'learning_rate': 0.0003302421916175629, 'p_miss': 0.10854858616001584}. Best is trial 6 with value: 0.3412848806470087.
running
[I 2024-10-15 04:37:03,060] Trial 88 finished with value: 0.34085822836005997 and parameters: {'model_name': 'VAE', 'batch_size': 343, 'iterations': 2, 'learning_rate': 0.0005695272364193025, 'p_miss': 0.15479719344616957}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:37:12,810] Trial 89 finished with value: 0.34179076933525565 and parameters: {'model_name': 'VAE', 'batch_size': 371, 'iterations': 2, 'learning_rate': 0.0005681387350758639, 'p_miss': 0.1762747899460339}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:37:24,202] Trial 90 finished with value: 0.34269832871224754 and parameters: {'model_name': 'VAE', 'batch_size': 432, 'iterations': 2, 'learning_rate': 0.0005719382397585797, 'p_miss': 0.17899952949305756}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:37:42,406] Trial 91 finished with value: 0.3584526351299641 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17811, 'weights': 'distance'}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:38:18,749] Trial 42 finished with value: 0.3725020571681452 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 4835, 'learning_rate': 0.0010083278633882125, 'p_miss': 0.13342956277654996}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:38:30,726] Trial 93 finished with value: 0.34809919148590235 and parameters: {'model_name': 'VAE', 'batch_size': 321, 'iterations': 2, 'learning_rate': 0.0005939493688691106, 'p_miss': 0.15932694672528583}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:39:18,441] Trial 94 finished with value: 0.34292301798710473 and parameters: {'model_name': 'VAE', 'batch_size': 600, 'iterations': 5, 'learning_rate': 0.003603160015177324, 'p_miss': 0.20192620279396206}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:39:37,266] Trial 95 finished with value: 0.38297192528664037 and parameters: {'model_name': 'VAE', 'batch_size': 192, 'iterations': 3, 'learning_rate': 0.08915983637607455, 'p_miss': 0.17049682174101813}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:39:46,153] Trial 96 finished with value: 0.34414499666400095 and parameters: {'model_name': 'VAE', 'batch_size': 174, 'iterations': 2, 'learning_rate': 0.000397733462197759, 'p_miss': 0.14875769458583893}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:39:52,837] Trial 97 finished with value: 0.34281425943877863 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 1, 'learning_rate': 0.00030548876523662453, 'p_miss': 0.11667491265829673}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:40:35,665] Trial 98 finished with value: 0.3433058110287788 and parameters: {'model_name': 'VAE', 'batch_size': 114, 'iterations': 12, 'learning_rate': 0.0014094148004065773, 'p_miss': 0.19719828760028105}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:40:44,576] Trial 99 finished with value: 0.34387604536977723 and parameters: {'model_name': 'VAE', 'batch_size': 283, 'iterations': 2, 'learning_rate': 0.0004828681859855324, 'p_miss': 0.10261766928697484}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:41:00,605] Trial 100 finished with value: 0.3429219211482466 and parameters: {'model_name': 'VAE', 'batch_size': 349, 'iterations': 3, 'learning_rate': 0.00017297150193816243, 'p_miss': 0.14702152199557794}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 04:41:58,916] Trial 101 finished with value: 0.36043073803234243 and parameters: {'model_name': 'VAE', 'batch_size': 618, 'iterations': 4, 'learning_rate': 0.008280485035067387, 'p_miss': 0.17512186979865607}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:16:47,214] Trial 102 finished with value: 0.36407500860698083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:17:10,311] Trial 103 finished with value: 0.3425513535219818 and parameters: {'model_name': 'VAE', 'batch_size': 209, 'iterations': 6, 'learning_rate': 0.0007000803310970957, 'p_miss': 0.12226737628633216}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:17:15,020] Trial 104 finished with value: 0.34150571607376345 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.005392475595348323, 'p_miss': 0.16321939923602702}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:17:23,763] Trial 105 finished with value: 0.5847443733015563 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.7246986330142631, 'alpha': 57, 'iterations': 2, 'learning_rate': 0.005692321053151815, 'p_miss': 0.16193291252544284}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:17:28,781] Trial 106 finished with value: 0.3426427516426823 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.003995688429181663, 'p_miss': 0.19327962461950488}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:17:34,862] Trial 107 finished with value: 0.3411956475289938 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.00025445076251963964, 'p_miss': 0.20867777736465487}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:21:19,309] Trial 29 finished with value: 0.3725819233909131 and parameters: {'model_name': 'VAE', 'batch_size': 249, 'iterations': 6067, 'learning_rate': 0.00019989547655161602, 'p_miss': 0.11266508102350521}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:21:30,998] Trial 109 finished with value: 0.3433042656749338 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 3, 'learning_rate': 0.010874839915779857, 'p_miss': 0.22465053581528935}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:21:37,061] Trial 110 finished with value: 0.3437311018046623 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 1, 'learning_rate': 0.01314374135361388, 'p_miss': 0.14561627779878097}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:33:37,845] Trial 111 finished with value: 0.39442439317397493 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 209, 'learning_rate': 0.0028368321394041376, 'p_miss': 0.2130652383558091}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:33:52,284] Trial 112 finished with value: 0.34490979774305847 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 4, 'learning_rate': 0.00024682181323442423, 'p_miss': 0.18672144071904478}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:33:52,848] Trial 113 finished with value: 0.5880046006380537 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:34:05,814] Trial 114 finished with value: 0.35623142579360156 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 10253, 'weights': 'uniform'}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:34:53,103] Trial 115 finished with value: 0.3441254148532745 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 16, 'learning_rate': 0.002342713154714737, 'p_miss': 0.24391915626485983}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:34:58,927] Trial 116 finished with value: 0.34349716681465764 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 1, 'learning_rate': 0.0003449933874740365, 'p_miss': 0.16331085481395627}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:35:09,581] Trial 117 finished with value: 0.3423744942117921 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 2, 'learning_rate': 0.00027367583628751246, 'p_miss': 0.03710473592182216}. Best is trial 88 with value: 0.34085822836005997.
running
[I 2024-10-15 05:35:18,001] Trial 118 finished with value: 0.34043947124716817 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 2, 'learning_rate': 0.0002522988815644608, 'p_miss': 0.05862697642850874}. Best is trial 118 with value: 0.34043947124716817.
running
[I 2024-10-15 05:35:26,347] Trial 119 finished with value: 0.34299647173595793 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 2, 'learning_rate': 0.0005129785886797437, 'p_miss': 0.07775695016490128}. Best is trial 118 with value: 0.34043947124716817.
running
[I 2024-10-15 05:35:38,738] Trial 120 finished with value: 0.3399764158656495 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.005883518065900919, 'p_miss': 0.04348792197651151}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:36:02,610] Trial 121 finished with value: 0.3554621672423301 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 5, 'learning_rate': 0.01647469980426808, 'p_miss': 0.17695278250934432}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:36:14,144] Trial 122 finished with value: 0.3460312900827847 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 3, 'learning_rate': 0.005417980809748976, 'p_miss': 0.06529602287283959}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:41:45,410] Trial 123 finished with value: 0.37525441585649005 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 103, 'learning_rate': 0.006450484104124497, 'p_miss': 0.03971228938881404}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:42:08,400] Trial 124 finished with value: 0.34179133488536717 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 6, 'learning_rate': 0.0047691350232197125, 'p_miss': 0.02800724232359449}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:42:41,625] Trial 125 finished with value: 0.3798540229630459 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 3, 'imputation_order': 'roman'}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:43:02,360] Trial 126 finished with value: 0.3421598051410615 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 7, 'learning_rate': 0.004210437353387399, 'p_miss': 0.027741514748312306}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:45:14,353] Trial 127 finished with value: 0.36892669619132906 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 39, 'learning_rate': 0.00473009871991166, 'p_miss': 0.05000287027244314}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:45:28,630] Trial 128 finished with value: 0.3408033284503761 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.00310723515358133, 'p_miss': 0.0418758148607734}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:45:47,510] Trial 129 finished with value: 0.3477641562396793 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5, 'learning_rate': 0.0019209930721786107, 'p_miss': 0.04486444884853977}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:46:00,532] Trial 130 finished with value: 0.3436837056895918 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.003459981895988098, 'p_miss': 0.057996919299026437}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:46:26,137] Trial 131 finished with value: 0.34323737341356514 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 7, 'learning_rate': 0.007064302151366502, 'p_miss': 0.021524775584864597}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:46:34,025] Trial 132 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.3567407663861997, 'alpha': 76, 'iterations': 3, 'learning_rate': 0.009183902115892028, 'p_miss': 0.03427566333700237}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:46:50,386] Trial 133 finished with value: 0.3413114413940543 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.0025394983113240267, 'p_miss': 0.045636887192337106}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:47:31,328] Trial 134 finished with value: 0.3411734609651931 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 13, 'learning_rate': 0.003001250863427423, 'p_miss': 0.026863991914881476}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:48:01,462] Trial 135 finished with value: 0.34490684220637 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 9, 'learning_rate': 0.0027769432181510155, 'p_miss': 0.029829355889866148}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:49:16,045] Trial 136 finished with value: 0.34158306125832316 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 20, 'learning_rate': 0.002133405407088644, 'p_miss': 0.015194206806262394}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:50:11,008] Trial 137 finished with value: 0.34106925998077886 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 15, 'learning_rate': 0.0014314044729295755, 'p_miss': 0.013627050673258145}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:51:22,953] Trial 138 finished with value: 0.3453856598030182 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 19, 'learning_rate': 0.001522655935981065, 'p_miss': 0.014556864053990252}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:52:58,644] Trial 139 finished with value: 0.34342500403548865 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 28, 'learning_rate': 0.0018531739101125327, 'p_miss': 0.015840760937733345}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:53:38,192] Trial 140 finished with value: 0.34059488149245737 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 12, 'learning_rate': 0.0026441504884378397, 'p_miss': 0.019743936284826402}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:53:39,178] Trial 141 finished with value: 0.3695284648973275 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:54:27,719] Trial 142 finished with value: 0.3420705691755061 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 12, 'learning_rate': 0.0025271262410603867, 'p_miss': 0.011318924560674806}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:54:42,386] Trial 143 finished with value: 0.3690223766257562 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 23632, 'weights': 'uniform'}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:56:31,314] Trial 144 finished with value: 0.34456764665947726 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 28, 'learning_rate': 0.0020935683452869623, 'p_miss': 0.04525100681070457}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:57:51,269] Trial 145 finished with value: 0.34224264836814156 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 26, 'learning_rate': 0.001188137761751895, 'p_miss': 0.022733477061339026}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:58:37,496] Trial 146 finished with value: 0.3413533279522948 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 15, 'learning_rate': 0.002985999566906481, 'p_miss': 0.04336783670907306}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 05:59:22,902] Trial 147 finished with value: 0.34228125831922923 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 13, 'learning_rate': 0.0030718370830941, 'p_miss': 0.04272435941824948}. Best is trial 120 with value: 0.3399764158656495.
running
[I 2024-10-15 06:00:07,433] Trial 148 finished with value: 0.3399367323092276 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 15, 'learning_rate': 0.001645252854550758, 'p_miss': 0.051055915382271194}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:00:53,865] Trial 149 finished with value: 0.3414483838157622 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 14, 'learning_rate': 0.0016109725906269896, 'p_miss': 0.05007257431650081}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:01:28,545] Trial 150 finished with value: 0.3431323672413512 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 13, 'learning_rate': 0.0034941683690838036, 'p_miss': 0.05099830773968576}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:02:01,501] Trial 151 finished with value: 0.3416052158306376 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 10, 'learning_rate': 0.0015291660149545847, 'p_miss': 0.03453288004606989}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:02:46,610] Trial 152 finished with value: 0.343323651626451 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 15, 'learning_rate': 0.0024189765714512897, 'p_miss': 0.0561570896215961}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:03:51,810] Trial 153 finished with value: 0.3441527479339121 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 17, 'learning_rate': 0.002725633653220007, 'p_miss': 0.2526714777835063}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:06:20,193] Trial 154 finished with value: 0.3467246210164567 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 37, 'learning_rate': 0.0016516104458967425, 'p_miss': 0.04753444510973079}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:09:26,558] Trial 155 finished with value: 0.37206351988017144 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 55, 'learning_rate': 0.004027560298449455, 'p_miss': 0.02876285290088481}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:10:04,136] Trial 156 finished with value: 0.3419232186060107 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 10, 'learning_rate': 0.0012356602661501028, 'p_miss': 0.06563943352553014}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:11:30,716] Trial 157 finished with value: 0.34957862227616915 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 26, 'learning_rate': 0.003143654095108036, 'p_miss': 0.04053960975123813}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:11:57,893] Trial 158 finished with value: 0.3406439557359625 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 8, 'learning_rate': 0.002181004739363639, 'p_miss': 0.02352769271668257}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:12:27,395] Trial 159 finished with value: 0.34398115756674863 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 8, 'learning_rate': 0.0020907512659636422, 'p_miss': 0.022868809772903263}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:13:05,521] Trial 160 finished with value: 0.3427783297022661 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 11, 'learning_rate': 0.0017629559544747198, 'p_miss': 0.03236216630478754}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:13:17,696] Trial 161 finished with value: 0.3623280549816439 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'random'}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:14:45,000] Trial 162 finished with value: 0.3447229059295635 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 24, 'learning_rate': 0.0024244730983902546, 'p_miss': 0.040004503775849284}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:14:55,347] Trial 163 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.38400572997865273, 'alpha': 3, 'iterations': 8, 'learning_rate': 0.0036086840609558407, 'p_miss': 0.05374302832208147}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:15:53,214] Trial 164 finished with value: 0.3495178295449202 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 16, 'learning_rate': 0.005638629741716271, 'p_miss': 0.017847106918530004}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:16:12,249] Trial 165 finished with value: 0.3436673382357986 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 5, 'learning_rate': 0.001369127019667977, 'p_miss': 0.02356640827509325}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:17:05,680] Trial 166 finished with value: 0.34226974658845855 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 16, 'learning_rate': 0.0028883783629430866, 'p_miss': 0.06006362414493058}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:17:49,302] Trial 167 finished with value: 0.3416896217442834 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 12, 'learning_rate': 0.0021448572153724816, 'p_miss': 0.03824779696298429}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:18:13,072] Trial 168 finished with value: 0.3441203799869125 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.0009214135842048651, 'p_miss': 0.04580154436353083}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:18:28,601] Trial 169 finished with value: 0.3405776738848794 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 4, 'learning_rate': 0.0032177894086778836, 'p_miss': 0.07429390159074904}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:18:43,069] Trial 170 finished with value: 0.34415550377364046 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 4, 'learning_rate': 0.004116262671619423, 'p_miss': 0.06886485699485098}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:19:04,925] Trial 171 finished with value: 0.3426148419067251 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6, 'learning_rate': 0.0033266917381475, 'p_miss': 0.23139465059998654}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:19:22,487] Trial 172 finished with value: 0.34209603580246684 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 5, 'learning_rate': 0.0025787555723102654, 'p_miss': 0.010496977068435834}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:19:23,193] Trial 173 finished with value: 0.5880046006380537 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:20:04,703] Trial 174 finished with value: 0.34399551316078447 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 13, 'learning_rate': 0.0016752372478310224, 'p_miss': 0.080302954084551}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:20:16,631] Trial 175 finished with value: 0.35833628432303877 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 658, 'weights': 'distance'}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:21:25,603] Trial 176 finished with value: 0.3435156171512919 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 21, 'learning_rate': 0.003022858617281207, 'p_miss': 0.05131084371688656}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:21:41,225] Trial 177 finished with value: 0.342533381648142 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.001940191240272246, 'p_miss': 0.07237098707537308}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:22:15,590] Trial 178 finished with value: 0.3404192288775393 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 10, 'learning_rate': 0.002380633467201677, 'p_miss': 0.16666747982962446}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:23:04,222] Trial 179 finished with value: 0.34160232178988037 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 14, 'learning_rate': 0.0023002438130994684, 'p_miss': 0.15603311135096387}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:23:36,935] Trial 180 finished with value: 0.3420518667220228 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8, 'learning_rate': 0.004862049356998569, 'p_miss': 0.20631087101227583}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:24:15,022] Trial 181 finished with value: 0.34202298128002184 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 10, 'learning_rate': 0.00016239480653344282, 'p_miss': 0.1424446577474946}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:24:35,372] Trial 182 finished with value: 0.3418054220119921 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.0038792385565555613, 'p_miss': 0.18371996063506701}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:25:41,874] Trial 183 finished with value: 0.344303872734294 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 20, 'learning_rate': 0.002806302121183284, 'p_miss': 0.16799824263257776}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:26:18,724] Trial 184 finished with value: 0.341065875805232 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 10, 'learning_rate': 0.0008064775102573745, 'p_miss': 0.027939684227943608}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:26:46,202] Trial 185 finished with value: 0.34096699902378924 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 10, 'learning_rate': 0.0011124207026042146, 'p_miss': 0.03315041409415612}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:27:20,643] Trial 186 finished with value: 0.346523144626009 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 10, 'learning_rate': 0.0010021147334425802, 'p_miss': 0.026848739911155186}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:27:58,172] Trial 187 finished with value: 0.34146030570773456 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 8, 'learning_rate': 0.0007734494544726364, 'p_miss': 0.03415126772998911}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:29:02,173] Trial 188 finished with value: 0.3445932953926423 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 17, 'learning_rate': 0.0012902279536235281, 'p_miss': 0.020178288270048216}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:29:37,405] Trial 189 finished with value: 0.34131761616151157 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 11, 'learning_rate': 0.0016984303650688887, 'p_miss': 0.03141392180421129}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:31:22,083] Trial 49 finished with value: 0.37470223820397697 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 5582, 'learning_rate': 0.00014213210708302252, 'p_miss': 0.12041155734490731}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:31:48,823] Trial 191 finished with value: 0.3415645291104063 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 6, 'learning_rate': 0.0010437247493351694, 'p_miss': 0.0320527940577202}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:32:24,374] Trial 192 finished with value: 0.3416391560006592 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 11, 'learning_rate': 0.0011722712987798822, 'p_miss': 0.03979999689892383}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:32:51,765] Trial 193 finished with value: 0.3425296681876865 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 8, 'learning_rate': 0.0014400236484255978, 'p_miss': 0.025932028277966312}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:33:33,192] Trial 194 finished with value: 0.34348794077885525 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 10, 'learning_rate': 0.0008396300645020642, 'p_miss': 0.017516210320365364}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:33:50,922] Trial 195 finished with value: 0.3437100449909605 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.0021198063389636906, 'p_miss': 0.03466950781496157}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:34:34,991] Trial 196 finished with value: 0.3488460155151709 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 14, 'learning_rate': 0.001629328002149257, 'p_miss': 0.04350796538217464}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:35:20,549] Trial 197 finished with value: 0.340646125821887 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 13, 'learning_rate': 0.001845583596201374, 'p_miss': 0.057532816901573136}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:43:34,252] Trial 43 finished with value: 0.3736716675705733 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 6063, 'learning_rate': 0.0007947866450776354, 'p_miss': 0.1344095437248909}. Best is trial 148 with value: 0.3399367323092276.
running
[I 2024-10-15 06:44:08,262] Trial 199 finished with value: 0.3492911733351415 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 07:05:38,413] Trial 69 finished with value: 0.3803305160207081 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 5797, 'learning_rate': 0.007703050006960862, 'p_miss': 0.09711766655938904}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 07:45:57,653] Trial 47 finished with value: 0.3723560771773557 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 8429, 'learning_rate': 0.00010068583937210844, 'p_miss': 0.13547391048892485}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 08:33:52,720] Trial 55 finished with value: 0.37694950274943884 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7238, 'learning_rate': 0.0003359023299606356, 'p_miss': 0.06076053944165148}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 08:47:22,815] Trial 54 finished with value: 0.3772825719868492 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 7137, 'learning_rate': 0.0003419100682215121, 'p_miss': 0.11248179210425793}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 08:57:32,278] Trial 48 finished with value: 0.3725227108169123 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 9754, 'learning_rate': 0.00014836981576010254, 'p_miss': 0.13184917551997272}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:18:16,097] Trial 74 finished with value: 0.37575623475225606 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 7941, 'learning_rate': 0.011758890574463523, 'p_miss': 0.16962152930956084}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:18:40,410] Trial 80 finished with value: 0.3729582251511876 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 6436, 'learning_rate': 0.024029209885970113, 'p_miss': 0.11561185625539931}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:21:14,664] Trial 57 finished with value: 0.39129624641273714 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8785, 'learning_rate': 0.00029479486456631657, 'p_miss': 0.09222715845274457}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:23:02,530] Trial 62 finished with value: 0.3786346008218265 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 8233, 'learning_rate': 0.00013060410449341233, 'p_miss': 0.10697077628073774}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:42:02,249] Trial 78 finished with value: 0.39405888530079525 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 8586, 'learning_rate': 0.00033522834182089133, 'p_miss': 0.11554473281448092}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:47:58,188] Trial 92 finished with value: 0.37246332652354086 and parameters: {'model_name': 'VAE', 'batch_size': 310, 'iterations': 9775, 'learning_rate': 0.08276236110518145, 'p_miss': 0.20441182052073156}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:48:29,607] Trial 58 finished with value: 0.381109676219446 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9631, 'learning_rate': 0.0003467955344246456, 'p_miss': 0.10014792691043735}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:53:59,484] Trial 190 finished with value: 0.37669859176006437 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 9458, 'learning_rate': 0.0019175435215424339, 'p_miss': 0.03321103274151961}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:55:58,224] Trial 198 finished with value: 0.3755594373141759 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 9899, 'learning_rate': 0.0018727098554265256, 'p_miss': 0.05913637367207834}. Best is trial 148 with value: 0.3399367323092276.
[I 2024-10-15 09:56:09,617] Trial 108 finished with value: 0.3861340324536268 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 9650, 'learning_rate': 0.013568714324067322, 'p_miss': 0.2226314636948429}. Best is trial 148 with value: 0.3399367323092276.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0.3399367323092276
{'model_name': 'VAE', 'batch_size': 4, 'iterations': 15, 'learning_rate': 0.001645252854550758, 'p_miss': 0.051055915382271194}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.5089016368819473
Generation:   4%|         | 1/25 [00:53<21:16, 53.17s/it]Generation:  2
Best f1_score score: 0.5190189442124664
Generation:   8%|         | 2/25 [03:05<38:14, 99.78s/it]Generation:  3
Best f1_score score: 0.5190189442124664
Generation:  12%|        | 3/25 [12:13<1:51:35, 304.36s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467def340> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  4
Best f1_score score: 0.5260207988003128
Generation:  16%|        | 4/25 [15:43<1:33:31, 267.21s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a55d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.5260207988003128
Generation:  20%|        | 5/25 [18:14<1:15:04, 225.21s/it]Generation:  6
Best f1_score score: 0.5260207988003128
Generation:  24%|       | 6/25 [23:34<1:21:34, 257.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554652cd120> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.5260207988003128
Generation:  28%|       | 7/25 [27:20<1:14:07, 247.07s/it]Generation:  8
Best f1_score score: 0.5260207988003128
Generation:  32%|      | 8/25 [28:44<55:19, 195.27s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467dd9a20> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  9
Best f1_score score: 0.5260207988003128
Generation:  36%|      | 9/25 [31:23<49:03, 183.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ff9ed0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.5260207988003128
Generation:  40%|      | 10/25 [32:11<35:29, 141.98s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ded360> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  11
Best f1_score score: 0.5260207988003128
Generation:  44%|     | 11/25 [32:31<24:24, 104.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676f9ea0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  12
Best f1_score score: 0.5260207988003128
Generation:  48%|     | 12/25 [34:27<23:26, 108.18s/it]Generation:  13
Best f1_score score: 0.5260207988003128
Generation:  52%|    | 13/25 [35:05<17:21, 86.75s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a26800> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.5260207988003128
Generation:  56%|    | 14/25 [36:49<16:50, 91.88s/it]Generation:  15
Best f1_score score: 0.5260207988003128
Generation:  60%|    | 15/25 [37:10<11:45, 70.57s/it]Generation:  16
Best f1_score score: 0.5260207988003128
Generation:  64%|   | 16/25 [37:56<09:30, 63.38s/it]Generation:  17
Best f1_score score: 0.5260207988003128
Generation:  68%|   | 17/25 [38:42<07:44, 58.10s/it]Generation:  18
Best f1_score score: 0.5260207988003128
Generation:  72%|  | 18/25 [41:38<10:54, 93.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464951540> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  19
Best f1_score score: 0.5260207988003128
Generation:  76%|  | 19/25 [44:34<11:49, 118.32s/it]Generation:  20
Best f1_score score: 0.5260207988003128
Generation:  80%|  | 20/25 [45:43<08:36, 103.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e332e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  21
Best f1_score score: 0.5260207988003128
Generation:  84%| | 21/25 [47:50<07:22, 110.64s/it]Generation:  22
Best f1_score score: 0.5260794422879729
Generation:  88%| | 22/25 [48:36<04:32, 90.99s/it] Generation:  23
Best f1_score score: 0.5262989935901968
Generation:  92%|| 23/25 [52:30<04:28, 134.12s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546584e0e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  24
Best f1_score score: 0.5270165410461467
Generation:  96%|| 24/25 [54:41<02:13, 133.17s/it]Generation:  25
Best f1_score score: 0.5270165410461467
Generation: 100%|| 25/25 [56:10<00:00, 119.70s/it]Generation: 100%|| 25/25 [56:13<00:00, 134.93s/it]
2024-10-15 10:52:32,601 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37011' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-53d697fd49d3e13ce179ef1b16c4d251', 'ndarray-b9c4abab84cb9042d3fd8eefd90defae'} (stimulus_id='handle-worker-cleanup-1729014752.6017144')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      max_features=0.4583491418619,
                                      min_samples_leaf=13, min_samples_split=9,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.7995544303483874, 'accuracy': 0.7304077225962149, 'balanced_accuracy': 0.7208295198201116, 'logloss': 0.6506104735524328, 'f1': 0.7121658635170075}
original test score: {'auroc': 0.52818327767281, 'accuracy': 0.586995173990348, 'balanced_accuracy': 0.5060800251780151, 'logloss': 0.68352728006945, 'f1': 0.4988666189453591}
imputed test score: {'auroc': 0.4952975914555313, 'accuracy': 0.5261620523241046, 'balanced_accuracy': 0.49762660767313105, 'logloss': 0.6903213784668735, 'f1': 0.4957743531113288}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4c10> 

Generation:  1
Best f1_score score: 0.6892646173978538
Generation:   4%|         | 1/25 [10:02<4:01:04, 602.71s/it]Generation:  2
Best f1_score score: 0.6892646173978538
Generation:   8%|         | 2/25 [15:04<2:43:13, 425.79s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547450b130> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15541d4b4100> 

Generation:  3
Best f1_score score: 0.6892646173978538
Generation:  12%|        | 3/25 [25:07<3:05:48, 506.75s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ec7b460> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745ce8f0> 

Generation:  4
Best f1_score score: 0.6980408545825706
Generation:  16%|        | 4/25 [35:11<3:10:45, 545.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d1e0b0> 

Generation:  5
Best f1_score score: 0.6980408545825706
Generation:  20%|        | 5/25 [45:16<3:08:50, 566.53s/it]Generation:  6
Best f1_score score: 0.7092215068682189
Generation:  24%|       | 6/25 [51:33<2:39:04, 502.35s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545ff26ce0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545fead5d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474178190> 

Generation:  7
Best f1_score score: 0.7092215068682189
Generation:  28%|       | 7/25 [1:01:38<2:40:45, 535.84s/it]Generation:  8
Best f1_score score: 0.7092215068682189
Generation:  32%|      | 8/25 [1:06:21<2:08:59, 455.28s/it]Generation:  9
Best f1_score score: 0.7092215068682189
Generation:  36%|      | 9/25 [1:10:43<1:45:16, 394.81s/it]Generation:  10
Best f1_score score: 0.7092215068682189
Generation:  40%|      | 10/25 [1:16:43<1:36:03, 384.23s/it]Generation:  11
Best f1_score score: 0.7092215068682189
Generation:  44%|     | 11/25 [1:21:08<1:21:08, 347.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554740f36d0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456abecb0> 

Generation:  12
Best f1_score score: 0.7092215068682189
Generation:  48%|     | 12/25 [1:31:13<1:32:16, 425.89s/it]Generation:  13
Best f1_score score: 0.7092215068682189
Generation:  52%|    | 13/25 [1:36:21<1:18:03, 390.31s/it]Generation:  14
Best f1_score score: 0.7092215068682189
Generation:  56%|    | 14/25 [1:41:13<1:06:06, 360.56s/it]Generation:  15
Best f1_score score: 0.7092215068682189
Generation:  60%|    | 15/25 [1:45:27<54:43, 328.31s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456429390> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456796260> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f6dff70> 

Generation:  16
Best f1_score score: 0.7092215068682189
Generation:  64%|   | 16/25 [1:55:31<1:01:41, 411.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456be1b10> 

Generation:  17
Best f1_score score: 0.7092215068682189
Generation:  68%|   | 17/25 [2:05:36<1:02:37, 469.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f022b30> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545e00f430> 

Generation:  18
Best f1_score score: 0.7092215068682189
Generation:  72%|  | 18/25 [2:15:41<59:31, 510.26s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474423b20> 

Generation:  19
Best f1_score score: 0.7092215068682189
Generation:  76%|  | 19/25 [2:25:48<53:55, 539.32s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553c897ece0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745bae30> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.7092215068682189
Generation:  80%|  | 20/25 [2:29:46<37:24, 448.85s/it]Generation:  21
Best f1_score score: 0.7092215068682189
Generation:  84%| | 21/25 [2:33:36<25:32, 383.05s/it]Generation:  22
Best f1_score score: 0.7092215068682189
Generation:  88%| | 22/25 [2:37:46<17:09, 343.17s/it]Generation:  23
Best f1_score score: 0.710481417403032
Generation:  92%|| 23/25 [2:42:02<10:33, 317.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554521f3fd0> 

Generation:  24
Best f1_score score: 0.710481417403032
Generation:  96%|| 24/25 [2:52:08<06:43, 403.69s/it]Generation:  25
Best f1_score score: 0.710481417403032
Generation: 100%|| 25/25 [2:55:58<00:00, 351.61s/it]Generation: 100%|| 25/25 [2:55:58<00:00, 422.33s/it]
2024-10-15 13:48:43,341 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:37593' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-4292d98ea78fed56ad99fe169ba0b859', 'ndarray-53d697fd49d3e13ce179ef1b16c4d251'} (stimulus_id='handle-worker-cleanup-1729025323.3413882')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=6,
                                n_estimators=88, n_jobs=1, num_leaves=194,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8254184158683392, 'accuracy': 0.7432363774926966, 'balanced_accuracy': 0.744472157571911, 'logloss': 0.5158613554409296, 'f1': 0.7297217966912708}
test score: {'auroc': 0.7706425952429807, 'accuracy': 0.6696723393446787, 'balanced_accuracy': 0.6944188875539283, 'logloss': 0.6290230821523155, 'f1': 0.6638646406269524}
original test score: {'auroc': 0.8515302426921232, 'accuracy': 0.7627635255270511, 'balanced_accuracy': 0.7665654378932686, 'logloss': 0.4771945531986229, 'f1': 0.7504658799316752}
score end
137
lvl
0.5
type
MAR
num_run
2
class_full
finished
all finished
full run takes
13.2353500013219
hours
DONE
