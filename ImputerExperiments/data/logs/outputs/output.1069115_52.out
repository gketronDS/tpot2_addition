Run: 52
/cm/local/apps/slurm/var/spool/job1069115/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/41027/41027.pkl
working on 
../data/c/41027/class_full_MCAR_0.5_3
4.046825885772705
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-22 14:29:13,684] A new study created in memory with name: no-name-fe5682b0-8db2-4883-afce-9b4e5b5b7139
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-22 14:29:14,135] Trial 15 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.45234011750037073.
running
[I 2024-11-22 14:29:14,317] Trial 8 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 15 with value: 0.45234011750037073.
[I 2024-11-22 14:29:14,510] Trial 9 finished with value: 0.3159782644947139 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 9 with value: 0.3159782644947139.
running
running
[I 2024-11-22 14:29:38,722] Trial 13 finished with value: 0.45298166423826236 and parameters: {'model_name': 'GAIN', 'batch_size': 251, 'hint_rate': 0.4489669201475312, 'alpha': 26, 'iterations': 12, 'learning_rate': 0.0002081985176262043, 'p_miss': 0.14703218639063695}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:41,248] Trial 7 finished with value: 0.3162051590718288 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13560, 'weights': 'uniform'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:43,880] Trial 11 finished with value: 0.31609287154975335 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20523, 'weights': 'uniform'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:44,379] Trial 6 finished with value: 0.31605836799679377 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 24654, 'weights': 'uniform'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:48,156] Trial 3 finished with value: 0.32847658519537987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31072, 'weights': 'distance'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:48,767] Trial 18 finished with value: 0.3284766515509756 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13761, 'weights': 'distance'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:50,833] Trial 14 finished with value: 0.3284766672792833 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 20275, 'weights': 'distance'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:29:51,396] Trial 17 finished with value: 0.3284758184578911 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 18886, 'weights': 'distance'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:30:02,013] Trial 20 finished with value: 0.3159782644947139 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 27543, 'weights': 'uniform'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:30:09,127] Trial 21 finished with value: 0.3284770446107938 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9948, 'weights': 'distance'}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:30:51,518] Trial 23 finished with value: 0.32626187941171697 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 19, 'learning_rate': 0.041430690923427556, 'p_miss': 0.1037392648858453}. Best is trial 9 with value: 0.3159782644947139.
running
[I 2024-11-22 14:34:19,309] Trial 1 finished with value: 0.2802942133276525 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 109, 'learning_rate': 0.0011749997216165132, 'p_miss': 0.09187482376053704}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:34:29,100] Trial 12 finished with value: 0.30117264887681555 and parameters: {'model_name': 'VAE', 'batch_size': 139, 'iterations': 84, 'learning_rate': 0.0014254563177583488, 'p_miss': 0.07542958000654643}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:38:53,206] Trial 24 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9895808822677421, 'alpha': 84, 'iterations': 2022, 'learning_rate': 0.009330082756731936, 'p_miss': 0.22337001634641349}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:39:53,005] Trial 10 finished with value: 0.2824324457182211 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 207, 'learning_rate': 0.0007550496837581426, 'p_miss': 0.07436374807037138}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:39:58,967] Trial 0 finished with value: 0.33066995701419827 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 193, 'learning_rate': 0.018246718312569358, 'p_miss': 0.1001956476857799}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:40:08,982] Trial 33 finished with value: 0.3159823121355837 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'ascending'}. Best is trial 1 with value: 0.2802942133276525.
running
[I 2024-11-22 14:40:11,571] Trial 35 finished with value: 0.26319122141504886 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0008582813986056105, 'p_miss': 0.016003715102463567}. Best is trial 35 with value: 0.26319122141504886.
running
[I 2024-11-22 14:40:15,344] Trial 36 finished with value: 0.2666616808736742 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.000846324186883909, 'p_miss': 0.011838065739603398}. Best is trial 35 with value: 0.26319122141504886.
running
[I 2024-11-22 14:40:17,964] Trial 37 finished with value: 0.2606236922513846 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.000627380540463559, 'p_miss': 0.012523667668298105}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:40:20,195] Trial 38 finished with value: 0.2610702402552278 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0002531195256968487, 'p_miss': 0.011715642306588447}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:40:23,100] Trial 39 finished with value: 0.26338576414573767 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0001311769533008772, 'p_miss': 0.010106222745284946}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:40:37,697] Trial 34 finished with value: 0.4063499205164284 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:40:52,007] Trial 41 finished with value: 0.26416767431644816 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.0003720763943625387, 'p_miss': 0.015568375906807376}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:40:56,381] Trial 42 finished with value: 0.2613890258669557 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.003177426903812184, 'p_miss': 0.045383848069633644}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:41:08,664] Trial 43 finished with value: 0.2627864127302241 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 4, 'learning_rate': 0.005671472706614553, 'p_miss': 0.05269066055738267}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:41:23,897] Trial 44 finished with value: 0.2631765232443134 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 4, 'learning_rate': 0.0027870327679345224, 'p_miss': 0.2862882172666771}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:41:58,879] Trial 45 finished with value: 0.3384591978580144 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:42:10,350] Trial 46 finished with value: 0.26113275299159666 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 3, 'learning_rate': 0.005635309956594831, 'p_miss': 0.04465699176287207}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:42:14,963] Trial 47 finished with value: 0.2634794028907766 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0034851114533096064, 'p_miss': 0.04490239290945086}. Best is trial 37 with value: 0.2606236922513846.
running
[I 2024-11-22 14:42:25,273] Trial 48 finished with value: 0.2606180435997406 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 3, 'learning_rate': 0.00034127187900731467, 'p_miss': 0.041519409814516565}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:43:00,050] Trial 49 finished with value: 0.26154863499979786 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 9, 'learning_rate': 0.0002907164614168238, 'p_miss': 0.04767395697439501}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:43:11,762] Trial 50 finished with value: 0.2620676057778623 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4, 'learning_rate': 0.0004555207793791866, 'p_miss': 0.042453667812606476}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:43:20,018] Trial 51 finished with value: 0.45423499247709553 and parameters: {'model_name': 'GAIN', 'batch_size': 88, 'hint_rate': 0.017665390006109227, 'alpha': 0, 'iterations': 2, 'learning_rate': 0.00011393998134196091, 'p_miss': 0.15934882734649528}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:44:52,623] Trial 52 finished with value: 0.26137938762857144 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 32, 'learning_rate': 0.00020248103895541603, 'p_miss': 0.14727053315776445}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:44:53,899] Trial 53 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:45:06,407] Trial 54 finished with value: 0.26488455134970534 and parameters: {'model_name': 'VAE', 'batch_size': 644, 'iterations': 2, 'learning_rate': 0.00047814491144656656, 'p_miss': 0.06780168543562169}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:45:13,914] Trial 55 finished with value: 0.26230243261354896 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 2, 'learning_rate': 0.0020208015119920195, 'p_miss': 0.027305221341088204}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:45:34,233] Trial 5 finished with value: 0.3169460732882981 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:46:50,379] Trial 56 finished with value: 0.2676104598277629 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 25, 'learning_rate': 0.00019851551746075628, 'p_miss': 0.1306160704106883}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:47:13,022] Trial 57 finished with value: 0.2629264263032692 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 32, 'learning_rate': 0.00019509673964335298, 'p_miss': 0.13066659089066052}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:47:38,789] Trial 59 finished with value: 0.2631919347083034 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 8, 'learning_rate': 0.00010260679346506587, 'p_miss': 0.18712820054750473}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:57:22,072] Trial 29 finished with value: 0.320111256216955 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'ascending'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:59:13,405] Trial 2 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.01135466801082083, 'alpha': 56, 'iterations': 7015, 'learning_rate': 0.0062754100523139955, 'p_miss': 0.028275645906747436}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:59:20,976] Trial 62 finished with value: 0.2634635366190266 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.0002868780533173401, 'p_miss': 0.20893101362935723}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:59:51,381] Trial 32 finished with value: 0.3182987583911074 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 493, 'learning_rate': 0.0007072558943585359, 'p_miss': 0.016303013437376904}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 14:59:52,884] Trial 64 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:00:06,871] Trial 65 finished with value: 0.45214177018390567 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.8898731079568174, 'alpha': 98, 'iterations': 6, 'learning_rate': 0.012325183236756502, 'p_miss': 0.09235426973740858}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:00:11,369] Trial 66 finished with value: 0.26250859618871886 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.004526408932557216, 'p_miss': 0.03698700279469373}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:00:19,793] Trial 67 finished with value: 0.2611505916267224 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2, 'learning_rate': 0.0023251733976209633, 'p_miss': 0.05743992827713025}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:00:28,174] Trial 68 finished with value: 0.26775052420928025 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 2, 'learning_rate': 0.027561304933871048, 'p_miss': 0.06659962603153739}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:01:25,210] Trial 16 finished with value: 0.3226765677961881 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:01:39,481] Trial 70 finished with value: 0.26227224190582915 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 3, 'learning_rate': 0.001581583756035688, 'p_miss': 0.10720460431706509}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:02:48,377] Trial 69 finished with value: 0.2629734186310664 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 45, 'learning_rate': 0.00044987691924089796, 'p_miss': 0.06154166129013038}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:04:21,672] Trial 71 finished with value: 0.26348189664077554 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 53, 'learning_rate': 0.0004242238565057802, 'p_miss': 0.06046454476546462}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:11:33,487] Trial 72 finished with value: 0.26521650541831054 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 170, 'learning_rate': 0.0002510733852623175, 'p_miss': 0.08236702744235608}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:11:34,615] Trial 74 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:12:13,713] Trial 75 finished with value: 0.2615633425463732 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 12, 'learning_rate': 0.00016612692914095702, 'p_miss': 0.031083123623001342}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:12:14,185] Trial 40 finished with value: 0.3320704449924385 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:12:18,564] Trial 77 finished with value: 0.26110170297571844 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1, 'learning_rate': 0.0073069781595498165, 'p_miss': 0.03131537551642173}. Best is trial 48 with value: 0.2606180435997406.
[I 2024-11-22 15:12:18,698] Trial 76 finished with value: 0.26397985277804553 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 1, 'learning_rate': 0.002950303635756074, 'p_miss': 0.03315408829271048}. Best is trial 48 with value: 0.2606180435997406.
running
running
[I 2024-11-22 15:12:26,745] Trial 79 finished with value: 0.262300088234247 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.009360479908011629, 'p_miss': 0.025230415312641467}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:12:27,052] Trial 78 finished with value: 0.2638658277394347 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 2, 'learning_rate': 0.00865353226995278, 'p_miss': 0.02555065696467698}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:18:51,159] Trial 73 finished with value: 0.2768793843060752 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 276, 'learning_rate': 0.0002651613679188312, 'p_miss': 0.030186005400903812}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:22:16,529] Trial 82 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5346538303946969, 'alpha': 57, 'iterations': 781, 'learning_rate': 0.0006745462183959822, 'p_miss': 0.2793325575992532}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:22:33,863] Trial 83 finished with value: 0.31609218732279953 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4476, 'weights': 'uniform'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:22:46,451] Trial 84 finished with value: 0.2670778169437536 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 3, 'learning_rate': 0.01769714506107334, 'p_miss': 0.076950697979648}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:23:28,498] Trial 85 finished with value: 0.2606210339246727 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 16, 'learning_rate': 0.0013049021666115064, 'p_miss': 0.010991959391359662}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:24:32,661] Trial 86 finished with value: 0.262178052224844 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 17, 'learning_rate': 0.0010796405651083024, 'p_miss': 0.011085821428344418}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:24:46,426] Trial 81 finished with value: 0.4497003682329243 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.5976588653752231, 'alpha': 58, 'iterations': 534, 'learning_rate': 0.0063676874495913385, 'p_miss': 0.25480583793364986}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:24:53,663] Trial 87 finished with value: 0.26285203019725756 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 6, 'learning_rate': 0.0020612595146863736, 'p_miss': 0.0526930589745972}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:25:04,825] Trial 63 finished with value: 0.32730389364016227 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 621, 'learning_rate': 0.000563164471195984, 'p_miss': 0.25000859767918765}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:25:50,838] Trial 90 finished with value: 0.2641258029482385 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 17, 'learning_rate': 0.0009822091720376165, 'p_miss': 0.018004306965006153}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:26:00,084] Trial 91 finished with value: 0.2624261132756188 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 3, 'learning_rate': 0.004518129775878133, 'p_miss': 0.04084040065167031}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:28:57,774] Trial 88 finished with value: 0.27936380482356843 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 77, 'learning_rate': 0.001060846630184023, 'p_miss': 0.056444853936247555}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:02,902] Trial 93 finished with value: 0.2606602660487866 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.0013589744997640333, 'p_miss': 0.010645370591118839}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:14,181] Trial 94 finished with value: 0.31596663761131794 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:30,610] Trial 95 finished with value: 0.31521495796168675 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1072, 'weights': 'uniform'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:33,391] Trial 92 finished with value: 0.2894543508143477 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 88, 'learning_rate': 0.0015228576712164868, 'p_miss': 0.021010957451841478}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:35,778] Trial 96 finished with value: 0.2640813646715696 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 1, 'learning_rate': 0.0014137336988214839, 'p_miss': 0.01134552722569101}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:38,506] Trial 97 finished with value: 0.26287145182355603 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.001936616917674767, 'p_miss': 0.01238275610276278}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:39,967] Trial 98 finished with value: 0.26281254538241355 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.0022897764309740567, 'p_miss': 0.03824490945789541}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:48,365] Trial 99 finished with value: 0.2611912302092145 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 3, 'learning_rate': 0.0003497038610270578, 'p_miss': 0.03946538875906472}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:49,523] Trial 101 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:29:57,111] Trial 100 finished with value: 0.2652999016242736 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 6, 'learning_rate': 0.00015345546130005245, 'p_miss': 0.022967702023512247}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:30:03,790] Trial 102 finished with value: 0.26588427158528294 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 3, 'learning_rate': 0.0007323711449130255, 'p_miss': 0.04841360335811734}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:30:07,827] Trial 103 finished with value: 0.2609001243686675 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 3, 'learning_rate': 0.00063948488110298, 'p_miss': 0.04315489701522392}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:30:23,539] Trial 105 finished with value: 0.26100914465456093 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 5, 'learning_rate': 0.0005799196252107427, 'p_miss': 0.021877286398739}. Best is trial 48 with value: 0.2606180435997406.
running
[I 2024-11-22 15:30:38,669] Trial 106 finished with value: 0.2605776230391621 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 4, 'learning_rate': 0.0005309056915164466, 'p_miss': 0.022028710377703854}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:31:11,968] Trial 107 finished with value: 0.2608769470808329 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 10, 'learning_rate': 0.0005640100246965076, 'p_miss': 0.02153310228796475}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:31:48,852] Trial 108 finished with value: 0.267406068686718 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 11, 'learning_rate': 0.0005982725358799969, 'p_miss': 0.020595690190288434}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:32:05,311] Trial 109 finished with value: 0.26310497260160465 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 5, 'learning_rate': 0.00035547996281914485, 'p_miss': 0.0312988316243647}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:32:38,757] Trial 110 finished with value: 0.26302210975662743 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 9, 'learning_rate': 0.0005703914550054079, 'p_miss': 0.010557089923821622}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:33:01,986] Trial 111 finished with value: 0.32894111564096135 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 5, 'learning_rate': 0.09077793701578937, 'p_miss': 0.02095158326351469}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:33:10,496] Trial 31 finished with value: 0.36476015574076764 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1453, 'learning_rate': 0.0012015389585548102, 'p_miss': 0.03272941391912014}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:33:19,074] Trial 112 finished with value: 0.3159760308398798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:33:29,473] Trial 113 finished with value: 0.3159760308398798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 106 with value: 0.2605776230391621.
running
[I 2024-11-22 15:33:32,899] Trial 114 finished with value: 0.2600545336593759 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 8, 'learning_rate': 0.0009155485516348146, 'p_miss': 0.032061827567301644}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:33:54,769] Trial 115 finished with value: 0.2641661052053804 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 7, 'learning_rate': 0.0008242630269791737, 'p_miss': 0.030182201787568558}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:34:02,606] Trial 116 finished with value: 0.26171699211999233 and parameters: {'model_name': 'VAE', 'batch_size': 208, 'iterations': 7, 'learning_rate': 0.000862035297504679, 'p_miss': 0.03157692777294693}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:34:03,441] Trial 58 finished with value: 0.2996159107570895 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1010, 'learning_rate': 0.00023480192510642815, 'p_miss': 0.23282844519885249}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:34:11,080] Trial 117 finished with value: 0.26298171592794184 and parameters: {'model_name': 'VAE', 'batch_size': 368, 'iterations': 4, 'learning_rate': 0.000502501751999195, 'p_miss': 0.019877889134574753}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:34:40,679] Trial 119 finished with value: 0.26122552542345995 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 13, 'learning_rate': 0.0005347025774565969, 'p_miss': 0.01899795057192702}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:34:42,239] Trial 120 finished with value: 0.2626259651127046 and parameters: {'model_name': 'VAE', 'batch_size': 99, 'iterations': 11, 'learning_rate': 0.0006528985087493159, 'p_miss': 0.04075859671512349}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:35:06,876] Trial 122 finished with value: 0.32847658519537987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 35850, 'weights': 'distance'}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:37:22,548] Trial 61 finished with value: 0.30837418524263627 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 784, 'learning_rate': 0.00031745512315019313, 'p_miss': 0.22785502814706254}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:37:23,773] Trial 124 finished with value: 0.3159782644947139 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:38:25,724] Trial 125 finished with value: 0.2608985457850987 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 22, 'learning_rate': 0.00043292554817004497, 'p_miss': 0.05092710686259423}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:39:17,793] Trial 126 finished with value: 0.26490064356016646 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 14, 'learning_rate': 0.0009039970240628448, 'p_miss': 0.04819897115823378}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:40:22,193] Trial 127 finished with value: 0.2632280646950047 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 21, 'learning_rate': 0.00041725484130938185, 'p_miss': 0.026102493513814794}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:41:56,778] Trial 128 finished with value: 0.26606567725141983 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 30, 'learning_rate': 0.0012771092670581191, 'p_miss': 0.036842728711201256}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:50:40,395] Trial 19 finished with value: 0.34069901696781035 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 1726, 'learning_rate': 0.002831892206815396, 'p_miss': 0.12931305519820183}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:51:06,327] Trial 130 finished with value: 0.2629322797151511 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 8, 'learning_rate': 0.0003979625110704831, 'p_miss': 0.01570943173939318}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:51:17,714] Trial 131 finished with value: 0.45155180144580953 and parameters: {'model_name': 'GAIN', 'batch_size': 124, 'hint_rate': 0.27464278186953905, 'alpha': 0, 'iterations': 4, 'learning_rate': 0.0007466860980979021, 'p_miss': 0.024984008394184107}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:51:37,970] Trial 132 finished with value: 0.26137012551532063 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 5, 'learning_rate': 0.0004936718677344982, 'p_miss': 0.04672253348860228}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:52:04,692] Trial 80 finished with value: 0.33702100099506366 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 875, 'learning_rate': 0.009010003526188892, 'p_miss': 0.033104867455605556}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:52:08,545] Trial 4 finished with value: 0.3707180564425383 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 1731, 'learning_rate': 0.014650497581355613, 'p_miss': 0.16017585963272457}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:53:20,636] Trial 134 finished with value: 0.2620301132611199 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 25, 'learning_rate': 0.000668328826131856, 'p_miss': 0.016319959779401934}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:53:32,707] Trial 133 finished with value: 0.26194611311184923 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 41, 'learning_rate': 0.00030049826596405027, 'p_miss': 0.03376042303251416}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:53:37,085] Trial 136 finished with value: 0.2665513004855685 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 4, 'learning_rate': 0.005800963662374863, 'p_miss': 0.042039948638894965}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:54:00,505] Trial 137 finished with value: 0.26290993203118984 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 9, 'learning_rate': 0.00037075087389681536, 'p_miss': 0.043981739972277945}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:54:10,013] Trial 138 finished with value: 0.26850967573237583 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 9, 'learning_rate': 0.007416178219627407, 'p_miss': 0.06576548539790368}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:54:20,474] Trial 140 finished with value: 0.26126840329145795 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 3, 'learning_rate': 0.00022983615274891443, 'p_miss': 0.027721610568940274}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:55:13,601] Trial 141 finished with value: 0.3223519610064728 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 15, 'learning_rate': 0.012753329023636148, 'p_miss': 0.053026048062380066}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 15:55:22,185] Trial 142 finished with value: 0.2621063663665776 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 2, 'learning_rate': 0.0012855354918722662, 'p_miss': 0.01061305181811029}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 16:36:23,140] Trial 60 finished with value: 0.3285590273632359 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 2303, 'learning_rate': 0.0003159618337669699, 'p_miss': 0.2086881727472992}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:02:56,185] Trial 22 finished with value: 0.4524945374138 and parameters: {'model_name': 'GAIN', 'batch_size': 282, 'hint_rate': 0.38288993104948116, 'alpha': 21, 'iterations': 8858, 'learning_rate': 0.0002619194564568223, 'p_miss': 0.012899285886256396}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:03:14,969] Trial 145 finished with value: 0.2624304445043889 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 6, 'learning_rate': 0.0017531223982071521, 'p_miss': 0.024628148511472152}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:10:50,693] Trial 129 finished with value: 0.3253320208825599 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 3520, 'learning_rate': 0.0007500711277159019, 'p_miss': 0.017886436441031238}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:11:09,915] Trial 147 finished with value: 0.2612897995222251 and parameters: {'model_name': 'VAE', 'batch_size': 852, 'iterations': 2, 'learning_rate': 0.003911686054980641, 'p_miss': 0.05897739359560495}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:11:23,394] Trial 148 finished with value: 0.2625050540855667 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 4, 'learning_rate': 0.001109343252988955, 'p_miss': 0.0351394870283743}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:11:34,274] Trial 149 finished with value: 0.2666439311494836 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 3, 'learning_rate': 0.0006106080875558932, 'p_miss': 0.05012856224024882}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:11:53,131] Trial 150 finished with value: 0.2658582173147358 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.0009500133152840929, 'p_miss': 0.07348925749669749}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:12:01,185] Trial 151 finished with value: 0.26137280940643604 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 2, 'learning_rate': 0.0004745712841807567, 'p_miss': 0.026736359213789664}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:12:36,612] Trial 152 finished with value: 0.26313703445393666 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 11, 'learning_rate': 0.002529525888126228, 'p_miss': 0.03761863718171131}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:13:47,726] Trial 153 finished with value: 0.27140352009786767 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 20, 'learning_rate': 0.0035425069163563206, 'p_miss': 0.11570314701986238}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:14:05,963] Trial 154 finished with value: 0.3163045652093194 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6740, 'weights': 'uniform'}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:14:07,001] Trial 155 finished with value: 0.3159782644947139 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:14:18,507] Trial 156 finished with value: 0.2671811329353554 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 3, 'learning_rate': 0.00035483414748727196, 'p_miss': 0.04159334922553182}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:14:47,213] Trial 157 finished with value: 0.2611921953739792 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 7, 'learning_rate': 0.0003406447370938696, 'p_miss': 0.01647154837998628}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:14:57,458] Trial 158 finished with value: 0.26050692032840667 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 3, 'learning_rate': 0.0004465950350286171, 'p_miss': 0.05483856036185866}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:15:02,113] Trial 159 finished with value: 0.262446375404075 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.0004308386352121545, 'p_miss': 0.07171465822441353}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:15:13,664] Trial 160 finished with value: 0.2631344762085015 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 4, 'learning_rate': 0.0005808195093663608, 'p_miss': 0.05447671515608433}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:15:29,325] Trial 161 finished with value: 0.262888981189355 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.000524487490599633, 'p_miss': 0.023435665066820544}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:15:42,756] Trial 162 finished with value: 0.26375034387648066 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 3, 'learning_rate': 0.004897877866695408, 'p_miss': 0.06101979497524532}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:15:50,445] Trial 163 finished with value: 0.45068327337854014 and parameters: {'model_name': 'GAIN', 'batch_size': 52, 'hint_rate': 0.7478168995157217, 'alpha': 78, 'iterations': 1, 'learning_rate': 0.0017180547818464926, 'p_miss': 0.17888081858827368}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:16:04,053] Trial 164 finished with value: 0.26307914223561524 and parameters: {'model_name': 'VAE', 'batch_size': 348, 'iterations': 2, 'learning_rate': 0.0008294224307766377, 'p_miss': 0.02928512510525445}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:16:21,684] Trial 165 finished with value: 0.2634536156775276 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 5, 'learning_rate': 0.000662311394467552, 'p_miss': 0.010850322030650571}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:16:32,410] Trial 166 finished with value: 0.2634741804290062 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 3, 'learning_rate': 0.0002745403737298498, 'p_miss': 0.03744089542758379}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:16:48,042] Trial 167 finished with value: 0.2613241873170116 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 4, 'learning_rate': 0.00040415791722885736, 'p_miss': 0.047502020381637505}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:17:03,601] Trial 168 finished with value: 0.2610974316913872 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 6, 'learning_rate': 0.00029874059894236644, 'p_miss': 0.020501313673726634}. Best is trial 114 with value: 0.2600545336593759.
running
[I 2024-11-22 18:17:25,057] Trial 169 finished with value: 0.25980053098540734 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.0003175376906157667, 'p_miss': 0.016012569505971488}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:17:50,273] Trial 170 finished with value: 0.26323682864986114 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 8, 'learning_rate': 0.00020772313781359736, 'p_miss': 0.016220262093710885}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:18:21,773] Trial 171 finished with value: 0.2620411394504895 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 11, 'learning_rate': 0.00024665817272099497, 'p_miss': 0.021720403063415165}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:18:47,148] Trial 172 finished with value: 0.2613356499858293 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.00018217049134259102, 'p_miss': 0.03151904821048669}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:19:27,914] Trial 173 finished with value: 0.3365569944482449 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:19:52,782] Trial 174 finished with value: 0.2622846909218516 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 6, 'learning_rate': 0.0003171356578176107, 'p_miss': 0.01556613896799913}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:20:24,175] Trial 175 finished with value: 0.26163161901891047 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 10, 'learning_rate': 0.0004624937588678492, 'p_miss': 0.023026495295597166}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:21:16,546] Trial 176 finished with value: 0.27869807609352193 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 15, 'learning_rate': 0.007177186483649657, 'p_miss': 0.028415052234923757}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:21:35,287] Trial 177 finished with value: 0.2611773442552171 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.0005443795351414702, 'p_miss': 0.018100013062168508}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:21:56,610] Trial 178 finished with value: 0.26172564467130555 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 5, 'learning_rate': 0.0002884539403947927, 'p_miss': 0.032911824607404584}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:22:12,720] Trial 179 finished with value: 0.26642513572966653 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 4, 'learning_rate': 0.01073794347607136, 'p_miss': 0.08439095850119815}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:22:32,844] Trial 180 finished with value: 0.2631933719997279 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 6, 'learning_rate': 0.001191952810289737, 'p_miss': 0.044377884704248007}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:23:07,556] Trial 181 finished with value: 0.2617192107317296 and parameters: {'model_name': 'VAE', 'batch_size': 123, 'iterations': 13, 'learning_rate': 0.00041272181845420573, 'p_miss': 0.01272952279773805}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:23:14,615] Trial 182 finished with value: 0.261205550335295 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 2, 'learning_rate': 0.0007449583798851082, 'p_miss': 0.02123269673057203}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:24:12,466] Trial 183 finished with value: 0.2609470776171649 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 18, 'learning_rate': 0.00023394373403598748, 'p_miss': 0.010129332324422372}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:25:27,536] Trial 184 finished with value: 0.26144989468429364 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 22, 'learning_rate': 0.0002411590355497464, 'p_miss': 0.010801787862003025}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:25:51,721] Trial 185 finished with value: 0.32847658519537987 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 33926, 'weights': 'distance'}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:26:37,905] Trial 186 finished with value: 0.2628935764422503 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 17, 'learning_rate': 0.0001521826961393071, 'p_miss': 0.024718508307396678}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:27:44,842] Trial 187 finished with value: 0.26184622927211787 and parameters: {'model_name': 'VAE', 'batch_size': 11, 'iterations': 26, 'learning_rate': 0.00032241338037359283, 'p_miss': 0.01688423363340503}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:29:53,959] Trial 188 finished with value: 0.2671042616692462 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 42, 'learning_rate': 0.0010095436593970128, 'p_miss': 0.03453583983241942}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:35:43,261] Trial 189 finished with value: 0.31102054011537483 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 127, 'learning_rate': 0.0013739161097217271, 'p_miss': 0.056880510912658167}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:36:09,206] Trial 190 finished with value: 0.26266482894038784 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 8, 'learning_rate': 0.0005050402017171222, 'p_miss': 0.010476402837641764}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:36:10,606] Trial 191 finished with value: 0.45234011750037073 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:36:39,475] Trial 192 finished with value: 0.2643698119615679 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 9, 'learning_rate': 0.00022388673333340061, 'p_miss': 0.02758425038898997}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:36:54,162] Trial 193 finished with value: 0.2631395859162985 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 4, 'learning_rate': 0.0006118268377219957, 'p_miss': 0.020869201594170772}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:37:43,975] Trial 194 finished with value: 0.2634991042247851 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 17, 'learning_rate': 0.00037409588294029213, 'p_miss': 0.03911591099418245}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:37:53,906] Trial 195 finished with value: 0.4518580950006469 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.20843256094559104, 'alpha': 30, 'iterations': 3, 'learning_rate': 0.0004671482896460482, 'p_miss': 0.06521834660781489}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:38:17,601] Trial 196 finished with value: 0.26116762007853833 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 7, 'learning_rate': 0.0005658614112061861, 'p_miss': 0.01797138646038532}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:38:33,790] Trial 197 finished with value: 0.26393796352044097 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 5, 'learning_rate': 0.0007042935477472062, 'p_miss': 0.016003449554127802}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:39:09,333] Trial 198 finished with value: 0.26227100597866243 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 12, 'learning_rate': 0.0005642895941279423, 'p_miss': 0.010223000075014707}. Best is trial 169 with value: 0.25980053098540734.
running
[I 2024-11-22 18:39:31,952] Trial 199 finished with value: 0.26455294755384523 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 6, 'learning_rate': 0.0003855794228298299, 'p_miss': 0.021357763779640816}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 18:52:20,148] Trial 121 finished with value: 0.32559961931444786 and parameters: {'model_name': 'VAE', 'batch_size': 115, 'iterations': 4236, 'learning_rate': 0.00038078676991528917, 'p_miss': 0.042892436524475074}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 19:05:37,761] Trial 30 finished with value: 0.36291592861530947 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8046, 'learning_rate': 0.0010397397306078182, 'p_miss': 0.011270516207087744}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 19:24:48,154] Trial 27 finished with value: 0.3711232930675773 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7266, 'learning_rate': 0.0408393784987263, 'p_miss': 0.2841899275996643}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:22:55,906] Trial 25 finished with value: 0.3721004769017962 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 7502, 'learning_rate': 0.07960754729739206, 'p_miss': 0.28887221435562116}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:23:46,010] Trial 26 finished with value: 0.3689812436653205 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8109, 'learning_rate': 0.09577522960785907, 'p_miss': 0.2881714339092633}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:27:02,432] Trial 139 finished with value: 0.3251815686454691 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 7319, 'learning_rate': 0.003822843852083576, 'p_miss': 0.02647956639471661}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:37:58,138] Trial 28 finished with value: 0.3875969996835793 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8355, 'learning_rate': 0.04469041810676578, 'p_miss': 0.2864895380391955}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:41:32,101] Trial 104 finished with value: 0.3270642187033881 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 7529, 'learning_rate': 0.00035783755599519266, 'p_miss': 0.03594851791443088}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:44:56,030] Trial 146 finished with value: 0.3267660545820623 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 4860, 'learning_rate': 0.000589838709133494, 'p_miss': 0.059512202529525146}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:51:08,080] Trial 118 finished with value: 0.32570252584374687 and parameters: {'model_name': 'VAE', 'batch_size': 107, 'iterations': 8403, 'learning_rate': 0.0005126831820897785, 'p_miss': 0.01951748139751668}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:51:37,791] Trial 123 finished with value: 0.3281771630092602 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 8021, 'learning_rate': 0.0003231692579471587, 'p_miss': 0.04833367920480293}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:51:51,412] Trial 89 finished with value: 0.3596229484767806 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 9503, 'learning_rate': 0.0006469099711503598, 'p_miss': 0.020646919555809197}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:52:06,007] Trial 143 finished with value: 0.32545242669705593 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 7589, 'learning_rate': 0.0005684207626610412, 'p_miss': 0.0241929205401162}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:53:30,330] Trial 135 finished with value: 0.32467358613647934 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 7892, 'learning_rate': 0.00030903535612789604, 'p_miss': 0.010012736622595365}. Best is trial 169 with value: 0.25980053098540734.
[I 2024-11-22 20:55:31,111] Trial 144 finished with value: 0.32318061247241003 and parameters: {'model_name': 'VAE', 'batch_size': 382, 'iterations': 8153, 'learning_rate': 0.003615226742541069, 'p_miss': 0.023517359649479014}. Best is trial 169 with value: 0.25980053098540734.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
dtype: int64
0.25980053098540734
{'model_name': 'VAE', 'batch_size': 6, 'iterations': 7, 'learning_rate': 0.0003175376906157667, 'p_miss': 0.016012569505971488}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0af0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  1
Best f1_score score: 0.3353730472837485
Generation:   4%|▍         | 1/25 [02:45<1:06:04, 165.20s/it]Generation:  2
Best f1_score score: 0.3401271376984971
Generation:   8%|▊         | 2/25 [07:10<1:26:00, 224.35s/it]Generation:  3
Best f1_score score: 0.3403226624023109
Generation:  12%|█▏        | 3/25 [14:19<1:56:30, 317.74s/it]Generation:  4
Best f1_score score: 0.3403226624023109
Generation:  16%|█▌        | 4/25 [19:30<1:50:15, 315.03s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f06170> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1f00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474733610> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  5
Best f1_score score: 0.34232135415839265
Generation:  20%|██        | 5/25 [23:29<1:35:51, 287.58s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f5180> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  6
Best f1_score score: 0.34232135415839265
Generation:  24%|██▍       | 6/25 [26:44<1:21:03, 255.99s/it]Generation:  7
Best f1_score score: 0.34232135415839265
Generation:  28%|██▊       | 7/25 [29:54<1:10:23, 234.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a4f5e0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  8
Best f1_score score: 0.34232135415839265
Generation:  32%|███▏      | 8/25 [34:32<1:10:21, 248.33s/it]Generation:  9
Best f1_score score: 0.34232135415839265
Generation:  36%|███▌      | 9/25 [41:38<1:21:02, 303.91s/it]Generation:  10
Best f1_score score: 0.34232135415839265
Generation:  40%|████      | 10/25 [48:58<1:26:27, 345.85s/it]Generation:  11
Best f1_score score: 0.34232135415839265
Generation:  44%|████▍     | 11/25 [51:58<1:08:53, 295.23s/it]Generation:  12
Best f1_score score: 0.34232135415839265
Generation:  48%|████▊     | 12/25 [54:20<53:51, 248.60s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467528df0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  13
Best f1_score score: 0.34232135415839265
Generation:  52%|█████▏    | 13/25 [1:01:44<1:01:32, 307.71s/it]Generation:  14
Best f1_score score: 0.34232135415839265
Generation:  56%|█████▌    | 14/25 [1:11:14<1:10:56, 386.92s/it]Generation:  15
Best f1_score score: 0.34500285453922597
Generation:  60%|██████    | 15/25 [1:13:37<52:12, 313.25s/it]  Generation:  16
Best f1_score score: 0.34500285453922597
Generation:  64%|██████▍   | 16/25 [1:20:30<51:29, 343.33s/it]Generation:  17
Best f1_score score: 0.34568859107824246
Generation:  68%|██████▊   | 17/25 [1:21:34<34:35, 259.44s/it]Generation:  18
Best f1_score score: 0.34568859107824246
Generation:  72%|███████▏  | 18/25 [1:25:54<30:17, 259.65s/it]Generation:  19
Best f1_score score: 0.34568859107824246
Generation:  76%|███████▌  | 19/25 [1:33:22<31:36, 316.07s/it]Generation:  20
Best f1_score score: 0.34568859107824246
Generation:  80%|████████  | 20/25 [1:39:23<27:28, 329.64s/it]Generation:  21
Best f1_score score: 0.34854476133752765
Generation:  84%|████████▍ | 21/25 [1:45:04<22:12, 333.07s/it]Generation:  22
Best f1_score score: 0.34854476133752765
Generation:  88%|████████▊ | 22/25 [1:52:16<18:07, 362.62s/it]Generation:  23
Best f1_score score: 0.34854476133752765
Generation:  92%|█████████▏| 23/25 [1:56:28<10:58, 329.50s/it]Generation:  24
Best f1_score score: 0.34854476133752765
Generation:  96%|█████████▌| 24/25 [2:03:45<06:01, 361.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1900> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.34854476133752765
Generation: 100%|██████████| 25/25 [2:06:54<00:00, 309.98s/it]Generation: 100%|██████████| 25/25 [2:06:57<00:00, 304.71s/it]
2024-11-22 23:02:41,392 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:39461' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-db6c220a0c559c0ba34434e9f2a3f653', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732345361.392239')
Fitted
Pipeline(steps=[('extratreesclassifier',
                 ExtraTreesClassifier(bootstrap=True, class_weight='balanced',
                                      max_features=0.5034294671857,
                                      min_samples_leaf=7, min_samples_split=11,
                                      n_jobs=1))])
score start
train score: {'auroc': 0.8199430297890844, 'accuracy': 0.6624459629061498, 'balanced_accuracy': 0.6879037669848431, 'logloss': 0.9802067614870261, 'f1': 0.6417978215529859}
original test score: {'auroc': 0.5890492090060312, 'accuracy': 0.5158411423471665, 'balanced_accuracy': 0.37088323101893633, 'logloss': 1.0364421310091891, 'f1': 0.36009747325776836}
imputed test score: {'auroc': 0.5210646680168239, 'accuracy': 0.43395805443998214, 'balanced_accuracy': 0.35527855545597015, 'logloss': 1.0564143163377633, 'f1': 0.35357724905366233}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554350145b0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e20> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0bb0> 
 Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 302, in fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0eb0> 

Generation:  1
Best f1_score score: 0.49485201640533666
Generation:   4%|▍         | 1/25 [10:02<4:01:06, 602.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474715240> 

Generation:  2
Best f1_score score: 0.5081603139632883
Generation:   8%|▊         | 2/25 [20:07<3:51:23, 603.64s/it]Generation:  3
Best f1_score score: 0.508581738643372
Generation:  12%|█▏        | 3/25 [28:11<3:21:24, 549.32s/it]Generation:  4
Best f1_score score: 0.5109270313141753
Generation:  16%|█▌        | 4/25 [36:17<3:03:32, 524.39s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554671a0ca0> 

Generation:  5
Best f1_score score: 0.5115565486513409
Generation:  20%|██        | 5/25 [46:23<3:04:36, 553.81s/it]Generation:  6
Best f1_score score: 0.5115565486513409
Generation:  24%|██▍       | 6/25 [53:55<2:44:24, 519.18s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554649a84f0> 

Generation:  7
Best f1_score score: 0.5163497658074248
Generation:  28%|██▊       | 7/25 [1:04:02<2:44:17, 547.65s/it]Generation:  8
Best f1_score score: 0.5163497658074248
Generation:  32%|███▏      | 8/25 [1:10:25<2:20:20, 495.33s/it]Generation:  9
Best f1_score score: 0.5163497658074248
Generation:  36%|███▌      | 9/25 [1:20:12<2:19:46, 524.13s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464994460> 

Generation:  10
Best f1_score score: 0.5185807785579553
Generation:  40%|████      | 10/25 [1:30:18<2:17:18, 549.20s/it]Generation:  11
Best f1_score score: 0.5188135139123038
Generation:  44%|████▍     | 11/25 [1:37:13<1:58:33, 508.09s/it]Generation:  12
Best f1_score score: 0.5188135139123038
Generation:  48%|████▊     | 12/25 [1:43:32<1:41:36, 468.94s/it]Generation:  13
Best f1_score score: 0.5188135139123038
Generation:  52%|█████▏    | 13/25 [1:50:06<1:29:13, 446.13s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554644f43d0> 

Generation:  14
Best f1_score score: 0.5188135139123038
Generation:  56%|█████▌    | 14/25 [2:00:13<1:30:41, 494.72s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b4d7730> 

Generation:  15
Best f1_score score: 0.519040642103109
Generation:  60%|██████    | 15/25 [2:10:21<1:28:09, 528.90s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f247c0> 

Generation:  16
Best f1_score score: 0.519040642103109
Generation:  64%|██████▍   | 16/25 [2:20:32<1:23:02, 553.66s/it]Generation:  17
Best f1_score score: 0.5211848477777715
Generation:  68%|██████▊   | 17/25 [2:21:26<53:46, 403.35s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15544d360520> 

Generation:  18
Best f1_score score: 0.5211848477777715
Generation:  72%|███████▏  | 18/25 [2:31:32<54:10, 464.32s/it]Generation:  19
Best f1_score score: 0.5211848477777715
Generation:  76%|███████▌  | 19/25 [2:38:46<45:31, 455.19s/it]Generation:  20
Best f1_score score: 0.5211848477777715
Generation:  80%|████████  | 20/25 [2:45:06<36:03, 432.63s/it]Generation:  21
Best f1_score score: 0.5211848477777715
Generation:  84%|████████▍ | 21/25 [2:46:04<21:21, 320.35s/it]Generation:  22
Best f1_score score: 0.5211848477777715
Generation:  88%|████████▊ | 22/25 [2:50:33<15:14, 304.75s/it]Generation:  23
Best f1_score score: 0.5211848477777715
Generation:  92%|█████████▏| 23/25 [2:56:53<10:54, 327.24s/it]Generation:  24
Best f1_score score: 0.5214862006789831
Generation:  96%|█████████▌| 24/25 [3:03:16<05:44, 344.13s/it]Generation:  25
Best f1_score score: 0.5214862006789831
Generation: 100%|██████████| 25/25 [3:09:49<00:00, 358.88s/it]Generation: 100%|██████████| 25/25 [3:09:49<00:00, 455.59s/it]
2024-11-23 02:12:43,763 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:36721' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-3023ccd7d2107eaa0f54434f229bc361', 'ndarray-bbcff8349ee42c708f6fa6a3154c2ae0'} (stimulus_id='handle-worker-cleanup-1732356763.7635195')
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=8,
                                n_estimators=81, n_jobs=1, num_leaves=44,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.8141894759137372, 'accuracy': 0.6004462418072793, 'balanced_accuracy': 0.6205629590668102, 'logloss': 0.8157849345585009, 'f1': 0.5542503882828046}
test score: {'auroc': 0.784948706996269, 'accuracy': 0.5759705488621151, 'balanced_accuracy': 0.5829585036004096, 'logloss': 0.8559051460414365, 'f1': 0.5267093299662082}
original test score: {'auroc': 0.9524867049513229, 'accuracy': 0.81871932173137, 'balanced_accuracy': 0.8366288164007317, 'logloss': 0.4273148243830046, 'f1': 0.7784633011272949}
score end
41027
lvl
0.5
type
MCAR
num_run
3
class_full
finished
all finished
full run takes
11.730661098294789
hours
DONE
