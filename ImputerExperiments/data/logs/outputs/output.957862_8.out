Run: 8
/cm/local/apps/slurm/var/spool/job957862/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
starting loops
../data/r/189/189.pkl
working on 
../data/r/189/reg_full_MAR_0.5_1
2.9013829231262207
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-09-19 17:54:46,342] A new study created in memory with name: no-name-57a8c49a-5194-420f-b406-a806d18150ed
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-09-19 17:54:47,167] Trial 0 finished with value: 0.42625682129010284 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.42625682129010284.
[I 2024-09-19 17:54:47,170] Trial 10 finished with value: 0.42625682129010284 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.42625682129010284.
running
running
[I 2024-09-19 17:54:47,489] Trial 4 finished with value: 0.3529543631846269 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.3529543631846269.
[I 2024-09-19 17:54:47,602] Trial 12 finished with value: 0.42625682129010284 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.3529543631846269.
running
running
[I 2024-09-19 17:54:47,780] Trial 6 finished with value: 0.42625682129010284 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 4 with value: 0.3529543631846269.
running
[I 2024-09-19 17:54:47,906] Trial 5 finished with value: 0.3529543631846269 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.3529543631846269.
[I 2024-09-19 17:54:48,099] Trial 17 finished with value: 0.3529543631846269 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 4 with value: 0.3529543631846269.
running
running
[I 2024-09-19 17:54:48,305] Trial 20 finished with value: 0.2592414823395561 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 20 with value: 0.2592414823395561.
running
[I 2024-09-19 17:54:49,728] Trial 14 finished with value: 0.25800940394165645 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6438, 'weights': 'distance'}. Best is trial 14 with value: 0.25800940394165645.
running
[I 2024-09-19 17:54:49,886] Trial 1 finished with value: 0.2549280212342482 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2336, 'weights': 'distance'}. Best is trial 1 with value: 0.2549280212342482.
running
[I 2024-09-19 17:54:50,104] Trial 18 finished with value: 0.25800940394165645 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6131, 'weights': 'distance'}. Best is trial 1 with value: 0.2549280212342482.
running
[I 2024-09-19 17:54:50,348] Trial 21 finished with value: 0.25372187656880074 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 818, 'weights': 'distance'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:52,045] Trial 26 finished with value: 0.2542540270025461 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1638, 'weights': 'distance'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:52,248] Trial 27 finished with value: 0.25373839711582746 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 664, 'weights': 'uniform'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:55,235] Trial 24 finished with value: 0.2562766294371218 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:56,435] Trial 7 finished with value: 0.27444628195690973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:56,891] Trial 8 finished with value: 0.2834105885448423 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:57,671] Trial 9 finished with value: 0.3345889282101318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:54:59,150] Trial 29 finished with value: 0.3494276755586746 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 21 with value: 0.25372187656880074.
running
[I 2024-09-19 17:55:05,099] Trial 23 finished with value: 0.22170014785371253 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1, 'learning_rate': 0.0054730920169144106, 'p_miss': 0.21885729441660773}. Best is trial 23 with value: 0.22170014785371253.
running
[I 2024-09-19 17:55:10,687] Trial 22 finished with value: 0.37921161777000095 and parameters: {'model_name': 'GAIN', 'batch_size': 264, 'hint_rate': 0.29476301336336597, 'alpha': 72, 'iterations': 4, 'learning_rate': 0.0033935777609156513, 'p_miss': 0.29446224850957853}. Best is trial 23 with value: 0.22170014785371253.
running
[I 2024-09-19 17:55:11,096] Trial 35 finished with value: 0.22078329808737318 and parameters: {'model_name': 'VAE', 'batch_size': 22, 'iterations': 1, 'learning_rate': 0.00915954574257937, 'p_miss': 0.2403438067850788}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:16,366] Trial 36 finished with value: 0.24257169521159364 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.07984425662032904, 'p_miss': 0.16356610719045175}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:16,878] Trial 37 finished with value: 0.22343144410431806 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1, 'learning_rate': 0.011053419157520169, 'p_miss': 0.23167543459866552}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:17,551] Trial 3 finished with value: 0.22364193782164285 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 5, 'learning_rate': 0.0006312633501341873, 'p_miss': 0.16155514734673176}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:20,192] Trial 32 finished with value: 0.3988381593680122 and parameters: {'model_name': 'GAIN', 'batch_size': 60, 'hint_rate': 0.8816109397172229, 'alpha': 85, 'iterations': 11, 'learning_rate': 0.014281149403979447, 'p_miss': 0.1918061348264434}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:21,053] Trial 2 finished with value: 0.3818739356205097 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.05094027120976755, 'alpha': 48, 'iterations': 11, 'learning_rate': 0.00018883113218613545, 'p_miss': 0.23708603573431705}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:22,874] Trial 38 finished with value: 0.2261173228859111 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.055527837454010964, 'p_miss': 0.19880978627313217}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:23,174] Trial 30 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.5431494979585367, 'alpha': 100, 'iterations': 76, 'learning_rate': 0.001131650283814203, 'p_miss': 0.1838239460119176}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:23,473] Trial 40 finished with value: 0.227399495391228 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 1, 'learning_rate': 0.01003897885987423, 'p_miss': 0.2506731188437939}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:55:25,655] Trial 39 finished with value: 0.2241376325338992 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 1, 'learning_rate': 0.010701569639674703, 'p_miss': 0.23679008912459235}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:56:01,721] Trial 16 finished with value: 0.3932628256350389 and parameters: {'model_name': 'GAIN', 'batch_size': 73, 'hint_rate': 0.22002999723864733, 'alpha': 3, 'iterations': 36, 'learning_rate': 0.0011004274373637773, 'p_miss': 0.22590103754979154}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:56:46,659] Trial 31 finished with value: 0.22220244112576276 and parameters: {'model_name': 'VAE', 'batch_size': 434, 'iterations': 20, 'learning_rate': 0.0008511814380819458, 'p_miss': 0.137994459978687}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:56:53,688] Trial 25 finished with value: 0.22203535947116668 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 36, 'learning_rate': 0.0009866862420408868, 'p_miss': 0.03272697774087251}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 17:57:29,791] Trial 33 finished with value: 0.22664564113929586 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 51, 'learning_rate': 0.0009164108689596299, 'p_miss': 0.2800820379354242}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:00:13,172] Trial 19 finished with value: 0.27080811171329505 and parameters: {'model_name': 'VAE', 'batch_size': 5, 'iterations': 79, 'learning_rate': 0.013865982650148496, 'p_miss': 0.2125808637912295}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:03:47,565] Trial 34 finished with value: 0.26099843806662915 and parameters: {'model_name': 'VAE', 'batch_size': 854, 'iterations': 114, 'learning_rate': 0.0017065353468758994, 'p_miss': 0.08181353335045854}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:15:25,167] Trial 11 finished with value: 0.24314429447812413 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 437, 'learning_rate': 0.0003977879312718884, 'p_miss': 0.14238579310916763}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:25:55,465] Trial 15 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.3498494380330527, 'alpha': 30, 'iterations': 6914, 'learning_rate': 0.001400104508327516, 'p_miss': 0.06504250938491345}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:29:43,551] Trial 42 finished with value: 0.2648050162530821 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 529, 'learning_rate': 0.009809299082070028, 'p_miss': 0.25317123142066555}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:29:52,068] Trial 46 finished with value: 0.2642074921766353 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 605, 'learning_rate': 0.003081047119716813, 'p_miss': 0.08683852690654259}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:29:56,220] Trial 55 finished with value: 0.22271230331887332 and parameters: {'model_name': 'VAE', 'batch_size': 44, 'iterations': 3, 'learning_rate': 0.0036050457013812663, 'p_miss': 0.01261155835720101}. Best is trial 35 with value: 0.22078329808737318.
running
[I 2024-09-19 18:30:12,465] Trial 56 finished with value: 0.2196228205148733 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 4, 'learning_rate': 0.0044895274432126455, 'p_miss': 0.01813700045479741}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:30:13,229] Trial 57 finished with value: 0.22098440729331617 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 3, 'learning_rate': 0.004286561475869543, 'p_miss': 0.010707292358491875}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:30:25,309] Trial 59 finished with value: 0.22119684665886147 and parameters: {'model_name': 'VAE', 'batch_size': 121, 'iterations': 2, 'learning_rate': 0.005145103438633152, 'p_miss': 0.014049898413248087}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:30:47,433] Trial 60 finished with value: 0.2237503223023992 and parameters: {'model_name': 'VAE', 'batch_size': 130, 'iterations': 3, 'learning_rate': 0.0048073488224681426, 'p_miss': 0.013814741549653606}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:31:01,912] Trial 61 finished with value: 0.21966715624505878 and parameters: {'model_name': 'VAE', 'batch_size': 128, 'iterations': 2, 'learning_rate': 0.0063279821413979075, 'p_miss': 0.04873860143593996}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:31:14,240] Trial 58 finished with value: 0.24360260005105555 and parameters: {'model_name': 'VAE', 'batch_size': 101, 'iterations': 18, 'learning_rate': 0.006454729836756342, 'p_miss': 0.0154541748122454}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:31:18,546] Trial 62 finished with value: 0.24065180890616372 and parameters: {'model_name': 'VAE', 'batch_size': 129, 'iterations': 2, 'learning_rate': 0.02667175671002014, 'p_miss': 0.043746659987701664}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:31:32,986] Trial 63 finished with value: 0.253457362242564 and parameters: {'model_name': 'VAE', 'batch_size': 164, 'iterations': 2, 'learning_rate': 0.029164749091908186, 'p_miss': 0.04069582121182044}. Best is trial 56 with value: 0.2196228205148733.
running
[I 2024-09-19 18:31:47,752] Trial 64 finished with value: 0.21931920971081972 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 7, 'learning_rate': 0.0024744900724880817, 'p_miss': 0.04379926419941416}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:32:05,065] Trial 65 finished with value: 0.22091169527388482 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 8, 'learning_rate': 0.0025548092107403144, 'p_miss': 0.06143949309969468}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:32:16,281] Trial 66 finished with value: 0.2200030452091261 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 7, 'learning_rate': 0.00246704167713314, 'p_miss': 0.056976906160973895}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:32:27,821] Trial 67 finished with value: 0.22492269136396043 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 7, 'learning_rate': 0.0021682763405766517, 'p_miss': 0.0573316471577809}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:32:49,112] Trial 68 finished with value: 0.22163602864438156 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 7, 'learning_rate': 0.0021460534385920695, 'p_miss': 0.06442830188780277}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:33:00,601] Trial 69 finished with value: 0.22286264639454262 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 8, 'learning_rate': 0.002210057560498749, 'p_miss': 0.11078958440286937}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:33:29,740] Trial 70 finished with value: 0.22191267274414495 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 10, 'learning_rate': 0.0022465101834855464, 'p_miss': 0.11670842605711336}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:37:55,221] Trial 52 finished with value: 0.26556568014916027 and parameters: {'model_name': 'VAE', 'batch_size': 51, 'iterations': 615, 'learning_rate': 0.0037559145868189675, 'p_miss': 0.014587922845174933}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:38:15,545] Trial 51 finished with value: 0.2637318241938663 and parameters: {'model_name': 'VAE', 'batch_size': 791, 'iterations': 543, 'learning_rate': 0.0024277313188341243, 'p_miss': 0.06452643134589958}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:38:16,382] Trial 74 finished with value: 0.426251768520966 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:41:40,655] Trial 54 finished with value: 0.2664377904053352 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 305, 'learning_rate': 0.0035993956666771384, 'p_miss': 0.010891705222492595}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:49:45,970] Trial 71 finished with value: 0.28461313115158765 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:06,882] Trial 72 finished with value: 0.2836978863908106 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:09,858] Trial 77 finished with value: 0.2261166762021194 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 5, 'learning_rate': 0.0004265695739918342, 'p_miss': 0.03768098751944189}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:22,961] Trial 78 finished with value: 0.22480756433944077 and parameters: {'model_name': 'VAE', 'batch_size': 76, 'iterations': 4, 'learning_rate': 0.00032161911904406555, 'p_miss': 0.03304468114174504}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:33,368] Trial 80 finished with value: 0.2227720255778674 and parameters: {'model_name': 'VAE', 'batch_size': 24, 'iterations': 2, 'learning_rate': 0.007056852308169942, 'p_miss': 0.0873632918738681}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:33,590] Trial 79 finished with value: 0.22733599902650323 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 4, 'learning_rate': 0.007202205412990393, 'p_miss': 0.050310815361679626}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:36,689] Trial 82 finished with value: 0.25816719395031007 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4344, 'weights': 'uniform'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:36,947] Trial 81 finished with value: 0.2578488683947221 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4136, 'weights': 'uniform'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:37,655] Trial 84 finished with value: 0.426251768520966 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:37,915] Trial 83 finished with value: 0.426251768520966 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:50:57,982] Trial 86 finished with value: 0.22005586539396388 and parameters: {'model_name': 'VAE', 'batch_size': 223, 'iterations': 2, 'learning_rate': 0.004881266300651752, 'p_miss': 0.031117402852530816}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:51:14,629] Trial 85 finished with value: 0.4137550956809363 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.9028963450392274, 'alpha': 3, 'iterations': 22, 'learning_rate': 0.019833576310970245, 'p_miss': 0.07588849211441981}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:51:40,067] Trial 88 finished with value: 0.22029884067209388 and parameters: {'model_name': 'VAE', 'batch_size': 239, 'iterations': 3, 'learning_rate': 0.004791066368521249, 'p_miss': 0.0263092464112942}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:51:56,038] Trial 89 finished with value: 0.2209191144412396 and parameters: {'model_name': 'VAE', 'batch_size': 281, 'iterations': 2, 'learning_rate': 0.007312577349396433, 'p_miss': 0.029338146348169697}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:05,371] Trial 49 finished with value: 0.26418429853773917 and parameters: {'model_name': 'VAE', 'batch_size': 521, 'iterations': 742, 'learning_rate': 0.0021891790978471686, 'p_miss': 0.0641494048121144}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:14,850] Trial 90 finished with value: 0.22343983489473454 and parameters: {'model_name': 'VAE', 'batch_size': 9, 'iterations': 6, 'learning_rate': 0.0013866646435450754, 'p_miss': 0.028789878473767804}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:33,655] Trial 48 finished with value: 0.26288941223045703 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 943, 'learning_rate': 0.004552842515252703, 'p_miss': 0.09574833047330435}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:34,144] Trial 87 finished with value: 0.2218034325510893 and parameters: {'model_name': 'VAE', 'batch_size': 205, 'iterations': 20, 'learning_rate': 0.0014025095420333272, 'p_miss': 0.03174019874036373}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:36,532] Trial 91 finished with value: 0.2198899010754546 and parameters: {'model_name': 'VAE', 'batch_size': 227, 'iterations': 6, 'learning_rate': 0.001515050473850332, 'p_miss': 0.02834526964056228}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:52:59,574] Trial 94 finished with value: 0.2215249291522489 and parameters: {'model_name': 'VAE', 'batch_size': 325, 'iterations': 3, 'learning_rate': 0.002997923559051907, 'p_miss': 0.05378579525063257}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:03,620] Trial 95 finished with value: 0.4188092806861795 and parameters: {'model_name': 'GAIN', 'batch_size': 372, 'hint_rate': 0.5867950667764105, 'alpha': 35, 'iterations': 14, 'learning_rate': 0.000740663755683415, 'p_miss': 0.048287951232801773}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:12,022] Trial 92 finished with value: 0.22191207710797672 and parameters: {'model_name': 'VAE', 'batch_size': 210, 'iterations': 11, 'learning_rate': 0.002951137646510238, 'p_miss': 0.049192230842353746}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:23,438] Trial 50 finished with value: 0.2642777123456298 and parameters: {'model_name': 'VAE', 'batch_size': 443, 'iterations': 738, 'learning_rate': 0.0034472129441948276, 'p_miss': 0.08492251603858743}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:50,195] Trial 97 finished with value: 0.2221142380285727 and parameters: {'model_name': 'VAE', 'batch_size': 205, 'iterations': 10, 'learning_rate': 0.001546004861800247, 'p_miss': 0.02742433562187165}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:51,696] Trial 99 finished with value: 0.22117718683954637 and parameters: {'model_name': 'VAE', 'batch_size': 209, 'iterations': 5, 'learning_rate': 0.0014573812607580649, 'p_miss': 0.02364737057223096}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:54,209] Trial 73 finished with value: 0.28335622660060056 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:55,330] Trial 96 finished with value: 0.21937963003075608 and parameters: {'model_name': 'VAE', 'batch_size': 229, 'iterations': 14, 'learning_rate': 0.0015176279242600603, 'p_miss': 0.04837764915331058}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:53:59,198] Trial 98 finished with value: 0.2273067176907409 and parameters: {'model_name': 'VAE', 'batch_size': 206, 'iterations': 6, 'learning_rate': 0.005532608773037936, 'p_miss': 0.0225001253322379}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:04,538] Trial 93 finished with value: 0.2254047140610913 and parameters: {'model_name': 'VAE', 'batch_size': 217, 'iterations': 18, 'learning_rate': 0.0032100805090567713, 'p_miss': 0.05425447009134657}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:08,488] Trial 100 finished with value: 0.22143339353009042 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 5, 'learning_rate': 0.006042111502799045, 'p_miss': 0.024447267660004286}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:08,920] Trial 102 finished with value: 0.2197258742891366 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 3, 'learning_rate': 0.00587945454579354, 'p_miss': 0.17366508108157533}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:23,020] Trial 107 finished with value: 0.22156131952886127 and parameters: {'model_name': 'VAE', 'batch_size': 19, 'iterations': 3, 'learning_rate': 0.008218414083816942, 'p_miss': 0.20910406028494635}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:24,599] Trial 75 finished with value: 0.2867520856290089 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:25,856] Trial 105 finished with value: 0.22457297483315028 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 3, 'learning_rate': 0.008873820525650307, 'p_miss': 0.07405208925536244}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:31,710] Trial 104 finished with value: 0.23860517258610395 and parameters: {'model_name': 'VAE', 'batch_size': 531, 'iterations': 3, 'learning_rate': 0.013100087834616627, 'p_miss': 0.1757245524052708}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:54:44,446] Trial 109 finished with value: 0.22079896462800974 and parameters: {'model_name': 'VAE', 'batch_size': 506, 'iterations': 4, 'learning_rate': 0.001130360247250483, 'p_miss': 0.15876693758806676}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:56:23,897] Trial 106 finished with value: 0.22485490302633387 and parameters: {'model_name': 'VAE', 'batch_size': 152, 'iterations': 36, 'learning_rate': 0.0011013916529659445, 'p_miss': 0.03926675668153814}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:56:27,616] Trial 111 finished with value: 0.2216106783522272 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 33, 'learning_rate': 0.0017746698956795342, 'p_miss': 0.1421740341599332}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:56:59,346] Trial 108 finished with value: 0.2639759331821601 and parameters: {'model_name': 'VAE', 'batch_size': 152, 'iterations': 38, 'learning_rate': 0.013092743135899367, 'p_miss': 0.1664586742488319}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:00,000] Trial 76 finished with value: 0.2825973415516163 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'ascending'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:01,324] Trial 115 finished with value: 0.25691443458771446 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3508, 'weights': 'uniform'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:21,932] Trial 103 finished with value: 0.2645693894746403 and parameters: {'model_name': 'VAE', 'batch_size': 547, 'iterations': 35, 'learning_rate': 0.005781089760321031, 'p_miss': 0.07275203201401187}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:27,406] Trial 117 finished with value: 0.22552501406518638 and parameters: {'model_name': 'VAE', 'batch_size': 620, 'iterations': 4, 'learning_rate': 0.004009645336558204, 'p_miss': 0.27629504930101234}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:30,482] Trial 116 finished with value: 0.22054543563417628 and parameters: {'model_name': 'VAE', 'batch_size': 728, 'iterations': 4, 'learning_rate': 0.004210561886485804, 'p_miss': 0.13275483782215938}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:32,302] Trial 119 finished with value: 0.2247078370107433 and parameters: {'model_name': 'VAE', 'batch_size': 283, 'iterations': 1, 'learning_rate': 0.00012141614503576361, 'p_miss': 0.1532191868309682}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:39,827] Trial 121 finished with value: 0.21955456601414078 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 2, 'learning_rate': 0.0043085754656172585, 'p_miss': 0.11829812095326475}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:40,204] Trial 118 finished with value: 0.2231083319820056 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 4, 'learning_rate': 0.004681074852819202, 'p_miss': 0.15171634213792487}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:44,283] Trial 120 finished with value: 0.2228046629938838 and parameters: {'model_name': 'VAE', 'batch_size': 274, 'iterations': 2, 'learning_rate': 0.004886867809923005, 'p_miss': 0.0454217508608111}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:47,969] Trial 122 finished with value: 0.22804192324149639 and parameters: {'model_name': 'VAE', 'batch_size': 58, 'iterations': 2, 'learning_rate': 0.004483775201552974, 'p_miss': 0.12515719570446848}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:57:51,532] Trial 123 finished with value: 0.22171139295447037 and parameters: {'model_name': 'VAE', 'batch_size': 57, 'iterations': 2, 'learning_rate': 0.004185919327736954, 'p_miss': 0.13299989448867}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:58:01,510] Trial 125 finished with value: 0.40410294983655587 and parameters: {'model_name': 'GAIN', 'batch_size': 104, 'hint_rate': 0.694318237314056, 'alpha': 67, 'iterations': 8, 'learning_rate': 0.0018278715738444442, 'p_miss': 0.1303882073333872}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:58:07,695] Trial 127 finished with value: 0.22347810115597713 and parameters: {'model_name': 'VAE', 'batch_size': 365, 'iterations': 1, 'learning_rate': 0.0028702085502350875, 'p_miss': 0.09731992257020995}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:58:33,360] Trial 128 finished with value: 0.2277668357513818 and parameters: {'model_name': 'VAE', 'batch_size': 30, 'iterations': 6, 'learning_rate': 0.008124632583711254, 'p_miss': 0.2494739296911096}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:58:48,400] Trial 129 finished with value: 0.22314963809592708 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 4, 'learning_rate': 0.006335625697266585, 'p_miss': 0.03734978777098745}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:59:35,939] Trial 130 finished with value: 0.22081838192808828 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 13, 'learning_rate': 0.002563036209146598, 'p_miss': 0.10810308770236701}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 18:59:36,309] Trial 131 finished with value: 0.2592414823395561 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:04:30,295] Trial 124 finished with value: 0.26270953756625065 and parameters: {'model_name': 'VAE', 'batch_size': 60, 'iterations': 156, 'learning_rate': 0.0027751720536798984, 'p_miss': 0.1335885968245726}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:04:43,303] Trial 133 finished with value: 0.22329907091085716 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 3, 'learning_rate': 0.003795712507451007, 'p_miss': 0.19374505498706224}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:23:33,982] Trial 41 finished with value: 0.2694081614971204 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 1451, 'learning_rate': 0.009490942515022211, 'p_miss': 0.2543009613939657}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:23:47,019] Trial 47 finished with value: 0.2665582957287925 and parameters: {'model_name': 'VAE', 'batch_size': 6, 'iterations': 1648, 'learning_rate': 0.004141613215191124, 'p_miss': 0.08204178280865768}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:24:16,144] Trial 135 finished with value: 0.23926390304438092 and parameters: {'model_name': 'VAE', 'batch_size': 877, 'iterations': 5, 'learning_rate': 0.011022179516249713, 'p_miss': 0.019106402167278887}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:24:27,612] Trial 136 finished with value: 0.22462048309085034 and parameters: {'model_name': 'VAE', 'batch_size': 769, 'iterations': 5, 'learning_rate': 0.0009623377037097623, 'p_miss': 0.018436250074008953}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:24:47,624] Trial 137 finished with value: 0.22078452756880532 and parameters: {'model_name': 'VAE', 'batch_size': 702, 'iterations': 7, 'learning_rate': 0.0009067899749814552, 'p_miss': 0.16060553534770536}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:24:51,898] Trial 138 finished with value: 0.22209146241275723 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 8, 'learning_rate': 0.0011942878240321047, 'p_miss': 0.1778649877709659}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:25:17,566] Trial 139 finished with value: 0.221430313836423 and parameters: {'model_name': 'VAE', 'batch_size': 25, 'iterations': 8, 'learning_rate': 0.00059951018713347, 'p_miss': 0.03377996996495592}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:25:42,270] Trial 140 finished with value: 0.22541530649302288 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 14, 'learning_rate': 0.0005705075048827141, 'p_miss': 0.034572229375178974}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:25:50,540] Trial 141 finished with value: 0.22197558388846575 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 13, 'learning_rate': 0.0018671839306766288, 'p_miss': 0.1689757428785642}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:25:52,198] Trial 143 finished with value: 0.2592396587943634 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4983, 'weights': 'uniform'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:26:01,657] Trial 142 finished with value: 0.22220742018370396 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.0053474239839061645, 'p_miss': 0.14675317752514333}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:26:20,196] Trial 144 finished with value: 0.22142463062813683 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 6, 'learning_rate': 0.003496710281492231, 'p_miss': 0.14661103729872796}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:26:48,775] Trial 145 finished with value: 0.22943575716553094 and parameters: {'model_name': 'VAE', 'batch_size': 172, 'iterations': 10, 'learning_rate': 0.0007630252568230321, 'p_miss': 0.04399185315374306}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:27:17,976] Trial 147 finished with value: 0.22544886047576163 and parameters: {'model_name': 'VAE', 'batch_size': 663, 'iterations': 4, 'learning_rate': 0.0012780683946187303, 'p_miss': 0.16027639965908075}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:27:33,327] Trial 148 finished with value: 0.22404650898487613 and parameters: {'model_name': 'VAE', 'batch_size': 711, 'iterations': 2, 'learning_rate': 0.0008448048306937773, 'p_miss': 0.22459942332822608}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:43:40,466] Trial 45 finished with value: 0.26615179975540676 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 1761, 'learning_rate': 0.009023720891554208, 'p_miss': 0.05699789000308858}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:44:06,617] Trial 150 finished with value: 0.2235736577589534 and parameters: {'model_name': 'VAE', 'batch_size': 464, 'iterations': 3, 'learning_rate': 0.0069148401665064235, 'p_miss': 0.057705627030299}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:44:41,149] Trial 151 finished with value: 0.22295383569338778 and parameters: {'model_name': 'VAE', 'batch_size': 918, 'iterations': 5, 'learning_rate': 0.0016091558996648397, 'p_miss': 0.15642825912033326}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:44:50,811] Trial 152 finished with value: 0.3850519588982967 and parameters: {'model_name': 'GAIN', 'batch_size': 414, 'hint_rate': 0.01359478957360749, 'alpha': 25, 'iterations': 4, 'learning_rate': 0.002035605683458436, 'p_miss': 0.20683591458349948}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:45:32,478] Trial 153 finished with value: 0.22572240182837722 and parameters: {'model_name': 'VAE', 'batch_size': 244, 'iterations': 7, 'learning_rate': 0.005158547129517195, 'p_miss': 0.18488071024125366}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:45:44,375] Trial 154 finished with value: 0.22441163111960014 and parameters: {'model_name': 'VAE', 'batch_size': 35, 'iterations': 3, 'learning_rate': 0.0024693792302998554, 'p_miss': 0.27503799150533226}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:45:44,753] Trial 155 finished with value: 0.2592414823395561 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:46:41,674] Trial 156 finished with value: 0.2252343909661191 and parameters: {'model_name': 'VAE', 'batch_size': 48, 'iterations': 16, 'learning_rate': 0.0033130933240175294, 'p_miss': 0.11540537511933197}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:47:23,082] Trial 157 finished with value: 0.22480445167583069 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 11, 'learning_rate': 0.0010398502333640693, 'p_miss': 0.11429622530336785}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:47:53,542] Trial 158 finished with value: 0.22940338263007468 and parameters: {'model_name': 'VAE', 'batch_size': 29, 'iterations': 9, 'learning_rate': 0.005959505548450648, 'p_miss': 0.10118687703022088}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:48:12,819] Trial 53 finished with value: 0.2640285909858565 and parameters: {'model_name': 'VAE', 'batch_size': 63, 'iterations': 2023, 'learning_rate': 0.0038958156177558113, 'p_miss': 0.019844916044673085}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:48:30,698] Trial 159 finished with value: 0.22120160488629725 and parameters: {'model_name': 'VAE', 'batch_size': 323, 'iterations': 7, 'learning_rate': 0.002425504252286885, 'p_miss': 0.126159529579068}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:49:19,490] Trial 160 finished with value: 0.22214198104861865 and parameters: {'model_name': 'VAE', 'batch_size': 344, 'iterations': 12, 'learning_rate': 0.002624635677247848, 'p_miss': 0.1038647930600379}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:49:23,703] Trial 162 finished with value: 0.25613181424796877 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:50:01,100] Trial 161 finished with value: 0.26297110216280384 and parameters: {'model_name': 'VAE', 'batch_size': 583, 'iterations': 13, 'learning_rate': 0.007974506871943636, 'p_miss': 0.29140700273381037}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:50:12,624] Trial 163 finished with value: 0.2320768872832364 and parameters: {'model_name': 'VAE', 'batch_size': 609, 'iterations': 4, 'learning_rate': 0.007776515275786264, 'p_miss': 0.12109515564464562}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:51:32,692] Trial 165 finished with value: 0.2328260803204092 and parameters: {'model_name': 'VAE', 'batch_size': 21, 'iterations': 25, 'learning_rate': 0.004190373822176964, 'p_miss': 0.06932151610772865}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:51:56,081] Trial 166 finished with value: 0.22090302838576875 and parameters: {'model_name': 'VAE', 'batch_size': 45, 'iterations': 5, 'learning_rate': 0.0031318929296444216, 'p_miss': 0.05673760325113131}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:52:22,420] Trial 167 finished with value: 0.2203627678075361 and parameters: {'model_name': 'VAE', 'batch_size': 43, 'iterations': 6, 'learning_rate': 0.003143843811232271, 'p_miss': 0.04967647666679033}. Best is trial 64 with value: 0.21931920971081972.
running
[I 2024-09-19 19:52:36,786] Trial 168 finished with value: 0.21860135899794875 and parameters: {'model_name': 'VAE', 'batch_size': 36, 'iterations': 3, 'learning_rate': 0.004763264846266908, 'p_miss': 0.040824926909151474}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:52:50,794] Trial 169 finished with value: 0.2219527041378698 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 3, 'learning_rate': 0.004616574890468084, 'p_miss': 0.04201286483236699}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:53:08,632] Trial 170 finished with value: 0.22286652916018057 and parameters: {'model_name': 'VAE', 'batch_size': 41, 'iterations': 4, 'learning_rate': 0.005476239681185079, 'p_miss': 0.04917009694845257}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:53:30,203] Trial 171 finished with value: 0.22048903093255748 and parameters: {'model_name': 'VAE', 'batch_size': 982, 'iterations': 2, 'learning_rate': 0.003708832272278693, 'p_miss': 0.028412443862793825}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:53:51,151] Trial 172 finished with value: 0.2207559990965759 and parameters: {'model_name': 'VAE', 'batch_size': 945, 'iterations': 2, 'learning_rate': 0.003742139898879646, 'p_miss': 0.027658230840548206}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:54:09,628] Trial 173 finished with value: 0.22021675063108975 and parameters: {'model_name': 'VAE', 'batch_size': 987, 'iterations': 2, 'learning_rate': 0.003738664376346336, 'p_miss': 0.024812550244201377}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:54:35,120] Trial 174 finished with value: 0.22061900025043069 and parameters: {'model_name': 'VAE', 'batch_size': 999, 'iterations': 2, 'learning_rate': 0.003780473568098612, 'p_miss': 0.02591543978819435}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 19:54:37,611] Trial 175 finished with value: 0.2554773298985237 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2768, 'weights': 'distance'}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:23:05,456] Trial 13 finished with value: 0.29113520474230054 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2889, 'learning_rate': 0.00034477928044365585, 'p_miss': 0.22886512690831828}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:23:26,523] Trial 177 finished with value: 0.22192668615030597 and parameters: {'model_name': 'VAE', 'batch_size': 977, 'iterations': 2, 'learning_rate': 0.003600413633890592, 'p_miss': 0.026312527554126275}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:23:45,109] Trial 178 finished with value: 0.22205899942614896 and parameters: {'model_name': 'VAE', 'batch_size': 864, 'iterations': 2, 'learning_rate': 0.004071207664882651, 'p_miss': 0.02996763935736765}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:24:07,084] Trial 179 finished with value: 0.21961929599012864 and parameters: {'model_name': 'VAE', 'batch_size': 953, 'iterations': 2, 'learning_rate': 0.0032151935446489434, 'p_miss': 0.023047206373004274}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:24:39,844] Trial 180 finished with value: 0.21955701868042427 and parameters: {'model_name': 'VAE', 'batch_size': 778, 'iterations': 3, 'learning_rate': 0.003105999574207868, 'p_miss': 0.02122756022750313}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:25:12,884] Trial 181 finished with value: 0.22112580456816913 and parameters: {'model_name': 'VAE', 'batch_size': 819, 'iterations': 3, 'learning_rate': 0.003224362865953692, 'p_miss': 0.01726732333021469}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:25:49,178] Trial 182 finished with value: 0.2279114325136932 and parameters: {'model_name': 'VAE', 'batch_size': 742, 'iterations': 3, 'learning_rate': 0.004821856752793376, 'p_miss': 0.010380756674424382}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:26:09,198] Trial 183 finished with value: 0.22434646160929622 and parameters: {'model_name': 'VAE', 'batch_size': 52, 'iterations': 5, 'learning_rate': 0.0029018813437155034, 'p_miss': 0.037438800706305536}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:26:32,090] Trial 184 finished with value: 0.22113323916692035 and parameters: {'model_name': 'VAE', 'batch_size': 252, 'iterations': 3, 'learning_rate': 0.0064313531677969394, 'p_miss': 0.041869960836674734}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:26:43,374] Trial 185 finished with value: 0.22366677948498165 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 2, 'learning_rate': 0.002013569507008794, 'p_miss': 0.02101473525926303}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:27:06,013] Trial 186 finished with value: 0.22197550328691545 and parameters: {'model_name': 'VAE', 'batch_size': 798, 'iterations': 2, 'learning_rate': 0.004069925049228379, 'p_miss': 0.023513008037614126}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:27:19,895] Trial 187 finished with value: 0.22654976777079378 and parameters: {'model_name': 'VAE', 'batch_size': 994, 'iterations': 1, 'learning_rate': 0.0034148906553625917, 'p_miss': 0.03543610130468778}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:27:32,544] Trial 188 finished with value: 0.22227795736404263 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 4, 'learning_rate': 0.004762984167296607, 'p_miss': 0.0313557582159887}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:27:58,206] Trial 189 finished with value: 0.22296367443647677 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 6, 'learning_rate': 0.005669473727798259, 'p_miss': 0.0507342018115646}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:28:20,615] Trial 190 finished with value: 0.2235075581616642 and parameters: {'model_name': 'VAE', 'batch_size': 989, 'iterations': 2, 'learning_rate': 0.003706133323923539, 'p_miss': 0.016974157693110926}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:28:29,923] Trial 191 finished with value: 0.41768566255556916 and parameters: {'model_name': 'GAIN', 'batch_size': 84, 'hint_rate': 0.736025720146578, 'alpha': 54, 'iterations': 4, 'learning_rate': 0.0028342247484143502, 'p_miss': 0.023197469195982683}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:28:48,638] Trial 192 finished with value: 0.22292793680387718 and parameters: {'model_name': 'VAE', 'batch_size': 112, 'iterations': 3, 'learning_rate': 0.004320834886413543, 'p_miss': 0.041234247515127546}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:29:12,964] Trial 193 finished with value: 0.22827221405194767 and parameters: {'model_name': 'VAE', 'batch_size': 661, 'iterations': 2, 'learning_rate': 0.0031698434735394935, 'p_miss': 0.03350181156236276}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:44:07,401] Trial 194 finished with value: 0.264628408441531 and parameters: {'model_name': 'VAE', 'batch_size': 178, 'iterations': 209, 'learning_rate': 0.002308888832925735, 'p_miss': 0.04715213806067759}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:44:07,991] Trial 195 finished with value: 0.2592414823395561 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:44:31,421] Trial 196 finished with value: 0.22141274015725637 and parameters: {'model_name': 'VAE', 'batch_size': 863, 'iterations': 2, 'learning_rate': 0.003883887190029728, 'p_miss': 0.027618086114409742}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:44:58,650] Trial 197 finished with value: 0.2206748207904367 and parameters: {'model_name': 'VAE', 'batch_size': 993, 'iterations': 3, 'learning_rate': 0.005349962325270635, 'p_miss': 0.028176956048540893}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:52:35,285] Trial 198 finished with value: 0.26374665402533154 and parameters: {'model_name': 'VAE', 'batch_size': 797, 'iterations': 89, 'learning_rate': 0.005058145878893588, 'p_miss': 0.02142863256846797}. Best is trial 168 with value: 0.21860135899794875.
running
[I 2024-09-19 20:53:10,244] Trial 199 finished with value: 0.22503910066550553 and parameters: {'model_name': 'VAE', 'batch_size': 702, 'iterations': 3, 'learning_rate': 0.006469808795233566, 'p_miss': 0.03631712274391762}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 21:22:26,367] Trial 126 finished with value: 0.26402395609391127 and parameters: {'model_name': 'VAE', 'batch_size': 28, 'iterations': 2803, 'learning_rate': 0.0027527457815425794, 'p_miss': 0.2500607298150928}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 22:00:51,023] Trial 112 finished with value: 0.26341512549253954 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 2536, 'learning_rate': 0.00429100951264412, 'p_miss': 0.28320039242103034}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 22:06:15,674] Trial 134 finished with value: 0.3038996228277216 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 3737, 'learning_rate': 0.010343149927339725, 'p_miss': 0.019326073633751443}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 22:45:24,897] Trial 44 finished with value: 0.2683580351729437 and parameters: {'model_name': 'VAE', 'batch_size': 14, 'iterations': 6243, 'learning_rate': 0.00891989471788424, 'p_miss': 0.015855091801535687}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 22:54:21,927] Trial 101 finished with value: 0.2627422510470258 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 5073, 'learning_rate': 0.006247799810225577, 'p_miss': 0.15777763093180402}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 23:10:44,044] Trial 114 finished with value: 0.2652859893551313 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 6316, 'learning_rate': 0.0044116323419178165, 'p_miss': 0.271654366290215}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-19 23:57:45,834] Trial 113 finished with value: 0.26395843486254106 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 7798, 'learning_rate': 0.004309007540521225, 'p_miss': 0.14037192326717107}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:06:17,039] Trial 132 finished with value: 0.2632999609317913 and parameters: {'model_name': 'VAE', 'batch_size': 982, 'iterations': 6038, 'learning_rate': 0.0036311603583739837, 'p_miss': 0.020284584491793517}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:21:45,438] Trial 164 finished with value: 0.2660805165718977 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 8061, 'learning_rate': 0.004482931538133729, 'p_miss': 0.1230334007563517}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:32:48,926] Trial 146 finished with value: 0.26390023355271597 and parameters: {'model_name': 'VAE', 'batch_size': 637, 'iterations': 6509, 'learning_rate': 0.0008635748598481539, 'p_miss': 0.057037740524319494}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:33:02,646] Trial 28 finished with value: 0.2667525609130826 and parameters: {'model_name': 'VAE', 'batch_size': 26, 'iterations': 9993, 'learning_rate': 0.012168069931788199, 'p_miss': 0.010442050124406826}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:37:01,604] Trial 43 finished with value: 0.2677844933619253 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 9863, 'learning_rate': 0.009301308148440044, 'p_miss': 0.06798959546102414}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:40:45,689] Trial 110 finished with value: 0.26488413504220365 and parameters: {'model_name': 'VAE', 'batch_size': 620, 'iterations': 8021, 'learning_rate': 0.013829519310091657, 'p_miss': 0.16185471935040716}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:41:41,689] Trial 149 finished with value: 0.2646315647643376 and parameters: {'model_name': 'VAE', 'batch_size': 469, 'iterations': 7294, 'learning_rate': 0.006392189008270672, 'p_miss': 0.123394978099658}. Best is trial 168 with value: 0.21860135899794875.
[I 2024-09-20 00:46:34,528] Trial 176 finished with value: 0.26363345631023877 and parameters: {'model_name': 'VAE', 'batch_size': 799, 'iterations': 8613, 'learning_rate': 0.0036812420197463737, 'p_miss': 0.027252448440506852}. Best is trial 168 with value: 0.21860135899794875.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
dtype: int64
0.21860135899794875
{'model_name': 'VAE', 'batch_size': 36, 'iterations': 3, 'learning_rate': 0.004763264846266908, 'p_miss': 0.040824926909151474}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746acc40> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  1
Best root_mean_squared_error score: -0.2634215194911339
Generation:   4%|         | 1/25 [00:21<08:26, 21.10s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fa2890> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472c8e0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  2
Best root_mean_squared_error score: -0.2634215194911339
Generation:   8%|         | 2/25 [00:43<08:23, 21.88s/it]Generation:  3
Best root_mean_squared_error score: -0.26303978487772467
Generation:  12%|        | 3/25 [01:13<09:26, 25.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fe620> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  4
Best root_mean_squared_error score: -0.26303978487772467
Generation:  16%|        | 4/25 [01:50<10:31, 30.08s/it]Generation:  5
Best root_mean_squared_error score: -0.263015494029603
Generation:  20%|        | 5/25 [02:24<10:27, 31.37s/it]Generation:  6
Best root_mean_squared_error score: -0.263015494029603
Generation:  24%|       | 6/25 [03:07<11:15, 35.57s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a66e0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  7
Best root_mean_squared_error score: -0.26298039820430563
Generation:  28%|       | 7/25 [03:45<10:54, 36.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f0ae60> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  8
Best root_mean_squared_error score: -0.26296281973927893
Generation:  32%|      | 8/25 [04:15<09:40, 34.15s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472f490> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  9
Best root_mean_squared_error score: -0.26296281973927893
Generation:  36%|      | 9/25 [04:49<09:04, 34.01s/it]Generation:  10
Best root_mean_squared_error score: -0.26296281973927893
Generation:  40%|      | 10/25 [05:26<08:46, 35.11s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547470b880> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  11
Best root_mean_squared_error score: -0.26296281973927893
Generation:  44%|     | 11/25 [06:06<08:32, 36.58s/it]Generation:  12
Best root_mean_squared_error score: -0.26296281973927893
Generation:  48%|     | 12/25 [06:46<08:09, 37.65s/it]Generation:  13
Best root_mean_squared_error score: -0.26296281973927893
Generation:  52%|    | 13/25 [07:31<07:58, 39.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f076d0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  14
Best root_mean_squared_error score: -0.26296281973927893
Generation:  56%|    | 14/25 [13:27<24:48, 135.34s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fad270> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  15
Best root_mean_squared_error score: -0.26296281973927893
Generation:  60%|    | 15/25 [14:11<17:56, 107.67s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474719f60> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  16
Best root_mean_squared_error score: -0.26296281973927893
Generation:  64%|   | 16/25 [14:45<12:51, 85.74s/it] Generation:  17
Best root_mean_squared_error score: -0.26296281973927893
Generation:  68%|   | 17/25 [17:11<13:48, 103.58s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f21a0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  18
Best root_mean_squared_error score: -0.26296281973927893
Generation:  72%|  | 18/25 [18:21<10:55, 93.70s/it] Generation:  19
Best root_mean_squared_error score: -0.26294727083280456
Generation:  76%|  | 19/25 [18:59<07:40, 76.78s/it]Generation:  20
Best root_mean_squared_error score: -0.26294727083280456
Generation:  80%|  | 20/25 [19:39<05:28, 65.79s/it]Generation:  21
Best root_mean_squared_error score: -0.26294727083280456
Generation:  84%| | 21/25 [20:19<03:51, 57.99s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f7df0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  22
Best root_mean_squared_error score: -0.26294727083280456
Generation:  88%| | 22/25 [21:05<02:43, 54.59s/it]Generation:  23
Best root_mean_squared_error score: -0.26294727083280456
Generation:  92%|| 23/25 [22:55<02:22, 71.00s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f02cb0> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  24
Best root_mean_squared_error score: -0.26294183728492404
Generation:  96%|| 24/25 [23:36<01:02, 62.04s/it]Generation:  25
Best root_mean_squared_error score: -0.26294183728492404
Generation: 100%|| 25/25 [24:21<00:00, 57.16s/it]Generation: 100%|| 25/25 [24:27<00:00, 58.70s/it]
2024-09-20 01:11:13,373 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:46671' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-a82fd27edf85ba91bbd4de01694c1652', 'DataFrame-199f3c31ceebfff04409bf1345a44d8c'} (stimulus_id='handle-worker-cleanup-1726819873.373609')
2024-09-20 01:11:17,362 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,363 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,363 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,363 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,363 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,363 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,365 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,366 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,366 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 01:11:17,368 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('adaboostregressor',
                 AdaBoostRegressor(learning_rate=0.0038596530327, loss='square',
                                   n_estimators=61))])
score start
train score: {'explained_var': 0.018672750319578157, 'r2': 0.018668023293013092, 'rmse': 0.2622031693059497}
original test score: {'explained_var': 0.004476214269718892, 'r2': 0.0035437674910246963, 'rmse': 0.2586850264635057}
imputed test score: {'explained_var': -0.003941747307491639, 'r2': -0.0048869407892977446, 'rmse': 0.25977704855112427}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554001067d0>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released 2 days ago.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d34190> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd55a0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd47c0> 
 Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_regression.py", line 223, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4d00> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474cd4a90> 

Generation:  1
Best root_mean_squared_error score: -0.2195838945271713
Generation:   4%|         | 1/25 [10:04<4:01:47, 604.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d2e110> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  2
Best root_mean_squared_error score: -0.2195838945271713
Generation:   8%|         | 2/25 [10:41<1:43:46, 270.74s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554745898a0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  3
Best root_mean_squared_error score: -0.2195838945271713
Generation:  12%|        | 3/25 [11:30<1:02:07, 169.42s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d49f00> 
 Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_regression.py", line 223, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d48a00> 
 Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  4
Best root_mean_squared_error score: -0.217909067240033
Generation:  16%|        | 4/25 [11:53<39:03, 111.59s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d73580> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d13250> 
 Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  5
Best root_mean_squared_error score: -0.21735467787045418
Generation:  20%|        | 5/25 [12:26<27:48, 83.41s/it] WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d719c0> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457139fc0> 

Generation:  6
Best root_mean_squared_error score: -0.21702623691806008
Generation:  24%|       | 6/25 [22:30<1:22:24, 260.22s/it]Generation:  7
Best root_mean_squared_error score: -0.20548779312840776
Generation:  28%|       | 7/25 [23:01<55:34, 185.26s/it]  Generation:  8
Best root_mean_squared_error score: -0.20548779312840776
Generation:  32%|      | 8/25 [23:39<39:12, 138.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554742d7700> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  9
Best root_mean_squared_error score: -0.20548779312840776
Generation:  36%|      | 9/25 [27:35<45:02, 168.89s/it]Generation:  10
Best root_mean_squared_error score: -0.20548779312840776
Generation:  40%|      | 10/25 [34:57<1:03:20, 253.37s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456db4190> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  11
Best root_mean_squared_error score: -0.20548779312840776
Generation:  44%|     | 11/25 [40:24<1:04:21, 275.85s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545f3e3190> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

Generation:  12
Best root_mean_squared_error score: -0.20548779312840776
Generation:  48%|     | 12/25 [45:29<1:01:42, 284.84s/it]Generation:  13
Best root_mean_squared_error score: -0.20548779312840776
Generation:  52%|    | 13/25 [48:53<52:00, 260.08s/it]  Generation:  14
Best root_mean_squared_error score: -0.20522025055310672
Generation:  56%|    | 14/25 [52:16<44:32, 242.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547402c3d0> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  15
Best root_mean_squared_error score: -0.20494035947264302
Generation:  60%|    | 15/25 [56:55<42:17, 253.74s/it]Generation:  16
Best root_mean_squared_error score: -0.20494035947264302
Generation:  64%|   | 16/25 [58:52<31:55, 212.78s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15540173dae0> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d4e110> 
 Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 751, in fit
    return self._fit(X, y, incremental=False)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 441, in _fit
    X, y = self._validate_input(X, y, incremental, reset=first_pass)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py", line 1621, in _validate_input
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
MLPRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452c11e40> 

Generation:  17
Best root_mean_squared_error score: -0.20494035947264302
Generation:  68%|   | 17/25 [1:09:01<44:14, 331.85s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545d359fc0> 

Generation:  18
Best root_mean_squared_error score: -0.20494035947264302
Generation:  72%|  | 18/25 [1:19:08<48:21, 414.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452542b90> 
 The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454673d90> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456b6fa60> 

Generation:  19
Best root_mean_squared_error score: -0.20494035947264302
Generation:  76%|  | 19/25 [1:29:14<47:11, 471.96s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452684790> 

Generation:  20
Best root_mean_squared_error score: -0.20494035947264302
Generation:  80%|  | 20/25 [1:39:21<42:42, 512.53s/it]Generation:  21
Best root_mean_squared_error score: -0.20494035947264302
Generation:  84%| | 21/25 [1:49:24<35:58, 539.74s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554547b0520> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554546fe800> 

Generation:  22
Best root_mean_squared_error score: -0.20494035947264302
Generation:  88%| | 22/25 [1:59:30<27:58, 559.46s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545495eb00> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

Generation:  23
Best root_mean_squared_error score: -0.20494035947264302
Generation:  92%|| 23/25 [2:03:27<15:25, 462.73s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155456b31f90> 
 The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mse' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454cd44f0> 

Generation:  24
Best root_mean_squared_error score: -0.20494035947264302
Generation:  96%|| 24/25 [2:13:32<08:25, 505.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545449f130> 
 The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of ExtraTreesRegressor must be a str among {'friedman_mse', 'poisson', 'absolute_error', 'squared_error'}. Got 'mae' instead.

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547461f820> 

Generation:  25
Best root_mean_squared_error score: -0.20494035947264302
Generation: 100%|| 25/25 [2:23:40<00:00, 536.33s/it]Generation: 100%|| 25/25 [2:23:40<00:00, 344.83s/it]
2024-09-20 03:35:11,675 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:38319' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-199f3c31ceebfff04409bf1345a44d8c', 'DataFrame-e4ade441dcf72f57468a1f1ea1de1561'} (stimulus_id='handle-worker-cleanup-1726828511.675667')
2024-09-20 03:35:15,655 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,656 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,656 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,656 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,657 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,657 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,657 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,658 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,659 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,659 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,660 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,661 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,661 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,661 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,662 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-09-20 03:35:15,662 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('simpleimputer', SimpleImputer()),
                ('mlpregressor',
                 MLPRegressor(activation='tanh', alpha=1.598981e-05,
                              early_stopping=True,
                              hidden_layer_sizes=[123, 123],
                              learning_rate='invscaling',
                              learning_rate_init=0.0067860813393,
                              n_iter_no_change=32))])
transform worked
try transform
transform worked
score start
train score: {'explained_var': 0.4269538078172854, 'r2': 0.4268052266009098, 'rmse': 0.20039231958596507}
test score: {'explained_var': 0.5740298997511726, 'r2': 0.572037119758031, 'rmse': 0.1695294792475205}
original test score: {'explained_var': 0.7645882963684754, 'r2': 0.7642646128037904, 'rmse': 0.12582141577856373}
score end
189
lvl
0.5
type
MAR
num_run
1
reg_full
finished
all finished
full run takes
9.677553476691246
hours
DONE
