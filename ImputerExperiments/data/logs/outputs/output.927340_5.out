Run: 5
/cm/local/apps/slurm/var/spool/job927340/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
starting loops
../data/c/32/32.pkl
working on 
../data/c/32/class_full_MAR_0.01_1
0.0684661865234375
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-08-20 18:09:29,985] A new study created in memory with name: no-name-2afe2515-91d3-4bef-901b-5fcb93ece405
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-08-20 18:09:30,742] Trial 0 finished with value: 0.11405989291950487 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:30,990] Trial 3 finished with value: 0.11405989291950487 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:31,821] Trial 12 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:32,121] Trial 14 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:32,262] Trial 4 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:32,380] Trial 2 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:32,951] Trial 19 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.11405989291950487.
running
[I 2024-08-20 18:09:33,824] Trial 22 finished with value: 0.11400211420612491 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 22 with value: 0.11400211420612491.
running
[I 2024-08-20 18:09:34,325] Trial 21 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 22 with value: 0.11400211420612491.
running
[I 2024-08-20 18:09:38,862] Trial 17 finished with value: 0.06079807311957368 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 711, 'weights': 'uniform'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:39,981] Trial 13 finished with value: 0.09755844539858817 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4691, 'weights': 'uniform'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:40,274] Trial 16 finished with value: 0.08852962393190343 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3182, 'weights': 'uniform'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:40,528] Trial 15 finished with value: 0.11321846991685362 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8365, 'weights': 'uniform'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:40,827] Trial 7 finished with value: 0.10122077197522932 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 8667, 'weights': 'distance'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:41,099] Trial 18 finished with value: 0.06400642060338693 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1339, 'weights': 'distance'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:41,344] Trial 20 finished with value: 0.1001974760916631 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 5252, 'weights': 'uniform'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:41,857] Trial 6 finished with value: 0.0956151705165133 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6909, 'weights': 'distance'}. Best is trial 17 with value: 0.06079807311957368.
running
[I 2024-08-20 18:09:45,221] Trial 25 finished with value: 0.04505394803801046 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 167, 'weights': 'uniform'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:09:46,013] Trial 27 finished with value: 0.04890419236139852 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 259, 'weights': 'uniform'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:09:50,691] Trial 26 finished with value: 0.07209908725025452 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1464, 'weights': 'uniform'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:10:00,218] Trial 1 finished with value: 0.26371743903773165 and parameters: {'model_name': 'GAIN', 'batch_size': 83, 'hint_rate': 0.5480131066564852, 'alpha': 36, 'iterations': 1, 'learning_rate': 0.00015628569708494243, 'p_miss': 0.21065192367179375}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:10:12,332] Trial 5 finished with value: 0.2450022189462135 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.9246989395444475, 'alpha': 84, 'iterations': 15, 'learning_rate': 0.047908905629911756, 'p_miss': 0.2594803973678907}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:10:14,284] Trial 28 finished with value: 0.2673460674126998 and parameters: {'model_name': 'GAIN', 'batch_size': 295, 'hint_rate': 0.5443265122819921, 'alpha': 58, 'iterations': 11, 'learning_rate': 0.023841686482978935, 'p_miss': 0.21434858988273278}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:10:19,977] Trial 9 finished with value: 0.061148760304892066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 11, 'imputation_order': 'ascending'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:10:54,038] Trial 33 finished with value: 0.059168489105898295 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 12, 'imputation_order': 'arabic'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:11:16,259] Trial 39 finished with value: 0.10545721838128466 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:11:28,715] Trial 36 finished with value: 0.055666581883360836 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:11:42,198] Trial 23 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.0790431964833298, 'alpha': 23, 'iterations': 809, 'learning_rate': 0.005021547146084883, 'p_miss': 0.2930352004939725}. Best is trial 25 with value: 0.04505394803801046.
running
[I 2024-08-20 18:12:45,656] Trial 38 finished with value: 0.03929124558267979 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 38 with value: 0.03929124558267979.
running
[I 2024-08-20 18:13:09,986] Trial 31 finished with value: 0.03118958407590161 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.03118958407590161.
running
[I 2024-08-20 18:13:14,221] Trial 41 finished with value: 0.05566657535482428 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 31 with value: 0.03118958407590161.
running
[I 2024-08-20 18:14:25,405] Trial 40 finished with value: 0.031009857133203856 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:14:50,549] Trial 44 finished with value: 0.060975011229458996 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:14:51,023] Trial 35 finished with value: 0.2592480224548493 and parameters: {'model_name': 'GAIN', 'batch_size': 73, 'hint_rate': 0.5451694973769285, 'alpha': 58, 'iterations': 156, 'learning_rate': 0.013428317075612527, 'p_miss': 0.04197354761254664}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:15:04,185] Trial 42 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:15:18,874] Trial 43 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:15:26,177] Trial 45 finished with value: 0.047743247959487554 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:15:34,400] Trial 46 finished with value: 0.049769673241177884 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:15:55,959] Trial 37 finished with value: 0.05628070600264297 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'arabic', 'sample_posterior': False}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:16:47,965] Trial 47 finished with value: 0.04264679286281622 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:17:23,289] Trial 49 finished with value: 0.04001001697358662 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
[I 2024-08-20 18:17:23,414] Trial 48 finished with value: 0.03951039629245741 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'arabic'}. Best is trial 40 with value: 0.031009857133203856.
running
running
[I 2024-08-20 18:17:51,648] Trial 50 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:18:11,243] Trial 52 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:18:11,584] Trial 51 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 40 with value: 0.031009857133203856.
running
[I 2024-08-20 18:18:20,250] Trial 53 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:18:21,241] Trial 54 finished with value: 0.031014114048937353 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:19:35,048] Trial 60 finished with value: 0.031293306820579986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:19:39,192] Trial 62 finished with value: 0.031293306820579986 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:27:35,373] Trial 29 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.8738135678233988, 'alpha': 71, 'iterations': 7118, 'learning_rate': 0.0008071978125119177, 'p_miss': 0.09223157492642599}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:28:14,600] Trial 11 finished with value: 0.27557700998730256 and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.7011255103803135, 'alpha': 56, 'iterations': 764, 'learning_rate': 0.002644621147370843, 'p_miss': 0.1153771466588775}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:29:07,764] Trial 8 finished with value: 0.30861245198866477 and parameters: {'model_name': 'GAIN', 'batch_size': 190, 'hint_rate': 0.33512684267701975, 'alpha': 80, 'iterations': 981, 'learning_rate': 0.07998516536302269, 'p_miss': 0.29359026024805224}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:34:24,366] Trial 24 finished with value: 0.2802673709557314 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.950299994741957, 'alpha': 55, 'iterations': 5403, 'learning_rate': 0.016314788870985038, 'p_miss': 0.09396104600813428}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 18:36:51,652] Trial 34 finished with value: 0.32382633300676134 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.42911714090817116, 'alpha': 41, 'iterations': 8932, 'learning_rate': 0.01567356882571483, 'p_miss': 0.2342841596782767}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:06:00,721] Trial 30 finished with value: 0.04532164045097649 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:44:33,723] Trial 32 finished with value: 0.03722388082602403 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:45:18,516] Trial 71 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:46:02,693] Trial 72 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:46:46,049] Trial 73 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:47:29,225] Trial 74 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:48:11,782] Trial 75 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:48:53,518] Trial 76 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:49:35,224] Trial 77 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:50:08,639] Trial 78 finished with value: 0.03234483487881516 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 11, 'imputation_order': 'ascending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:50:08,907] Trial 79 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 20:50:50,640] Trial 80 finished with value: 0.030802411037168798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 53 with value: 0.030802411037168798.
running
[I 2024-08-20 22:35:22,655] Trial 61 finished with value: 0.029850236088410233 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 61 with value: 0.029850236088410233.
running
[I 2024-08-20 22:46:03,561] Trial 10 finished with value: 0.028537552516814852 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:50:51,105] Trial 55 finished with value: 0.028867781083387993 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:50:51,394] Trial 84 finished with value: 0.11400211420612491 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:51:00,143] Trial 58 finished with value: 0.0289646166520926 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:51:31,096] Trial 59 finished with value: 0.02899200925108192 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:51:53,638] Trial 64 finished with value: 0.029016470230939662 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:52:41,272] Trial 63 finished with value: 0.029052910158044582 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 22:58:57,232] Trial 65 finished with value: 0.02907446754510131 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 23:00:11,536] Trial 66 finished with value: 0.028950595203879066 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 23:00:58,124] Trial 67 finished with value: 0.029249907656798725 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 23:05:39,077] Trial 68 finished with value: 0.028785938148121987 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 23:08:02,061] Trial 69 finished with value: 0.028726916457339664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 10 with value: 0.028537552516814852.
running
[I 2024-08-20 23:08:05,013] Trial 57 finished with value: 0.028262092570045184 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-20 23:08:08,421] Trial 95 finished with value: 0.10122077197522932 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 9724, 'weights': 'distance'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-20 23:08:11,560] Trial 56 finished with value: 0.028500520334293462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 16, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 00:26:01,921] Trial 81 finished with value: 0.03319852145615005 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 11, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 00:36:53,504] Trial 70 finished with value: 0.02905797274218857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 14, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:11:58,479] Trial 82 finished with value: 0.03308159316929029 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 11, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:22:59,171] Trial 83 finished with value: 0.031266111592406005 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 11, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:22:59,550] Trial 101 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.0151487972226782, 'alpha': 5, 'iterations': 1, 'learning_rate': 0.000171898939043677, 'p_miss': 0.0109480977795883}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:22:59,787] Trial 102 finished with value: 0.259758000990039 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:30:35,787] Trial 85 finished with value: 0.0323788052370558 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 11, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:46:42,516] Trial 88 finished with value: 0.03025414428600589 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:47:19,839] Trial 86 finished with value: 0.029640237594367735 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:47:46,233] Trial 87 finished with value: 0.029938060323749523 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:50:10,274] Trial 89 finished with value: 0.030447065568707805 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:56:19,987] Trial 92 finished with value: 0.0301029797248083 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'roman'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:56:33,461] Trial 91 finished with value: 0.030546197826086197 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:57:51,747] Trial 90 finished with value: 0.030381064408709624 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 02:59:43,260] Trial 109 finished with value: 0.08111192097170608 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:00:03,336] Trial 110 finished with value: 0.08111192097170608 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:00:12,160] Trial 113 finished with value: 0.08314557676220423 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3855, 'weights': 'distance'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:00:29,808] Trial 112 finished with value: 0.0556662391584397 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:00:34,933] Trial 115 finished with value: 0.2645230319873447 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.20014504030747743, 'alpha': 99, 'iterations': 9, 'learning_rate': 0.0007034983058870794, 'p_miss': 0.16075315232366466}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:00:57,080] Trial 114 finished with value: 0.05566662682903266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:01:24,500] Trial 111 finished with value: 0.08111192097170608 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random', 'sample_posterior': True}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:04:28,635] Trial 93 finished with value: 0.02943629468377975 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:06:40,514] Trial 94 finished with value: 0.02943285369585949 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:10:04,333] Trial 97 finished with value: 0.029315037978702007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 03:10:07,780] Trial 96 finished with value: 0.029445015117880814 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 12, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 05:17:48,340] Trial 98 finished with value: 0.028465058184450387 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'ascending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 05:29:59,733] Trial 99 finished with value: 0.028353561491698535 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:02:14,383] Trial 100 finished with value: 0.028452780077237748 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:11:29,982] Trial 103 finished with value: 0.02874988220490284 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:12:55,992] Trial 117 finished with value: 0.029955918722223928 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:13:15,766] Trial 118 finished with value: 0.02968836285616474 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:14:35,211] Trial 119 finished with value: 0.029887163063552956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:18:38,045] Trial 120 finished with value: 0.029932625058983718 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:21:21,407] Trial 122 finished with value: 0.030049822801059178 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 57 with value: 0.028262092570045184.
running
[I 2024-08-21 07:22:27,103] Trial 104 finished with value: 0.028206703601620985 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:22:27,422] Trial 132 finished with value: 0.11400211420612491 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:23:48,230] Trial 121 finished with value: 0.03006445105732265 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:33:37,873] Trial 105 finished with value: 0.028262843926119822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:34:22,282] Trial 107 finished with value: 0.028233727278582532 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:34:24,579] Trial 106 finished with value: 0.028396138181916157 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:37:29,449] Trial 108 finished with value: 0.028662680239756377 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 07:46:29,063] Trial 116 finished with value: 0.02861112275728215 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 15, 'imputation_order': 'descending'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 09:23:09,797] Trial 123 finished with value: 0.029744375279324504 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 09:35:28,525] Trial 124 finished with value: 0.029793990203835247 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 13, 'imputation_order': 'descending'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:39:55,033] Trial 125 finished with value: 0.028598946293218498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 15, 'imputation_order': 'descending'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:39:58,729] Trial 142 finished with value: 0.09418528418215177 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6464, 'weights': 'distance'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:48:58,768] Trial 126 finished with value: 0.02844417822042708 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:50:51,507] Trial 127 finished with value: 0.028511420490883805 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:50:59,770] Trial 144 finished with value: 0.27625183875488285 and parameters: {'model_name': 'GAIN', 'batch_size': 965, 'hint_rate': 0.7393546810012628, 'alpha': 1, 'iterations': 76, 'learning_rate': 0.0005256249490420012, 'p_miss': 0.17377028945523162}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:51:33,160] Trial 128 finished with value: 0.028488566298697338 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:51:53,491] Trial 145 finished with value: 0.2760093503245443 and parameters: {'model_name': 'GAIN', 'batch_size': 657, 'hint_rate': 0.7573589165073538, 'alpha': 2, 'iterations': 82, 'learning_rate': 0.0005789101673278168, 'p_miss': 0.16004686687139344}. Best is trial 104 with value: 0.028206703601620985.
running
[I 2024-08-21 11:52:37,586] Trial 129 finished with value: 0.028166136158976833 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 11:56:24,972] Trial 130 finished with value: 0.02854376727498219 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 11:58:22,648] Trial 131 finished with value: 0.028483841371714187 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:00:30,154] Trial 133 finished with value: 0.02848990800503496 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:02:32,706] Trial 134 finished with value: 0.028617225564755145 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:11:06,290] Trial 137 finished with value: 0.02839973089964391 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:11:10,233] Trial 136 finished with value: 0.028555391788159207 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:11:33,831] Trial 135 finished with value: 0.028674762925928778 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:14:55,038] Trial 138 finished with value: 0.028542529249807082 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 12:24:34,782] Trial 139 finished with value: 0.028469296280174312 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 14:05:04,930] Trial 140 finished with value: 0.028458236323447843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 14:17:14,175] Trial 141 finished with value: 0.028196295688389956 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 15:11:22,449] Trial 154 finished with value: 0.03332042359106567 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 15:28:15,983] Trial 158 finished with value: 0.0334264126419732 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:26:56,724] Trial 143 finished with value: 0.02848654098165627 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:27:21,449] Trial 163 finished with value: 0.05566590571680756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:36:30,610] Trial 146 finished with value: 0.028478248164312846 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:36:46,521] Trial 147 finished with value: 0.028701180146034334 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:37:50,501] Trial 148 finished with value: 0.02859080811575675 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:38:37,565] Trial 149 finished with value: 0.028692145510832823 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:42:01,623] Trial 150 finished with value: 0.028478162569207145 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:46:08,811] Trial 151 finished with value: 0.02865638386897097 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:46:27,341] Trial 152 finished with value: 0.028718951338298042 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:46:27,601] Trial 171 finished with value: 0.11405989291950487 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:52:40,637] Trial 153 finished with value: 0.028321452030104548 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 129 with value: 0.028166136158976833.
running
[I 2024-08-21 16:59:50,834] Trial 155 finished with value: 0.028074528426107987 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 17:02:12,412] Trial 156 finished with value: 0.028281745892982935 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 17:03:26,656] Trial 157 finished with value: 0.028985912693651583 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 17:50:29,818] Trial 165 finished with value: 0.09202061966099642 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 17:50:49,047] Trial 166 finished with value: 0.09232850425598571 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 19:10:03,335] Trial 159 finished with value: 0.028253220953133085 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 19:20:58,769] Trial 160 finished with value: 0.028425816645806103 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 20:13:17,072] Trial 161 finished with value: 0.02836084741075499 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 20:32:10,374] Trial 162 finished with value: 0.02862696541450535 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 20:34:33,733] Trial 182 finished with value: 0.05558511191854003 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random', 'sample_posterior': False}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:29:46,220] Trial 164 finished with value: 0.02862854167759333 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 16, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:29:49,552] Trial 184 finished with value: 0.0747255487605719 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2555, 'weights': 'distance'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:38:47,879] Trial 167 finished with value: 0.028759260823663757 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:39:35,995] Trial 168 finished with value: 0.028381892482853822 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:43:15,658] Trial 169 finished with value: 0.028188256949755908 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:48:19,804] Trial 172 finished with value: 0.0285248069400109 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:49:34,882] Trial 170 finished with value: 0.028286169878732288 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 21:56:04,658] Trial 173 finished with value: 0.028271981227083243 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:02:56,216] Trial 174 finished with value: 0.02856031873470958 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:05:37,454] Trial 176 finished with value: 0.02827614502361462 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:07:20,391] Trial 175 finished with value: 0.02852741070332889 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:07:46,327] Trial 194 finished with value: 0.05566662682903266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:33:11,818] Trial 177 finished with value: 0.028238012553726925 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 22:33:28,380] Trial 178 finished with value: 0.028267693877665322 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-21 23:51:00,123] Trial 179 finished with value: 0.028648879124258946 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-22 00:02:55,036] Trial 180 finished with value: 0.02849049350741816 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
running
[I 2024-08-22 00:53:50,211] Trial 181 finished with value: 0.028326086696735076 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 01:15:20,830] Trial 183 finished with value: 0.02853776647436631 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:09:00,723] Trial 185 finished with value: 0.028320918595967047 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:17:52,515] Trial 186 finished with value: 0.028444264328883286 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:19:11,639] Trial 187 finished with value: 0.02848358824895921 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:22:58,607] Trial 188 finished with value: 0.028289480012134004 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:28:05,081] Trial 189 finished with value: 0.02850697871868362 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:28:51,147] Trial 190 finished with value: 0.028216665398494857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:31:24,679] Trial 195 finished with value: 0.029087246043062814 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:36:00,802] Trial 191 finished with value: 0.028269764736058762 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:41:45,666] Trial 192 finished with value: 0.02867847060729803 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 02:44:30,691] Trial 193 finished with value: 0.028171439823689602 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'roman'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 03:10:12,929] Trial 197 finished with value: 0.028385665273905798 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 03:11:27,551] Trial 196 finished with value: 0.028568747785311654 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 04:19:37,202] Trial 199 finished with value: 0.029451375512555313 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 14, 'imputation_order': 'arabic'}. Best is trial 155 with value: 0.028074528426107987.
[I 2024-08-22 04:24:44,389] Trial 198 finished with value: 0.02845130900141653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 15, 'imputation_order': 'random'}. Best is trial 155 with value: 0.028074528426107987.
fit
auto fit
auto transform
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0     0
1     0
2     0
3     0
4     0
5     0
6     0
7     0
8     0
9     0
10    0
11    0
12    0
13    0
14    0
15    0
dtype: int64
0.028074528426107987
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 15, 'imputation_order': 'random'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9917101394264491
Generation:   4%|         | 1/25 [08:20<3:20:17, 500.74s/it]Generation:  2
Best f1_score score: 0.9917101394264491
Generation:   8%|         | 2/25 [09:50<1:39:22, 259.24s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547577cca0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  3
Best f1_score score: 0.9917101394264491
Generation:  12%|        | 3/25 [12:03<1:13:48, 201.30s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475eef8b0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  4
Best f1_score score: 0.9917101394264491
Generation:  16%|        | 4/25 [13:39<55:52, 159.63s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554753dceb0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  5
Best f1_score score: 0.9934339805800768
Generation:  20%|        | 5/25 [22:06<1:35:02, 285.11s/it]Generation:  6
Best f1_score score: 0.9934339805800768
Generation:  24%|       | 6/25 [23:07<1:06:09, 208.92s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554751994e0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e51360> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474ea7b80> 

Generation:  7
Best f1_score score: 0.9936331780335687
Generation:  28%|       | 7/25 [33:12<1:41:28, 338.23s/it]Generation:  8
Best f1_score score: 0.9936331780335687
Generation:  32%|      | 8/25 [34:33<1:12:39, 256.43s/it]Generation:  9
Best f1_score score: 0.994038273666707
Generation:  36%|      | 9/25 [36:55<58:49, 220.62s/it]  Generation:  10
Best f1_score score: 0.994038273666707
Generation:  40%|      | 10/25 [38:34<45:46, 183.11s/it]Generation:  11
Best f1_score score: 0.9941363837803916
Generation:  44%|     | 11/25 [44:11<53:42, 230.14s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475027430> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  12
Best f1_score score: 0.9941363837803916
Generation:  48%|     | 12/25 [45:48<41:04, 189.60s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554753eea10> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  13
Best f1_score score: 0.9941363837803916
Generation:  52%|    | 13/25 [47:53<34:02, 170.24s/it]Generation:  14
Best f1_score score: 0.9941363837803916
Generation:  56%|    | 14/25 [49:08<25:54, 141.35s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e05de0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  15
Best f1_score score: 0.9941363837803916
Generation:  60%|    | 15/25 [50:43<21:15, 127.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547522c5e0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  16
Best f1_score score: 0.9941363837803916
Generation:  64%|   | 16/25 [55:36<26:33, 177.11s/it]Generation:  17
Best f1_score score: 0.9941363837803916
Generation:  68%|   | 17/25 [57:18<20:38, 154.77s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554751745b0> 

Generation:  18
Best f1_score score: 0.9941363837803916
Generation:  72%|  | 18/25 [1:07:28<33:59, 291.38s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474ec4eb0> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  19
Best f1_score score: 0.9941363837803916
Generation:  76%|  | 19/25 [1:10:38<26:06, 261.03s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554757587c0> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  20
Best f1_score score: 0.9941363837803916
Generation:  80%|  | 20/25 [1:14:48<21:28, 257.70s/it]Generation:  21
Best f1_score score: 0.9941363837803916
Generation:  84%| | 21/25 [1:16:17<13:48, 207.05s/it]Generation:  22
Best f1_score score: 0.9941363837803916
Generation:  88%| | 22/25 [1:18:04<08:50, 176.87s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e05000> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  23
Best f1_score score: 0.9941363837803916
Generation:  92%|| 23/25 [1:20:32<05:36, 168.27s/it]Generation:  24
Best f1_score score: 0.994442006984656
Generation:  96%|| 24/25 [1:21:39<02:18, 138.10s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547888e380> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474564b80> 
 Argument 'metric' has incorrect type (expected str, got numpy.str_) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in cross_val_score_objective
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 31, in <listcomp>
    this_fold_scores = [sklearn.metrics.get_scorer(scorer)(this_fold_pipeline, X_test, y_test) for scorer in scorers]
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 279, in __call__
    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 371, in _score
    y_pred = method_caller(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 89, in _cached_call
    result, _ = _get_response_values(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_response.py", line 211, in _get_response_values
    y_pred = prediction_method(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 601, in predict
    return self.steps[-1][1].predict(Xt, **params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 259, in predict
    probabilities = self.predict_proba(X)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 343, in predict_proba
    probabilities = ArgKminClassMode.compute(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 584, in compute
    return ArgKminClassMode64.compute(
TypeError: Argument 'metric' has incorrect type (expected str, got numpy.str_)

Generation:  25
Best f1_score score: 0.994442006984656
Generation: 100%|| 25/25 [1:24:15<00:00, 143.26s/it]Generation: 100%|| 25/25 [1:24:18<00:00, 202.33s/it]
2024-08-22 06:18:42,141 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45723' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-8b4743f120cdf1d2d041d5fbe3018c60', 'ndarray-1f9122a3dadacefe51c68266ddae4833'} (stimulus_id='handle-worker-cleanup-1724332722.141511')
2024-08-22 06:18:46,131 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,131 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,132 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,132 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,133 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,133 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,134 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,135 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,135 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,135 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,136 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,149 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,150 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,150 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,150 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2024-08-22 06:18:46,150 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
Fitted
Pipeline(steps=[('histgradientboostingclassifier',
                 HistGradientBoostingClassifier(early_stopping=False,
                                                l2_regularization=1.5989e-09,
                                                learning_rate=0.1064611954839,
                                                max_features=0.9630196898979,
                                                max_leaf_nodes=425,
                                                min_samples_leaf=187,
                                                tol=0.0001,
                                                validation_fraction=None))])
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 2.102462188117393e-05, 'f1': 1.0}
original test score: {'auroc': 0.9999790625530032, 'accuracy': 0.9945454545454545, 'balanced_accuracy': 0.9945382323733863, 'logloss': 0.025375118176771762, 'f1': 0.9945409071670458}
imputed test score: {'auroc': 0.9999799522010584, 'accuracy': 0.9945454545454545, 'balanced_accuracy': 0.9945382323733863, 'logloss': 0.025374649169297873, 'f1': 0.9945409071670458}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155436502230>
Start tpot fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475eee650> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475eee770> 

Generation:  1
Best f1_score score: 0.9933276512889255
Generation:   4%|         | 1/25 [10:02<4:00:54, 602.26s/it]Generation:  2
Best f1_score score: 0.9933276512889255
Generation:   8%|         | 2/25 [12:20<2:06:14, 329.34s/it]Generation:  3
Best f1_score score: 0.9933276512889255
Generation:  12%|        | 3/25 [16:46<1:50:12, 300.56s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474d73040> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  4
Best f1_score score: 0.9933276512889255
Generation:  16%|        | 4/25 [18:41<1:19:29, 227.14s/it]Generation:  5
Best f1_score score: 0.9933276512889255
Generation:  20%|        | 5/25 [20:49<1:03:51, 191.57s/it]Generation:  6
Best f1_score score: 0.9933276512889255
Generation:  24%|       | 6/25 [25:40<1:11:17, 225.14s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547579e9e0> 

Generation:  7
Best f1_score score: 0.9935299159710901
Generation:  28%|       | 7/25 [35:45<1:44:47, 349.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457ef5690> 

Generation:  8
Best f1_score score: 0.9935352631461102
Generation:  32%|      | 8/25 [45:49<2:01:59, 430.54s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545afc4700> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  9
Best f1_score score: 0.9936357532382585
Generation:  36%|      | 9/25 [50:02<1:39:58, 374.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547579d660> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  10
Best f1_score score: 0.9936357532382585
Generation:  40%|      | 10/25 [50:22<1:06:20, 265.33s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554757f0d00> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155457d94310> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  11
Best f1_score score: 0.9936357532382585
Generation:  44%|     | 11/25 [51:32<47:59, 205.67s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453987cd0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554744e68f0> 

Generation:  12
Best f1_score score: 0.9936357532382585
Generation:  48%|     | 12/25 [1:01:35<1:10:46, 326.64s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547546f4c0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  13
Best f1_score score: 0.9936357532382585
Generation:  52%|    | 13/25 [1:03:54<53:55, 269.64s/it]  Generation:  14
Best f1_score score: 0.9938336742138419
Generation:  56%|    | 14/25 [1:06:55<44:31, 242.91s/it]Generation:  15
Best f1_score score: 0.9938336742138419
Generation:  60%|    | 15/25 [1:07:19<29:29, 176.93s/it]Generation:  16
Best f1_score score: 0.9938336742138419
Generation:  64%|   | 16/25 [1:12:39<32:58, 219.87s/it]Generation:  17
Best f1_score score: 0.9938336742138419
Generation:  68%|   | 17/25 [1:14:46<25:36, 192.00s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155453d1fcd0> 

Generation:  18
Best f1_score score: 0.9938336742138419
Generation:  72%|  | 18/25 [1:24:53<36:56, 316.61s/it]Generation:  19
Best f1_score score: 0.9939335200061853
Generation:  76%|  | 19/25 [1:26:33<25:09, 251.65s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554744dab30> 
 Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py", line 238, in fit
    return self._fit(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 475, in _fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  20
Best f1_score score: 0.9939335200061853
Generation:  80%|  | 20/25 [1:28:56<18:15, 219.15s/it]Generation:  21
Best f1_score score: 0.9939335200061853
Generation:  84%| | 21/25 [1:30:23<11:57, 179.45s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545aad84f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554507f6410> 

Generation:  22
Best f1_score score: 0.994035175718438
Generation:  88%| | 22/25 [1:40:27<15:20, 306.86s/it]Generation:  23
Best f1_score score: 0.994035175718438
Generation:  92%|| 23/25 [1:43:53<09:13, 276.52s/it]Generation:  24
Best f1_score score: 0.9941367600000455
Generation:  96%|| 24/25 [1:47:08<04:12, 252.06s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545d629060> 

Generation:  25
Best f1_score score: 0.9941370166674364
Generation: 100%|| 25/25 [1:57:11<00:00, 357.36s/it]Generation: 100%|| 25/25 [1:57:11<00:00, 281.26s/it]
2024-08-22 08:16:07,805 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:41899' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-1f9122a3dadacefe51c68266ddae4833', 'DataFrame-66f19a5d53447fbc783dab1dcb2d9cff'} (stimulus_id='handle-worker-cleanup-1724339767.8053684')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=38)),
                ('kneighborsclassifier',
                 KNeighborsClassifier(n_jobs=1, n_neighbors=1, p=1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 2.2204460492503136e-16, 'f1': 1.0}
test score: {'auroc': 0.9979773872911023, 'accuracy': 0.9963636363636363, 'balanced_accuracy': 0.9963588215822575, 'logloss': 0.13106783050588078, 'f1': 0.9963634559943998}
original test score: {'auroc': 0.9979773872911023, 'accuracy': 0.9963636363636363, 'balanced_accuracy': 0.9963588215822575, 'logloss': 0.13106783050588078, 'f1': 0.9963634559943998}
score end
32
lvl
0.01
type
MAR
num_run
1
class_full
finished
all finished
full run takes
38.11405103908645
hours
DONE
