Run: 1
/cm/local/apps/slurm/var/spool/job920477/slurm_script: line 26: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
starting loops
../data/c/30/30.pkl
      height  lenght  area    eccen  p_black  p_and  mean_tr  blackpix  \
0          5       7    35    1.400    0.400  0.657     2.33        14   
1          6       7    42    1.167    0.429  0.881     3.60        18   
2          6      18   108    3.000    0.287  0.741     4.43        31   
3          5       7    35    1.400    0.371  0.743     4.33        13   
4          6       3    18    0.500    0.500  0.944     2.25         9   
...      ...     ...   ...      ...      ...    ...      ...       ...   
5468       4     524  2096  131.000    0.542  0.603    40.57      1136   
5469       7       4    28    0.571    0.714  0.929    10.00        20   
5470       6      95   570   15.833    0.300  0.911     1.64       171   
5471       7      41   287    5.857    0.213  0.801     1.36        61   
5472       8       1     8    0.125    1.000  1.000     8.00         8   

      blackand  wb_trans  
0           23         6  
1           37         5  
2           80         7  
3           26         3  
4           17         4  
...        ...       ...  
5468      1264        28  
5469        26         2  
5470       519       104  
5471       230        45  
5472         8         1  

[5473 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
     class
0        1
1        1
2        1
3        1
4        1
...    ...
5468     2
5469     1
5470     1
5471     1
5472     4

[5473 rows x 1 columns]
<class 'pandas.core.frame.DataFrame'>
      height  lenght  area    eccen  p_black  p_and  mean_tr  blackpix  \
0          5       7    35    1.400    0.400  0.657     2.33        14   
1          6       7    42    1.167    0.429  0.881     3.60        18   
2          6      18   108    3.000    0.287  0.741     4.43        31   
3          5       7    35    1.400    0.371  0.743     4.33        13   
4          6       3    18    0.500    0.500  0.944     2.25         9   
...      ...     ...   ...      ...      ...    ...      ...       ...   
5468       4     524  2096  131.000    0.542  0.603    40.57      1136   
5469       7       4    28    0.571    0.714  0.929    10.00        20   
5470       6      95   570   15.833    0.300  0.911     1.64       171   
5471       7      41   287    5.857    0.213  0.801     1.36        61   
5472       8       1     8    0.125    1.000  1.000     8.00         8   

      blackand  wb_trans  
0           23         6  
1           37         5  
2           80         7  
3           26         3  
4           17         4  
...        ...       ...  
5468      1264        28  
5469        26         2  
5470       519       104  
5471       230        45  
5472         8         1  

[5473 rows x 10 columns]
<class 'pandas.core.frame.DataFrame'>
working on 
../data/c/30/class_full_MCAR_0.01_1
2.735748767852783
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-08-13 01:09:33,743] A new study created in memory with name: no-name-27363c0a-1af7-4204-96bb-b6141d8d700e
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-08-13 01:09:34,159] Trial 11 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 11 with value: 0.31667300201457727.
running
[I 2024-08-13 01:09:34,490] Trial 0 finished with value: 0.0737517208855286 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.0737517208855286.
[I 2024-08-13 01:09:34,657] Trial 9 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.0737517208855286.
running
[I 2024-08-13 01:09:34,870] Trial 4 finished with value: 0.0737517208855286 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 0 with value: 0.0737517208855286.
running
running
[I 2024-08-13 01:09:35,786] Trial 19 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.0737517208855286.
running
[I 2024-08-13 01:09:36,160] Trial 20 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 0 with value: 0.0737517208855286.
running
[I 2024-08-13 01:09:37,030] Trial 21 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 0 with value: 0.0737517208855286.
running
[I 2024-08-13 01:09:39,177] Trial 13 finished with value: 0.07186338317501619 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4239, 'weights': 'uniform'}. Best is trial 13 with value: 0.07186338317501619.
running
[I 2024-08-13 01:09:39,730] Trial 23 finished with value: 0.0737517208855286 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 13 with value: 0.07186338317501619.
running
[I 2024-08-13 01:09:40,466] Trial 17 finished with value: 0.06448784847945452 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1922, 'weights': 'uniform'}. Best is trial 17 with value: 0.06448784847945452.
running
[I 2024-08-13 01:09:40,661] Trial 6 finished with value: 0.05680483175235281 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4468, 'weights': 'distance'}. Best is trial 6 with value: 0.05680483175235281.
running
[I 2024-08-13 01:09:41,023] Trial 16 finished with value: 0.06480893964648093 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1995, 'weights': 'uniform'}. Best is trial 6 with value: 0.05680483175235281.
[I 2024-08-13 01:09:41,183] Trial 14 finished with value: 0.05291442892952107 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2627, 'weights': 'distance'}. Best is trial 14 with value: 0.05291442892952107.
running
running
[I 2024-08-13 01:09:41,431] Trial 7 finished with value: 0.04879060601015047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1775, 'weights': 'distance'}. Best is trial 7 with value: 0.04879060601015047.
running
[I 2024-08-13 01:09:44,170] Trial 22 finished with value: 0.05680483175235281 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 4829, 'weights': 'distance'}. Best is trial 7 with value: 0.04879060601015047.
running
[I 2024-08-13 01:09:45,805] Trial 24 finished with value: 0.03129829423584312 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 210, 'weights': 'distance'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:46,577] Trial 25 finished with value: 0.055962275930324566 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 814, 'weights': 'uniform'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:47,604] Trial 26 finished with value: 0.046122912317428565 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1376, 'weights': 'distance'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:53,175] Trial 12 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.21317459374782807, 'alpha': 15, 'iterations': 1, 'learning_rate': 0.054319057968500534, 'p_miss': 0.11466962373842518}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:53,505] Trial 31 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.36807521584080316, 'alpha': 90, 'iterations': 29, 'learning_rate': 0.0050068202614128015, 'p_miss': 0.08478055900663162}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:55,645] Trial 5 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.7366680512589993, 'alpha': 32, 'iterations': 42, 'learning_rate': 0.00010711693217348593, 'p_miss': 0.2983119006759143}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:09:56,953] Trial 3 finished with value: 0.054645953191195695 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 2, 'imputation_order': 'random'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:10:00,114] Trial 18 finished with value: 0.3212680610847104 and parameters: {'model_name': 'GAIN', 'batch_size': 68, 'hint_rate': 0.6495086605633903, 'alpha': 46, 'iterations': 7, 'learning_rate': 0.0005404219207434758, 'p_miss': 0.2068941113344442}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:10:14,882] Trial 10 finished with value: 0.039196811065924916 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:10:21,455] Trial 35 finished with value: 0.05776299647210227 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:10:25,088] Trial 27 finished with value: 0.04693056107552032 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 24 with value: 0.03129829423584312.
running
[I 2024-08-13 01:10:55,503] Trial 28 finished with value: 0.025784191270384664 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 28 with value: 0.025784191270384664.
running
[I 2024-08-13 01:11:00,603] Trial 32 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.9823390926194597, 'alpha': 56, 'iterations': 656, 'learning_rate': 0.000289192765275898, 'p_miss': 0.1053119123805829}. Best is trial 28 with value: 0.025784191270384664.
running
[I 2024-08-13 01:11:08,573] Trial 34 finished with value: 0.023923706292317486 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 34 with value: 0.023923706292317486.
running
[I 2024-08-13 01:12:10,369] Trial 42 finished with value: 0.0227721489801136 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 42 with value: 0.0227721489801136.
running
[I 2024-08-13 01:12:15,564] Trial 43 finished with value: 0.0227721489801136 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 42 with value: 0.0227721489801136.
running
[I 2024-08-13 01:12:21,133] Trial 33 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.28599236679736606, 'alpha': 90, 'iterations': 723, 'learning_rate': 0.00014332193249451543, 'p_miss': 0.18640693871660838}. Best is trial 42 with value: 0.0227721489801136.
running
[I 2024-08-13 01:12:24,802] Trial 44 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:12:37,277] Trial 8 finished with value: 0.06099200044939653 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'arabic', 'sample_posterior': True}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:12:39,203] Trial 37 finished with value: 0.036940751668200454 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 10, 'imputation_order': 'descending', 'sample_posterior': False}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:22,089] Trial 41 finished with value: 0.03692566654302602 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:33,588] Trial 45 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:37,199] Trial 46 finished with value: 0.0227721489801136 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:37,790] Trial 40 finished with value: 0.06076695336314556 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman', 'sample_posterior': True}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:45,600] Trial 47 finished with value: 0.0227721489801136 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:13:50,321] Trial 48 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:01,511] Trial 50 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:03,634] Trial 49 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:39,211] Trial 51 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:41,047] Trial 54 finished with value: 0.031011832615269276 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:41,705] Trial 52 finished with value: 0.022450886753677318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:43,888] Trial 53 finished with value: 0.022450886753677318 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:14:55,260] Trial 56 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:15:06,644] Trial 57 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:18:32,316] Trial 1 finished with value: 0.35374657445353735 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.2515299352639702, 'alpha': 22, 'iterations': 396, 'learning_rate': 0.013143802117623235, 'p_miss': 0.22503554517812033}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:41:26,612] Trial 2 finished with value: 0.06307288243946658 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 1, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:42:00,458] Trial 66 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:48:45,011] Trial 15 finished with value: 0.04421063754213386 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:49:13,418] Trial 68 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:49:47,294] Trial 69 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:50:26,071] Trial 70 finished with value: 0.02956840926545281 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:51:05,919] Trial 71 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:56:17,145] Trial 30 finished with value: 0.03263647780866999 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 3, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:56:45,324] Trial 73 finished with value: 0.024133312430305122 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 01:57:27,711] Trial 74 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 02:00:09,557] Trial 29 finished with value: 0.026080699977976025 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 02:00:36,855] Trial 76 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 02:01:04,816] Trial 77 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 02:01:32,369] Trial 78 finished with value: 0.022431661080337714 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 44 with value: 0.022431661080337714.
running
[I 2024-08-13 02:01:59,237] Trial 79 finished with value: 0.022042529688034558 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 79 with value: 0.022042529688034558.
running
[I 2024-08-13 02:01:59,662] Trial 80 finished with value: 0.07186408237465443 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 79 with value: 0.022042529688034558.
running
[I 2024-08-13 02:02:20,723] Trial 81 finished with value: 0.02207714254087311 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 79 with value: 0.022042529688034558.
running
[I 2024-08-13 02:02:57,049] Trial 82 finished with value: 0.0396082915574427 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'random'}. Best is trial 79 with value: 0.022042529688034558.
running
[I 2024-08-13 02:13:04,641] Trial 36 finished with value: 0.01747240761128349 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 36 with value: 0.01747240761128349.
running
[I 2024-08-13 02:13:34,025] Trial 55 finished with value: 0.020748701251764097 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 6, 'imputation_order': 'ascending'}. Best is trial 36 with value: 0.01747240761128349.
running
[I 2024-08-13 02:23:04,379] Trial 59 finished with value: 0.0189794208586246 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 36 with value: 0.01747240761128349.
running
[I 2024-08-13 02:25:06,030] Trial 38 finished with value: 0.016716220892850592 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 38 with value: 0.016716220892850592.
running
[I 2024-08-13 02:25:42,866] Trial 39 finished with value: 0.015257779959219625 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:27:52,781] Trial 58 finished with value: 0.01775127621345467 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:28:40,032] Trial 60 finished with value: 0.017181864963313156 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:28:40,511] Trial 90 finished with value: 0.07186408237465443 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:29:01,880] Trial 61 finished with value: 0.017441283479942643 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:29:32,564] Trial 62 finished with value: 0.018535155505108973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:31:11,840] Trial 63 finished with value: 0.017467761165362007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:31:18,657] Trial 65 finished with value: 0.01765402001306905 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:33:51,108] Trial 64 finished with value: 0.018010562612336238 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:37:13,819] Trial 72 finished with value: 0.024484157024211285 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 02:58:19,940] Trial 67 finished with value: 0.0175501670971148 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 03:15:51,138] Trial 75 finished with value: 0.017925362257968903 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 10, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 03:21:31,994] Trial 83 finished with value: 0.018272409459647133 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 03:25:04,337] Trial 96 finished with value: 0.027703769282926994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 4, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 03:25:58,605] Trial 86 finished with value: 0.017067287489593186 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 03:26:04,034] Trial 102 finished with value: 0.069163615778652 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3264, 'weights': 'uniform'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 07:31:29,385] Trial 98 finished with value: 0.3151197972362428 and parameters: {'model_name': 'GAIN', 'batch_size': 584, 'hint_rate': 0.015356155331948118, 'alpha': 66, 'iterations': 5085, 'learning_rate': 0.001399321340212484, 'p_miss': 0.01315315422236335}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 07:31:38,429] Trial 104 finished with value: 0.3129596484126317 and parameters: {'model_name': 'GAIN', 'batch_size': 869, 'hint_rate': 0.8394861264418114, 'alpha': 0, 'iterations': 1, 'learning_rate': 0.07788550074919816, 'p_miss': 0.011267474785049358}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 07:31:39,797] Trial 105 finished with value: 0.31667300201457727 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 07:43:24,319] Trial 89 finished with value: 0.31752643608269493 and parameters: {'model_name': 'GAIN', 'batch_size': 873, 'hint_rate': 0.025765780697811824, 'alpha': 3, 'iterations': 5541, 'learning_rate': 0.09420397494880665, 'p_miss': 0.03927099238384567}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:18:50,409] Trial 84 finished with value: 0.3143711825901231 and parameters: {'model_name': 'GAIN', 'batch_size': 861, 'hint_rate': 0.08885336839336827, 'alpha': 3, 'iterations': 7344, 'learning_rate': 0.0976081932536776, 'p_miss': 0.01347056679958128}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:40:19,424] Trial 106 finished with value: 0.018276054717332645 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:41:18,150] Trial 92 finished with value: 0.31664851995488397 and parameters: {'model_name': 'GAIN', 'batch_size': 702, 'hint_rate': 0.10611040651627396, 'alpha': 0, 'iterations': 6816, 'learning_rate': 0.09287841994068129, 'p_miss': 0.04033819449671475}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:42:32,166] Trial 100 finished with value: 0.3157773442254849 and parameters: {'model_name': 'GAIN', 'batch_size': 705, 'hint_rate': 0.02024237503191989, 'alpha': 0, 'iterations': 5957, 'learning_rate': 0.001253887048028728, 'p_miss': 0.02970687673092051}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:51:37,372] Trial 107 finished with value: 0.019083462510067994 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 08:54:24,329] Trial 94 finished with value: 0.3173173152444763 and parameters: {'model_name': 'GAIN', 'batch_size': 560, 'hint_rate': 0.029111573525879064, 'alpha': 1, 'iterations': 7084, 'learning_rate': 0.08650089027556486, 'p_miss': 0.025735135693393835}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:06:31,240] Trial 85 finished with value: 0.31515863407457856 and parameters: {'model_name': 'GAIN', 'batch_size': 777, 'hint_rate': 0.053181978525469964, 'alpha': 0, 'iterations': 8219, 'learning_rate': 0.08351955443340642, 'p_miss': 0.010975527371590382}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:13:48,495] Trial 109 finished with value: 0.06454683518243226 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 1, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:27:48,854] Trial 108 finished with value: 0.018541494438329146 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:44:11,108] Trial 99 finished with value: 0.314962391236927 and parameters: {'model_name': 'GAIN', 'batch_size': 898, 'hint_rate': 0.09054924954520566, 'alpha': 66, 'iterations': 6880, 'learning_rate': 0.08903078436605188, 'p_miss': 0.03388634569049198}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:48:59,586] Trial 112 finished with value: 0.021350057461867612 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:49:57,796] Trial 110 finished with value: 0.017543437768493132 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:50:33,885] Trial 111 finished with value: 0.01804874255055804 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:51:46,844] Trial 113 finished with value: 0.020709156010623796 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 09:56:50,013] Trial 95 finished with value: 0.3142670229724951 and parameters: {'model_name': 'GAIN', 'batch_size': 386, 'hint_rate': 0.016715826775260345, 'alpha': 67, 'iterations': 8536, 'learning_rate': 0.09813953431002019, 'p_miss': 0.020141345117009657}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:03:38,151] Trial 114 finished with value: 0.02009909824806071 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:14:58,022] Trial 87 finished with value: 0.3147377111710067 and parameters: {'model_name': 'GAIN', 'batch_size': 760, 'hint_rate': 0.0318643327718669, 'alpha': 68, 'iterations': 8638, 'learning_rate': 0.0017139692633393012, 'p_miss': 0.01867868701484457}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:15:24,534] Trial 101 finished with value: 0.37469602640787536 and parameters: {'model_name': 'GAIN', 'batch_size': 358, 'hint_rate': 0.014501845963976967, 'alpha': 0, 'iterations': 7900, 'learning_rate': 0.0996703720278456, 'p_miss': 0.29771247085317415}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:25:17,015] Trial 116 finished with value: 0.02306200031462482 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:27:50,650] Trial 115 finished with value: 0.016906972287947637 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:35:59,519] Trial 88 finished with value: 0.31448883634694863 and parameters: {'model_name': 'GAIN', 'batch_size': 812, 'hint_rate': 0.015234468589719219, 'alpha': 68, 'iterations': 8934, 'learning_rate': 0.08880799971162957, 'p_miss': 0.044940654826623794}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:41:09,616] Trial 117 finished with value: 0.022591447140915356 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 5, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:51:26,024] Trial 118 finished with value: 0.02107084037704618 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:52:04,673] Trial 119 finished with value: 0.020688868543300203 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:54:12,219] Trial 121 finished with value: 0.020887903452368607 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:54:13,064] Trial 120 finished with value: 0.021087923329509404 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:54:18,778] Trial 132 finished with value: 0.06979553000583054 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3497, 'weights': 'uniform'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:54:20,363] Trial 133 finished with value: 0.0705200310853874 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 3793, 'weights': 'uniform'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:56:41,496] Trial 134 finished with value: 0.03764423405894808 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:56:45,662] Trial 135 finished with value: 0.03764423405894808 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 10:57:13,858] Trial 93 finished with value: 0.31341419286603933 and parameters: {'model_name': 'GAIN', 'batch_size': 843, 'hint_rate': 0.012354937604084903, 'alpha': 68, 'iterations': 9385, 'learning_rate': 0.09233713385719754, 'p_miss': 0.02533535588179625}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:00:52,901] Trial 97 finished with value: 0.31586531217909913 and parameters: {'model_name': 'GAIN', 'batch_size': 503, 'hint_rate': 0.015938160045553595, 'alpha': 66, 'iterations': 9807, 'learning_rate': 0.001234581964776956, 'p_miss': 0.021410068620424966}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:01:29,769] Trial 122 finished with value: 0.021280553981341075 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:05:57,187] Trial 91 finished with value: 0.3137365383637446 and parameters: {'model_name': 'GAIN', 'batch_size': 965, 'hint_rate': 0.9590823737389323, 'alpha': 67, 'iterations': 9777, 'learning_rate': 0.09321194087458198, 'p_miss': 0.02274264046763888}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:06:38,899] Trial 123 finished with value: 0.021583707895900313 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:08:09,915] Trial 103 finished with value: 0.315191634916847 and parameters: {'model_name': 'GAIN', 'batch_size': 833, 'hint_rate': 0.026280958982913105, 'alpha': 0, 'iterations': 9736, 'learning_rate': 0.09142839830723772, 'p_miss': 0.010730647962828521}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:15:23,191] Trial 124 finished with value: 0.02025488964816594 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:24:54,727] Trial 127 finished with value: 0.021146840049156228 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:24:59,762] Trial 125 finished with value: 0.01678520961148222 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:30:50,732] Trial 128 finished with value: 0.02088987064855767 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 6, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:32:22,359] Trial 126 finished with value: 0.0175305133380971 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:45:41,257] Trial 129 finished with value: 0.01836596526522586 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:53:40,902] Trial 130 finished with value: 0.016088786422785425 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:54:17,411] Trial 131 finished with value: 0.017500371721112778 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:54:54,136] Trial 151 finished with value: 0.0396770317952337 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:56:59,732] Trial 137 finished with value: 0.018918669416926156 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:57:06,118] Trial 136 finished with value: 0.018558702387166365 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 11:58:09,726] Trial 138 finished with value: 0.01861105802570756 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:00:45,311] Trial 139 finished with value: 0.017887487339683032 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:00:56,384] Trial 140 finished with value: 0.018904191753358876 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:05:05,356] Trial 141 finished with value: 0.01845467687595388 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:05:31,309] Trial 142 finished with value: 0.017947071521882647 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:06:55,957] Trial 143 finished with value: 0.017737842366883184 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:14:05,263] Trial 144 finished with value: 0.017688521126491972 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:14:05,514] Trial 161 finished with value: 0.07186408237465443 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:24:07,003] Trial 145 finished with value: 0.019421646304408857 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:24:28,857] Trial 146 finished with value: 0.018841253236685743 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:29:52,164] Trial 147 finished with value: 0.01902664275243332 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:31:00,300] Trial 148 finished with value: 0.020133897714164108 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:44:22,133] Trial 149 finished with value: 0.019374959529486195 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'descending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:49:26,747] Trial 153 finished with value: 0.017603942941205007 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:49:27,280] Trial 154 finished with value: 0.018282234895364166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:51:11,693] Trial 155 finished with value: 0.01823520363088877 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:51:55,319] Trial 150 finished with value: 0.017377046321265806 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:52:28,158] Trial 171 finished with value: 0.0388099040443692 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 12:53:20,390] Trial 152 finished with value: 0.0167612098526913 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:04:58,223] Trial 156 finished with value: 0.017127596960453524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:05:05,174] Trial 157 finished with value: 0.01657608404130847 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:09:17,632] Trial 158 finished with value: 0.016249680209849446 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:09:26,712] Trial 159 finished with value: 0.016563689893277493 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:10:57,297] Trial 160 finished with value: 0.016173036423902477 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:17:56,375] Trial 162 finished with value: 0.015773724924240465 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:28:04,140] Trial 163 finished with value: 0.016533693435189477 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:29:24,003] Trial 164 finished with value: 0.016341790745888606 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:33:38,591] Trial 165 finished with value: 0.017261956973881644 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:35:05,247] Trial 166 finished with value: 0.01639128381834102 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:41:39,123] Trial 168 finished with value: 0.017585023830361125 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 7, 'imputation_order': 'roman'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:48:13,064] Trial 167 finished with value: 0.01664808536621149 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:52:58,139] Trial 169 finished with value: 0.01778867773126922 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:55:43,612] Trial 172 finished with value: 0.015984250368228262 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:56:22,573] Trial 170 finished with value: 0.01708620715622266 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 13:56:30,313] Trial 173 finished with value: 0.017442103520484947 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:08:41,667] Trial 174 finished with value: 0.01750141404584928 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:08:43,106] Trial 175 finished with value: 0.01730495964172169 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:12:52,954] Trial 176 finished with value: 0.01629360343439725 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:12:53,205] Trial 192 finished with value: 0.07186408237465443 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:13:00,617] Trial 177 finished with value: 0.016923270419934123 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:14:02,198] Trial 193 finished with value: 0.06050762041784524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:14:12,438] Trial 194 finished with value: 0.06050762041784524 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending', 'sample_posterior': True}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:15:17,064] Trial 178 finished with value: 0.016852309602720692 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:22:22,774] Trial 179 finished with value: 0.015857705716992902 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 39 with value: 0.015257779959219625.
running
[I 2024-08-13 14:32:09,947] Trial 180 finished with value: 0.01513788510705732 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
running
[I 2024-08-13 14:34:50,801] Trial 181 finished with value: 0.016356233898663555 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:37:53,122] Trial 182 finished with value: 0.016007628570871932 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:39:08,324] Trial 183 finished with value: 0.016710949966053094 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'random'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:45:24,302] Trial 184 finished with value: 0.017135171233538166 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:51:44,446] Trial 185 finished with value: 0.015840044800107284 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:56:03,280] Trial 186 finished with value: 0.016334305501051843 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:58:30,946] Trial 187 finished with value: 0.01615424025097041 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 14:59:26,544] Trial 189 finished with value: 0.01685694869178426 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:00:24,150] Trial 188 finished with value: 0.016451865582072824 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:10:09,035] Trial 191 finished with value: 0.016006397985148604 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'random'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:10:44,534] Trial 190 finished with value: 0.015909350106123595 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 10, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:14:35,190] Trial 196 finished with value: 0.01704036702910638 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:14:58,893] Trial 195 finished with value: 0.016229608422096864 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:15:23,768] Trial 197 finished with value: 0.015478841180373733 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:21:48,588] Trial 198 finished with value: 0.016703956181431327 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
[I 2024-08-13 15:30:13,693] Trial 199 finished with value: 0.016470983665700777 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 180 with value: 0.01513788510705732.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
9    0
dtype: int64
0.01513788510705732
{'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 9, 'imputation_order': 'ascending'}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]Generation:  1
Best f1_score score: 0.9704570480857786
Generation:   4%|         | 1/25 [00:43<17:22, 43.45s/it]Generation:  2
Best f1_score score: 0.9704570480857786
Generation:   8%|         | 2/25 [01:29<17:19, 45.18s/it]Generation:  3
Best f1_score score: 0.9704570480857786
Generation:  12%|        | 3/25 [02:15<16:42, 45.56s/it]Generation:  4
Best f1_score score: 0.9704570480857786
Generation:  16%|        | 4/25 [03:03<16:15, 46.43s/it]Generation:  5
Best f1_score score: 0.9704570480857786
Generation:  20%|        | 5/25 [03:50<15:29, 46.49s/it]Generation:  6
Best f1_score score: 0.9704570480857786
Generation:  24%|       | 6/25 [04:33<14:24, 45.49s/it]Generation:  7
Best f1_score score: 0.9708042716828131
Generation:  28%|       | 7/25 [04:56<11:23, 37.98s/it]Generation:  8
Best f1_score score: 0.9708042716828131
Generation:  32%|      | 8/25 [05:32<10:37, 37.47s/it]Generation:  9
Best f1_score score: 0.9708042716828131
Generation:  36%|      | 9/25 [06:26<11:19, 42.48s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475050a30> 

Generation:  10
Best f1_score score: 0.9719116820847503
Generation:  40%|      | 10/25 [16:32<54:08, 216.56s/it]Generation:  11
Best f1_score score: 0.9719116820847503
Generation:  44%|     | 11/25 [19:55<49:34, 212.46s/it]Generation:  12
Best f1_score score: 0.9719116820847503
Generation:  48%|     | 12/25 [21:08<36:48, 169.90s/it]Generation:  13
Best f1_score score: 0.9719116820847503
Generation:  52%|    | 13/25 [28:44<51:20, 256.68s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475143130> 

Generation:  14
Best f1_score score: 0.9719116820847503
Generation:  56%|    | 14/25 [38:51<1:06:26, 362.42s/it]Generation:  15
Best f1_score score: 0.9719116820847503
Generation:  60%|    | 15/25 [39:16<43:28, 260.84s/it]  Generation:  16
Best f1_score score: 0.9719116820847503
Generation:  64%|   | 16/25 [47:19<49:09, 327.72s/it]Generation:  17
Best f1_score score: 0.9719116820847503
Generation:  68%|   | 17/25 [49:56<36:50, 276.32s/it]Generation:  18
Best f1_score score: 0.9719116820847503
Generation:  72%|  | 18/25 [51:55<26:43, 229.14s/it]Generation:  19
Best f1_score score: 0.9719116820847503
Generation:  76%|  | 19/25 [1:00:07<30:48, 308.10s/it]Generation:  20
Best f1_score score: 0.9726510518857528
Generation:  80%|  | 20/25 [1:03:14<22:37, 271.58s/it]Generation:  21
Best f1_score score: 0.9726510518857528
Generation:  84%| | 21/25 [1:04:01<13:36, 204.16s/it]Generation:  22
Best f1_score score: 0.9726510518857528
Generation:  88%| | 22/25 [1:11:09<13:34, 271.42s/it]Generation:  23
Best f1_score score: 0.9726510518857528
Generation:  92%|| 23/25 [1:14:47<08:30, 255.21s/it]Generation:  24
Best f1_score score: 0.9726510518857528
Generation:  96%|| 24/25 [1:15:18<03:07, 187.93s/it]Generation:  25
Best f1_score score: 0.9726510518857528
Generation: 100%|| 25/25 [1:17:09<00:00, 165.00s/it]Generation: 100%|| 25/25 [1:17:13<00:00, 185.33s/it]
2024-08-13 16:53:37,197 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:45991' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-cbeb7041807646fba1f32cb30c440613', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723593217.1975107')
Fitted
Pipeline(steps=[('lgbmclassifier',
                 LGBMClassifier(class_weight='balanced', max_depth=8,
                                n_estimators=50, n_jobs=1, num_leaves=52,
                                verbose=-1))])
score start
train score: {'auroc': 0.9998239977936537, 'accuracy': 0.9920812182741117, 'balanced_accuracy': 0.9950969809090143, 'logloss': 0.02904596760208405, 'f1': 0.9922293631068542}
original test score: {'auroc': 0.9981777451558603, 'accuracy': 0.9762773722627737, 'balanced_accuracy': 0.9890613451589061, 'logloss': 0.08473322637411583, 'f1': 0.9774727223044891}
imputed test score: {'auroc': 0.9977055846105882, 'accuracy': 0.9744525547445255, 'balanced_accuracy': 0.9830007390983001, 'logloss': 0.0899289551838334, 'f1': 0.9756219008109466}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x1554365061d0>
Start tpot fit
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475b466b0> 
 Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 911, in fit
    X, y = self._validate_data(X, y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
QuadraticDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475b466b0> 

Generation:  1
Best f1_score score: 0.9651302436146165
Generation:   4%|         | 1/25 [10:01<4:00:38, 601.62s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554754331c0> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475435f30> 

Generation:  2
Best f1_score score: 0.9691948724035637
Generation:   8%|         | 2/25 [20:04<3:50:53, 602.34s/it]Generation:  3
Best f1_score score: 0.9691948724035637
Generation:  12%|        | 3/25 [21:06<2:10:22, 355.57s/it]Generation:  4
Best f1_score score: 0.9691948724035637
Generation:  16%|        | 4/25 [21:49<1:21:19, 232.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bb5cc0> 

Generation:  5
Best f1_score score: 0.9698135288321021
Generation:  20%|        | 5/25 [31:53<2:02:03, 366.19s/it]Generation:  6
Best f1_score score: 0.9703109542696703
Generation:  24%|       | 6/25 [32:02<1:17:33, 244.93s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bd4cd0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155475bb6050> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  7
Best f1_score score: 0.9703109542696703
Generation:  28%|       | 7/25 [32:22<51:23, 171.33s/it]  Generation:  8
Best f1_score score: 0.9703109542696703
Generation:  32%|      | 8/25 [32:35<34:12, 120.75s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474ee5960> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  9
Best f1_score score: 0.9703109542696703
Generation:  36%|      | 9/25 [36:51<43:30, 163.15s/it]Generation:  10
Best f1_score score: 0.9703109542696703
Generation:  40%|      | 10/25 [37:05<29:16, 117.08s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554581f26b0> 

Generation:  11
Best f1_score score: 0.9710540223019603
Generation:  44%|     | 11/25 [47:09<1:02:05, 266.09s/it]Generation:  12
Best f1_score score: 0.9710540223019603
Generation:  48%|     | 12/25 [49:04<47:42, 220.18s/it]  Generation:  13
Best f1_score score: 0.9710540223019603
Generation:  52%|    | 13/25 [49:30<32:14, 161.19s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474b23d90> 

Generation:  14
Best f1_score score: 0.9710540223019603
Generation:  56%|    | 14/25 [59:33<54:02, 294.76s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747710c0> 
 Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py", line 377, in fit
    estimator._compute_missing_values_in_feature_mask(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/tree/_classes.py", line 214, in _compute_missing_values_in_feature_mask
    assert_all_finite(X, **common_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Generation:  15
Best f1_score score: 0.9718661398176854
Generation:  60%|    | 15/25 [59:43<34:48, 208.84s/it]Generation:  16
Best f1_score score: 0.9718661398176854
Generation:  64%|   | 16/25 [59:55<22:27, 149.74s/it]Generation:  17
Best f1_score score: 0.9718661398176854
Generation:  68%|   | 17/25 [1:00:40<15:44, 118.10s/it]Generation:  18
Best f1_score score: 0.971869661269803
Generation:  72%|  | 18/25 [1:09:44<28:42, 246.08s/it]Generation:  19
Best f1_score score: 0.971869661269803
Generation:  76%|  | 19/25 [1:09:56<17:35, 175.87s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474e96980> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474785b10> 

Generation:  20
Best f1_score score: 0.971869661269803
Generation:  80%|  | 20/25 [1:20:01<25:23, 304.69s/it]Generation:  21
Best f1_score score: 0.971869661269803
Generation:  84%| | 21/25 [1:20:12<14:26, 216.70s/it]Generation:  22
Best f1_score score: 0.971869661269803
Generation:  88%| | 22/25 [1:20:36<07:55, 158.58s/it]Generation:  23
Best f1_score score: 0.971869661269803
Generation:  92%|| 23/25 [1:21:15<04:05, 122.86s/it]Generation:  24
Best f1_score score: 0.971869661269803
Generation:  96%|| 24/25 [1:23:26<02:05, 125.29s/it]Generation:  25
Best f1_score score: 0.971869661269803
Generation: 100%|| 25/25 [1:23:56<00:00, 96.58s/it] Generation: 100%|| 25/25 [1:23:56<00:00, 201.44s/it]
2024-08-13 18:17:44,930 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:43631' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-e42da39257c6683d2a394d63baa7b3c0', 'ndarray-23f0eef1ec7034d09b67651117ebaf48'} (stimulus_id='handle-worker-cleanup-1723598264.930563')
Fitted
Pipeline(steps=[('knnimputer', KNNImputer(n_neighbors=13)),
                ('lgbmclassifier',
                 LGBMClassifier(boosting_type='dart', max_depth=6,
                                n_estimators=77, n_jobs=1, num_leaves=234,
                                verbose=-1))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9999341075057668, 'accuracy': 0.9969543147208122, 'balanced_accuracy': 0.9905794572065162, 'logloss': 0.018112980126215598, 'f1': 0.9969776578288433}
test score: {'auroc': 0.9972761791004391, 'accuracy': 0.9744525547445255, 'balanced_accuracy': 0.8092756836659275, 'logloss': 0.07423920779670426, 'f1': 0.9737949015992851}
original test score: {'auroc': 0.9981935364808935, 'accuracy': 0.9744525547445255, 'balanced_accuracy': 0.8149297856614931, 'logloss': 0.0644346256760702, 'f1': 0.9739731116447116}
score end
30
lvl
0.01
type
MCAR
num_run
1
class_full
finished
all finished
full run takes
17.13962404065662
hours
DONE
