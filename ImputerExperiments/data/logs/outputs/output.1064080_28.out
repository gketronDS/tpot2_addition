Run: 28
/cm/local/apps/slurm/var/spool/job1064080/slurm_script: line 27: 
pip install -e tpot2
pip install -r tpot2/ImputerExperiments/requirements_.txt
: No such file or directory
RunStart
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
starting loops
../data/c/40685/40685.pkl
working on 
../data/c/40685/class_full_MCAR_0.5_2
3.643522024154663
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2024-11-19 08:08:09,521] A new study created in memory with name: no-name-a7ea9b45-01ee-4075-a3e2-ee81cda0bbed
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
running
[I 2024-11-19 08:08:10,166] Trial 12 finished with value: 0.19254101149483263 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 12 with value: 0.19254101149483263.
running
[I 2024-11-19 08:08:10,816] Trial 0 finished with value: 0.2444507842268596 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.19254101149483263.
[I 2024-11-19 08:08:11,257] Trial 11 finished with value: 0.2444507842268596 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'median'}. Best is trial 12 with value: 0.19254101149483263.
running
running
[I 2024-11-19 08:08:11,690] Trial 3 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 12 with value: 0.19254101149483263.
running
[I 2024-11-19 08:08:21,844] Trial 15 finished with value: 0.18538695076401684 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 2, 'learning_rate': 0.08522859321753776, 'p_miss': 0.2671983644134224}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:08:28,053] Trial 20 finished with value: 0.34927956148027517 and parameters: {'model_name': 'GAIN', 'batch_size': 163, 'hint_rate': 0.9370943369434526, 'alpha': 33, 'iterations': 4, 'learning_rate': 0.020386527684253343, 'p_miss': 0.19823915157211036}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:08:47,034] Trial 9 finished with value: 0.37264041051725927 and parameters: {'model_name': 'GAIN', 'batch_size': 59, 'hint_rate': 0.412236569537427, 'alpha': 28, 'iterations': 47, 'learning_rate': 0.00011709746514212705, 'p_miss': 0.03409362894577361}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:20,443] Trial 18 finished with value: 0.19247294913937396 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'mean', 'n_nearest_features': 2, 'imputation_order': 'roman', 'sample_posterior': False}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:20,865] Trial 8 finished with value: 0.19253878397449387 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 31802, 'weights': 'uniform'}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:21,986] Trial 10 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7628018341179718, 'alpha': 94, 'iterations': 618, 'learning_rate': 0.05273128927079659, 'p_miss': 0.03483310680637023}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:22,586] Trial 13 finished with value: 0.19254736135552059 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 28944, 'weights': 'uniform'}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:23,164] Trial 2 finished with value: 0.19253866111122436 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 33713, 'weights': 'uniform'}. Best is trial 15 with value: 0.18538695076401684.
running
[I 2024-11-19 08:09:25,677] Trial 25 finished with value: 0.11465234775134989 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.0013103069881546165, 'p_miss': 0.2873350044159647}. Best is trial 25 with value: 0.11465234775134989.
running
[I 2024-11-19 08:09:26,037] Trial 24 finished with value: 0.34202309331275105 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.7474174015713817, 'alpha': 2, 'iterations': 1, 'learning_rate': 0.00036444546142317275, 'p_miss': 0.22582682961430037}. Best is trial 25 with value: 0.11465234775134989.
running
[I 2024-11-19 08:09:26,804] Trial 26 finished with value: 0.11561999271069671 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 1, 'learning_rate': 0.0016597720735947198, 'p_miss': 0.29816048994231636}. Best is trial 25 with value: 0.11465234775134989.
running
[I 2024-11-19 08:09:28,767] Trial 27 finished with value: 0.11368368431936555 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 2, 'learning_rate': 0.001603276590838078, 'p_miss': 0.29230775772174944}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:29,740] Trial 28 finished with value: 0.11526262618631736 and parameters: {'model_name': 'VAE', 'batch_size': 3, 'iterations': 1, 'learning_rate': 0.000992220955590149, 'p_miss': 0.28144793516889727}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:31,117] Trial 29 finished with value: 0.11504427750275488 and parameters: {'model_name': 'VAE', 'batch_size': 10, 'iterations': 1, 'learning_rate': 0.002424018275510259, 'p_miss': 0.29797108578500503}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:35,697] Trial 17 finished with value: 0.20819761732815176 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'most_frequent', 'n_nearest_features': 6, 'imputation_order': 'descending'}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:41,905] Trial 31 finished with value: 0.11720079961760543 and parameters: {'model_name': 'VAE', 'batch_size': 8, 'iterations': 13, 'learning_rate': 0.0030740374066372178, 'p_miss': 0.12087471783414014}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:49,816] Trial 30 finished with value: 0.11649718055561568 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 21, 'learning_rate': 0.0017194988248832397, 'p_miss': 0.29758652598844926}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:50,368] Trial 34 finished with value: 0.11795260734107241 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 18, 'learning_rate': 0.005974027195534656, 'p_miss': 0.11430384400790392}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:51,626] Trial 33 finished with value: 0.15980662730044215 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 24, 'learning_rate': 0.010708161513514971, 'p_miss': 0.12700967775873306}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:53,413] Trial 32 finished with value: 0.1843120613598979 and parameters: {'model_name': 'VAE', 'batch_size': 17, 'iterations': 26, 'learning_rate': 0.005591775675967722, 'p_miss': 0.163429929649129}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:09:56,355] Trial 22 finished with value: 0.2702701827040214 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Bayesian', 'initial_strategy': 'most_frequent', 'n_nearest_features': 1, 'imputation_order': 'descending', 'sample_posterior': True}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:00,021] Trial 36 finished with value: 0.11458098540012482 and parameters: {'model_name': 'VAE', 'batch_size': 16, 'iterations': 6, 'learning_rate': 0.00736993285198082, 'p_miss': 0.23187702197113425}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:05,850] Trial 23 finished with value: 0.19254101149483263 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 41796, 'weights': 'uniform'}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:17,386] Trial 4 finished with value: inf and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5213737570939629, 'alpha': 93, 'iterations': 1098, 'learning_rate': 0.0031383356020254437, 'p_miss': 0.03789466804425996}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:23,144] Trial 41 finished with value: 0.11608170043309615 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 6, 'learning_rate': 0.0005918114091742162, 'p_miss': 0.2432256722568818}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:27,755] Trial 42 finished with value: 0.11410893740472013 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 6, 'learning_rate': 0.000678453643851046, 'p_miss': 0.23441299777181882}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:10:32,779] Trial 43 finished with value: 0.11578333284489291 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 5, 'learning_rate': 0.0005805079400575586, 'p_miss': 0.2408453730287639}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:14:19,801] Trial 19 finished with value: 0.22774108070560528 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 190, 'learning_rate': 0.00546153091733008, 'p_miss': 0.2971397389170654}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:14:42,574] Trial 47 finished with value: 0.1158622536384123 and parameters: {'model_name': 'VAE', 'batch_size': 710, 'iterations': 4, 'learning_rate': 0.0002761898157243772, 'p_miss': 0.20489488243919876}. Best is trial 27 with value: 0.11368368431936555.
running
[I 2024-11-19 08:14:53,032] Trial 48 finished with value: 0.11007012191230947 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 2, 'learning_rate': 0.0010804590141635707, 'p_miss': 0.25822679168427803}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:15:22,168] Trial 49 finished with value: 0.1126442040121921 and parameters: {'model_name': 'VAE', 'batch_size': 131, 'iterations': 8, 'learning_rate': 0.0007673064070802318, 'p_miss': 0.2539798041768711}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:15:23,039] Trial 50 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:21:39,452] Trial 39 finished with value: 0.17060893713512257 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 266, 'learning_rate': 0.0005952720129286672, 'p_miss': 0.24025958684559526}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:21:45,418] Trial 51 finished with value: 0.15786594074152444 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 121, 'learning_rate': 0.0007833412488206673, 'p_miss': 0.26238877109481}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:17,647] Trial 46 finished with value: 0.1261968669253432 and parameters: {'model_name': 'VAE', 'batch_size': 454, 'iterations': 186, 'learning_rate': 0.00024775948355019664, 'p_miss': 0.202940948865363}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:18,681] Trial 52 finished with value: 0.21782281724479047 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 1662, 'weights': 'distance'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:29,935] Trial 53 finished with value: 0.21684435342379887 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 6442, 'weights': 'distance'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:50,700] Trial 40 finished with value: 0.17057664957933777 and parameters: {'model_name': 'VAE', 'batch_size': 7, 'iterations': 295, 'learning_rate': 0.0005796193174351324, 'p_miss': 0.251153303639266}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:52,130] Trial 57 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:22:56,333] Trial 54 finished with value: 0.2174150259790605 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 2901, 'weights': 'distance'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:23:00,002] Trial 56 finished with value: 0.11533367300200584 and parameters: {'model_name': 'VAE', 'batch_size': 23, 'iterations': 10, 'learning_rate': 0.0014035100140237678, 'p_miss': 0.25928815599193544}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:01,700] Trial 45 finished with value: 0.1600345486802855 and parameters: {'model_name': 'VAE', 'batch_size': 931, 'iterations': 271, 'learning_rate': 0.0003652722284974067, 'p_miss': 0.2126609025292961}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:07,887] Trial 38 finished with value: 0.1810247622548306 and parameters: {'model_name': 'VAE', 'batch_size': 12, 'iterations': 363, 'learning_rate': 0.00037245456942813543, 'p_miss': 0.23601598625753292}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:13,378] Trial 61 finished with value: 0.1924352040715 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'ascending'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:19,240] Trial 62 finished with value: 0.19243520388328567 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'median', 'n_nearest_features': 9, 'imputation_order': 'arabic'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:28,437] Trial 64 finished with value: 0.3511168733652152 and parameters: {'model_name': 'GAIN', 'batch_size': 112, 'hint_rate': 0.012134699513806024, 'alpha': 65, 'iterations': 2, 'learning_rate': 0.0024367835770052132, 'p_miss': 0.17289506371439825}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:28:29,287] Trial 65 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:45:00,246] Trial 1 finished with value: 0.19394395877682355 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 2, 'imputation_order': 'arabic'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:52:10,882] Trial 21 finished with value: 0.3539283293653446 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.43603751019979775, 'alpha': 80, 'iterations': 2146, 'learning_rate': 0.0001591526310649699, 'p_miss': 0.19735412183848522}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:52:19,629] Trial 68 finished with value: 0.11303391274668732 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 2, 'learning_rate': 0.0011320951933315195, 'p_miss': 0.27383383714200094}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:52:27,875] Trial 69 finished with value: 0.1349813979264552 and parameters: {'model_name': 'VAE', 'batch_size': 37, 'iterations': 2, 'learning_rate': 0.0009196675568566547, 'p_miss': 0.2742925932668078}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:52:42,076] Trial 70 finished with value: 0.11411053990765396 and parameters: {'model_name': 'VAE', 'batch_size': 94, 'iterations': 3, 'learning_rate': 0.001035676896444406, 'p_miss': 0.27134446166657067}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:52:52,887] Trial 71 finished with value: 0.11358794189650749 and parameters: {'model_name': 'VAE', 'batch_size': 79, 'iterations': 3, 'learning_rate': 0.0011060647154645365, 'p_miss': 0.2726798484701991}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:53:03,218] Trial 72 finished with value: 0.11541967642136604 and parameters: {'model_name': 'VAE', 'batch_size': 80, 'iterations': 2, 'learning_rate': 0.0015504181253807362, 'p_miss': 0.2576784940496914}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:56:24,526] Trial 73 finished with value: 0.192350520471604 and parameters: {'model_name': 'VAE', 'batch_size': 250, 'iterations': 56, 'learning_rate': 0.0024166487627748953, 'p_miss': 0.2781155779165351}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:56:57,976] Trial 74 finished with value: 0.1133274037833637 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 10, 'learning_rate': 0.0007995851542929027, 'p_miss': 0.0659391569603297}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:57:23,592] Trial 75 finished with value: 0.11635894974305427 and parameters: {'model_name': 'VAE', 'batch_size': 4, 'iterations': 9, 'learning_rate': 0.0011485112526471706, 'p_miss': 0.012823972095235232}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:57:34,537] Trial 76 finished with value: 0.11597737208844952 and parameters: {'model_name': 'VAE', 'batch_size': 32, 'iterations': 3, 'learning_rate': 0.0007310445381345799, 'p_miss': 0.08645744700928701}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 08:58:00,781] Trial 77 finished with value: 0.11557972307782753 and parameters: {'model_name': 'VAE', 'batch_size': 70, 'iterations': 8, 'learning_rate': 0.00045723622671251223, 'p_miss': 0.056908218367327415}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:07:12,958] Trial 14 finished with value: 0.3517385511015391 and parameters: {'model_name': 'GAIN', 'batch_size': 498, 'hint_rate': 0.4120954386702235, 'alpha': 71, 'iterations': 2491, 'learning_rate': 0.03147049060138924, 'p_miss': 0.2565461451391274}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:07:24,568] Trial 79 finished with value: 0.11230705186117648 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 3, 'learning_rate': 0.0008220998973205305, 'p_miss': 0.21798980123052789}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:07:37,317] Trial 80 finished with value: 0.11233254311705139 and parameters: {'model_name': 'VAE', 'batch_size': 162, 'iterations': 3, 'learning_rate': 0.002002021300749203, 'p_miss': 0.18437969095656062}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:07:49,558] Trial 81 finished with value: 0.11559149287398349 and parameters: {'model_name': 'VAE', 'batch_size': 133, 'iterations': 3, 'learning_rate': 0.002013958836966346, 'p_miss': 0.18174697897865577}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:08:06,524] Trial 82 finished with value: 0.11189988497026482 and parameters: {'model_name': 'VAE', 'batch_size': 300, 'iterations': 3, 'learning_rate': 0.003239073842722413, 'p_miss': 0.21545441935098558}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:08:59,539] Trial 83 finished with value: 0.20913840646168894 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'KNN', 'initial_strategy': 'constant', 'n_nearest_features': 5, 'imputation_order': 'random'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:09:59,602] Trial 84 finished with value: 0.3609757608161693 and parameters: {'model_name': 'GAIN', 'batch_size': 311, 'hint_rate': 0.010531035128027277, 'alpha': 4, 'iterations': 41, 'learning_rate': 0.003963273812175323, 'p_miss': 0.21747992218441778}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:10:50,152] Trial 85 finished with value: 0.1310113997114145 and parameters: {'model_name': 'VAE', 'batch_size': 319, 'iterations': 13, 'learning_rate': 0.003984497909545418, 'p_miss': 0.18697200535062636}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:11:02,113] Trial 86 finished with value: 0.11392470356444569 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 3, 'learning_rate': 0.0011734729570028197, 'p_miss': 0.2534874911013908}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:23:54,340] Trial 6 finished with value: 0.20478734340884194 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'mean', 'n_nearest_features': 5, 'imputation_order': 'descending'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:48:05,462] Trial 7 finished with value: 0.20262273829205973 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'most_frequent', 'n_nearest_features': 7, 'imputation_order': 'descending'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:48:24,330] Trial 89 finished with value: 0.11277727671455229 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 4, 'learning_rate': 0.0009271629860749534, 'p_miss': 0.22259144449843}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:48:41,384] Trial 90 finished with value: 0.11471563332904429 and parameters: {'model_name': 'VAE', 'batch_size': 237, 'iterations': 4, 'learning_rate': 0.000853993882742719, 'p_miss': 0.22304548547173417}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 09:48:48,551] Trial 91 finished with value: 0.1135982781511238 and parameters: {'model_name': 'VAE', 'batch_size': 381, 'iterations': 1, 'learning_rate': 0.0014684099267912765, 'p_miss': 0.18470285029383884}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:11:29,829] Trial 55 finished with value: 0.20064916281495498 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'median', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:11:39,470] Trial 93 finished with value: 0.11568143057381511 and parameters: {'model_name': 'VAE', 'batch_size': 171, 'iterations': 2, 'learning_rate': 0.0020385043394117917, 'p_miss': 0.14457485853939622}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:12:01,847] Trial 60 finished with value: 0.20101417072008515 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'RFR', 'initial_strategy': 'constant', 'n_nearest_features': 8, 'imputation_order': 'arabic'}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:12:23,740] Trial 94 finished with value: 0.1123097196400105 and parameters: {'model_name': 'VAE', 'batch_size': 224, 'iterations': 8, 'learning_rate': 0.0032078925936736753, 'p_miss': 0.21467564724994093}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:12:23,927] Trial 95 finished with value: 0.11159988880034552 and parameters: {'model_name': 'VAE', 'batch_size': 107, 'iterations': 5, 'learning_rate': 0.003183602789896055, 'p_miss': 0.21215211268965364}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:12:54,244] Trial 97 finished with value: 0.11382018167204411 and parameters: {'model_name': 'VAE', 'batch_size': 120, 'iterations': 5, 'learning_rate': 0.003655125307683433, 'p_miss': 0.2119460846017454}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:13:05,160] Trial 96 finished with value: 0.11173986246510222 and parameters: {'model_name': 'VAE', 'batch_size': 226, 'iterations': 8, 'learning_rate': 0.002942912220787818, 'p_miss': 0.21111860165738353}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:13:09,135] Trial 98 finished with value: 0.11878052986744543 and parameters: {'model_name': 'VAE', 'batch_size': 209, 'iterations': 2, 'learning_rate': 0.002578471798258045, 'p_miss': 0.1944587404134646}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:34:57,247] Trial 5 finished with value: 0.375299464095724 and parameters: {'model_name': 'GAIN', 'batch_size': 765, 'hint_rate': 0.37226537069973914, 'alpha': 2, 'iterations': 5879, 'learning_rate': 0.00017859634899884208, 'p_miss': 0.06517564141165905}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:36:40,950] Trial 101 finished with value: 0.20681033406178545 and parameters: {'model_name': 'VAE', 'batch_size': 649, 'iterations': 14, 'learning_rate': 0.009224187401818018, 'p_miss': 0.2257000520152349}. Best is trial 48 with value: 0.11007012191230947.
running
[I 2024-11-19 10:37:20,324] Trial 102 finished with value: 0.10957139192626772 and parameters: {'model_name': 'VAE', 'batch_size': 271, 'iterations': 7, 'learning_rate': 0.0029675354177505003, 'p_miss': 0.20901572552002087}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:37:21,185] Trial 103 finished with value: 0.19254101149483263 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:39:59,003] Trial 104 finished with value: 0.20344777919866797 and parameters: {'model_name': 'VAE', 'batch_size': 292, 'iterations': 35, 'learning_rate': 0.005113911313079209, 'p_miss': 0.1947846005642505}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:40:47,348] Trial 105 finished with value: 0.21636349250312065 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 16138, 'weights': 'distance'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:41:39,767] Trial 106 finished with value: 0.1143234069567591 and parameters: {'model_name': 'VAE', 'batch_size': 499, 'iterations': 8, 'learning_rate': 0.0031886579185067755, 'p_miss': 0.2151944665326212}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:42:13,839] Trial 107 finished with value: 0.11520132834961386 and parameters: {'model_name': 'VAE', 'batch_size': 175, 'iterations': 6, 'learning_rate': 0.002997714308707316, 'p_miss': 0.20618291439241182}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:42:33,094] Trial 108 finished with value: 0.11403844197982642 and parameters: {'model_name': 'VAE', 'batch_size': 110, 'iterations': 4, 'learning_rate': 0.004327204954682487, 'p_miss': 0.22548193076071127}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:43:04,483] Trial 109 finished with value: 0.11321913741654963 and parameters: {'model_name': 'VAE', 'batch_size': 245, 'iterations': 7, 'learning_rate': 0.0019188873007579053, 'p_miss': 0.170874936923886}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:43:31,421] Trial 110 finished with value: 0.11439315211972725 and parameters: {'model_name': 'VAE', 'batch_size': 375, 'iterations': 4, 'learning_rate': 0.0030986212921269053, 'p_miss': 0.2435073413095107}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 10:44:25,903] Trial 111 finished with value: 0.13904197350627906 and parameters: {'model_name': 'VAE', 'batch_size': 200, 'iterations': 14, 'learning_rate': 0.005336365922589307, 'p_miss': 0.23079454148241857}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:04:23,088] Trial 66 finished with value: 0.20039911971802496 and parameters: {'model_name': 'VAE', 'batch_size': 33, 'iterations': 3128, 'learning_rate': 0.001120107050673798, 'p_miss': 0.26939110200816624}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:04:47,553] Trial 113 finished with value: 0.11424810427808678 and parameters: {'model_name': 'VAE', 'batch_size': 149, 'iterations': 5, 'learning_rate': 0.002217833779854295, 'p_miss': 0.20228192648451024}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:05:46,075] Trial 37 finished with value: 0.20006846666931177 and parameters: {'model_name': 'VAE', 'batch_size': 15, 'iterations': 4213, 'learning_rate': 0.00806729863103548, 'p_miss': 0.23596113533403232}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:06:19,139] Trial 115 finished with value: 0.35010537503201533 and parameters: {'model_name': 'GAIN', 'batch_size': 552, 'hint_rate': 0.9469846059246574, 'alpha': 46, 'iterations': 18, 'learning_rate': 0.013959403688765372, 'p_miss': 0.24875189271757853}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:06:28,541] Trial 116 finished with value: 0.11652770917159605 and parameters: {'model_name': 'VAE', 'batch_size': 387, 'iterations': 1, 'learning_rate': 0.001592256019414141, 'p_miss': 0.2159807249902187}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:06:42,443] Trial 117 finished with value: 0.11038896150238289 and parameters: {'model_name': 'VAE', 'batch_size': 93, 'iterations': 3, 'learning_rate': 0.0027601471514908534, 'p_miss': 0.2830246551624449}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:06:53,621] Trial 114 finished with value: 0.200868843926619 and parameters: {'model_name': 'VAE', 'batch_size': 555, 'iterations': 19, 'learning_rate': 0.016700577083943728, 'p_miss': 0.2182041907170186}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:07:00,157] Trial 118 finished with value: 0.1205385704773478 and parameters: {'model_name': 'VAE', 'batch_size': 98, 'iterations': 4, 'learning_rate': 0.002992158116294199, 'p_miss': 0.28475812092198877}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:07:07,050] Trial 119 finished with value: 0.11122450157258054 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 3, 'learning_rate': 0.002787703338460501, 'p_miss': 0.2900371241023215}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:07:25,449] Trial 120 finished with value: 0.2169724895229792 and parameters: {'model_name': 'VAE', 'batch_size': 144, 'iterations': 3, 'learning_rate': 0.04899920609910489, 'p_miss': 0.20924315140301933}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:07:29,212] Trial 121 finished with value: 0.11868208879953582 and parameters: {'model_name': 'VAE', 'batch_size': 139, 'iterations': 3, 'learning_rate': 0.006615436636926415, 'p_miss': 0.29269988834355887}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:07:30,083] Trial 123 finished with value: 0.19254101149483263 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'mean'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:08:03,148] Trial 122 finished with value: 0.1268760302268664 and parameters: {'model_name': 'VAE', 'batch_size': 59, 'iterations': 10, 'learning_rate': 0.006697097427830888, 'p_miss': 0.2898091022196978}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:08:15,801] Trial 124 finished with value: 0.12743605848090575 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 11, 'learning_rate': 0.004602539081415962, 'p_miss': 0.2652947249905904}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:08:51,567] Trial 126 finished with value: 0.11609569706416449 and parameters: {'model_name': 'VAE', 'batch_size': 213, 'iterations': 6, 'learning_rate': 0.002563611261634206, 'p_miss': 0.20092532195941426}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:08:53,213] Trial 125 finished with value: 0.21611176667380483 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 46300, 'weights': 'distance'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:09:17,035] Trial 127 finished with value: 0.11147984437855045 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 5, 'learning_rate': 0.0034731004301840934, 'p_miss': 0.23167728619739442}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:09:18,340] Trial 128 finished with value: 0.1171050827844862 and parameters: {'model_name': 'VAE', 'batch_size': 98, 'iterations': 5, 'learning_rate': 0.0005043751997368583, 'p_miss': 0.19138542828151967}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:09:45,696] Trial 130 finished with value: 0.1121636844584037 and parameters: {'model_name': 'VAE', 'batch_size': 82, 'iterations': 7, 'learning_rate': 0.0035273307639669812, 'p_miss': 0.23282208168382504}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:09:50,856] Trial 129 finished with value: 0.1110172959469882 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 7, 'learning_rate': 0.0035303050788782248, 'p_miss': 0.2335713130901293}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:10:16,169] Trial 63 finished with value: 0.3547498298434372 and parameters: {'model_name': 'GAIN', 'batch_size': 120, 'hint_rate': 0.021449036462828863, 'alpha': 68, 'iterations': 7367, 'learning_rate': 0.012213324018081858, 'p_miss': 0.27244593049296795}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:10:16,333] Trial 131 finished with value: 0.11656034099096872 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 7, 'learning_rate': 0.002706226805618701, 'p_miss': 0.2291264037882742}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:10:46,144] Trial 133 finished with value: 0.11716377712201034 and parameters: {'model_name': 'VAE', 'batch_size': 47, 'iterations': 7, 'learning_rate': 0.003904742947682998, 'p_miss': 0.23214414520420917}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:11:09,478] Trial 135 finished with value: 0.11798297264931468 and parameters: {'model_name': 'VAE', 'batch_size': 73, 'iterations': 5, 'learning_rate': 0.0033417161181131462, 'p_miss': 0.24582064961958153}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:11:21,822] Trial 136 finished with value: 0.11538036152846816 and parameters: {'model_name': 'VAE', 'batch_size': 18, 'iterations': 3, 'learning_rate': 0.00470902573095207, 'p_miss': 0.23887861280735584}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:26:27,481] Trial 35 finished with value: 0.23937408379683953 and parameters: {'model_name': 'VAE', 'batch_size': 1, 'iterations': 4086, 'learning_rate': 0.013447538848971352, 'p_miss': 0.13545753624813128}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:26:54,887] Trial 138 finished with value: 0.11704351674323996 and parameters: {'model_name': 'VAE', 'batch_size': 97, 'iterations': 6, 'learning_rate': 0.0017848220430941018, 'p_miss': 0.21015095721849536}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:49:05,448] Trial 134 finished with value: 0.1963375310181062 and parameters: {'model_name': 'VAE', 'batch_size': 56, 'iterations': 792, 'learning_rate': 0.0037612062706165175, 'p_miss': 0.23888103230440294}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:49:54,482] Trial 140 finished with value: 0.1123045142583042 and parameters: {'model_name': 'VAE', 'batch_size': 166, 'iterations': 12, 'learning_rate': 0.002099970695856501, 'p_miss': 0.22078666072985523}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:50:37,281] Trial 141 finished with value: 0.11805241285696857 and parameters: {'model_name': 'VAE', 'batch_size': 86, 'iterations': 12, 'learning_rate': 0.00355155249627417, 'p_miss': 0.2827526175860313}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:51:27,059] Trial 142 finished with value: 0.1164321496369223 and parameters: {'model_name': 'VAE', 'batch_size': 253, 'iterations': 9, 'learning_rate': 0.002792529538152232, 'p_miss': 0.21792549633438418}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:51:48,382] Trial 143 finished with value: 0.11402469356743468 and parameters: {'model_name': 'VAE', 'batch_size': 109, 'iterations': 4, 'learning_rate': 0.0024612074227999903, 'p_miss': 0.2220172213952162}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:57:19,209] Trial 144 finished with value: 0.19560712705233657 and parameters: {'model_name': 'VAE', 'batch_size': 124, 'iterations': 93, 'learning_rate': 0.0022122899342848536, 'p_miss': 0.2609999115021533}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:58:53,353] Trial 145 finished with value: 0.11631543674667817 and parameters: {'model_name': 'VAE', 'batch_size': 270, 'iterations': 23, 'learning_rate': 0.00130680530380234, 'p_miss': 0.23488892728099367}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 11:59:16,446] Trial 146 finished with value: 0.11685792868238817 and parameters: {'model_name': 'VAE', 'batch_size': 167, 'iterations': 5, 'learning_rate': 0.0018255565501272058, 'p_miss': 0.19901106432041382}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:00:26,004] Trial 147 finished with value: 0.13023357249562845 and parameters: {'model_name': 'VAE', 'batch_size': 165, 'iterations': 16, 'learning_rate': 0.0034208844683768897, 'p_miss': 0.20734750564442375}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:00:57,046] Trial 137 finished with value: 0.19335117428735893 and parameters: {'model_name': 'VAE', 'batch_size': 103, 'iterations': 1153, 'learning_rate': 0.0018708148293048764, 'p_miss': 0.20805725099058983}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:01:22,376] Trial 149 finished with value: 0.11425106500491408 and parameters: {'model_name': 'VAE', 'batch_size': 20, 'iterations': 8, 'learning_rate': 0.0021701808362540697, 'p_miss': 0.1790205030064771}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:01:34,887] Trial 150 finished with value: 0.11684253566533136 and parameters: {'model_name': 'VAE', 'batch_size': 13, 'iterations': 3, 'learning_rate': 0.00434541859640585, 'p_miss': 0.22779277989172222}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:01:48,240] Trial 139 finished with value: 0.19953127243205412 and parameters: {'model_name': 'VAE', 'batch_size': 276, 'iterations': 658, 'learning_rate': 0.0035266678924562697, 'p_miss': 0.22017980087382288}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:01,069] Trial 151 finished with value: 0.19242176885125342 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'constant', 'n_nearest_features': 4, 'imputation_order': 'roman'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:02,533] Trial 153 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'most_frequent'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:06,535] Trial 148 finished with value: 0.1323933373576789 and parameters: {'model_name': 'VAE', 'batch_size': 332, 'iterations': 30, 'learning_rate': 0.0022034030918351632, 'p_miss': 0.17848424455792716}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:09,925] Trial 154 finished with value: 0.11214533439125354 and parameters: {'model_name': 'VAE', 'batch_size': 219, 'iterations': 2, 'learning_rate': 0.002731658439293686, 'p_miss': 0.19034345141103892}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:14,151] Trial 152 finished with value: 0.19245939947899227 and parameters: {'model_name': 'IterativeImputer', 'estimator': 'Ridge', 'initial_strategy': 'mean', 'n_nearest_features': 4, 'imputation_order': 'random'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:20,689] Trial 156 finished with value: 0.11458207839145129 and parameters: {'model_name': 'VAE', 'batch_size': 220, 'iterations': 2, 'learning_rate': 0.0027245385088161475, 'p_miss': 0.18947717098772585}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:28,041] Trial 157 finished with value: 0.113088243577305 and parameters: {'model_name': 'VAE', 'batch_size': 194, 'iterations': 2, 'learning_rate': 0.0027208613646057225, 'p_miss': 0.15913502958627995}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:49,014] Trial 159 finished with value: 0.11139825472379902 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 4, 'learning_rate': 0.0031388399332800874, 'p_miss': 0.21199119956952445}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:50,318] Trial 155 finished with value: 0.19257562977894183 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 17112, 'weights': 'uniform'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:02:55,169] Trial 158 finished with value: 0.1183880779783463 and parameters: {'model_name': 'VAE', 'batch_size': 129, 'iterations': 7, 'learning_rate': 0.003030348367319258, 'p_miss': 0.16167650719819487}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:16,260] Trial 162 finished with value: 0.11899089463520503 and parameters: {'model_name': 'VAE', 'batch_size': 65, 'iterations': 4, 'learning_rate': 0.005217485167559444, 'p_miss': 0.21409017885452236}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:17,307] Trial 160 finished with value: 0.11691907471192228 and parameters: {'model_name': 'VAE', 'batch_size': 122, 'iterations': 5, 'learning_rate': 0.005983104779793299, 'p_miss': 0.29987649023689744}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:30,124] Trial 163 finished with value: 0.34068200609098864 and parameters: {'model_name': 'GAIN', 'batch_size': 27, 'hint_rate': 0.22334612844632384, 'alpha': 21, 'iterations': 6, 'learning_rate': 0.004051579517198364, 'p_miss': 0.22558630731683993}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:31,391] Trial 164 finished with value: 0.34133108902984144 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.2168225493428847, 'alpha': 23, 'iterations': 6, 'learning_rate': 0.004251616531791346, 'p_miss': 0.2248005633609048}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:36,803] Trial 161 finished with value: 0.13468950617517605 and parameters: {'model_name': 'VAE', 'batch_size': 129, 'iterations': 7, 'learning_rate': 0.005512125525619646, 'p_miss': 0.2119747656051765}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:46,463] Trial 166 finished with value: 0.11199252387065368 and parameters: {'model_name': 'VAE', 'batch_size': 159, 'iterations': 3, 'learning_rate': 0.0033791177197600177, 'p_miss': 0.19913207933442947}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:03:51,460] Trial 167 finished with value: 0.11397256244356482 and parameters: {'model_name': 'VAE', 'batch_size': 179, 'iterations': 3, 'learning_rate': 0.0031695754628229796, 'p_miss': 0.20303444744614826}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:05,586] Trial 165 finished with value: 0.11371959108076887 and parameters: {'model_name': 'VAE', 'batch_size': 81, 'iterations': 9, 'learning_rate': 0.004445255115291039, 'p_miss': 0.20243271965969067}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:06,440] Trial 168 finished with value: 0.11165110382583761 and parameters: {'model_name': 'VAE', 'batch_size': 89, 'iterations': 4, 'learning_rate': 0.003237373403257047, 'p_miss': 0.19518306389560383}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:06,886] Trial 169 finished with value: 0.11480897875611 and parameters: {'model_name': 'VAE', 'batch_size': 83, 'iterations': 4, 'learning_rate': 0.002339803999657268, 'p_miss': 0.19579723372859634}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:18,358] Trial 172 finished with value: 0.1170902463075161 and parameters: {'model_name': 'VAE', 'batch_size': 156, 'iterations': 2, 'learning_rate': 0.0036521600820611953, 'p_miss': 0.2504795612777782}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:19,594] Trial 170 finished with value: 0.11504520859689109 and parameters: {'model_name': 'VAE', 'batch_size': 151, 'iterations': 2, 'learning_rate': 0.0024199345736938722, 'p_miss': 0.1960176842070513}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:30,097] Trial 171 finished with value: 0.11216998091658563 and parameters: {'model_name': 'VAE', 'batch_size': 150, 'iterations': 4, 'learning_rate': 0.002427002004210679, 'p_miss': 0.277655139056038}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:38,839] Trial 174 finished with value: 0.1108558298802628 and parameters: {'model_name': 'VAE', 'batch_size': 91, 'iterations': 4, 'learning_rate': 0.002796141993046553, 'p_miss': 0.2349607405898137}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:44,387] Trial 175 finished with value: 0.11255496829403644 and parameters: {'model_name': 'VAE', 'batch_size': 104, 'iterations': 4, 'learning_rate': 0.0027981528698120665, 'p_miss': 0.26756914199715}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:44,598] Trial 173 finished with value: 0.11008364691711507 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 5, 'learning_rate': 0.002990250130018884, 'p_miss': 0.19703048062474243}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:04:53,489] Trial 176 finished with value: 0.11213262718435561 and parameters: {'model_name': 'VAE', 'batch_size': 71, 'iterations': 4, 'learning_rate': 0.002852336830223726, 'p_miss': 0.28126845111415383}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:08,416] Trial 178 finished with value: 0.11044934483441923 and parameters: {'model_name': 'VAE', 'batch_size': 69, 'iterations': 4, 'learning_rate': 0.0032584103888499893, 'p_miss': 0.2787601492125901}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:08,617] Trial 177 finished with value: 0.11587250636469715 and parameters: {'model_name': 'VAE', 'batch_size': 96, 'iterations': 5, 'learning_rate': 0.0032223682718094896, 'p_miss': 0.2780032731703179}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:14,915] Trial 179 finished with value: 0.11241172501362533 and parameters: {'model_name': 'VAE', 'batch_size': 50, 'iterations': 5, 'learning_rate': 0.003241752483510522, 'p_miss': 0.28906463124876103}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:21,526] Trial 181 finished with value: 0.11206927375006422 and parameters: {'model_name': 'VAE', 'batch_size': 42, 'iterations': 3, 'learning_rate': 0.004769399664871522, 'p_miss': 0.29343951300422}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:29,292] Trial 180 finished with value: 0.11332191464987948 and parameters: {'model_name': 'VAE', 'batch_size': 46, 'iterations': 5, 'learning_rate': 0.0030065313490740793, 'p_miss': 0.29192588992402185}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:31,607] Trial 182 finished with value: 0.1109566504431001 and parameters: {'model_name': 'VAE', 'batch_size': 40, 'iterations': 3, 'learning_rate': 0.00467663316357233, 'p_miss': 0.2811585790840629}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:35,905] Trial 183 finished with value: 0.11135256460250913 and parameters: {'model_name': 'VAE', 'batch_size': 66, 'iterations': 3, 'learning_rate': 0.004699491980965584, 'p_miss': 0.29230508375847597}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:42,520] Trial 184 finished with value: 0.11164822121729205 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 3, 'learning_rate': 0.0047262176029460295, 'p_miss': 0.2862279663286615}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:45,359] Trial 185 finished with value: 0.1145764892382682 and parameters: {'model_name': 'VAE', 'batch_size': 38, 'iterations': 3, 'learning_rate': 0.0077440550737009175, 'p_miss': 0.28611122528345406}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:55,941] Trial 186 finished with value: 0.1218261047779754 and parameters: {'model_name': 'VAE', 'batch_size': 39, 'iterations': 3, 'learning_rate': 0.008365789129799437, 'p_miss': 0.284720481205152}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:57,488] Trial 187 finished with value: 0.11545648775682564 and parameters: {'model_name': 'VAE', 'batch_size': 62, 'iterations': 3, 'learning_rate': 0.006168124481340849, 'p_miss': 0.28698887069611345}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:05:58,547] Trial 188 finished with value: 0.111990633134136 and parameters: {'model_name': 'VAE', 'batch_size': 61, 'iterations': 3, 'learning_rate': 0.004042619787339316, 'p_miss': 0.29615873828773187}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:06:15,408] Trial 191 finished with value: 0.11188355969786615 and parameters: {'model_name': 'VAE', 'batch_size': 54, 'iterations': 4, 'learning_rate': 0.003966211494378233, 'p_miss': 0.29891853932486595}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:06:15,734] Trial 190 finished with value: 0.11363634949997278 and parameters: {'model_name': 'VAE', 'batch_size': 55, 'iterations': 4, 'learning_rate': 0.003957571588141874, 'p_miss': 0.2744442013133752}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:06:16,116] Trial 192 finished with value: 0.3777575351548193 and parameters: {'model_name': 'SimpleImputer', 'strategy': 'constant'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:06:18,349] Trial 189 finished with value: 0.11362540282192612 and parameters: {'model_name': 'VAE', 'batch_size': 64, 'iterations': 4, 'learning_rate': 0.006576400849009135, 'p_miss': 0.29518444939339183}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:06:37,632] Trial 195 finished with value: 0.11758906964431078 and parameters: {'model_name': 'VAE', 'batch_size': 74, 'iterations': 5, 'learning_rate': 0.00012555671129746928, 'p_miss': 0.28004716844932126}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:07:03,254] Trial 196 finished with value: 0.11501224157485543 and parameters: {'model_name': 'VAE', 'batch_size': 53, 'iterations': 6, 'learning_rate': 0.004926546981403419, 'p_miss': 0.29639998022214237}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:07:05,774] Trial 194 finished with value: 0.2164260807679222 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13958, 'weights': 'distance'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:07:06,012] Trial 193 finished with value: 0.21644589099105996 and parameters: {'model_name': 'KNNImputer', 'n_neighbors': 13381, 'weights': 'distance'}. Best is trial 102 with value: 0.10957139192626772.
running
[I 2024-11-19 12:07:19,331] Trial 197 finished with value: 0.11513144745491947 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 4, 'learning_rate': 0.004099198777126425, 'p_miss': 0.29950385289683223}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 12:07:21,019] Trial 199 finished with value: 0.11373274299549632 and parameters: {'model_name': 'VAE', 'batch_size': 90, 'iterations': 4, 'learning_rate': 0.004265673746379892, 'p_miss': 0.29007795434557293}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 12:07:23,374] Trial 198 finished with value: 0.11402363554085193 and parameters: {'model_name': 'VAE', 'batch_size': 88, 'iterations': 4, 'learning_rate': 0.0040089087343912365, 'p_miss': 0.2885439458679482}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 12:29:46,807] Trial 67 finished with value: 0.20082585616319326 and parameters: {'model_name': 'VAE', 'batch_size': 27, 'iterations': 4531, 'learning_rate': 0.001119727399201409, 'p_miss': 0.2725562372441399}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 12:49:13,540] Trial 112 finished with value: 0.20013764918579158 and parameters: {'model_name': 'VAE', 'batch_size': 138, 'iterations': 2903, 'learning_rate': 0.007214253122465448, 'p_miss': 0.21958357789844418}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 12:50:59,449] Trial 78 finished with value: 0.19748934840379076 and parameters: {'model_name': 'VAE', 'batch_size': 132, 'iterations': 5282, 'learning_rate': 0.0018933345475376122, 'p_miss': 0.2827521985295261}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:25:13,657] Trial 16 finished with value: 0.21261926134373182 and parameters: {'model_name': 'VAE', 'batch_size': 2, 'iterations': 6447, 'learning_rate': 0.009818444182505328, 'p_miss': 0.10669948697460964}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:30:44,677] Trial 59 finished with value: 0.20026883226819053 and parameters: {'model_name': 'VAE', 'batch_size': 31, 'iterations': 7433, 'learning_rate': 0.0010982595024950311, 'p_miss': 0.22425419045386233}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:36:27,356] Trial 58 finished with value: 0.19768453677501346 and parameters: {'model_name': 'VAE', 'batch_size': 111, 'iterations': 8252, 'learning_rate': 0.0012536309311365192, 'p_miss': 0.22199879268003186}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:38:17,881] Trial 99 finished with value: 0.19774431181966978 and parameters: {'model_name': 'VAE', 'batch_size': 210, 'iterations': 4953, 'learning_rate': 0.0028227227709107685, 'p_miss': 0.22419560786017145}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:48:00,244] Trial 92 finished with value: 0.19735098268121587 and parameters: {'model_name': 'VAE', 'batch_size': 182, 'iterations': 6703, 'learning_rate': 0.0020633836607823115, 'p_miss': 0.14451346724322056}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:55:08,004] Trial 88 finished with value: 0.19816482322180456 and parameters: {'model_name': 'VAE', 'batch_size': 215, 'iterations': 7380, 'learning_rate': 0.0008855608769193475, 'p_miss': 0.14625568216536927}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:57:31,250] Trial 44 finished with value: 0.20166094924436512 and parameters: {'model_name': 'VAE', 'batch_size': 644, 'iterations': 8101, 'learning_rate': 0.00027272011903505406, 'p_miss': 0.24644821796263075}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 13:59:50,392] Trial 87 finished with value: 0.1981652459645664 and parameters: {'model_name': 'VAE', 'batch_size': 211, 'iterations': 9054, 'learning_rate': 0.0009506624189890839, 'p_miss': 0.22519959734861916}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 14:00:34,863] Trial 100 finished with value: 0.20027376098124944 and parameters: {'model_name': 'VAE', 'batch_size': 282, 'iterations': 8206, 'learning_rate': 0.003194332432807156, 'p_miss': 0.22370412683603885}. Best is trial 102 with value: 0.10957139192626772.
[I 2024-11-19 14:03:19,852] Trial 132 finished with value: 0.19473075831750528 and parameters: {'model_name': 'VAE', 'batch_size': 49, 'iterations': 9939, 'learning_rate': 0.0034851819151998083, 'p_miss': 0.23132116123627938}. Best is trial 102 with value: 0.10957139192626772.
fit
auto fit
auto transform
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0    0
1    0
2    0
3    0
4    0
5    0
6    0
7    0
8    0
dtype: int64
0.10957139192626772
{'model_name': 'VAE', 'batch_size': 271, 'iterations': 7, 'learning_rate': 0.0029675354177505003, 'p_miss': 0.20901572552002087}
running experiment 2/3 - Does reconstruction give good automl predictions
Start est fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0e80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0c70> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746faa10> 

Generation:  1
Best f1_score score: 0.13775085793367545
Generation:   4%|         | 1/25 [10:03<4:01:17, 603.23s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746f9d80> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  2
Best f1_score score: 0.13775085793367545
Generation:   8%|         | 2/25 [16:26<3:01:37, 473.82s/it]Generation:  3
Best f1_score score: 0.1378437972267247
Generation:  12%|        | 3/25 [20:24<2:14:10, 365.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554747361d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2170> 

Generation:  4
Best f1_score score: 0.14020234578763233
Generation:  16%|        | 4/25 [30:29<2:41:08, 460.40s/it]Generation:  5
Best f1_score score: 0.1414219288318502
Generation:  20%|        | 5/25 [40:12<2:48:10, 504.55s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471b580> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554679172b0> 

Generation:  6
Best f1_score score: 0.1414219288318502
Generation:  24%|       | 6/25 [50:17<2:50:39, 538.94s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467edf760> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  7
Best f1_score score: 0.1459825397036839
Generation:  28%|       | 7/25 [57:03<2:28:36, 495.38s/it]Generation:  8
Best f1_score score: 0.1459825397036839
Generation:  32%|      | 8/25 [1:04:46<2:17:27, 485.18s/it]Generation:  9
Best f1_score score: 0.1459825397036839
Generation:  36%|      | 9/25 [1:12:11<2:05:59, 472.44s/it]Generation:  10
Best f1_score score: 0.1459825397036839
Generation:  40%|      | 10/25 [1:20:55<2:02:06, 488.40s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467855d80> 

Generation:  11
Best f1_score score: 0.1459825397036839
Generation:  44%|     | 11/25 [1:31:03<2:02:30, 525.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554676b9300> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467a247c0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546772b5e0> 

Generation:  12
Best f1_score score: 0.1459825397036839
Generation:  48%|     | 12/25 [1:41:12<1:59:16, 550.51s/it]Generation:  13
Best f1_score score: 0.1459825397036839
Generation:  52%|    | 13/25 [1:48:03<1:41:41, 508.43s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ff0d0> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  14
Best f1_score score: 0.1459825397036839
Generation:  56%|    | 14/25 [1:52:12<1:18:49, 429.91s/it]Generation:  15
Best f1_score score: 0.1459825397036839
Generation:  60%|    | 15/25 [2:01:07<1:16:56, 461.68s/it]Generation:  16
Best f1_score score: 0.1459825397036839
Generation:  64%|   | 16/25 [2:07:25<1:05:28, 436.50s/it]Generation:  17
Best f1_score score: 0.1459825397036839
Generation:  68%|   | 17/25 [2:07:58<41:59, 314.99s/it]  WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fa110> 
 The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead. 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1466, in wrapper
    estimator._validate_params()
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 666, in _validate_params
    validate_parameter_constraints(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 95, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.

Generation:  18
Best f1_score score: 0.1459825397036839
Generation:  72%|  | 18/25 [2:12:26<35:06, 300.88s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c28df0> 

Generation:  19
Best f1_score score: 0.1459825397036839
Generation:  76%|  | 19/25 [2:22:37<39:24, 394.05s/it]Generation:  20
Best f1_score score: 0.1459825397036839
Generation:  80%|  | 20/25 [2:29:08<32:46, 393.29s/it]Generation:  21
Best f1_score score: 0.1459825397036839
Generation:  84%| | 21/25 [2:35:09<25:34, 383.60s/it]Generation:  22
Best f1_score score: 0.1459825397036839
Generation:  88%| | 22/25 [2:39:22<17:13, 344.44s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467cafe50> 

Generation:  23
Best f1_score score: 0.1459825397036839
Generation:  92%|| 23/25 [2:49:35<14:09, 424.99s/it]Generation:  24
Best f1_score score: 0.1459825397036839
Generation:  96%|| 24/25 [2:51:05<05:24, 324.50s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467229390> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464515330> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

Generation:  25
Best f1_score score: 0.1459825397036839
Generation: 100%|| 25/25 [2:54:27<00:00, 287.63s/it]Generation: 100%|| 25/25 [2:54:30<00:00, 418.83s/it]
2024-11-19 16:58:04,032 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44665' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-08e2b28cd26b443d1296bc2cda8a08c0', 'ndarray-3e87d5d222d5024533867dd138a81e31'} (stimulus_id='handle-worker-cleanup-1732064284.0327978')
Fitted
Pipeline(steps=[('kneighborsclassifier',
                 KNeighborsClassifier(n_jobs=1, n_neighbors=1,
                                      weights='distance'))])
score start
train score: {'auroc': 1.0, 'accuracy': 1.0, 'balanced_accuracy': 1.0, 'logloss': 2.2204460492503136e-16, 'f1': 1.0}
original test score: {'auroc': 0.4633496278494382, 'accuracy': 0.5673275862068966, 'balanced_accuracy': 0.10331338790565918, 'logloss': 15.595094513791292, 'f1': 0.10400231669670869}
imputed test score: {'auroc': 0.5034169937149795, 'accuracy': 0.6438793103448276, 'balanced_accuracy': 0.149513384632288, 'logloss': 12.835890702624392, 'f1': 0.14952379076969663}
score end
check intended
EXP2 Finished
running experiment 3/3 - What is the best automl settings?
<tpot2.search_spaces.pipelines.sequential.SequentialPipeline object at 0x155435014610>
Start tpot fit
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
Version 0.1.7a0 of tpot2 is outdated. Version 0.1.8a0 was released Tuesday September 17, 2024.
  0%|          | 0/25 [00:00<?, ?it/s]Generation:   0%|          | 0/25 [00:00<?, ?it/s]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1ea0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a1240> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a0f10> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746fca30> 

Generation:  1
Best f1_score score: 0.4943251686584434
Generation:   4%|         | 1/25 [10:03<4:01:18, 603.26s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746ffbe0> 
 Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 938, in fit
    return self._fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 725, in _fit
    self._partial_fit(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 596, in _partial_fit
    X, y = self._validate_data(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 650, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1301, in check_X_y
    X = check_array(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1064, in check_array
    _assert_all_finite(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SGDClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f2b0a0> 

Generation:  2
Best f1_score score: 0.4943251686584434
Generation:   8%|         | 2/25 [20:07<3:51:27, 603.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f57130> 

Generation:  3
Best f1_score score: 0.5204304977098361
Generation:  12%|        | 3/25 [30:11<3:41:28, 604.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466c1ec50> 

Generation:  4
Best f1_score score: 0.5563336090373369
Generation:  16%|        | 4/25 [40:17<3:31:35, 604.53s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a2530> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554651e2620> 

Generation:  5
Best f1_score score: 0.5577144895618211
Generation:  20%|        | 5/25 [50:22<3:21:39, 604.98s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467eb3940> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459817ca0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467e22dd0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155407c83670> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f079d0> 

Generation:  6
Best f1_score score: 0.5577144895618211
Generation:  24%|       | 6/25 [1:00:30<3:11:50, 605.79s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554666e1d80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464b148e0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c742b0> 

Generation:  7
Best f1_score score: 0.5577799799208787
Generation:  28%|       | 7/25 [1:10:36<3:01:49, 606.11s/it]Generation:  8
Best f1_score score: 0.5625765733959834
Generation:  32%|      | 8/25 [1:13:09<2:10:51, 461.83s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554671d3820> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f30250> 

Generation:  9
Best f1_score score: 0.5742940949848285
Generation:  36%|      | 9/25 [1:23:16<2:15:12, 507.03s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15535086eaa0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546519be20> 

Generation:  10
Best f1_score score: 0.5742940949848285
Generation:  40%|      | 10/25 [1:33:21<2:14:20, 537.40s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a22f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b0fbb20> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c451e0> 

Generation:  11
Best f1_score score: 0.5900081235430842
Generation:  44%|     | 11/25 [1:43:28<2:10:20, 558.62s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546722dba0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546759e1d0> 

Generation:  12
Best f1_score score: 0.5901463996546668
Generation:  48%|     | 12/25 [1:53:35<2:04:13, 573.34s/it]Generation:  13
Best f1_score score: 0.5901463996546668
Generation:  52%|    | 13/25 [1:58:28<1:37:40, 488.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1553d17bc6a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554667d76a0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466139690> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554669063b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464d626e0> 

Generation:  14
Best f1_score score: 0.6026524468670504
Generation:  56%|    | 14/25 [2:08:35<1:36:07, 524.36s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554545c8730> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554669f11b0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155464920850> 

Generation:  15
Best f1_score score: 0.6026524468670504
Generation:  60%|    | 15/25 [2:18:42<1:31:31, 549.16s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155466a1f550> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452637d00> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f10460> 

Generation:  16
Best f1_score score: 0.6026524468670504
Generation:  64%|   | 16/25 [2:28:50<1:25:03, 567.04s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554678dcee0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b17d360> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546708af80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155459783850> 

Generation:  17
Best f1_score score: 0.6026524468670504
Generation:  68%|   | 17/25 [2:38:59<1:17:16, 579.54s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450ea1ba0> 

Generation:  18
Best f1_score score: 0.6101358430564533
Generation:  72%|  | 18/25 [2:49:08<1:08:38, 588.32s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15546451bd00> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467fe7010> 

Generation:  19
Best f1_score score: 0.6101358430564533
Generation:  76%|  | 19/25 [2:59:15<59:23, 593.85s/it]  WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15545b17c970> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155452b115d0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155474708190> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454d484f0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547472acb0> 

Generation:  20
Best f1_score score: 0.6101358430564533
Generation:  80%|  | 20/25 [3:09:23<49:51, 598.37s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467c11600> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454e26c80> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554670d9240> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471abf0> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467f5b340> 

Generation:  21
Best f1_score score: 0.6101358430564533
Generation:  84%| | 21/25 [3:19:32<40:05, 601.45s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155450cd2110> 

Generation:  22
Best f1_score score: 0.6101358430564533
Generation:  88%| | 22/25 [3:29:37<30:07, 602.55s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x15547471b130> 

Generation:  23
Best f1_score score: 0.6101358430564533
Generation:  92%|| 23/25 [3:39:43<20:07, 603.60s/it]WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155454d64c70> 

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x1554746a3a00> 

Generation:  24
Best f1_score score: 0.6101358430564533
Generation:  96%|| 24/25 [3:49:53<10:05, 605.30s/it]WARNING THIS INDIVIDUAL CAUSED AND EXCEPTION 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467d71e40> 
 Negative values in data passed to MultinomialNB (input X) 
 Traceback (most recent call last):
  File "/common/ketrong/tpotexp/tpot2/tpot2/utils/eval_utils.py", line 53, in objective_nan_wrapper
    value = func_timeout.func_timeout(timeout, objective_function, args=[individual], kwargs=objective_kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/dafunc.py", line 108, in func_timeout
    raise_exception(exception)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/func_timeout/py3_raise.py", line 7, in raise_exception
    raise exception[0] from None
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator.py", line 623, in objective_function
    return objective_function_generator(
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/estimator_utils.py", line 55, in objective_function_generator
    cv_obj_scores = cross_val_score_objective(sklearn.base.clone(pipeline),x,y,scorers=scorers, cv=cv , fold=step)
  File "/common/ketrong/tpotexp/tpot2/tpot2/tpot_estimator/cross_val_utils.py", line 28, in cross_val_score_objective
    this_fold_pipeline.fit(X_train,y_train)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/pipeline.py", line 473, in fit
    self._final_estimator.fit(Xt, y, **last_step_params["fit"])
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 759, in fit
    self._count(X, Y)
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/naive_bayes.py", line 881, in _count
    check_non_negative(X, "MultinomialNB (input X)")
  File "/common/ketrong/tpotexp/env/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1689, in check_non_negative
    raise ValueError("Negative values in data passed to %s" % whom)
ValueError: Negative values in data passed to MultinomialNB (input X)

WARNING AN INDIVIDUAL TIMED OUT: 
 <tpot2.search_spaces.pipelines.sequential.SequentialPipelineIndividual object at 0x155467ef5150> 

Generation:  25
Best f1_score score: 0.6101358430564533
Generation: 100%|| 25/25 [3:59:59<00:00, 605.76s/it]Generation: 100%|| 25/25 [3:59:59<00:00, 576.00s/it]
2024-11-19 20:59:01,074 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:44111' caused the cluster to lose scattered data, which can't be recovered: {'ndarray-08e2b28cd26b443d1296bc2cda8a08c0', 'DataFrame-8d6ecc1221152d354f24b92dd3c26a61'} (stimulus_id='handle-worker-cleanup-1732078741.0745127')
Fitted
Pipeline(steps=[('iterativeimputer',
                 IterativeImputer(estimator=Ridge(), imputation_order='roman',
                                  n_nearest_features=30)),
                ('randomforestclassifier',
                 RandomForestClassifier(class_weight='balanced',
                                        max_features=0.4745697360149,
                                        min_samples_leaf=5, min_samples_split=5,
                                        n_estimators=128))])
transform worked
try transform
transform worked
score start
train score: {'auroc': 0.9994866515295834, 'accuracy': 0.9768965517241379, 'balanced_accuracy': 0.9923049187442627, 'logloss': 0.0750258839012389, 'f1': 0.9095410145827337}
test score: {'auroc': 0.9668351335997777, 'accuracy': 0.9535344827586207, 'balanced_accuracy': 0.569063748889234, 'logloss': 0.13018911075119424, 'f1': 0.5236658136449199}
original test score: {'auroc': 0.9999120811263645, 'accuracy': 0.9983620689655173, 'balanced_accuracy': 0.7488440444713673, 'logloss': 0.00967254989153186, 'f1': 0.7445949441989284}
score end
40685
lvl
0.5
type
MCAR
num_run
2
class_full
finished
all finished
full run takes
12.853069547613462
hours
DONE
